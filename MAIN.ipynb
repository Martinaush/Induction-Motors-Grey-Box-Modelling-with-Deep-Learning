{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxRdusiZC2Cf"
      },
      "source": [
        "# Libraries and Constants\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kyo--poCPBuV"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# Importing auxiliar .ipynbs\n",
        "# Note: they have the libraries in the scrypts, so there is no need of importing them here\n",
        "\n",
        "# Intructions -------------------------------------------------\n",
        "# Folder with data and util should be in your drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install import_ipynb\n",
        "import import_ipynb\n",
        "import seaborn as sns\n",
        "import random\n",
        "from tensorflow.keras.utils import to_categorical, plot_model\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dense, Dropout\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, GlobalAveragePooling1D, BatchNormalization\n",
        "from tensorflow.keras.utils import to_categorical, plot_model\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras import regularizers\n",
        "# !pip install tensorflow_addons\n",
        "# import tensorflow_addons as tfa\n",
        "\n",
        "\n",
        "# Changing directory in order to open the notebooks\n",
        "os.chdir('/content/drive/MyDrive/Colab Notebooks')\n",
        "import MAFAULDA_Functions\n",
        "\n",
        "# Useful for FFT and Dynamic time warping\n",
        "SAMPLES = 250000  # Hertz (number of cycles per second)\n",
        "DURATION = 5  # Seconds\n",
        "SAMPLE_RATE = 50000\n",
        "seed = 1111\n",
        "\n",
        "# Number of total samples\n",
        "N = int(SAMPLE_RATE * DURATION)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rirl9Ari-r7E"
      },
      "outputs": [],
      "source": [
        "##################################################################\n",
        "# GRAD - CAM (tool to visualize CNN choice)\n",
        "##################################################################\n",
        "\n",
        "def grad_cam(layer_name, data):\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model2_.inputs], [model2_.get_layer(layer_name).output, model2_.output]\n",
        "    )\n",
        "    last_conv_layer_output, preds = grad_model(data)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        last_conv_layer_output, preds = grad_model(data)\n",
        "        pred_index = tf.argmax(preds[0])\n",
        "        class_channel = preds[:, pred_index]\n",
        "\n",
        "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
        "\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0))\n",
        "\n",
        "    last_conv_layer_output = last_conv_layer_output[0]\n",
        "\n",
        "    heatmap = last_conv_layer_output * pooled_grads\n",
        "    heatmap = tf.reduce_mean(heatmap, axis=(1))\n",
        "    heatmap = np.expand_dims(heatmap,0)\n",
        "    return heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4Auk_kEXiYC"
      },
      "outputs": [],
      "source": [
        "###################################################\n",
        "# Average - Spectrum frequencies\n",
        "###################################################\n",
        "\n",
        "def average_spectrum(vector, labels, name, model2_, Binary = True):\n",
        "\n",
        "  input_size = 5000\n",
        "\n",
        "  #########################################################\n",
        "  # Calculating mean of each class spectrum\n",
        "  #########################################################\n",
        "\n",
        "  # Class activation map from the input layer to the last Conv. layer\n",
        "  cnt = 0\n",
        "  avl_normal, avl_HorMis, avl_Imb, avl_VerMis, avl_Under, avl_Over = [], [], [], [], [], []\n",
        "  av_normal, av_HorMis, av_Imb, av_VerMis, av_Under, av_Over = [], [], [], [], [], []\n",
        "\n",
        "  ###########################################################################\n",
        "\n",
        "  for i in vector:\n",
        "\n",
        "      data = np.expand_dims(i,0)\n",
        "      pred = model2_.predict(data)\n",
        "      real_label = np.argmax(labels[cnt])\n",
        "\n",
        "      # Creating numpy arrays for different class activation maps\n",
        "      if real_label == 0:\n",
        "        if len(avl_normal) != 0:\n",
        "          av_normal = np.concatenate((av_normal, data))\n",
        "        else:\n",
        "          av_normal = data\n",
        "          avl_normal.append(1) # Filled\n",
        "\n",
        "      elif real_label == 1:\n",
        "        if len(avl_HorMis) != 0:\n",
        "          av_HorMis = np.concatenate((av_HorMis, data))\n",
        "        else:\n",
        "          av_HorMis = data\n",
        "          avl_HorMis.append(1) # Filled\n",
        "\n",
        "      elif real_label == 2:\n",
        "        if len(avl_Imb) != 0:\n",
        "          av_Imb = np.concatenate((av_Imb, data))\n",
        "        else:\n",
        "          av_Imb = data\n",
        "          avl_Imb.append(1) # Filled\n",
        "\n",
        "      elif real_label == 3:\n",
        "        if len(avl_VerMis) != 0:\n",
        "          av_VerMis = np.concatenate((av_VerMis, data))\n",
        "        else:\n",
        "          av_VerMis = data\n",
        "          avl_VerMis.append(1) # Filled\n",
        "\n",
        "      elif real_label == 4:\n",
        "        if len(avl_Over) != 0:\n",
        "          av_Over = np.concatenate((av_Over, data))\n",
        "        else:\n",
        "          av_Over = data\n",
        "          avl_Over.append(1) # Filled\n",
        "\n",
        "      else:\n",
        "        if len(avl_Under) != 0:\n",
        "          av_Under = np.concatenate((av_Under, data))\n",
        "        else:\n",
        "          av_Under = data\n",
        "          avl_Under.append(1) # Filled\n",
        "\n",
        "      # Adding one to the counter\n",
        "      cnt +=1\n",
        "\n",
        "  #################################################################\n",
        "  # Averaginig ºº\n",
        "  ################################################################\n",
        "  scaler = MinMaxScaler()\n",
        "\n",
        "  if Binary:\n",
        "\n",
        "    av_normal = scaler.fit_transform(np.average(av_normal, axis = 0))\n",
        "\n",
        "    av_HorMis = scaler.fit_transform(np.average(av_HorMis, axis = 0))\n",
        "\n",
        "    av_Imb = scaler.fit_transform(np.average(av_Imb, axis = 0))\n",
        "\n",
        "    av_VerMis = scaler.fit_transform(np.average(av_VerMis, axis = 0))\n",
        "\n",
        "    av_Over = scaler.fit_transform(np.average(av_Over, axis = 0))\n",
        "\n",
        "    av_Under = scaler.fit_transform(np.average(av_Under, axis = 0))\n",
        "\n",
        "  else:\n",
        "\n",
        "    av_normal = scaler.fit_transform(np.average(av_normal, axis = 0))\n",
        "\n",
        "    av_HorMis = scaler.fit_transform(np.average(av_HorMis, axis = 0))\n",
        "\n",
        "    av_Imb = scaler.fit_transform(np.average(av_Imb, axis = 0))\n",
        "\n",
        "    av_VerMis = scaler.fit_transform(np.average(av_VerMis, axis = 0))\n",
        "\n",
        "  # ####################################################################\n",
        "  # # Plotting average activation map fuctions for each class\n",
        "  # ####################################################################\n",
        "\n",
        "  xticks = [int(xf[i]) for i in range(0, input_size, 749)]\n",
        "  ticks = [i for i in range(0, input_size, 749)]\n",
        "\n",
        "  if Binary:\n",
        "\n",
        "    fig, (ax1, ax2, ax3, ax4, ax5, ax6) = plt.subplots(6, sharex = True, figsize = (30,30))\n",
        "\n",
        "    plt.suptitle('Average Spectrum for each class', fontsize = 30)\n",
        "\n",
        "    ax1.plot(av_normal, 'k')\n",
        "    ax1.set_title('Class 1 - Normal', fontsize = 25)\n",
        "\n",
        "    ax2.plot(av_HorMis, 'k')\n",
        "    ax2.set_title('Class 2 - Horizontal Misalignment', fontsize = 25)\n",
        "\n",
        "    ax3.plot(av_Imb, 'k')\n",
        "    ax3.set_title('Class 3 - Imbalance', fontsize = 25)\n",
        "\n",
        "    ax4.plot(av_VerMis, 'k')\n",
        "    ax4.set_title('Class 4 - Vertical Misalignment', fontsize = 25)\n",
        "\n",
        "    ax5.plot(av_Over, 'k')\n",
        "    ax5.set_title('Class 5 - Overhang', fontsize = 25)\n",
        "\n",
        "    ax6.plot(av_Under, 'k')\n",
        "    ax6.set_title('Class 6 - Underhang', fontsize = 25)\n",
        "    ax6.set_xlim([-50,input_size])\n",
        "    ax6.set_xticks(ticks)\n",
        "    ax6.set_xticklabels(xticks)\n",
        "    ax6.set_xlabel('Frequency (Hz)', fontsize = 15)\n",
        "\n",
        "    # Saving figure\n",
        "    path = '/content/drive/MyDrive/Photos_CNN/Average_Spectrum/' + name + '.jpg'\n",
        "    fig.savefig(path)\n",
        "\n",
        "  else:\n",
        "\n",
        "    fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, sharex = True, figsize = (30,30))\n",
        "\n",
        "    plt.suptitle('Average Spectrum for Binary Problem', fontsize = 30)\n",
        "    ax1.plot(av_normal, 'k')\n",
        "    ax1.set_title('Class 1 - Normal', fontsize = 25)\n",
        "\n",
        "    ax2.plot(av_HorMis, 'k')\n",
        "    ax2.set_title('Class 2 - Cage Fault', fontsize = 25)\n",
        "\n",
        "    ax3.plot(av_Imb, 'k')\n",
        "    ax3.set_title('Class 3 - Outer Race', fontsize = 25)\n",
        "\n",
        "    ax4.plot(av_VerMis, 'k')\n",
        "    ax4.set_title('Class 4 - Ball Fault', fontsize = 25)\n",
        "    ax4.set_xlim([-50,input_size])\n",
        "    ax4.set_xticks(ticks)\n",
        "    ax4.set_xticklabels(xticks)\n",
        "    ax4.set_xlabel('Frequency (Hz)', fontsize = 15)\n",
        "\n",
        "    # Saving figure\n",
        "    path = '/content/drive/MyDrive/Photos_CNN/Average_Spectrum/' + name + '.jpg'\n",
        "    fig.savefig(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X33EEOAx-4HR"
      },
      "outputs": [],
      "source": [
        "###################################################\n",
        "# Cleaning plot\n",
        "###################################################\n",
        "\n",
        "def cleaning_plot(vector):\n",
        "\n",
        "  # Obtaining stats from vector\n",
        "  vector_stats = pd.DataFrame(vector[0]).describe()\n",
        "\n",
        "\n",
        "  # taking 25% most important frequencies\n",
        "  # cut_off = vector_stats.iloc[3,0] + (vector_stats.iloc[6,0] - vector_stats.iloc[3,0])\n",
        "  cut_off = 0.5\n",
        "\n",
        "  # Making values less than the cut off 0\n",
        "  index = vector[0] < cut_off\n",
        "  vector[0][index] = 0\n",
        "\n",
        "  return vector\n",
        "\n",
        "####################################################\n",
        "# Average Heatmap\n",
        "####################################################\n",
        "\n",
        "\n",
        "def average_heatmap(vector, labels, name, model2_, Binary = True):\n",
        "\n",
        "  #########################################################\n",
        "  # Calculating mean of each class activation map\n",
        "  #########################################################\n",
        "\n",
        "  # Class activation map from the input layer to the last Conv. layer\n",
        "  cnt = 0\n",
        "  avl_normal, avl_HorMis, avl_Imb, avl_VerMis, avl_Under, avl_Over = [], [], [], [], [], []\n",
        "  av_normal, av_HorMis, av_Imb, av_VerMis, av_Under, av_Over = [], [], [], [], [], []\n",
        "\n",
        "  ###########################################################################\n",
        "\n",
        "  for i in vector:\n",
        "\n",
        "      data = np.expand_dims(i,0)\n",
        "      pred = model2_.predict(data)\n",
        "      real_label = np.argmax(labels[cnt])\n",
        "\n",
        "      heatmap = grad_cam(layer_name,data)\n",
        "\n",
        "      # Creating numpy arrays for different class activation maps\n",
        "      if real_label == 0:\n",
        "        if len(avl_normal) != 0:\n",
        "          av_normal = np.concatenate((av_normal, heatmap), axis = 0)\n",
        "        else:\n",
        "          av_normal = heatmap\n",
        "          avl_normal.append(1) # Filled\n",
        "\n",
        "      elif real_label == 1:\n",
        "        if len(avl_HorMis) != 0:\n",
        "          av_HorMis = np.concatenate((av_HorMis, heatmap), axis = 0)\n",
        "        else:\n",
        "          av_HorMis = heatmap\n",
        "          avl_HorMis.append(1) # Filled\n",
        "\n",
        "      elif real_label == 2:\n",
        "        if len(avl_Imb) != 0:\n",
        "          av_Imb = np.concatenate((av_Imb, heatmap), axis = 0)\n",
        "        else:\n",
        "          av_Imb = heatmap\n",
        "          avl_Imb.append(1) # Filled\n",
        "\n",
        "      elif real_label == 3:\n",
        "        if len(avl_VerMis) != 0:\n",
        "          av_VerMis = np.concatenate((av_VerMis, heatmap), axis = 0)\n",
        "        else:\n",
        "          av_VerMis = heatmap\n",
        "          avl_VerMis.append(1) # Filled\n",
        "\n",
        "      elif real_label == 4:\n",
        "        if len(avl_Over) != 0:\n",
        "          av_Over = np.concatenate((av_Over, heatmap), axis = 0)\n",
        "        else:\n",
        "          av_Over = heatmap\n",
        "          avl_Over.append(1) # Filled\n",
        "\n",
        "      else:\n",
        "        if len(avl_Under) != 0:\n",
        "          av_Under = np.concatenate((av_Under, heatmap), axis = 0)\n",
        "        else:\n",
        "          av_Under = heatmap\n",
        "          avl_Under.append(1) # Filled\n",
        "\n",
        "      # Adding one to the counter\n",
        "      cnt +=1\n",
        "\n",
        "  #################################################################\n",
        "  # Averaginig now and cleaning plot\n",
        "  ################################################################\n",
        "  scaler = StandardScaler()\n",
        "\n",
        "  if Binary:\n",
        "    av_normal = cleaning_plot(np.moveaxis(scaler.fit_transform(np.expand_dims(np.average(av_normal, axis=0),0).reshape(-1,1)),1,0))\n",
        "\n",
        "    av_HorMis = cleaning_plot(np.moveaxis(scaler.fit_transform(np.expand_dims(np.average(av_HorMis, axis=0),0).reshape(-1,1)),1,0))\n",
        "\n",
        "    av_Imb = cleaning_plot(np.moveaxis(scaler.fit_transform(np.expand_dims(np.average(av_Imb, axis=0),0).reshape(-1,1)),1,0))\n",
        "\n",
        "    av_VerMis = cleaning_plot(np.moveaxis(scaler.fit_transform(np.expand_dims(np.average(av_VerMis, axis=0),0).reshape(-1,1)),1,0))\n",
        "\n",
        "    av_Over = cleaning_plot(np.moveaxis(scaler.fit_transform(np.expand_dims(np.average(av_Over, axis=0),0).reshape(-1,1)),1,0))\n",
        "\n",
        "    av_Under = cleaning_plot(np.moveaxis(scaler.fit_transform(np.expand_dims(np.average(av_Under, axis=0),0).reshape(-1,1)),1,0))\n",
        "\n",
        "  else:\n",
        "\n",
        "    av_normal = cleaning_plot(np.moveaxis(scaler.fit_transform(np.expand_dims(np.average(av_normal, axis=0),0).reshape(-1,1)),1,0))\n",
        "\n",
        "    av_HorMis = cleaning_plot(np.moveaxis(scaler.fit_transform(np.expand_dims(np.average(av_HorMis, axis=0),0).reshape(-1,1)),1,0))\n",
        "\n",
        "    av_Imb = cleaning_plot(np.moveaxis(scaler.fit_transform(np.expand_dims(np.average(av_Imb, axis=0),0).reshape(-1,1)),1,0))\n",
        "\n",
        "    av_VerMis = cleaning_plot(np.moveaxis(scaler.fit_transform(np.expand_dims(np.average(av_VerMis, axis=0),0).reshape(-1,1)),1,0))\n",
        "\n",
        "\n",
        "  ####################################################################\n",
        "  # Plotting average activation map fuctions for each class\n",
        "  ####################################################################\n",
        "\n",
        "  input_size = 5000\n",
        "  xticks = [int(xf[i]) for i in range(0, input_size, 749)]\n",
        "  ticks = [i for i in range(0, input_size, 749)]\n",
        "\n",
        "  if Binary:\n",
        "\n",
        "    fig, (ax1, ax2, ax3, ax4, ax5, ax6) = plt.subplots(6, sharex = True, figsize = (30,30))\n",
        "\n",
        "    plt.suptitle('Average Class Activation Map', fontsize = 30)\n",
        "\n",
        "    ax1.imshow(av_normal, cmap='Reds', aspect=\"auto\", interpolation='nearest',extent=[0,input_size,i.min(),i.max()], alpha=1)\n",
        "    ax1.set_title('Class 1 - Normal', fontsize = 25)\n",
        "\n",
        "    ax2.imshow(av_HorMis,cmap='Reds', aspect=\"auto\", interpolation='nearest',extent=[0,input_size,i.min(),i.max()], alpha=1)\n",
        "    ax2.set_title('Class 2 - Horizontal Misalignment', fontsize = 25)\n",
        "\n",
        "    ax3.imshow(av_Imb,cmap='Reds', aspect=\"auto\", interpolation='nearest',extent=[0,input_size,i.min(),i.max()], alpha=1)\n",
        "    ax3.set_title('Class 3 - Imbalance', fontsize = 25)\n",
        "\n",
        "    ax4.imshow(av_VerMis,cmap='Reds', aspect=\"auto\", interpolation='nearest',extent=[0,input_size,i.min(),i.max()], alpha=1)\n",
        "    ax4.set_title('Class 4 - Vertical Misalignment', fontsize = 25)\n",
        "\n",
        "    ax5.imshow(av_Over,cmap='Reds', aspect=\"auto\", interpolation='nearest',extent=[0,input_size,i.min(),i.max()], alpha=1)\n",
        "    ax5.set_title('Class 5 - Overhang', fontsize = 25)\n",
        "\n",
        "    ax6.imshow(av_Under,cmap='Reds', aspect=\"auto\", interpolation='nearest',extent=[0,input_size,i.min(),i.max()], alpha=1)\n",
        "    ax6.set_title('Class 6 - Underhang', fontsize = 25)\n",
        "    ax6.set_xlim([0,input_size])\n",
        "    ax6.set_xticks(ticks = ticks)\n",
        "    ax6.set_xticklabels(xticks)\n",
        "    ax6.set_xlabel('Frequenxy (Hz)', fontsize = 15)\n",
        "\n",
        "    # Saving figure\n",
        "    path = '/content/drive/MyDrive/Photos_CNN/Average/' + name + '.jpg'\n",
        "    fig.savefig(path)\n",
        "\n",
        "  else:\n",
        "\n",
        "    fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, sharex = True, figsize = (30,30))\n",
        "\n",
        "    plt.suptitle('Average Class Activation Map', fontsize = 30)\n",
        "\n",
        "    ax1.imshow(av_normal, cmap='Reds', aspect=\"auto\", interpolation='nearest',extent=[0,input_size,i.min(),i.max()], alpha=1)\n",
        "    ax1.set_title('Class 1 - Normal', fontsize = 25)\n",
        "\n",
        "    ax2.imshow(av_HorMis,cmap='Reds', aspect=\"auto\", interpolation='nearest',extent=[0,input_size,i.min(),i.max()], alpha=1)\n",
        "    ax2.set_title('Class 2 - Cage Fault', fontsize = 25)\n",
        "\n",
        "    ax3.imshow(av_Imb,cmap='Reds', aspect=\"auto\", interpolation='nearest',extent=[0,input_size,i.min(),i.max()], alpha=1)\n",
        "    ax3.set_title('Class 3 - Outer Race', fontsize = 25)\n",
        "\n",
        "    ax4.imshow(av_VerMis,cmap='Reds', aspect=\"auto\", interpolation='nearest',extent=[0,input_size,i.min(),i.max()], alpha=1)\n",
        "    ax4.set_title('Class 4 - Vertical Ball Fault', fontsize = 25)\n",
        "    ax4.set_xlim([0,input_size])\n",
        "    ax4.set_xticks(ticks = ticks)\n",
        "    ax4.set_xticklabels(xticks)\n",
        "    ax4.set_xlabel('Frequenxy (Hz)', fontsize = 15)\n",
        "\n",
        "    # Saving figure\n",
        "    path = '/content/drive/MyDrive/Photos_CNN/Average/' + name + '.jpg'\n",
        "    fig.savefig(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5n6jT5hp_eYz"
      },
      "outputs": [],
      "source": [
        "###########################################################################\n",
        "# Saving all images from test set in each particular class\n",
        "###########################################################################\n",
        "directories = ['/content/drive/MyDrive/Photos_CNN/Normal',\n",
        "               '/content/drive/MyDrive/Photos_CNN/HorMis',\n",
        "               '/content/drive/MyDrive/Photos_CNN/Imbalance',\n",
        "               '/content/drive/MyDrive/Photos_CNN/VerMis',\n",
        "               '/content/drive/MyDrive/Photos_CNN/Overhang',\n",
        "               '/content/drive/MyDrive/Photos_CNN/Underhang',\n",
        "               '/content/drive/MyDrive/Photos_CNN/Incorrect']\n",
        "\n",
        "def image_allocation(pred, fig, stacked = True):\n",
        "\n",
        "  if stacked:\n",
        "    if pred == 0:\n",
        "      fig.savefig(directories[0]+ '/' + str(cnt)+'_PlotStacked.png')\n",
        "    elif pred == 1:\n",
        "      fig.savefig(directories[1]+ '/' + str(cnt)+'_PlotStacked.png')\n",
        "    elif pred == 2:\n",
        "      fig.savefig(directories[2]+ '/' + str(cnt)+'_PlotStacked.png')\n",
        "    elif pred == 3:\n",
        "      fig.savefig(directories[3]+ '/' + str(cnt)+'_PlotStacked.png')\n",
        "    elif pred == 4:\n",
        "      fig.savefig(directories[4]+ '/' + str(cnt)+'_PlotStacked.png')\n",
        "    else:\n",
        "      fig.savefig(directories[5]+ '/' + str(cnt)+'_PlotStacked.png')\n",
        "\n",
        "    plt.close()\n",
        "\n",
        "  else:\n",
        "    if pred == 0:\n",
        "      fig.savefig(directories[0]+ '/' + str(cnt)+'_Plot6Accelerometer.png')\n",
        "    elif pred == 1:\n",
        "      fig.savefig(directories[1]+ '/' + str(cnt)+'_Plot6Accelerometer.png')\n",
        "    elif pred == 2:\n",
        "      fig.savefig(directories[2]+ '/' + str(cnt)+'_Plot6Accelerometer.png')\n",
        "    elif pred == 3:\n",
        "      fig.savefig(directories[3]+ '/' + str(cnt)+'_Plot6Accelerometer.png')\n",
        "    elif pred == 4:\n",
        "      fig.savefig(directories[4]+ '/' + str(cnt)+'_Plot6Accelerometer.png')\n",
        "    else:\n",
        "      fig.savefig(directories[5]+ '/' + str(cnt)+'_Plot6Accelerometer.png')\n",
        "\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMdf-7JH9cSH"
      },
      "source": [
        "# Loading MAFAULDA dataset after FFT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgDyfwXHSBRm"
      },
      "source": [
        "## Normal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bxbep52wSDlL"
      },
      "outputs": [],
      "source": [
        "datasets, time = MAFAULDA_Functions.LoadNormal()\n",
        "\n",
        "input_size = 5000\n",
        "\n",
        "scaler = MinMaxScaler()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Fd98vl8ZojJ"
      },
      "source": [
        "### Fast Fourier Trasformation - FFT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpMFMzXifFsd"
      },
      "source": [
        "#### Acceleremoter - Underhang"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pa5GhZRcAuBb"
      },
      "outputs": [],
      "source": [
        "BandPass = 7509"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOVbEpaofHvi"
      },
      "outputs": [],
      "source": [
        "###############################################################\n",
        "# Axial\n",
        "###############################################################\n",
        "\n",
        "new_sig_axial = []\n",
        "\n",
        "for i in range(49):\n",
        "  xf, yf, new_sig = MAFAULDA_Functions.UnderAxialFFT(datasets, time, index = i, BandPass = BandPass)\n",
        "  new_sig_axial.append(scaler.fit_transform(np.abs(yf[0:input_size]).reshape(-1,1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OIqjU2jh7Sd"
      },
      "outputs": [],
      "source": [
        "###############################################################\n",
        "# Radiale\n",
        "###############################################################\n",
        "\n",
        "new_sig_radiale = []\n",
        "\n",
        "for i in range(49):\n",
        "  xf, yf, new_sig = MAFAULDA_Functions.UnderRadialFFT(datasets, time, index = i, BandPass = BandPass)\n",
        "  new_sig_radiale.append(scaler.fit_transform(np.abs(yf[0:input_size]).reshape(-1,1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YYmYUZwrlyaD"
      },
      "outputs": [],
      "source": [
        "###############################################################\n",
        "# Tangencial\n",
        "###############################################################\n",
        "\n",
        "new_sig_tangencial = []\n",
        "\n",
        "for i in range(49):\n",
        "  xf, yf, new_sig = MAFAULDA_Functions.UnderTangencialFFT(datasets, time, index = i, BandPass = BandPass)\n",
        "  new_sig_tangencial.append(scaler.fit_transform(np.abs(yf[0:input_size]).reshape(-1,1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tIjo1uhzbDJ",
        "outputId": "58a2f506-8d0e-4400-eae5-44f11a2fadea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of the resulting matrix is: (3, 49, 5000, 1)\n"
          ]
        }
      ],
      "source": [
        "# Joining all FFT from axial, radial and tangecial into a matrix of dimensions 3x49\n",
        "\n",
        "new_sig_underhang = np.array([new_sig_axial,\n",
        "                     new_sig_radiale,\n",
        "                     new_sig_tangencial])\n",
        "\n",
        "print('The shape of the resulting matrix is:', new_sig_underhang.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k50345ajt9-1"
      },
      "source": [
        "#### Acceleremoter - Overhang"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ylNLRPXAt9-7"
      },
      "outputs": [],
      "source": [
        "###############################################################\n",
        "# Axial\n",
        "###############################################################\n",
        "\n",
        "new_sig_axial = []\n",
        "\n",
        "for i in range(49):\n",
        "  xf, yf, new_sig = MAFAULDA_Functions.OverAxialFFT(datasets, time, index = i, BandPass = BandPass)\n",
        "  new_sig_axial.append(scaler.fit_transform(np.abs(yf[0:input_size]).reshape(-1,1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CubszKO8t9-7"
      },
      "outputs": [],
      "source": [
        "###############################################################\n",
        "# Radiale\n",
        "###############################################################\n",
        "\n",
        "new_sig_radiale = []\n",
        "\n",
        "for i in range(49):\n",
        "  xf, yf, new_sig = MAFAULDA_Functions.OverRadialFFT(datasets, time, index = i, BandPass = 5)\n",
        "  new_sig_radiale.append(scaler.fit_transform(np.abs(yf[0:input_size]).reshape(-1,1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khhtIQcLt9-7"
      },
      "outputs": [],
      "source": [
        "###############################################################\n",
        "# Tangencial\n",
        "###############################################################\n",
        "\n",
        "new_sig_tangencial = []\n",
        "\n",
        "for i in range(49):\n",
        "  xf, yf, new_sig = MAFAULDA_Functions.OverTangencialFFT(datasets, time, index = i, BandPass = 5)\n",
        "  new_sig_tangencial.append(scaler.fit_transform(np.abs(yf[0:input_size]).reshape(-1,1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Apc1wHo901Yr",
        "outputId": "0c9cdb42-9266-4637-df28-80e8f45b1b59"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 49, 5000, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Joining all FFT from axial, radial and tangecial into a matrix of dimensions\n",
        "\n",
        "new_signal = np.concatenate((new_sig_underhang,\n",
        "                                         np.array([new_sig_axial,\n",
        "                                                    new_sig_radiale,\n",
        "                                                    new_sig_tangencial])))\n",
        "\n",
        "new_signal.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vQ87KTo29_9"
      },
      "source": [
        "## Horizontal Misalignment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLhx75Nn4G9m"
      },
      "outputs": [],
      "source": [
        "datasets, time = MAFAULDA_Functions.LoadHorMis()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPoA4GEvAFBf"
      },
      "source": [
        "### Fast Fourier Trasformation - FFT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSgt0pjdAFBg"
      },
      "source": [
        "#### Acceleremoter - Underhang"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqW6bB6hAFBh"
      },
      "outputs": [],
      "source": [
        "###############################################################\n",
        "# Axial\n",
        "###############################################################\n",
        "\n",
        "new_sig_axial = []\n",
        "\n",
        "for i in range(197):\n",
        "  xf, yf, new_sig = MAFAULDA_Functions.UnderAxialFFT(datasets, time, index = i, BandPass = 5)\n",
        "  new_sig_axial.append(scaler.fit_transform(np.abs(yf[0:input_size]).reshape(-1,1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBBG6U7OAFBh"
      },
      "outputs": [],
      "source": [
        "###############################################################\n",
        "# Radiale\n",
        "###############################################################\n",
        "\n",
        "new_sig_radiale = []\n",
        "\n",
        "for i in range(197):\n",
        "  xf, yf, new_sig = MAFAULDA_Functions.UnderRadialFFT(datasets, time, index = i, BandPass = 5)\n",
        "  new_sig_radiale.append(scaler.fit_transform(np.abs(yf[0:input_size]).reshape(-1,1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eG687czUAFBh"
      },
      "outputs": [],
      "source": [
        "###############################################################\n",
        "# Tangencial\n",
        "###############################################################\n",
        "\n",
        "new_sig_tangencial = []\n",
        "\n",
        "for i in range(197):\n",
        "  xf, yf, new_sig = MAFAULDA_Functions.UnderTangencialFFT(datasets, time, index = i, BandPass = 5)\n",
        "  new_sig_tangencial.append(scaler.fit_transform(np.abs(yf[0:input_size]).reshape(-1,1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8NgTaYxTAFBh"
      },
      "outputs": [],
      "source": [
        "# Joining all FFT from axial, radial and tangecial into a matrix of dimensions\n",
        "\n",
        "new_sig_underhang = np.array([new_sig_axial,\n",
        "                     new_sig_radiale,\n",
        "                     new_sig_tangencial])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqSCyr70AFBh"
      },
      "source": [
        "#### Acceleremoter - Overhang"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xyLxzuwWAFBh"
      },
      "outputs": [],
      "source": [
        "###############################################################\n",
        "# Axial\n",
        "###############################################################\n",
        "\n",
        "new_sig_axial = []\n",
        "\n",
        "for i in range(197):\n",
        "  xf, yf, new_sig = MAFAULDA_Functions.OverAxialFFT(datasets, time, index = i, BandPass = 5)\n",
        "  new_sig_axial.append(scaler.fit_transform(np.abs(yf[0:input_size]).reshape(-1,1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kkXWNcixAFBi"
      },
      "outputs": [],
      "source": [
        "###############################################################\n",
        "# Radiale\n",
        "###############################################################\n",
        "\n",
        "new_sig_radiale = []\n",
        "\n",
        "for i in range(197):\n",
        "  xf, yf, new_sig = MAFAULDA_Functions.OverRadialFFT(datasets, time, index = i, BandPass = 5)\n",
        "  new_sig_radiale.append(scaler.fit_transform(np.abs(yf[0:input_size]).reshape(-1,1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-B3sl3FAFBi"
      },
      "outputs": [],
      "source": [
        "###############################################################\n",
        "# Tangencial\n",
        "###############################################################\n",
        "\n",
        "new_sig_tangencial = []\n",
        "\n",
        "for i in range(197):\n",
        "  xf, yf, new_sig = MAFAULDA_Functions.OverTangencialFFT(datasets, time, index = i, BandPass = 5)\n",
        "  new_sig_tangencial.append(scaler.fit_transform(np.abs(yf[0:input_size]).reshape(-1,1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xu-IAsffAFBi",
        "outputId": "1df798a1-4dec-415f-de00-61830518b092"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 197, 5000, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# Joining all FFT from axial, radial and tangecial into a matrix of dimensions\n",
        "\n",
        "new_sig_underhang = np.concatenate((new_sig_underhang,\n",
        "                                         np.array([new_sig_axial,\n",
        "                                                    new_sig_radiale,\n",
        "                                                    new_sig_tangencial])))\n",
        "\n",
        "new_sig_underhang.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQHn3q-GCNiG",
        "outputId": "a5aee4d2-1065-4ae1-9271-57ccb0b592b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 246, 5000, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "new_signal = np.concatenate((new_signal, new_sig_underhang), axis = 1)\n",
        "\n",
        "new_signal.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isjkxd8wxXgT"
      },
      "source": [
        "## Imbalance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3dWjzsYNxXgZ"
      },
      "outputs": [],
      "source": [
        "datasets, time = MAFAULDA_Functions.LoadImbalance()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jS-xyUq8xXgZ"
      },
      "source": [
        "### Fast Fourier Trasformation - FFT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbNfnlczxXgZ"
      },
      "source": [
        "#### Acceleremoter - Underhang"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Us7e_R0xXga"
      },
      "outputs": [],
      "source": [
        "###############################################################\n",
        "# Axial\n",
        "###############################################################\n",
        "\n",
        "new_sig_axial = []\n",
        "\n",
        "for i in range(333):\n",
        "  xf, yf, new_sig = MAFAULDA_Functions.UnderAxialFFT(datasets, time, index = i, BandPass = 5)\n",
        "  new_sig_axial.append(scaler.fit_transform(np.abs(yf[0:input_size]).reshape(-1,1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ls5dGTaxXga"
      },
      "outputs": [],
      "source": [
        "###############################################################\n",
        "# Radiale\n",
        "###############################################################\n",
        "\n",
        "new_sig_radiale = []\n",
        "\n",
        "for i in range(333):\n",
        "  xf, yf, new_sig = MAFAULDA_Functions.UnderRadialFFT(datasets, time, index = i, BandPass = 5)\n",
        "  new_sig_radiale.append(scaler.fit_transform(np.abs(yf[0:input_size]).reshape(-1,1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RnLP9xaNxXga"
      },
      "outputs": [],
      "source": [
        "###############################################################\n",
        "# Tangencial\n",
        "###############################################################\n",
        "\n",
        "new_sig_tangencial = []\n",
        "\n",
        "for i in range(333):\n",
        "  xf, yf, new_sig = MAFAULDA_Functions.UnderTangencialFFT(datasets, time, index = i, BandPass = 5)\n",
        "  new_sig_tangencial.append(scaler.fit_transform(np.abs(yf[0:input_size]).reshape(-1,1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5zlxZUWPxXga"
      },
      "outputs": [],
      "source": [
        "# Joining all FFT from axial, radial and tangecial into a matrix of dimensions\n",
        "\n",
        "new_sig_underhang = np.array([new_sig_axial,\n",
        "                     new_sig_radiale,\n",
        "                     new_sig_tangencial])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QF_HoiJWxXga"
      },
      "source": [
        "#### Acceleremoter - Overhang"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7ABUIDixXga"
      },
      "outputs": [],
      "source": [
        "###############################################################\n",
        "# Axial\n",
        "###############################################################\n",
        "\n",
        "new_sig_axial = []\n",
        "\n",
        "for i in range(333):\n",
        "  xf, yf, new_sig = MAFAULDA_Functions.OverAxialFFT(datasets, time, index = i, BandPass = 5)\n",
        "  new_sig_axial.append(scaler.fit_transform(np.abs(yf[0:input_size]).reshape(-1,1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffNyQvRKxXga"
      },
      "outputs": [],
      "source": [
        "###############################################################\n",
        "# Radiale\n",
        "###############################################################\n",
        "\n",
        "new_sig_radiale = []\n",
        "\n",
        "for i in range(333):\n",
        "  xf, yf, new_sig = MAFAULDA_Functions.OverRadialFFT(datasets, time, index = i, BandPass = 5)\n",
        "  new_sig_radiale.append(scaler.fit_transform(np.abs(yf[0:input_size]).reshape(-1,1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNP8q7P8xXgb"
      },
      "outputs": [],
      "source": [
        "###############################################################\n",
        "# Tangencial\n",
        "###############################################################\n",
        "\n",
        "new_sig_tangencial = []\n",
        "\n",
        "for i in range(333):\n",
        "  xf, yf, new_sig = MAFAULDA_Functions.OverTangencialFFT(datasets, time, index = i, BandPass = 5)\n",
        "  new_sig_tangencial.append(scaler.fit_transform(np.abs(yf[0:input_size]).reshape(-1,1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFNp99OyxXgb",
        "outputId": "299d7279-d9ae-4509-95e1-d485387e071e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 333, 5000, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "# Joining all FFT from axial, radial and tangecial into a matrix of dimensions\n",
        "\n",
        "new_sig_underhang = np.concatenate((new_sig_underhang,\n",
        "                                         np.array([new_sig_axial,\n",
        "                                                    new_sig_radiale,\n",
        "                                                    new_sig_tangencial])))\n",
        "\n",
        "new_sig_underhang.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AFmrd-pxXgb",
        "outputId": "a0aa555e-3664-4f76-f036-bfa690edc850"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 579, 5000, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "new_signal = np.concatenate((new_signal, new_sig_underhang), axis = 1)\n",
        "\n",
        "new_signal.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiLvLmhY93Qp"
      },
      "source": [
        "## Vertical Misalignment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8hheCXs93Qx"
      },
      "outputs": [],
      "source": [
        "datasets, time = MAFAULDA_Functions.LoadVerMis()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWXVYHl893Qx"
      },
      "source": [
        "### Fast Fourier Trasformation - FFT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1OhKKF093Qx"
      },
      "source": [
        "#### Acceleremoter - Underhang"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dHrREXdX93Qx"
      },
      "outputs": [],
      "source": [
        "###############################################################\n",
        "# Axial\n",
        "###############################################################\n",
        "\n",
        "new_sig_axial = []\n",
        "\n",
        "for i in range(301):\n",
        "  xf, yf, new_sig = MAFAULDA_Functions.UnderAxialFFT(datasets, time, index = i, BandPass = 5)\n",
        "  new_sig_axial.append(scaler.fit_transform(np.abs(yf[0:input_size]).reshape(-1,1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIyeh2MQ93Qy"
      },
      "outputs": [],
      "source": [
        "###############################################################\n",
        "# Radiale\n",
        "###############################################################\n",
        "\n",
        "new_sig_radiale = []\n",
        "\n",
        "for i in range(301):\n",
        "  xf, yf, new_sig = MAFAULDA_Functions.UnderRadialFFT(datasets, time, index = i, BandPass = 5)\n",
        "  new_sig_radiale.append(scaler.fit_transform(np.abs(yf[0:input_size]).reshape(-1,1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oIydc7al93Qy"
      },
      "outputs": [],
      "source": [
        "###############################################################\n",
        "# Tangencial\n",
        "###############################################################\n",
        "\n",
        "new_sig_tangencial = []\n",
        "\n",
        "for i in range(301):\n",
        "  xf, yf, new_sig = MAFAULDA_Functions.UnderTangencialFFT(datasets, time, index = i, BandPass = 5)\n",
        "  new_sig_tangencial.append(scaler.fit_transform(np.abs(yf[0:input_size]).reshape(-1,1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmy5TfuM93Qy"
      },
      "outputs": [],
      "source": [
        "# Joining all FFT from axial, radial and tangecial into a matrix of dimensions\n",
        "\n",
        "new_sig_underhang = np.array([new_sig_axial,\n",
        "                     new_sig_radiale,\n",
        "                     new_sig_tangencial])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hH5Y3W6h93Qy"
      },
      "source": [
        "#### Acceleremoter - Overhang"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGWgark-93Qy"
      },
      "outputs": [],
      "source": [
        "###############################################################\n",
        "# Axial\n",
        "###############################################################\n",
        "\n",
        "new_sig_axial = []\n",
        "\n",
        "for i in range(301):\n",
        "  xf, yf, new_sig = MAFAULDA_Functions.OverAxialFFT(datasets, time, index = i, BandPass = 5)\n",
        "  new_sig_axial.append(scaler.fit_transform(np.abs(yf[0:input_size]).reshape(-1,1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "buPeoGUp93Qy"
      },
      "outputs": [],
      "source": [
        "###############################################################\n",
        "# Radiale\n",
        "###############################################################\n",
        "\n",
        "new_sig_radiale = []\n",
        "\n",
        "for i in range(301):\n",
        "  xf, yf, new_sig = MAFAULDA_Functions.OverRadialFFT(datasets, time, index = i, BandPass = 5)\n",
        "  new_sig_radiale.append(scaler.fit_transform(np.abs(yf[0:input_size]).reshape(-1,1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q5NjaIEL93Qz"
      },
      "outputs": [],
      "source": [
        "###############################################################\n",
        "# Tangencial\n",
        "###############################################################\n",
        "\n",
        "new_sig_tangencial = []\n",
        "\n",
        "for i in range(301):\n",
        "  xf, yf, new_sig = MAFAULDA_Functions.OverTangencialFFT(datasets, time, index = i, BandPass = 5)\n",
        "  new_sig_tangencial.append(scaler.fit_transform(np.abs(yf[0:input_size]).reshape(-1,1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56M0xCHT93Qz",
        "outputId": "d5c947ca-ca31-4657-d797-6e5b9ad290e8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 301, 5000, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "# Joining all FFT from axial, radial and tangecial into a matrix of dimensions\n",
        "\n",
        "new_sig_underhang = np.concatenate((new_sig_underhang,\n",
        "                                         np.array([new_sig_axial,\n",
        "                                                    new_sig_radiale,\n",
        "                                                    new_sig_tangencial])))\n",
        "\n",
        "new_sig_underhang.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqadwRcP93Qz",
        "outputId": "14f224e2-6042-4914-8d7a-d0b11bd7bc47"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 880, 5000, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "new_signal = np.concatenate((new_signal, new_sig_underhang), axis = 1)\n",
        "\n",
        "new_signal.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5GSTknL-02z"
      },
      "source": [
        "## Overhang"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tuz7B_Qr-027"
      },
      "outputs": [],
      "source": [
        "datasets, time = MAFAULDA_Functions.LoadOverhang()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-tL0gV5-027"
      },
      "source": [
        "### Fast Fourier Trasformation - FFT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uItHHqaN-028"
      },
      "source": [
        "#### Acceleremoter - Underhang"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XTgpFNy3-028"
      },
      "outputs": [],
      "source": [
        "###############################################################\n",
        "# Axial\n",
        "###############################################################\n",
        "\n",
        "new_sig_axial = []\n",
        "\n",
        "for i in range(513):\n",
        "  xf, yf, new_sig = MAFAULDA_Functions.UnderAxialFFT(datasets, time, index = i, BandPass = 5)\n",
        "  new_sig_axial.append(scaler.fit_transform(np.abs(yf[0:input_size]).reshape(-1,1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2qzrwui-028"
      },
      "outputs": [],
      "source": [
        "###############################################################\n",
        "# Radiale\n",
        "###############################################################\n",
        "\n",
        "new_sig_radiale = []\n",
        "\n",
        "for i in range(513):\n",
        "  xf, yf, new_sig = MAFAULDA_Functions.UnderRadialFFT(datasets, time, index = i, BandPass = 5)\n",
        "  new_sig_radiale.append(scaler.fit_transform(np.abs(yf[0:input_size]).reshape(-1,1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzCso00Q-028"
      },
      "outputs": [],
      "source": [
        "###############################################################\n",
        "# Tangencial\n",
        "###############################################################\n",
        "\n",
        "new_sig_tangencial = []\n",
        "\n",
        "for i in range(513):\n",
        "  xf, yf, new_sig = MAFAULDA_Functions.UnderTangencialFFT(datasets, time, index = i, BandPass = 5)\n",
        "  new_sig_tangencial.append(scaler.fit_transform(np.abs(yf[0:input_size]).reshape(-1,1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGttU8Bf-028"
      },
      "outputs": [],
      "source": [
        "# Joining all FFT from axial, radial and tangecial into a matrix of dimensions\n",
        "\n",
        "new_sig_underhang = np.array([new_sig_axial,\n",
        "                     new_sig_radiale,\n",
        "                     new_sig_tangencial])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1zTBXqV-029"
      },
      "source": [
        "#### Acceleremoter - Overhang"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "um-qq7fH-029"
      },
      "outputs": [],
      "source": [
        "###############################################################\n",
        "# Axial\n",
        "###############################################################\n",
        "\n",
        "new_sig_axial = []\n",
        "\n",
        "for i in range(513):\n",
        "  xf, yf, new_sig = MAFAULDA_Functions.OverAxialFFT(datasets, time, index = i, BandPass = 5)\n",
        "  new_sig_axial.append(scaler.fit_transform(np.abs(yf[0:input_size]).reshape(-1,1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40MFQrUI-029"
      },
      "outputs": [],
      "source": [
        "###############################################################\n",
        "# Radiale\n",
        "###############################################################\n",
        "\n",
        "new_sig_radiale = []\n",
        "\n",
        "for i in range(513):\n",
        "  xf, yf, new_sig = MAFAULDA_Functions.OverRadialFFT(datasets, time, index = i, BandPass = 5)\n",
        "  new_sig_radiale.append(scaler.fit_transform(np.abs(yf[0:input_size]).reshape(-1,1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68DfNIqd-029"
      },
      "outputs": [],
      "source": [
        "###############################################################\n",
        "# Tangencial\n",
        "###############################################################\n",
        "\n",
        "new_sig_tangencial = []\n",
        "\n",
        "for i in range(513):\n",
        "  xf, yf, new_sig = MAFAULDA_Functions.OverTangencialFFT(datasets, time, index = i, BandPass = 5)\n",
        "  new_sig_tangencial.append(scaler.fit_transform(np.abs(yf[0:input_size]).reshape(-1,1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8T7Yjq5-029",
        "outputId": "dfbd272c-dbcd-465a-bf35-a3fdf757e9d1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 513, 5000, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "# Joining all FFT from axial, radial and tangecial into a matrix of dimensions\n",
        "\n",
        "new_sig_underhang = np.concatenate((new_sig_underhang,\n",
        "                                         np.array([new_sig_axial,\n",
        "                                                    new_sig_radiale,\n",
        "                                                    new_sig_tangencial])))\n",
        "\n",
        "new_sig_underhang.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AJ9Lrk9-029",
        "outputId": "3c5ded95-1ad5-4b79-b1fc-c35883df7ff8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 1393, 5000, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "new_signal = np.concatenate((new_signal, new_sig_underhang), axis = 1)\n",
        "\n",
        "new_signal.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJZWJT4JJ0Fb"
      },
      "outputs": [],
      "source": [
        "del new_sig_underhang\n",
        "del datasets, time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJagjjyw-8TA"
      },
      "source": [
        "\n",
        "\n",
        "## Underhang"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vrjFA1N5-8TB"
      },
      "outputs": [],
      "source": [
        "datasets, time = MAFAULDA_Functions.LoadUnderhang()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyocHdZI-8TB"
      },
      "source": [
        "### Fast Fourier Trasformation - FFT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnZaxTCT-8TC"
      },
      "source": [
        "#### Acceleremoter - Underhang"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ia-Zghwu-8TC"
      },
      "outputs": [],
      "source": [
        "###############################################################\n",
        "# Axial\n",
        "###############################################################\n",
        "\n",
        "new_sig_axial = []\n",
        "\n",
        "for i in range(558):\n",
        "  xf, yf, new_sig = MAFAULDA_Functions.UnderAxialFFT(datasets, time, index = i, BandPass = 5)\n",
        "  new_sig_axial.append(scaler.fit_transform(np.abs(yf[0:input_size]).reshape(-1,1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NkHmXNRJ-8TC"
      },
      "outputs": [],
      "source": [
        "###############################################################\n",
        "# Radiale\n",
        "###############################################################\n",
        "\n",
        "new_sig_radiale = []\n",
        "\n",
        "for i in range(558):\n",
        "  xf, yf, new_sig = MAFAULDA_Functions.UnderRadialFFT(datasets, time, index = i, BandPass = 5)\n",
        "  new_sig_radiale.append(scaler.fit_transform(np.abs(yf[0:input_size]).reshape(-1,1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dAqmzTHF-8TD"
      },
      "outputs": [],
      "source": [
        "###############################################################\n",
        "# Tangencial\n",
        "###############################################################\n",
        "\n",
        "new_sig_tangencial = []\n",
        "\n",
        "for i in range(558):\n",
        "  xf, yf, new_sig = MAFAULDA_Functions.UnderTangencialFFT(datasets, time, index = i, BandPass = 5)\n",
        "  new_sig_tangencial.append(scaler.fit_transform(np.abs(yf[0:input_size]).reshape(-1,1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDAYAImT-8TD"
      },
      "outputs": [],
      "source": [
        "# Joining all FFT from axial, radial and tangecial into a matrix of dimensions\n",
        "\n",
        "new_sig_underhang = np.array([new_sig_axial,\n",
        "                     new_sig_radiale,\n",
        "                     new_sig_tangencial])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBmoQuLg-8TE"
      },
      "source": [
        "#### Acceleremoter - Overhang"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2meWV_ys-8TE"
      },
      "outputs": [],
      "source": [
        "###############################################################\n",
        "# Axial\n",
        "###############################################################\n",
        "\n",
        "new_sig_axial = []\n",
        "\n",
        "for i in range(558):\n",
        "  xf, yf, new_sig = MAFAULDA_Functions.OverAxialFFT(datasets, time, index = i, BandPass = 5)\n",
        "  new_sig_axial.append(scaler.fit_transform(np.abs(yf[0:input_size]).reshape(-1,1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WSNOZjZ-8TF"
      },
      "outputs": [],
      "source": [
        "###############################################################\n",
        "# Radiale\n",
        "###############################################################\n",
        "\n",
        "new_sig_radiale = []\n",
        "\n",
        "for i in range(558):\n",
        "  xf, yf, new_sig = MAFAULDA_Functions.OverRadialFFT(datasets, time, index = i, BandPass = 5)\n",
        "  new_sig_radiale.append(scaler.fit_transform(np.abs(yf[0:input_size]).reshape(-1,1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "neJ-gymW-8TF"
      },
      "outputs": [],
      "source": [
        "###############################################################\n",
        "# Tangencial\n",
        "###############################################################\n",
        "\n",
        "new_sig_tangencial = []\n",
        "\n",
        "for i in range(558):\n",
        "  xf, yf, new_sig = MAFAULDA_Functions.OverTangencialFFT(datasets, time, index = i, BandPass = 5)\n",
        "  new_sig_tangencial.append(scaler.fit_transform(np.abs(yf[0:input_size]).reshape(-1,1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ycVcIpc1-8TF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50e79b1f-74fa-4002-d3e5-95e5aea10849"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 558, 5000, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "# Joining all FFT from axial, radial and tangecial into a matrix of dimensions\n",
        "\n",
        "new_sig_underhang = np.concatenate((new_sig_underhang,\n",
        "                                         np.array([new_sig_axial,\n",
        "                                                    new_sig_radiale,\n",
        "                                                    new_sig_tangencial])))\n",
        "\n",
        "new_sig_underhang.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQHTqnn6-8TG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bc78261-ff2c-4971-c569-6ffb5a47c265"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 1951, 5000, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "new_signal = np.concatenate((new_signal, new_sig_underhang), axis = 1)\n",
        "\n",
        "new_signal.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUGb5Q6PKVYC"
      },
      "outputs": [],
      "source": [
        "del new_sig_underhang\n",
        "del datasets, time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aFLb74gD-Fa"
      },
      "source": [
        "# Experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IPFdnNI9BTHG"
      },
      "outputs": [],
      "source": [
        "##############################\n",
        "# Creating labels\n",
        "##############################\n",
        "\n",
        "underhang_y = []\n",
        "\n",
        "# Normal\n",
        "for i in range(49):\n",
        "  underhang_y.append(0)\n",
        "\n",
        "# Hor Mis\n",
        "for i in range(197):\n",
        "  underhang_y.append(1)\n",
        "\n",
        "# Imbalance\n",
        "for i in range(333):\n",
        "  underhang_y.append(2)\n",
        "\n",
        "# Ver Mis\n",
        "for i in range(301):\n",
        "  underhang_y.append(3)\n",
        "\n",
        "# Overhang\n",
        "for i in range(513):\n",
        "  underhang_y.append(4)\n",
        "\n",
        "# Underhang\n",
        "for i in range(558):\n",
        "  underhang_y.append(5)\n",
        "\n",
        "underhang_y = np.array(underhang_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHj6LnEZECYa",
        "outputId": "102bcdbd-b67a-43d3-cdfe-2b1d2168b045"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "########################################\n",
            "# Underhang Accelerometer\n",
            "########################################\n",
            "\n",
            "Underhang - Training size: (1560, 5000, 6)\n",
            "Underhang - Test size: (391, 5000, 6)\n",
            "Underhang_y - Training size: (1560, 6)\n",
            "Underhang_y - Test size: (391, 6)\n"
          ]
        }
      ],
      "source": [
        "##########################################################\n",
        "# Splitting and shuffling the data\n",
        "##########################################################\n",
        "\n",
        "new_signal2 = new_signal.reshape(6, 1951, input_size)\n",
        "\n",
        "# Splitting it 65% - 35% (train-test)\n",
        "all_indices = list(range(len(new_signal[0])))\n",
        "# , stratify = underhang_y\n",
        "train_ind, test_ind = train_test_split(all_indices,stratify = underhang_y, test_size=0.2, shuffle = True,\n",
        "                                       random_state = 420)\n",
        "\n",
        "X_train = np.moveaxis(new_signal2[:,train_ind,:], 0, -1)\n",
        "X_test = np.moveaxis(new_signal2[:,test_ind, :], 0, -1)\n",
        "# One-hot encoding\n",
        "y_train = to_categorical(underhang_y[train_ind])\n",
        "y_test = to_categorical(underhang_y[test_ind])\n",
        "\n",
        "print(\"\"\"\n",
        "########################################\n",
        "# Underhang Accelerometer\n",
        "########################################\n",
        "\"\"\")\n",
        "print('Underhang - Training size:', X_train.shape)\n",
        "print('Underhang - Test size:', X_test.shape)\n",
        "print('Underhang_y - Training size:', y_train.shape)\n",
        "print('Underhang_y - Test size:', y_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhUVA95CwPGd"
      },
      "source": [
        "## CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYxZl_NtBMz5",
        "outputId": "d85fb8b5-1d63-4853-ae14-851d5c3f9c11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_28 (Conv1D)          (None, 5000, 16)          1264      \n",
            "                                                                 \n",
            " batch_normalization_21 (Bat  (None, 5000, 16)         64        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 5000, 16)          0         \n",
            "                                                                 \n",
            " conv1d_29 (Conv1D)          (None, 5000, 32)          6688      \n",
            "                                                                 \n",
            " max_pooling1d_10 (MaxPoolin  (None, 2500, 32)         0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_22 (Bat  (None, 2500, 32)         128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv1d_30 (Conv1D)          (None, 2500, 128)         53376     \n",
            "                                                                 \n",
            " max_pooling1d_11 (MaxPoolin  (None, 1250, 128)        0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 1250, 128)         0         \n",
            "                                                                 \n",
            " conv1d_31 (Conv1D)          (None, 1250, 32)          53280     \n",
            "                                                                 \n",
            " max_pooling1d_12 (MaxPoolin  (None, 625, 32)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_32 (Conv1D)          (None, 625, 16)           6672      \n",
            "                                                                 \n",
            " max_pooling1d_13 (MaxPoolin  (None, 312, 16)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 4992)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6)                 29958     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 151,430\n",
            "Trainable params: 151,334\n",
            "Non-trainable params: 96\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Obtaining the same model as described in the paper\n",
        "\n",
        "##################################################\n",
        "# GOOD\n",
        "##################################################\n",
        "\n",
        "\n",
        "num_errors = 6\n",
        "input_shape = (input_size ,6)\n",
        "kernel_size = 9\n",
        "pool_size = 2\n",
        "dropout = 0.1\n",
        "\n",
        "model2_ =  Sequential([\n",
        "                    Conv1D(filters=16,\n",
        "                                    kernel_size=13,\n",
        "                                    activation='relu',\n",
        "                                    input_shape=input_shape,\n",
        "                                    padding = 'same',\n",
        "                                    kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4),\n",
        "                                    bias_regularizer=regularizers.L2(1e-4),\n",
        "                                    activity_regularizer=regularizers.L2(1e-5)),\n",
        "\n",
        "                    BatchNormalization(),\n",
        "\n",
        "                    Dropout(dropout),\n",
        "\n",
        "                    Conv1D(filters=32,\n",
        "                                    kernel_size=13,\n",
        "                                    activation='relu',\n",
        "                                    padding = 'same',\n",
        "                                    kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4),\n",
        "                                    bias_regularizer=regularizers.L2(1e-4),\n",
        "                                    activity_regularizer=regularizers.L2(1e-5)),\n",
        "\n",
        "                    MaxPooling1D(pool_size),\n",
        "\n",
        "                    BatchNormalization(),\n",
        "\n",
        "                    Conv1D(filters=128,\n",
        "                                    kernel_size=13,\n",
        "                                    activation='relu',\n",
        "                                    padding = 'same',\n",
        "                                    kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4),\n",
        "                                    bias_regularizer=regularizers.L2(1e-4),\n",
        "                                    activity_regularizer=regularizers.L2(1e-5)),\n",
        "\n",
        "                    MaxPooling1D(pool_size),\n",
        "\n",
        "                    # dropout added as regularizer\n",
        "                    Dropout(dropout),\n",
        "\n",
        "                    Conv1D(filters=32,\n",
        "                                    kernel_size=13,\n",
        "                                    activation='relu',\n",
        "                                    padding = 'same',\n",
        "                                    kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4),\n",
        "                                    bias_regularizer=regularizers.L2(1e-4),\n",
        "                                    activity_regularizer=regularizers.L2(1e-5)),\n",
        "\n",
        "                    MaxPooling1D(pool_size),\n",
        "\n",
        "                    Conv1D(filters=16,\n",
        "                                    kernel_size=13,\n",
        "                                    activation='relu',\n",
        "                                    padding = 'same',\n",
        "                                    kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4),\n",
        "                                    bias_regularizer=regularizers.L2(1e-4),\n",
        "                                    activity_regularizer=regularizers.L2(1e-5)),\n",
        "\n",
        "                    MaxPooling1D(pool_size),\n",
        "\n",
        "\n",
        "                    Flatten(),\n",
        "\n",
        "                    Dense(num_errors),\n",
        "                    Activation('softmax')\n",
        "\n",
        "  ])\n",
        "model2_.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9b-gPCECmaYp",
        "outputId": "250a6aaf-3247-47ff-b72b-d06dd9083cd2"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "plot_model(model2_, show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TfOlyJDwPGd",
        "outputId": "5d88a35b-d124-44d5-fe69-21bd283cc72f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.7517 - accuracy: 0.5440\n",
            "Epoch 1: val_accuracy improved from -inf to 0.28645, saving model to /content/drive/MyDrive/best_model.hdf5\n",
            "195/195 [==============================] - 5s 18ms/step - loss: 1.7460 - accuracy: 0.5455 - val_loss: 1.6976 - val_accuracy: 0.2864\n",
            "Epoch 2/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.8628 - accuracy: 0.8982\n",
            "Epoch 2: val_accuracy improved from 0.28645 to 0.36061, saving model to /content/drive/MyDrive/best_model.hdf5\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.8621 - accuracy: 0.8981 - val_loss: 2.0786 - val_accuracy: 0.3606\n",
            "Epoch 3/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6222 - accuracy: 0.9560\n",
            "Epoch 3: val_accuracy improved from 0.36061 to 0.88747, saving model to /content/drive/MyDrive/best_model.hdf5\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.6212 - accuracy: 0.9558 - val_loss: 0.8007 - val_accuracy: 0.8875\n",
            "Epoch 4/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4917 - accuracy: 0.9767\n",
            "Epoch 4: val_accuracy improved from 0.88747 to 0.97954, saving model to /content/drive/MyDrive/best_model.hdf5\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.4908 - accuracy: 0.9769 - val_loss: 0.4298 - val_accuracy: 0.9795\n",
            "Epoch 5/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4170 - accuracy: 0.9903\n",
            "Epoch 5: val_accuracy improved from 0.97954 to 0.99488, saving model to /content/drive/MyDrive/best_model.hdf5\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.4166 - accuracy: 0.9904 - val_loss: 0.3722 - val_accuracy: 0.9949\n",
            "Epoch 6/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3671 - accuracy: 0.9910\n",
            "Epoch 6: val_accuracy did not improve from 0.99488\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.3665 - accuracy: 0.9910 - val_loss: 0.3518 - val_accuracy: 0.9898\n",
            "Epoch 7/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3156 - accuracy: 0.9923\n",
            "Epoch 7: val_accuracy did not improve from 0.99488\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.3153 - accuracy: 0.9923 - val_loss: 0.3213 - val_accuracy: 0.9872\n",
            "Epoch 8/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2822 - accuracy: 0.9974\n",
            "Epoch 8: val_accuracy did not improve from 0.99488\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.2820 - accuracy: 0.9974 - val_loss: 0.2641 - val_accuracy: 0.9949\n",
            "Epoch 9/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2587 - accuracy: 0.9961\n",
            "Epoch 9: val_accuracy did not improve from 0.99488\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.2586 - accuracy: 0.9962 - val_loss: 0.2641 - val_accuracy: 0.9898\n",
            "Epoch 10/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2383 - accuracy: 0.9955\n",
            "Epoch 10: val_accuracy did not improve from 0.99488\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.2380 - accuracy: 0.9955 - val_loss: 0.2232 - val_accuracy: 0.9923\n",
            "Epoch 11/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2103 - accuracy: 0.9981\n",
            "Epoch 11: val_accuracy did not improve from 0.99488\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.2109 - accuracy: 0.9981 - val_loss: 0.1969 - val_accuracy: 0.9949\n",
            "Epoch 12/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1928 - accuracy: 0.9987\n",
            "Epoch 12: val_accuracy did not improve from 0.99488\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1926 - accuracy: 0.9987 - val_loss: 0.1841 - val_accuracy: 0.9949\n",
            "Epoch 13/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1810 - accuracy: 0.9974\n",
            "Epoch 13: val_accuracy did not improve from 0.99488\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1807 - accuracy: 0.9974 - val_loss: 0.1747 - val_accuracy: 0.9949\n",
            "Epoch 14/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1640 - accuracy: 0.9987\n",
            "Epoch 14: val_accuracy did not improve from 0.99488\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.1643 - accuracy: 0.9987 - val_loss: 0.1609 - val_accuracy: 0.9923\n",
            "Epoch 15/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1570 - accuracy: 0.9974\n",
            "Epoch 15: val_accuracy did not improve from 0.99488\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.1567 - accuracy: 0.9974 - val_loss: 0.1614 - val_accuracy: 0.9949\n",
            "Epoch 16/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1453 - accuracy: 0.9987\n",
            "Epoch 16: val_accuracy did not improve from 0.99488\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1451 - accuracy: 0.9987 - val_loss: 0.1421 - val_accuracy: 0.9949\n",
            "Epoch 17/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1415 - accuracy: 0.9974\n",
            "Epoch 17: val_accuracy did not improve from 0.99488\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1414 - accuracy: 0.9974 - val_loss: 0.1396 - val_accuracy: 0.9949\n",
            "Epoch 18/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1306 - accuracy: 0.9987\n",
            "Epoch 18: val_accuracy improved from 0.99488 to 0.99744, saving model to /content/drive/MyDrive/best_model.hdf5\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.1306 - accuracy: 0.9987 - val_loss: 0.1288 - val_accuracy: 0.9974\n",
            "Epoch 19/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1258 - accuracy: 0.9981\n",
            "Epoch 19: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.1258 - accuracy: 0.9981 - val_loss: 0.1273 - val_accuracy: 0.9923\n",
            "Epoch 20/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1215 - accuracy: 0.9987\n",
            "Epoch 20: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.1215 - accuracy: 0.9987 - val_loss: 0.1208 - val_accuracy: 0.9923\n",
            "Epoch 21/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1134 - accuracy: 0.9994\n",
            "Epoch 21: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.1132 - accuracy: 0.9994 - val_loss: 0.1176 - val_accuracy: 0.9923\n",
            "Epoch 22/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1172 - accuracy: 0.9994\n",
            "Epoch 22: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.1170 - accuracy: 0.9994 - val_loss: 0.1144 - val_accuracy: 0.9923\n",
            "Epoch 23/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1046 - accuracy: 1.0000\n",
            "Epoch 23: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1045 - accuracy: 1.0000 - val_loss: 0.1060 - val_accuracy: 0.9974\n",
            "Epoch 24/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1001 - accuracy: 0.9994\n",
            "Epoch 24: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1000 - accuracy: 0.9994 - val_loss: 0.1060 - val_accuracy: 0.9923\n",
            "Epoch 25/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1008 - accuracy: 0.9994\n",
            "Epoch 25: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.1007 - accuracy: 0.9994 - val_loss: 0.1140 - val_accuracy: 0.9872\n",
            "Epoch 26/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0959 - accuracy: 0.9987\n",
            "Epoch 26: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0960 - accuracy: 0.9987 - val_loss: 0.1008 - val_accuracy: 0.9949\n",
            "Epoch 27/100\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0924 - accuracy: 0.9994\n",
            "Epoch 27: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0924 - accuracy: 0.9994 - val_loss: 0.1015 - val_accuracy: 0.9923\n",
            "Epoch 28/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0901 - accuracy: 1.0000\n",
            "Epoch 28: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0901 - accuracy: 1.0000 - val_loss: 0.0953 - val_accuracy: 0.9949\n",
            "Epoch 29/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0865 - accuracy: 0.9994\n",
            "Epoch 29: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0864 - accuracy: 0.9994 - val_loss: 0.0921 - val_accuracy: 0.9949\n",
            "Epoch 30/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0843 - accuracy: 1.0000\n",
            "Epoch 30: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0843 - accuracy: 1.0000 - val_loss: 0.0930 - val_accuracy: 0.9923\n",
            "Epoch 31/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0800 - accuracy: 1.0000\n",
            "Epoch 31: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0799 - accuracy: 1.0000 - val_loss: 0.0875 - val_accuracy: 0.9923\n",
            "Epoch 32/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0805 - accuracy: 0.9994\n",
            "Epoch 32: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0805 - accuracy: 0.9994 - val_loss: 0.0906 - val_accuracy: 0.9949\n",
            "Epoch 33/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0769 - accuracy: 1.0000\n",
            "Epoch 33: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0770 - accuracy: 1.0000 - val_loss: 0.0916 - val_accuracy: 0.9923\n",
            "Epoch 34/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0749 - accuracy: 1.0000\n",
            "Epoch 34: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0748 - accuracy: 1.0000 - val_loss: 0.0867 - val_accuracy: 0.9923\n",
            "Epoch 35/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0731 - accuracy: 1.0000\n",
            "Epoch 35: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0731 - accuracy: 1.0000 - val_loss: 0.0984 - val_accuracy: 0.9898\n",
            "Epoch 36/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0723 - accuracy: 1.0000\n",
            "Epoch 36: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0725 - accuracy: 1.0000 - val_loss: 0.0839 - val_accuracy: 0.9923\n",
            "Epoch 37/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0690 - accuracy: 1.0000\n",
            "Epoch 37: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0690 - accuracy: 1.0000 - val_loss: 0.0822 - val_accuracy: 0.9923\n",
            "Epoch 38/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0670 - accuracy: 1.0000\n",
            "Epoch 38: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0670 - accuracy: 1.0000 - val_loss: 0.0775 - val_accuracy: 0.9923\n",
            "Epoch 39/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0651 - accuracy: 1.0000\n",
            "Epoch 39: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0652 - accuracy: 1.0000 - val_loss: 0.0893 - val_accuracy: 0.9923\n",
            "Epoch 40/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0647 - accuracy: 1.0000\n",
            "Epoch 40: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0648 - accuracy: 1.0000 - val_loss: 0.0774 - val_accuracy: 0.9923\n",
            "Epoch 41/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0615 - accuracy: 1.0000\n",
            "Epoch 41: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0618 - accuracy: 1.0000 - val_loss: 0.0715 - val_accuracy: 0.9949\n",
            "Epoch 42/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0635 - accuracy: 0.9994\n",
            "Epoch 42: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0635 - accuracy: 0.9994 - val_loss: 0.0710 - val_accuracy: 0.9949\n",
            "Epoch 43/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0607 - accuracy: 1.0000\n",
            "Epoch 43: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0607 - accuracy: 1.0000 - val_loss: 0.0840 - val_accuracy: 0.9949\n",
            "Epoch 44/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0573 - accuracy: 1.0000\n",
            "Epoch 44: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0573 - accuracy: 1.0000 - val_loss: 0.0716 - val_accuracy: 0.9923\n",
            "Epoch 45/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0562 - accuracy: 1.0000\n",
            "Epoch 45: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0562 - accuracy: 1.0000 - val_loss: 0.0724 - val_accuracy: 0.9923\n",
            "Epoch 46/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0545 - accuracy: 1.0000\n",
            "Epoch 46: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0545 - accuracy: 1.0000 - val_loss: 0.0649 - val_accuracy: 0.9949\n",
            "Epoch 47/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0531 - accuracy: 1.0000\n",
            "Epoch 47: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0531 - accuracy: 1.0000 - val_loss: 0.0728 - val_accuracy: 0.9949\n",
            "Epoch 48/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0520 - accuracy: 1.0000\n",
            "Epoch 48: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0520 - accuracy: 1.0000 - val_loss: 0.0589 - val_accuracy: 0.9974\n",
            "Epoch 49/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0505 - accuracy: 1.0000\n",
            "Epoch 49: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0506 - accuracy: 1.0000 - val_loss: 0.0691 - val_accuracy: 0.9898\n",
            "Epoch 50/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0511 - accuracy: 1.0000\n",
            "Epoch 50: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0511 - accuracy: 1.0000 - val_loss: 0.0569 - val_accuracy: 0.9949\n",
            "Epoch 51/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0480 - accuracy: 1.0000\n",
            "Epoch 51: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0480 - accuracy: 1.0000 - val_loss: 0.0618 - val_accuracy: 0.9949\n",
            "Epoch 52/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0464 - accuracy: 1.0000\n",
            "Epoch 52: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0464 - accuracy: 1.0000 - val_loss: 0.0586 - val_accuracy: 0.9923\n",
            "Epoch 53/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0444 - accuracy: 1.0000\n",
            "Epoch 53: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0446 - accuracy: 1.0000 - val_loss: 0.0556 - val_accuracy: 0.9974\n",
            "Epoch 54/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0435 - accuracy: 1.0000\n",
            "Epoch 54: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0434 - accuracy: 1.0000 - val_loss: 0.0583 - val_accuracy: 0.9923\n",
            "Epoch 55/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0426 - accuracy: 1.0000\n",
            "Epoch 55: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0426 - accuracy: 1.0000 - val_loss: 0.0597 - val_accuracy: 0.9949\n",
            "Epoch 56/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0414 - accuracy: 1.0000\n",
            "Epoch 56: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0414 - accuracy: 1.0000 - val_loss: 0.0525 - val_accuracy: 0.9974\n",
            "Epoch 57/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0394 - accuracy: 1.0000\n",
            "Epoch 57: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0394 - accuracy: 1.0000 - val_loss: 0.0488 - val_accuracy: 0.9949\n",
            "Epoch 58/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0409 - accuracy: 0.9994\n",
            "Epoch 58: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0409 - accuracy: 0.9994 - val_loss: 0.2744 - val_accuracy: 0.9463\n",
            "Epoch 59/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0578 - accuracy: 0.9961\n",
            "Epoch 59: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0577 - accuracy: 0.9962 - val_loss: 0.0608 - val_accuracy: 0.9923\n",
            "Epoch 60/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0388 - accuracy: 1.0000\n",
            "Epoch 60: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0388 - accuracy: 1.0000 - val_loss: 0.0508 - val_accuracy: 0.9949\n",
            "Epoch 61/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0375 - accuracy: 1.0000\n",
            "Epoch 61: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0375 - accuracy: 1.0000 - val_loss: 0.0482 - val_accuracy: 0.9949\n",
            "Epoch 62/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0361 - accuracy: 1.0000\n",
            "Epoch 62: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0363 - accuracy: 1.0000 - val_loss: 0.0471 - val_accuracy: 0.9949\n",
            "Epoch 63/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0350 - accuracy: 1.0000\n",
            "Epoch 63: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0350 - accuracy: 1.0000 - val_loss: 0.0444 - val_accuracy: 0.9949\n",
            "Epoch 64/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0340 - accuracy: 1.0000\n",
            "Epoch 64: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0341 - accuracy: 1.0000 - val_loss: 0.0436 - val_accuracy: 0.9949\n",
            "Epoch 65/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0332 - accuracy: 1.0000\n",
            "Epoch 65: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0332 - accuracy: 1.0000 - val_loss: 0.0453 - val_accuracy: 0.9949\n",
            "Epoch 66/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0326 - accuracy: 1.0000\n",
            "Epoch 66: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0326 - accuracy: 1.0000 - val_loss: 0.0426 - val_accuracy: 0.9949\n",
            "Epoch 67/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0319 - accuracy: 1.0000\n",
            "Epoch 67: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0319 - accuracy: 1.0000 - val_loss: 0.0426 - val_accuracy: 0.9949\n",
            "Epoch 68/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0312 - accuracy: 1.0000\n",
            "Epoch 68: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0312 - accuracy: 1.0000 - val_loss: 0.0436 - val_accuracy: 0.9949\n",
            "Epoch 69/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0301 - accuracy: 1.0000\n",
            "Epoch 69: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0301 - accuracy: 1.0000 - val_loss: 0.0411 - val_accuracy: 0.9949\n",
            "Epoch 70/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0296 - accuracy: 1.0000\n",
            "Epoch 70: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 0.9974\n",
            "Epoch 71/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0292 - accuracy: 1.0000\n",
            "Epoch 71: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0292 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9949\n",
            "Epoch 72/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0281 - accuracy: 1.0000\n",
            "Epoch 72: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 0.0378 - val_accuracy: 0.9974\n",
            "Epoch 73/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0274 - accuracy: 1.0000\n",
            "Epoch 73: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0274 - accuracy: 1.0000 - val_loss: 0.0377 - val_accuracy: 0.9949\n",
            "Epoch 74/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0269 - accuracy: 1.0000\n",
            "Epoch 74: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0269 - accuracy: 1.0000 - val_loss: 0.0377 - val_accuracy: 0.9949\n",
            "Epoch 75/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0264 - accuracy: 1.0000\n",
            "Epoch 75: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0264 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 0.9949\n",
            "Epoch 76/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0260 - accuracy: 1.0000\n",
            "Epoch 76: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0260 - accuracy: 1.0000 - val_loss: 0.0335 - val_accuracy: 0.9974\n",
            "Epoch 77/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0251 - accuracy: 1.0000\n",
            "Epoch 77: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0251 - accuracy: 1.0000 - val_loss: 0.0349 - val_accuracy: 0.9923\n",
            "Epoch 78/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0252 - accuracy: 1.0000\n",
            "Epoch 78: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0252 - accuracy: 1.0000 - val_loss: 0.0372 - val_accuracy: 0.9923\n",
            "Epoch 79/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0239 - accuracy: 1.0000\n",
            "Epoch 79: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 0.0354 - val_accuracy: 0.9949\n",
            "Epoch 80/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0275 - accuracy: 0.9994\n",
            "Epoch 80: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0275 - accuracy: 0.9994 - val_loss: 0.0543 - val_accuracy: 0.9949\n",
            "Epoch 81/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0314 - accuracy: 0.9994\n",
            "Epoch 81: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0313 - accuracy: 0.9994 - val_loss: 0.0350 - val_accuracy: 0.9923\n",
            "Epoch 82/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0243 - accuracy: 1.0000\n",
            "Epoch 82: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 0.0316 - val_accuracy: 0.9949\n",
            "Epoch 83/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0231 - accuracy: 1.0000\n",
            "Epoch 83: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0232 - accuracy: 1.0000 - val_loss: 0.0320 - val_accuracy: 0.9974\n",
            "Epoch 84/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0227 - accuracy: 1.0000\n",
            "Epoch 84: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 0.0307 - val_accuracy: 0.9974\n",
            "Epoch 85/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0218 - accuracy: 1.0000\n",
            "Epoch 85: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 0.0303 - val_accuracy: 0.9974\n",
            "Epoch 86/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0216 - accuracy: 1.0000\n",
            "Epoch 86: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 0.0307 - val_accuracy: 0.9949\n",
            "Epoch 87/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0210 - accuracy: 1.0000\n",
            "Epoch 87: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 0.0292 - val_accuracy: 0.9974\n",
            "Epoch 88/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0207 - accuracy: 1.0000\n",
            "Epoch 88: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 0.0307 - val_accuracy: 0.9949\n",
            "Epoch 89/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0205 - accuracy: 1.0000\n",
            "Epoch 89: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 0.0282 - val_accuracy: 0.9949\n",
            "Epoch 90/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0200 - accuracy: 1.0000\n",
            "Epoch 90: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 0.0284 - val_accuracy: 0.9974\n",
            "Epoch 91/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0195 - accuracy: 1.0000\n",
            "Epoch 91: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.0302 - val_accuracy: 0.9949\n",
            "Epoch 92/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0192 - accuracy: 1.0000\n",
            "Epoch 92: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.0320 - val_accuracy: 0.9949\n",
            "Epoch 93/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0191 - accuracy: 1.0000\n",
            "Epoch 93: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 0.0269 - val_accuracy: 0.9974\n",
            "Epoch 94/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0185 - accuracy: 1.0000\n",
            "Epoch 94: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 0.0269 - val_accuracy: 0.9974\n",
            "Epoch 95/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0227 - accuracy: 0.9994\n",
            "Epoch 95: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0226 - accuracy: 0.9994 - val_loss: 0.0336 - val_accuracy: 0.9974\n",
            "Epoch 96/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0192 - accuracy: 1.0000\n",
            "Epoch 96: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.0305 - val_accuracy: 0.9949\n",
            "Epoch 97/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0181 - accuracy: 1.0000\n",
            "Epoch 97: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.0314 - val_accuracy: 0.9949\n",
            "Epoch 98/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0177 - accuracy: 1.0000\n",
            "Epoch 98: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.0290 - val_accuracy: 0.9949\n",
            "Epoch 99/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0173 - accuracy: 1.0000\n",
            "Epoch 99: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.0316 - val_accuracy: 0.9949\n",
            "Epoch 100/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0172 - accuracy: 1.0000\n",
            "Epoch 100: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.0244 - val_accuracy: 0.9974\n"
          ]
        }
      ],
      "source": [
        "########################################\n",
        "# Training the model now (Underhang)\n",
        "########################################\n",
        "import tensorflow as tf\n",
        "\n",
        "checkpoint_filepath = '/content/drive/MyDrive/best_model.hdf5'\n",
        "save_best_model = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath = checkpoint_filepath,\n",
        "    monitor=\"val_accuracy\",\n",
        "    verbose=1,\n",
        "    save_best_only=True,\n",
        "    mode=\"auto\",\n",
        "    save_freq=\"epoch\",\n",
        "    options=None,\n",
        "    initial_value_threshold=None\n",
        ")\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(\n",
        "    learning_rate= 0.0001,\n",
        "    beta_1=0.9,\n",
        "    beta_2=0.999,\n",
        "    epsilon=1e-07,\n",
        "    amsgrad=False,\n",
        "    name=\"Adam\"\n",
        "  )\n",
        "\n",
        "model2_.compile(loss='CategoricalCrossentropy',\n",
        "              optimizer= opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# train the network\n",
        "output = model2_.fit(X_train, y_train, epochs = 100, batch_size=8,\n",
        "                    validation_data = (X_test , y_test),\n",
        "                    callbacks = [save_best_model])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WKexS7HQDIxL"
      },
      "outputs": [],
      "source": [
        "# ######################################################\n",
        "# # Setting the weights for the best model found and saving the model\n",
        "# model2_.load_weights(checkpoint_filepath)\n",
        "# # Guardar el Modelo (Just only once if u are running the network again)\n",
        "# model2_.save('/content/drive/MyDrive/Model_CNN.h5')\n",
        "\n",
        "######################################################################\n",
        "# Loading model (already trained)\n",
        "model2_ = keras.models.load_model('/content/drive/MyDrive/Model_CNN.h5')\n",
        "#####################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAEeRT5-wPGe",
        "outputId": "6b1b2643-0d08-4e2f-bd06-62c52d85a81c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The minimum loss training found is: 0.017246  and was found in epoch number: 99\n",
            "The minimum loss test found is: 0.024432  and was found in epoch number: 99\n",
            "The maximum accuracy training found is: 100.0 % and was found in epoch number: 22\n",
            "The maximum accuracy test found is: 99.74 % and was found in epoch number: 17\n"
          ]
        }
      ],
      "source": [
        "# Minimum value of cross entropy\n",
        "\n",
        "print(\"The minimum loss training found is:\", round(min(output.history['loss']),6) ,\" and was found in epoch number:\", np.argmin(output.history['loss']))\n",
        "print(\"The minimum loss test found is:\", round(min(output.history['val_loss']),6) ,\" and was found in epoch number:\", np.argmin(output.history['val_loss']))\n",
        "\n",
        "# Maximum accuracy\n",
        "\n",
        "print(\"The maximum accuracy training found is:\", round(100*max(output.history['accuracy']),2) ,\"% and was found in epoch number:\", np.argmax(output.history['accuracy']))\n",
        "print(\"The maximum accuracy test found is:\", round(100*max(output.history['val_accuracy']),2) ,\"% and was found in epoch number:\", np.argmax(output.history['val_accuracy']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        },
        "id": "f2ocPUe_wPGe",
        "outputId": "70e58d92-cd49-4752-9e3c-f66db832f345"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.0, 0.4)"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x720 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plotting loss and val_loss vs epochs\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20,10))\n",
        "fig.suptitle('History Epochs - Loss')\n",
        "\n",
        "ax1.plot(range(100),output.history['loss'],output.history['val_loss'])\n",
        "ax1.set(ylabel= \"Loss\", xlabel = \"epochs\")\n",
        "ax1.legend([\"Training\", \"Validation\"],loc = \"best\")\n",
        "ax1.set_ylim([0, 0.5])\n",
        "\n",
        "ax2.plot(range(100),output.history['loss'],output.history['val_loss'])\n",
        "ax2.set(ylabel= \"Loss\", xlabel = \"epochs\")\n",
        "ax2.legend([\"Training\", \"Validation\"],loc = \"best\")\n",
        "ax2.set_xlim([20,100])\n",
        "ax2.set_ylim([0, 0.4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        },
        "id": "6IO4sOcHWU4S",
        "outputId": "88037f79-cce8-4a84-de27-731adcab4194"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.94, 1.02)"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x720 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plotting accuracy and val_accuracy vs epochs\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20,10))\n",
        "fig.suptitle('History Epochs - Accuracy')\n",
        "\n",
        "ax1.plot(range(100),output.history['accuracy'],output.history['val_accuracy'])\n",
        "ax1.set(ylabel= \"Loss\", xlabel = \"epochs\")\n",
        "ax1.legend([\"Training\", \"Validation\"],loc = \"best\")\n",
        "ax1.set_ylim([0.7, 1.05])\n",
        "\n",
        "ax2.plot(range(100),output.history['accuracy'],output.history['val_accuracy'])\n",
        "ax2.set(ylabel= \"Loss\", xlabel = \"epochs\")\n",
        "ax2.legend([\"Training\", \"Validation\"],loc = \"best\")\n",
        "ax2.set_xlim([20,100])\n",
        "ax2.set_ylim([0.94, 1.02])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJlI5uKywPGe",
        "outputId": "03401ae8-cd3e-4047-c7b4-19e66db48df9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 1s 12ms/step - loss: 0.1288 - accuracy: 0.9974\n",
            "\n",
            "Test accuracy: 99.7%\n",
            "49/49 [==============================] - 1s 10ms/step - loss: 0.1189 - accuracy: 0.9994\n",
            "\\Train accuracy: 99.9%\n"
          ]
        }
      ],
      "source": [
        "_, acc = model2_.evaluate(X_test,\n",
        "                        y_test,\n",
        "                        batch_size=32)\n",
        "print(\"\\nTest accuracy: %.1f%%\" % (100.0 * acc))\n",
        "\n",
        "_, acc = model2_.evaluate(X_train,\n",
        "                        y_train,\n",
        "                        batch_size=32)\n",
        "print(\"\\Train accuracy: %.1f%%\" % (100.0 * acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 876
        },
        "id": "zNq9WT2ZwPGf",
        "outputId": "f420a3cf-9749-4464-a690-53c3ce2a5d61"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(0, 0.5, 'Normal'),\n",
              " Text(0, 1.5, 'Hor Mis'),\n",
              " Text(0, 2.5, 'Imbalance'),\n",
              " Text(0, 3.5, 'Ver Mis'),\n",
              " Text(0, 4.5, 'Overhang'),\n",
              " Text(0, 5.5, 'Underhang')]"
            ]
          },
          "metadata": {},
          "execution_count": 77
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x864 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# COnfusion matrix resulting\n",
        "\n",
        "y_pred = model2_.predict(X_test)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "underhang_y_test_cm = np.argmax(y_test, axis = -1)\n",
        "matrix = confusion_matrix(underhang_y_test_cm, y_pred)\n",
        "\n",
        "figure = plt.figure(figsize = (12,12))\n",
        "\n",
        "ax = sns.heatmap(matrix, annot=True, cmap='Blues',fmt = 'g')\n",
        "\n",
        "ax.set_title('Underhang Test - Confusion Matrix\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted Values')\n",
        "ax.set_ylabel('Actual Values ');\n",
        "\n",
        "## Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels(['Normal','Hor Mis','Imbalance', 'Ver Mis', 'Overhang', 'Underhang'])\n",
        "ax.yaxis.set_ticklabels(['Normal','Hor Mis','Imbalance', 'Ver Mis', 'Overhang', 'Underhang'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7wuiSDSO_GQ",
        "outputId": "70644d38-006a-4283-8e6c-6546bf1a8d00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy for class Normal is: 100.0 % =  10 / 10\n",
            "The accuracy for class Hor Mis is: 100.0 % =  39 / 39\n",
            "The accuracy for class Imbalance is: 100.0 % =  67 / 67\n",
            "The accuracy for class Ver Mis is: 98.33 % =  59 / 60\n",
            "The accuracy for class Overhang is: 100.0 % =  103 / 103\n",
            "The accuracy for class Underhang is: 100.0 % =  112 / 112\n"
          ]
        }
      ],
      "source": [
        "# Accuracy per class\n",
        "names = ['Normal','Hor Mis','Imbalance', 'Ver Mis', 'Overhang', 'Underhang']\n",
        "\n",
        "for i in range(6):\n",
        "  ac =0\n",
        "  tot = 0\n",
        "  for j in range(6):\n",
        "    if i == j:\n",
        "      ac += matrix[i][j]\n",
        "      tot += matrix[i][j]\n",
        "    else:\n",
        "      tot += matrix[i][j]\n",
        "\n",
        "  print(\"The accuracy for class\", names[i], 'is:', round(100*ac/tot, 2), '% = ', ac, '/', tot)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DAwRM5IR2vM"
      },
      "source": [
        "### Explainability using Grad - CAM techniques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wD4ugXy0QXDI"
      },
      "outputs": [],
      "source": [
        "# Needed for visualization\n",
        "\n",
        "layer_name = \"conv1d_24\"  # last layer\n",
        "cnt = 0\n",
        "xticks = [int(xf[i]) for i in range(0, input_size, 749)]\n",
        "ticks = [i for i in range(0, input_size, 749)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05iLx9EYFvLF",
        "outputId": "61b5d8b3-9d40-4431-ed69-bbaf67861bf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: UserWarning: Attempting to set identical bottom == top == 0.0 results in singular transformations; automatically expanding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "390\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: UserWarning: Attempting to set identical bottom == top == 0.0 results in singular transformations; automatically expanding.\n"
          ]
        }
      ],
      "source": [
        "###########################################################################\n",
        "# Independent heatmaps for each data point\n",
        "###########################################################################\n",
        "\n",
        "cnt_2 = 0\n",
        "\n",
        "for i in X_test:\n",
        "    data = np.expand_dims(i,0)\n",
        "    pred = model2_.predict(data)\n",
        "    # Printing a class in particular\n",
        "    actual_class = np.argmax(y_test[cnt_2])\n",
        "\n",
        "\n",
        "    if np.argmax(pred) != actual_class:\n",
        "\n",
        "      heatmap = grad_cam(layer_name,data)\n",
        "\n",
        "      fig1, (ax1) = plt.subplots(1, sharex = True, figsize = (30,10))\n",
        "\n",
        "      ###########################################################################\n",
        "      # AX1 - CNN selection with stacked data\n",
        "      ###########################################################################\n",
        "\n",
        "      ax1.imshow(heatmap, cmap='Reds', aspect=\"auto\" ,extent=[0,5000,i.min(),i.max()], alpha=0.8)\n",
        "      ax1.plot(i,'k')\n",
        "      ax1.set_ylabel('Normalised Amplitud frequency')\n",
        "      ax1.set_title('HeatMap for Incorrect data point')\n",
        "\n",
        "      # Plotting 7 plots:\n",
        "      # - Stacking on all 6 frequencies\n",
        "      # - Axial/Radial/Tangencial Underhang Accelerometer\n",
        "      # - Axial/Radial/Tangencial Overhang Accelerometer\n",
        "\n",
        "      ###########################################################################\n",
        "      # AX2 - Stacked data with colors\n",
        "      ###########################################################################\n",
        "\n",
        "\n",
        "      # df = pd.DataFrame(i)\n",
        "\n",
        "      # ax2.plot(df.iloc[:,0], label = 'AxialUn')\n",
        "      # ax2.plot(df.iloc[:,1], label = 'RadialUn')\n",
        "      # ax2.plot(df.iloc[:,2], label = 'TangUn')\n",
        "      # ax2.plot(df.iloc[:,3], label = 'AxialOv')\n",
        "      # ax2.plot(df.iloc[:,4], label = 'RadialOv')\n",
        "      # ax2.plot(df.iloc[:,5], label = 'TangOv')\n",
        "      # ax2.set_title('Stacked data with colors')\n",
        "      # ax2.set_xlabel('Frequency (Hz)')\n",
        "      # ax2.set_xticks(ticks = ticks)\n",
        "      # ax2.set_xticklabels(xticks)\n",
        "      # ax2.set_ylabel('Normalised Amplitud frequency')\n",
        "      # ax2.legend()\n",
        "\n",
        "\n",
        "      fig1.savefig(directories[6] + '/' + str(cnt)+'_PlotStacked.png')\n",
        "      plt.close()\n",
        "\n",
        "      # Saving photos\n",
        "      ###########################################<################\n",
        "      # if names[np.argmax(pred)] != names[np.argmax(y_test[cnt])]:\n",
        "      #   fig1.savefig(directories[6] + '/' + str(cnt)+'_PlotStacked.png')\n",
        "      #   plt.close()\n",
        "      # else:\n",
        "      #   image_allocation(np.argmax(pred), fig1)\n",
        "      ##############################################################\n",
        "\n",
        "\n",
        "      ###########################################################################\n",
        "      # AX1 - 6 remaining graphs regarding accelerometer\n",
        "      ###########################################################################\n",
        "\n",
        "      # fig2, (ax1, ax2, ax3, ax4, ax5, ax6) = plt.subplots(6, sharex = True, figsize = (30,30))\n",
        "\n",
        "      # ax1.imshow(heatmap,cmap='Greens', aspect=\"auto\", interpolation='nearest',extent=[0,7509,i.min(),i.max()], alpha=0.8)\n",
        "      # ax1.plot(df.iloc[:,0], 'k', label = 'AxialUn')\n",
        "      # ax1.set_title('Axial - Underhang Accelerometer')\n",
        "      # ax1.set_ylabel('Normalised Amplitud frequency')\n",
        "\n",
        "      # ax2.imshow(heatmap,cmap='Greens', aspect=\"auto\", interpolation='nearest',extent=[0,7509,i.min(),i.max()], alpha=0.8)\n",
        "      # ax2.plot(df.iloc[:,1], 'k', label = 'RadialUn')\n",
        "      # ax2.set_title('Radiale - Underhang Accelerometer')\n",
        "      # ax2.set_ylabel('Normalised Amplitud frequency')\n",
        "\n",
        "      # ax3.imshow(heatmap,cmap='Greens', aspect=\"auto\", interpolation='nearest',extent=[0,7509,i.min(),i.max()], alpha=0.8)\n",
        "      # ax3.plot(df.iloc[:,2], 'k', label = 'TangUn')\n",
        "      # ax3.set_title('Tangencial - Underhang Accelerometer')\n",
        "      # ax3.set_ylabel('Normalised Amplitud frequency')\n",
        "\n",
        "      # ax4.imshow(heatmap,cmap='Greens', aspect=\"auto\", interpolation='nearest',extent=[0,7509,i.min(),i.max()], alpha=0.8)\n",
        "      # ax4.plot(df.iloc[:,3], 'k', label = 'AxialOv')\n",
        "      # ax4.set_title('Axial - Overhang Accelerometer')\n",
        "      # ax4.set_ylabel('Normalised Amplitud frequency')\n",
        "\n",
        "      # ax5.imshow(heatmap,cmap='Greens', aspect=\"auto\", interpolation='nearest',extent=[0,7509,i.min(),i.max()], alpha=0.8)\n",
        "      # ax5.plot(df.iloc[:,4], 'k', label = 'RadialOv')\n",
        "      # ax5.set_title('Radiale - Underhang Accelerometer')\n",
        "      # ax5.set_ylabel('Normalised Amplitud frequency')\n",
        "\n",
        "      # ax6.imshow(heatmap,cmap='Greens', aspect=\"auto\", interpolation='nearest',extent=[0,7509,i.min(),i.max()], alpha=0.8)\n",
        "      # ax6.plot(df.iloc[:,5], 'k', label = 'TangOv')\n",
        "      # ax6.set_title('Tangecial - Underhang Accelerometer')\n",
        "      # ax6.set_xlabel('Frequency (Hz)')\n",
        "      # ax6.set_xlim([0,7509])\n",
        "      # ax6.set_ylabel('Normalised Amplitud frequency')\n",
        "      # ax6.set_xticks(ticks = ticks)\n",
        "      # ax6.set_xticklabels(xticks)\n",
        "\n",
        "      # # Saving photos\n",
        "      # ###########################################<################\n",
        "      # if names[np.argmax(pred)] != names[np.argmax(y_test[cnt])]:\n",
        "      #   fig2.savefig(directories[6]+ '/' +str(cnt)+'_Plot6Accelerometer.png')\n",
        "      #   plt.close()\n",
        "      # else:\n",
        "      #   image_allocation(np.argmax(pred), fig2, stacked = False)\n",
        "      # ##############################################################\n",
        "\n",
        "    cnt_2 += 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZX4qy5ELfCXS"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "################################################################\n",
        "# Training + Test\n",
        "################################################################\n",
        "\n",
        "X = np.moveaxis(new_signal2, 0, -1)\n",
        "y = to_categorical(underhang_y)\n",
        "average_spectrum(X, y, 'Tran_Test', model2_ = model2_)\n",
        "average_heatmap(X, y, 'Train_Test', model2_ = model2_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sltMVQebgv4M"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "################################################################\n",
        "# Training\n",
        "################################################################\n",
        "\n",
        "average_heatmap(X_train, y_train, 'Train', model2_ = model2_)\n",
        "average_spectrum(X_train, y_train, 'Train', model2_ = model2_)\n",
        "\n",
        "################################################################\n",
        "# Test\n",
        "################################################################\n",
        "\n",
        "average_heatmap(X_test, y_test, 'Test', model2_ = model2_)\n",
        "average_spectrum(X_test, y_test, 'Test', model2_ = model2_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVh7fojfvQoO"
      },
      "source": [
        "## Hyperparametrizing CNN using Talos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTi8kMZ6vcQZ"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install talos\n",
        "!pip install wrangle\n",
        "import talos\n",
        "import wrangle\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "\n",
        "# set the parameter space boundary\n",
        "p = {'activation':['relu'],\n",
        "     'optimizer': ['Adam'],\n",
        "     'kernel_size_1':[7, 9, 11, 13],\n",
        "     'kernel_size_2':[7, 9, 11, 13],\n",
        "     'kernel_size_3':[7, 9, 11, 13],\n",
        "     'learning_rate' : [1e-03, 1e-02, 1e-04, 1e-05],\n",
        "     'pool_size' : [2,3,4],\n",
        "     'padding': ['same'],\n",
        "     'strides': [1],\n",
        "     'filters_1': [16, 32, 64, 128],\n",
        "     'filters_2': [16, 32, 64, 128],\n",
        "     'filters_3': [16, 32, 64, 128],\n",
        "     'dropout': [.01, 0.1, 0.05],\n",
        "     'batch_size': [8]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHhYVeidYZlJ"
      },
      "outputs": [],
      "source": [
        "# Saving best model - call back\n",
        "# Note: it should be outside the function to make it globally for all the models\n",
        "\n",
        "checkpoint_filepath = '/content/drive/MyDrive/hyper_CNN.hdf5'\n",
        "save_best_model = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath = checkpoint_filepath,\n",
        "    monitor=\"val_accuracy\",\n",
        "    verbose=1,\n",
        "    save_best_only=True,\n",
        "    mode=\"auto\",\n",
        "    save_freq=\"epoch\",\n",
        "    options=None,\n",
        "    initial_value_threshold=None\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8AUT4KF1vTyj"
      },
      "outputs": [],
      "source": [
        "# Obtaining the same model as described in the paper\n",
        "\n",
        "def model_CNN(X_train, y_train, X_test, y_test, params):\n",
        "\n",
        "  num_errors = 6\n",
        "  input_shape = (input_size,6)\n",
        "\n",
        "  model2_ =  Sequential([\n",
        "                      Conv1D(filters=params['filters_1'],\n",
        "                                      kernel_size=params['kernel_size_1'],\n",
        "                                      activation= params['activation'],\n",
        "                                      input_shape=input_shape,\n",
        "                                      padding = params['padding'],\n",
        "                                      strides = params['strides'],\n",
        "                                      kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4),\n",
        "                                      bias_regularizer=regularizers.L2(1e-4),\n",
        "                                      activity_regularizer=regularizers.L2(1e-5)),\n",
        "\n",
        "                      BatchNormalization(),\n",
        "\n",
        "                      Dropout(params['dropout']),\n",
        "\n",
        "                      Conv1D(filters=params['filters_2'],\n",
        "                                      kernel_size=params['kernel_size_2'],\n",
        "                                      activation= params['activation'],\n",
        "                                      input_shape=input_shape,\n",
        "                                      padding = params['padding'],\n",
        "                                      strides = params['strides'],\n",
        "                                      kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4),\n",
        "                                      bias_regularizer=regularizers.L2(1e-4),\n",
        "                                      activity_regularizer=regularizers.L2(1e-5)),\n",
        "\n",
        "                      MaxPooling1D(params['pool_size']),\n",
        "\n",
        "                      BatchNormalization(),\n",
        "\n",
        "                      Conv1D(filters=params['filters_3'],\n",
        "                                      kernel_size=params['kernel_size_3'],\n",
        "                                      activation= params['activation'],\n",
        "                                      input_shape=input_shape,\n",
        "                                      padding = params['padding'],\n",
        "                                      strides = params['strides'],\n",
        "                                      kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4),\n",
        "                                      bias_regularizer=regularizers.L2(1e-4),\n",
        "                                      activity_regularizer=regularizers.L2(1e-5)),\n",
        "\n",
        "                      MaxPooling1D(params['pool_size']),\n",
        "\n",
        "                      # dropout added as regularizer\n",
        "                      Dropout(params['dropout']),\n",
        "\n",
        "                      Conv1D(filters=params['filters_2'],\n",
        "                                      kernel_size=params['kernel_size_2'],\n",
        "                                      activation= params['activation'],\n",
        "                                      input_shape=input_shape,\n",
        "                                      padding = params['padding'],\n",
        "                                      strides = params['strides'],\n",
        "                                      kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4),\n",
        "                                      bias_regularizer=regularizers.L2(1e-4),\n",
        "                                      activity_regularizer=regularizers.L2(1e-5)),\n",
        "\n",
        "                      MaxPooling1D(params['pool_size']),\n",
        "\n",
        "                      Conv1D(filters=params['filters_1'],\n",
        "                                      kernel_size=params['kernel_size_1'],\n",
        "                                      activation= params['activation'],\n",
        "                                      input_shape=input_shape,\n",
        "                                      padding = params['padding'],\n",
        "                                      strides = params['strides'],\n",
        "                                      kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4),\n",
        "                                      bias_regularizer=regularizers.L2(1e-4),\n",
        "                                      activity_regularizer=regularizers.L2(1e-5)),\n",
        "\n",
        "                      MaxPooling1D(params['pool_size']),\n",
        "\n",
        "\n",
        "                      Flatten(),\n",
        "\n",
        "                      Dense(num_errors),\n",
        "                      Activation('softmax')\n",
        "\n",
        "    ])\n",
        "\n",
        "  early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    patience=5,\n",
        "    verbose=1,\n",
        "    mode=\"auto\"\n",
        "  )\n",
        "\n",
        "  opt = tf.keras.optimizers.Adam(\n",
        "    learning_rate= params['learning_rate'],\n",
        "    beta_1=0.9,\n",
        "    beta_2=0.999,\n",
        "    epsilon=1e-07,\n",
        "    amsgrad=False,\n",
        "    name=\"Adam\"\n",
        "  )\n",
        "\n",
        "  model2_.compile(loss='CategoricalCrossentropy',\n",
        "                optimizer= opt,\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  # train the network\n",
        "  output = model2_.fit(X_train, y_train, epochs = 50, batch_size=params['batch_size'],\n",
        "                      validation_data = (X_test , y_test),\n",
        "                      callbacks = [early_stopping, save_best_model])\n",
        "\n",
        "  return output, model2_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeN3OsVPy1cT",
        "outputId": "7e183eec-0b48-4922-84e5-2cfb666490ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.9291 - accuracy: 0.5052\n",
            "Epoch 1: val_accuracy improved from -inf to 0.26343, saving model to /content/drive/MyDrive/hyper_CNN.hdf5\n",
            "195/195 [==============================] - 6s 21ms/step - loss: 1.9264 - accuracy: 0.5064 - val_loss: 1.8482 - val_accuracy: 0.2634\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.1918 - accuracy: 0.8161\n",
            "Epoch 2: val_accuracy improved from 0.26343 to 0.29668, saving model to /content/drive/MyDrive/hyper_CNN.hdf5\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 1.1895 - accuracy: 0.8179 - val_loss: 1.8292 - val_accuracy: 0.2967\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8416 - accuracy: 0.9210\n",
            "Epoch 3: val_accuracy improved from 0.29668 to 0.60614, saving model to /content/drive/MyDrive/hyper_CNN.hdf5\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.8404 - accuracy: 0.9218 - val_loss: 1.4015 - val_accuracy: 0.6061\n",
            "Epoch 4/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.6769 - accuracy: 0.9479\n",
            "Epoch 4: val_accuracy improved from 0.60614 to 0.97954, saving model to /content/drive/MyDrive/hyper_CNN.hdf5\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.6756 - accuracy: 0.9474 - val_loss: 0.6213 - val_accuracy: 0.9795\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5654 - accuracy: 0.9702\n",
            "Epoch 5: val_accuracy improved from 0.97954 to 0.98721, saving model to /content/drive/MyDrive/hyper_CNN.hdf5\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.5650 - accuracy: 0.9705 - val_loss: 0.5184 - val_accuracy: 0.9872\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4996 - accuracy: 0.9825\n",
            "Epoch 6: val_accuracy improved from 0.98721 to 0.98977, saving model to /content/drive/MyDrive/hyper_CNN.hdf5\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.4989 - accuracy: 0.9827 - val_loss: 0.4478 - val_accuracy: 0.9898\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4413 - accuracy: 0.9890\n",
            "Epoch 7: val_accuracy improved from 0.98977 to 0.99233, saving model to /content/drive/MyDrive/hyper_CNN.hdf5\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.4418 - accuracy: 0.9885 - val_loss: 0.4135 - val_accuracy: 0.9923\n",
            "Epoch 8/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3973 - accuracy: 0.9896\n",
            "Epoch 8: val_accuracy did not improve from 0.99233\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.3960 - accuracy: 0.9897 - val_loss: 0.3738 - val_accuracy: 0.9898\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3661 - accuracy: 0.9922\n",
            "Epoch 9: val_accuracy did not improve from 0.99233\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.3657 - accuracy: 0.9923 - val_loss: 0.3723 - val_accuracy: 0.9872\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3380 - accuracy: 0.9929\n",
            "Epoch 10: val_accuracy improved from 0.99233 to 0.99488, saving model to /content/drive/MyDrive/hyper_CNN.hdf5\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.3376 - accuracy: 0.9929 - val_loss: 0.3252 - val_accuracy: 0.9949\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3081 - accuracy: 0.9922\n",
            "Epoch 11: val_accuracy did not improve from 0.99488\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.3081 - accuracy: 0.9923 - val_loss: 0.2996 - val_accuracy: 0.9898\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2878 - accuracy: 0.9935\n",
            "Epoch 12: val_accuracy did not improve from 0.99488\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.2875 - accuracy: 0.9936 - val_loss: 0.2794 - val_accuracy: 0.9898\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2703 - accuracy: 0.9942\n",
            "Epoch 13: val_accuracy did not improve from 0.99488\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.2702 - accuracy: 0.9942 - val_loss: 0.2695 - val_accuracy: 0.9898\n",
            "Epoch 14/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2454 - accuracy: 0.9974\n",
            "Epoch 14: val_accuracy did not improve from 0.99488\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.2453 - accuracy: 0.9974 - val_loss: 0.2406 - val_accuracy: 0.9949\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2339 - accuracy: 0.9955\n",
            "Epoch 15: val_accuracy did not improve from 0.99488\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.2338 - accuracy: 0.9955 - val_loss: 0.2257 - val_accuracy: 0.9949\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2254 - accuracy: 0.9948\n",
            "Epoch 16: val_accuracy did not improve from 0.99488\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.2267 - accuracy: 0.9942 - val_loss: 0.2170 - val_accuracy: 0.9923\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2088 - accuracy: 0.9994\n",
            "Epoch 17: val_accuracy did not improve from 0.99488\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.2086 - accuracy: 0.9994 - val_loss: 0.2048 - val_accuracy: 0.9923\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1984 - accuracy: 0.9994\n",
            "Epoch 18: val_accuracy did not improve from 0.99488\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1986 - accuracy: 0.9994 - val_loss: 0.1990 - val_accuracy: 0.9923\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1963 - accuracy: 0.9968\n",
            "Epoch 19: val_accuracy did not improve from 0.99488\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1961 - accuracy: 0.9968 - val_loss: 0.2055 - val_accuracy: 0.9923\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1839 - accuracy: 0.9987\n",
            "Epoch 20: val_accuracy did not improve from 0.99488\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1836 - accuracy: 0.9987 - val_loss: 0.1930 - val_accuracy: 0.9923\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1769 - accuracy: 0.9981\n",
            "Epoch 21: val_accuracy did not improve from 0.99488\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1769 - accuracy: 0.9981 - val_loss: 0.1794 - val_accuracy: 0.9923\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1693 - accuracy: 0.9994\n",
            "Epoch 22: val_accuracy did not improve from 0.99488\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1692 - accuracy: 0.9994 - val_loss: 0.2007 - val_accuracy: 0.9872\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1690 - accuracy: 0.9981\n",
            "Epoch 23: val_accuracy did not improve from 0.99488\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1694 - accuracy: 0.9981 - val_loss: 0.1682 - val_accuracy: 0.9923\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1604 - accuracy: 1.0000\n",
            "Epoch 24: val_accuracy did not improve from 0.99488\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1602 - accuracy: 1.0000 - val_loss: 0.1670 - val_accuracy: 0.9923\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1565 - accuracy: 0.9974\n",
            "Epoch 25: val_accuracy did not improve from 0.99488\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1564 - accuracy: 0.9974 - val_loss: 0.1626 - val_accuracy: 0.9923\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1518 - accuracy: 0.9994\n",
            "Epoch 26: val_accuracy did not improve from 0.99488\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1517 - accuracy: 0.9994 - val_loss: 0.1653 - val_accuracy: 0.9898\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1474 - accuracy: 0.9994\n",
            "Epoch 27: val_accuracy did not improve from 0.99488\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1481 - accuracy: 0.9994 - val_loss: 0.1587 - val_accuracy: 0.9923\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1425 - accuracy: 1.0000\n",
            "Epoch 28: val_accuracy did not improve from 0.99488\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1425 - accuracy: 1.0000 - val_loss: 0.1559 - val_accuracy: 0.9923\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1416 - accuracy: 0.9981\n",
            "Epoch 29: val_accuracy did not improve from 0.99488\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1414 - accuracy: 0.9981 - val_loss: 0.1563 - val_accuracy: 0.9923\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1376 - accuracy: 1.0000\n",
            "Epoch 30: val_accuracy did not improve from 0.99488\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1376 - accuracy: 1.0000 - val_loss: 0.1578 - val_accuracy: 0.9898\n",
            "Epoch 31/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1325 - accuracy: 1.0000\n",
            "Epoch 31: val_accuracy did not improve from 0.99488\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1323 - accuracy: 1.0000 - val_loss: 0.1444 - val_accuracy: 0.9923\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1300 - accuracy: 1.0000\n",
            "Epoch 32: val_accuracy did not improve from 0.99488\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1300 - accuracy: 1.0000 - val_loss: 0.1425 - val_accuracy: 0.9949\n",
            "Epoch 33/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1266 - accuracy: 1.0000\n",
            "Epoch 33: val_accuracy did not improve from 0.99488\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1265 - accuracy: 1.0000 - val_loss: 0.1411 - val_accuracy: 0.9923\n",
            "Epoch 34/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1236 - accuracy: 1.0000\n",
            "Epoch 34: val_accuracy did not improve from 0.99488\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1236 - accuracy: 1.0000 - val_loss: 0.1382 - val_accuracy: 0.9949\n",
            "Epoch 35/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1248 - accuracy: 1.0000\n",
            "Epoch 35: val_accuracy did not improve from 0.99488\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1247 - accuracy: 1.0000 - val_loss: 0.1343 - val_accuracy: 0.9949\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1196 - accuracy: 1.0000\n",
            "Epoch 36: val_accuracy improved from 0.99488 to 0.99744, saving model to /content/drive/MyDrive/hyper_CNN.hdf5\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1196 - accuracy: 1.0000 - val_loss: 0.1314 - val_accuracy: 0.9974\n",
            "Epoch 37/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1144 - accuracy: 1.0000\n",
            "Epoch 37: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1145 - accuracy: 1.0000 - val_loss: 0.1352 - val_accuracy: 0.9923\n",
            "Epoch 38/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1126 - accuracy: 1.0000\n",
            "Epoch 38: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1127 - accuracy: 1.0000 - val_loss: 0.1329 - val_accuracy: 0.9898\n",
            "Epoch 39/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1106 - accuracy: 1.0000\n",
            "Epoch 39: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1106 - accuracy: 1.0000 - val_loss: 0.1232 - val_accuracy: 0.9949\n",
            "Epoch 40/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1091 - accuracy: 1.0000\n",
            "Epoch 40: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1091 - accuracy: 1.0000 - val_loss: 0.1324 - val_accuracy: 0.9898\n",
            "Epoch 41/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1129 - accuracy: 0.9987\n",
            "Epoch 41: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1128 - accuracy: 0.9987 - val_loss: 0.1451 - val_accuracy: 0.9898\n",
            "Epoch 42/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1118 - accuracy: 1.0000\n",
            "Epoch 42: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1117 - accuracy: 1.0000 - val_loss: 0.1236 - val_accuracy: 0.9974\n",
            "Epoch 43/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1054 - accuracy: 1.0000\n",
            "Epoch 43: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1054 - accuracy: 1.0000 - val_loss: 0.1228 - val_accuracy: 0.9949\n",
            "Epoch 44/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1027 - accuracy: 1.0000\n",
            "Epoch 44: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1028 - accuracy: 1.0000 - val_loss: 0.1180 - val_accuracy: 0.9974\n",
            "Epoch 45/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1012 - accuracy: 1.0000\n",
            "Epoch 45: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1011 - accuracy: 1.0000 - val_loss: 0.1166 - val_accuracy: 0.9974\n",
            "Epoch 46/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0986 - accuracy: 1.0000\n",
            "Epoch 46: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0987 - accuracy: 1.0000 - val_loss: 0.1137 - val_accuracy: 0.9974\n",
            "Epoch 47/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0973 - accuracy: 1.0000\n",
            "Epoch 47: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0973 - accuracy: 1.0000 - val_loss: 0.1140 - val_accuracy: 0.9974\n",
            "Epoch 48/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0944 - accuracy: 1.0000\n",
            "Epoch 48: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0944 - accuracy: 1.0000 - val_loss: 0.1103 - val_accuracy: 0.9974\n",
            "Epoch 49/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0917 - accuracy: 1.0000\n",
            "Epoch 49: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0917 - accuracy: 1.0000 - val_loss: 0.1084 - val_accuracy: 0.9949\n",
            "Epoch 50/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0922 - accuracy: 0.9994\n",
            "Epoch 50: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0926 - accuracy: 0.9994 - val_loss: 0.1231 - val_accuracy: 0.9898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/0/assets\n",
            " 16%|█▌        | 31/200 [1:11:11<6:28:06, 137.79s/it]\n",
            "\n",
            "\n",
            "  0%|          | 1/200 [03:27<11:27:26, 207.27s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.7967 - accuracy: 0.5322\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 22ms/step - loss: 1.7923 - accuracy: 0.5346 - val_loss: 1.7439 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8539 - accuracy: 0.8860\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.8519 - accuracy: 0.8865 - val_loss: 1.6622 - val_accuracy: 0.3453\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5506 - accuracy: 0.9754\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.5490 - accuracy: 0.9756 - val_loss: 0.7619 - val_accuracy: 0.9233\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4483 - accuracy: 0.9819\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.4475 - accuracy: 0.9821 - val_loss: 0.4087 - val_accuracy: 0.9898\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3656 - accuracy: 0.9929\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.3651 - accuracy: 0.9929 - val_loss: 0.3464 - val_accuracy: 0.9847\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3189 - accuracy: 0.9929\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.3184 - accuracy: 0.9929 - val_loss: 0.2966 - val_accuracy: 0.9923\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2755 - accuracy: 0.9968\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2748 - accuracy: 0.9968 - val_loss: 0.2644 - val_accuracy: 0.9949\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2387 - accuracy: 0.9987\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2384 - accuracy: 0.9987 - val_loss: 0.2228 - val_accuracy: 0.9949\n",
            "Epoch 9/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2149 - accuracy: 0.9981\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2147 - accuracy: 0.9981 - val_loss: 0.2045 - val_accuracy: 0.9949\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1955 - accuracy: 0.9974\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1957 - accuracy: 0.9974 - val_loss: 0.1920 - val_accuracy: 0.9974\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1749 - accuracy: 0.9987\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1748 - accuracy: 0.9987 - val_loss: 0.1790 - val_accuracy: 0.9923\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1623 - accuracy: 0.9981\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1620 - accuracy: 0.9981 - val_loss: 0.1653 - val_accuracy: 0.9974\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1497 - accuracy: 0.9994\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1496 - accuracy: 0.9994 - val_loss: 0.1526 - val_accuracy: 0.9974\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1406 - accuracy: 0.9987\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1403 - accuracy: 0.9987 - val_loss: 0.1407 - val_accuracy: 0.9974\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1325 - accuracy: 0.9987\n",
            "Epoch 15: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1325 - accuracy: 0.9987 - val_loss: 0.1358 - val_accuracy: 0.9974\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1236 - accuracy: 0.9994\n",
            "Epoch 16: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1235 - accuracy: 0.9994 - val_loss: 0.1297 - val_accuracy: 0.9974\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1177 - accuracy: 0.9994\n",
            "Epoch 17: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1177 - accuracy: 0.9994 - val_loss: 0.1251 - val_accuracy: 0.9974\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1120 - accuracy: 0.9994\n",
            "Epoch 18: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1119 - accuracy: 0.9994 - val_loss: 0.1208 - val_accuracy: 0.9974\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1071 - accuracy: 1.0000\n",
            "Epoch 19: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1072 - accuracy: 1.0000 - val_loss: 0.1162 - val_accuracy: 0.9974\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1024 - accuracy: 1.0000\n",
            "Epoch 20: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1024 - accuracy: 1.0000 - val_loss: 0.1181 - val_accuracy: 0.9923\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0986 - accuracy: 1.0000\n",
            "Epoch 21: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0986 - accuracy: 1.0000 - val_loss: 0.1109 - val_accuracy: 0.9974\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0957 - accuracy: 1.0000\n",
            "Epoch 22: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0957 - accuracy: 1.0000 - val_loss: 0.1080 - val_accuracy: 0.9974\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0920 - accuracy: 1.0000\n",
            "Epoch 23: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0920 - accuracy: 1.0000 - val_loss: 0.1071 - val_accuracy: 0.9923\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0960 - accuracy: 0.9987\n",
            "Epoch 24: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0958 - accuracy: 0.9987 - val_loss: 0.1039 - val_accuracy: 0.9949\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0873 - accuracy: 1.0000\n",
            "Epoch 25: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0873 - accuracy: 1.0000 - val_loss: 0.1039 - val_accuracy: 0.9949\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0850 - accuracy: 1.0000\n",
            "Epoch 26: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0851 - accuracy: 1.0000 - val_loss: 0.0972 - val_accuracy: 0.9949\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0843 - accuracy: 1.0000\n",
            "Epoch 27: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0843 - accuracy: 1.0000 - val_loss: 0.0949 - val_accuracy: 0.9974\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0792 - accuracy: 1.0000\n",
            "Epoch 28: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0791 - accuracy: 1.0000 - val_loss: 0.0956 - val_accuracy: 0.9949\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0790 - accuracy: 1.0000\n",
            "Epoch 29: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0793 - accuracy: 1.0000 - val_loss: 0.0982 - val_accuracy: 0.9974\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0836 - accuracy: 0.9981\n",
            "Epoch 30: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0835 - accuracy: 0.9981 - val_loss: 0.1012 - val_accuracy: 0.9949\n",
            "Epoch 31/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0750 - accuracy: 1.0000\n",
            "Epoch 31: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0749 - accuracy: 1.0000 - val_loss: 0.0905 - val_accuracy: 0.9949\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0717 - accuracy: 1.0000\n",
            "Epoch 32: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0716 - accuracy: 1.0000 - val_loss: 0.0905 - val_accuracy: 0.9974\n",
            "Epoch 33/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0715 - accuracy: 1.0000\n",
            "Epoch 33: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0714 - accuracy: 1.0000 - val_loss: 0.0873 - val_accuracy: 0.9949\n",
            "Epoch 34/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0686 - accuracy: 1.0000\n",
            "Epoch 34: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0686 - accuracy: 1.0000 - val_loss: 0.0850 - val_accuracy: 0.9949\n",
            "Epoch 35/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0673 - accuracy: 1.0000\n",
            "Epoch 35: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0673 - accuracy: 1.0000 - val_loss: 0.0885 - val_accuracy: 0.9974\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0655 - accuracy: 1.0000\n",
            "Epoch 36: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0655 - accuracy: 1.0000 - val_loss: 0.0860 - val_accuracy: 0.9923\n",
            "Epoch 37/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0642 - accuracy: 1.0000\n",
            "Epoch 37: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0642 - accuracy: 1.0000 - val_loss: 0.0817 - val_accuracy: 0.9974\n",
            "Epoch 38/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0625 - accuracy: 1.0000\n",
            "Epoch 38: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0625 - accuracy: 1.0000 - val_loss: 0.0830 - val_accuracy: 0.9974\n",
            "Epoch 39/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0630 - accuracy: 1.0000\n",
            "Epoch 39: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0630 - accuracy: 1.0000 - val_loss: 0.0829 - val_accuracy: 0.9949\n",
            "Epoch 40/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0616 - accuracy: 1.0000\n",
            "Epoch 40: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0616 - accuracy: 1.0000 - val_loss: 0.0816 - val_accuracy: 0.9949\n",
            "Epoch 41/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0578 - accuracy: 1.0000\n",
            "Epoch 41: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0578 - accuracy: 1.0000 - val_loss: 0.0776 - val_accuracy: 0.9949\n",
            "Epoch 42/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0561 - accuracy: 1.0000\n",
            "Epoch 42: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0561 - accuracy: 1.0000 - val_loss: 0.0766 - val_accuracy: 0.9974\n",
            "Epoch 43/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0951 - accuracy: 0.9890\n",
            "Epoch 43: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0950 - accuracy: 0.9891 - val_loss: 0.1114 - val_accuracy: 0.9898\n",
            "Epoch 44/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0691 - accuracy: 0.9987\n",
            "Epoch 44: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0690 - accuracy: 0.9987 - val_loss: 0.0796 - val_accuracy: 0.9949\n",
            "Epoch 45/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0594 - accuracy: 1.0000\n",
            "Epoch 45: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0594 - accuracy: 1.0000 - val_loss: 0.0806 - val_accuracy: 0.9949\n",
            "Epoch 46/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0568 - accuracy: 1.0000\n",
            "Epoch 46: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0568 - accuracy: 1.0000 - val_loss: 0.0757 - val_accuracy: 0.9949\n",
            "Epoch 47/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0555 - accuracy: 1.0000\n",
            "Epoch 47: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0555 - accuracy: 1.0000 - val_loss: 0.0775 - val_accuracy: 0.9949\n",
            "Epoch 48/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0534 - accuracy: 1.0000\n",
            "Epoch 48: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0534 - accuracy: 1.0000 - val_loss: 0.0725 - val_accuracy: 0.9949\n",
            "Epoch 49/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0533 - accuracy: 1.0000\n",
            "Epoch 49: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0533 - accuracy: 1.0000 - val_loss: 0.0741 - val_accuracy: 0.9949\n",
            "Epoch 50/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0508 - accuracy: 1.0000\n",
            "Epoch 50: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0508 - accuracy: 1.0000 - val_loss: 0.0729 - val_accuracy: 0.9949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/1/assets\n",
            "\n",
            "\n",
            "  1%|          | 2/200 [06:50<11:15:58, 204.84s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.6985 - accuracy: 0.4056\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 12ms/step - loss: 1.6960 - accuracy: 0.4071 - val_loss: 1.7248 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.1663 - accuracy: 0.7212\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 1.1594 - accuracy: 0.7237 - val_loss: 1.8469 - val_accuracy: 0.3427\n",
            "Epoch 3/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.7886 - accuracy: 0.8547\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.7893 - accuracy: 0.8545 - val_loss: 1.7322 - val_accuracy: 0.4706\n",
            "Epoch 4/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.6149 - accuracy: 0.9220\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.6148 - accuracy: 0.9224 - val_loss: 0.7144 - val_accuracy: 0.8491\n",
            "Epoch 5/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5079 - accuracy: 0.9538\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.5079 - accuracy: 0.9538 - val_loss: 0.4690 - val_accuracy: 0.9591\n",
            "Epoch 6/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4186 - accuracy: 0.9782\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.4186 - accuracy: 0.9782 - val_loss: 0.4168 - val_accuracy: 0.9616\n",
            "Epoch 7/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3738 - accuracy: 0.9807\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.3740 - accuracy: 0.9801 - val_loss: 0.3643 - val_accuracy: 0.9719\n",
            "Epoch 8/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3299 - accuracy: 0.9852\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.3294 - accuracy: 0.9853 - val_loss: 0.3466 - val_accuracy: 0.9795\n",
            "Epoch 9/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.2965 - accuracy: 0.9908\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.2957 - accuracy: 0.9910 - val_loss: 0.3011 - val_accuracy: 0.9847\n",
            "Epoch 10/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.2705 - accuracy: 0.9901\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.2704 - accuracy: 0.9904 - val_loss: 0.2889 - val_accuracy: 0.9770\n",
            "Epoch 11/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.2476 - accuracy: 0.9935\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.2463 - accuracy: 0.9936 - val_loss: 0.2589 - val_accuracy: 0.9821\n",
            "Epoch 12/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.2316 - accuracy: 0.9948\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.2311 - accuracy: 0.9949 - val_loss: 0.2432 - val_accuracy: 0.9872\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2143 - accuracy: 0.9968\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.2147 - accuracy: 0.9968 - val_loss: 0.2221 - val_accuracy: 0.9923\n",
            "Epoch 14/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2024 - accuracy: 0.9961\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.2021 - accuracy: 0.9962 - val_loss: 0.2158 - val_accuracy: 0.9898\n",
            "Epoch 15/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1873 - accuracy: 0.9981\n",
            "Epoch 15: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1873 - accuracy: 0.9981 - val_loss: 0.2082 - val_accuracy: 0.9847\n",
            "Epoch 16/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1713 - accuracy: 0.9974\n",
            "Epoch 16: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1713 - accuracy: 0.9974 - val_loss: 0.1862 - val_accuracy: 0.9923\n",
            "Epoch 17/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1644 - accuracy: 0.9974\n",
            "Epoch 17: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1643 - accuracy: 0.9974 - val_loss: 0.1768 - val_accuracy: 0.9898\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1563 - accuracy: 0.9981\n",
            "Epoch 18: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1561 - accuracy: 0.9981 - val_loss: 0.1957 - val_accuracy: 0.9770\n",
            "Epoch 19/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1472 - accuracy: 0.9974\n",
            "Epoch 19: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1470 - accuracy: 0.9974 - val_loss: 0.1793 - val_accuracy: 0.9872\n",
            "Epoch 20/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.1389 - accuracy: 0.9987\n",
            "Epoch 20: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1387 - accuracy: 0.9987 - val_loss: 0.1519 - val_accuracy: 0.9923\n",
            "Epoch 21/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1307 - accuracy: 1.0000\n",
            "Epoch 21: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1307 - accuracy: 1.0000 - val_loss: 0.1509 - val_accuracy: 0.9872\n",
            "Epoch 22/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.1271 - accuracy: 0.9993\n",
            "Epoch 22: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1266 - accuracy: 0.9994 - val_loss: 0.1450 - val_accuracy: 0.9923\n",
            "Epoch 23/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1172 - accuracy: 0.9994\n",
            "Epoch 23: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1172 - accuracy: 0.9994 - val_loss: 0.1316 - val_accuracy: 0.9949\n",
            "Epoch 24/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1136 - accuracy: 0.9993\n",
            "Epoch 24: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1136 - accuracy: 0.9994 - val_loss: 0.1479 - val_accuracy: 0.9898\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1145 - accuracy: 0.9974\n",
            "Epoch 25: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1144 - accuracy: 0.9974 - val_loss: 0.1273 - val_accuracy: 0.9923\n",
            "Epoch 26/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1046 - accuracy: 1.0000\n",
            "Epoch 26: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1045 - accuracy: 1.0000 - val_loss: 0.1206 - val_accuracy: 0.9898\n",
            "Epoch 27/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0988 - accuracy: 0.9993\n",
            "Epoch 27: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0988 - accuracy: 0.9994 - val_loss: 0.1168 - val_accuracy: 0.9974\n",
            "Epoch 28/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0960 - accuracy: 0.9993\n",
            "Epoch 28: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0958 - accuracy: 0.9994 - val_loss: 0.1139 - val_accuracy: 0.9974\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0926 - accuracy: 1.0000\n",
            "Epoch 29: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0925 - accuracy: 1.0000 - val_loss: 0.1199 - val_accuracy: 0.9872\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0877 - accuracy: 1.0000\n",
            "Epoch 30: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0877 - accuracy: 1.0000 - val_loss: 0.1060 - val_accuracy: 0.9949\n",
            "Epoch 31/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0854 - accuracy: 1.0000\n",
            "Epoch 31: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0854 - accuracy: 1.0000 - val_loss: 0.1036 - val_accuracy: 0.9923\n",
            "Epoch 32/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0834 - accuracy: 0.9993\n",
            "Epoch 32: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0838 - accuracy: 0.9994 - val_loss: 0.0979 - val_accuracy: 0.9923\n",
            "Epoch 33/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.0798 - accuracy: 1.0000\n",
            "Epoch 33: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0799 - accuracy: 1.0000 - val_loss: 0.0971 - val_accuracy: 0.9949\n",
            "Epoch 34/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0785 - accuracy: 1.0000\n",
            "Epoch 34: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0785 - accuracy: 1.0000 - val_loss: 0.0970 - val_accuracy: 0.9923\n",
            "Epoch 35/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0753 - accuracy: 1.0000\n",
            "Epoch 35: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0753 - accuracy: 1.0000 - val_loss: 0.0898 - val_accuracy: 0.9949\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0778 - accuracy: 0.9981\n",
            "Epoch 36: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0778 - accuracy: 0.9981 - val_loss: 0.0929 - val_accuracy: 0.9949\n",
            "Epoch 37/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0721 - accuracy: 1.0000\n",
            "Epoch 37: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0720 - accuracy: 1.0000 - val_loss: 0.0861 - val_accuracy: 0.9974\n",
            "Epoch 38/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0687 - accuracy: 1.0000\n",
            "Epoch 38: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0688 - accuracy: 1.0000 - val_loss: 0.0817 - val_accuracy: 0.9949\n",
            "Epoch 39/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0677 - accuracy: 1.0000\n",
            "Epoch 39: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0677 - accuracy: 1.0000 - val_loss: 0.0835 - val_accuracy: 0.9949\n",
            "Epoch 40/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0656 - accuracy: 1.0000\n",
            "Epoch 40: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0655 - accuracy: 1.0000 - val_loss: 0.0834 - val_accuracy: 0.9949\n",
            "Epoch 41/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0655 - accuracy: 1.0000\n",
            "Epoch 41: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0655 - accuracy: 1.0000 - val_loss: 0.0832 - val_accuracy: 0.9923\n",
            "Epoch 42/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.0632 - accuracy: 1.0000\n",
            "Epoch 42: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0632 - accuracy: 1.0000 - val_loss: 0.0776 - val_accuracy: 0.9949\n",
            "Epoch 43/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0607 - accuracy: 1.0000\n",
            "Epoch 43: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0607 - accuracy: 1.0000 - val_loss: 0.0776 - val_accuracy: 0.9923\n",
            "Epoch 44/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0595 - accuracy: 1.0000\n",
            "Epoch 44: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0595 - accuracy: 1.0000 - val_loss: 0.0772 - val_accuracy: 0.9949\n",
            "Epoch 45/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 0.0582 - accuracy: 1.0000\n",
            "Epoch 45: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0582 - accuracy: 1.0000 - val_loss: 0.0791 - val_accuracy: 0.9923\n",
            "Epoch 46/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 0.0565 - accuracy: 1.0000\n",
            "Epoch 46: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0565 - accuracy: 1.0000 - val_loss: 0.0753 - val_accuracy: 0.9923\n",
            "Epoch 47/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0568 - accuracy: 1.0000\n",
            "Epoch 47: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0568 - accuracy: 1.0000 - val_loss: 0.0795 - val_accuracy: 0.9923\n",
            "Epoch 48/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0547 - accuracy: 1.0000\n",
            "Epoch 48: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0547 - accuracy: 1.0000 - val_loss: 0.0809 - val_accuracy: 0.9898\n",
            "Epoch 49/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0540 - accuracy: 1.0000\n",
            "Epoch 49: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0541 - accuracy: 1.0000 - val_loss: 0.0762 - val_accuracy: 0.9923\n",
            "Epoch 50/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0525 - accuracy: 1.0000\n",
            "Epoch 50: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0527 - accuracy: 1.0000 - val_loss: 0.0735 - val_accuracy: 0.9923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/2/assets\n",
            "\n",
            "\n",
            "  2%|▏         | 3/200 [09:17<9:46:15, 178.56s/it] \u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 2.1093 - accuracy: 0.2388\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 11ms/step - loss: 2.1034 - accuracy: 0.2417 - val_loss: 1.7936 - val_accuracy: 0.2788\n",
            "Epoch 2/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 1.8693 - accuracy: 0.2822\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 1.8678 - accuracy: 0.2814 - val_loss: 1.7608 - val_accuracy: 0.2941\n",
            "Epoch 3/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.7875 - accuracy: 0.3288\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.7856 - accuracy: 0.3295 - val_loss: 1.6824 - val_accuracy: 0.3325\n",
            "Epoch 4/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 1.7265 - accuracy: 0.3690\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.7244 - accuracy: 0.3705 - val_loss: 1.6450 - val_accuracy: 0.3734\n",
            "Epoch 5/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6664 - accuracy: 0.4111\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 1.6663 - accuracy: 0.4103 - val_loss: 1.6187 - val_accuracy: 0.4015\n",
            "Epoch 6/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.6162 - accuracy: 0.4594\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 1.6185 - accuracy: 0.4583 - val_loss: 1.5748 - val_accuracy: 0.4629\n",
            "Epoch 7/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 1.5605 - accuracy: 0.5026\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.5615 - accuracy: 0.5019 - val_loss: 1.5271 - val_accuracy: 0.5243\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.5192 - accuracy: 0.5376\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.5180 - accuracy: 0.5391 - val_loss: 1.4793 - val_accuracy: 0.5550\n",
            "Epoch 9/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 1.4609 - accuracy: 0.5711\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 1.4605 - accuracy: 0.5744 - val_loss: 1.4288 - val_accuracy: 0.6010\n",
            "Epoch 10/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 1.4068 - accuracy: 0.6059\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 1.4059 - accuracy: 0.6071 - val_loss: 1.3769 - val_accuracy: 0.6317\n",
            "Epoch 11/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.3453 - accuracy: 0.6433\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.3485 - accuracy: 0.6410 - val_loss: 1.3246 - val_accuracy: 0.6624\n",
            "Epoch 12/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.2894 - accuracy: 0.6727\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.2912 - accuracy: 0.6724 - val_loss: 1.2715 - val_accuracy: 0.6905\n",
            "Epoch 13/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 1.2320 - accuracy: 0.7017\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 1.2339 - accuracy: 0.7019 - val_loss: 1.2178 - val_accuracy: 0.7084\n",
            "Epoch 14/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.1737 - accuracy: 0.7103\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 1.1741 - accuracy: 0.7115 - val_loss: 1.1648 - val_accuracy: 0.7289\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.1259 - accuracy: 0.7286\n",
            "Epoch 15: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.1248 - accuracy: 0.7282 - val_loss: 1.1142 - val_accuracy: 0.7263\n",
            "Epoch 16/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.0634 - accuracy: 0.7571\n",
            "Epoch 16: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.0658 - accuracy: 0.7551 - val_loss: 1.0665 - val_accuracy: 0.7519\n",
            "Epoch 17/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.0155 - accuracy: 0.7670\n",
            "Epoch 17: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 1.0153 - accuracy: 0.7679 - val_loss: 1.0185 - val_accuracy: 0.7673\n",
            "Epoch 18/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 0.9723 - accuracy: 0.7930\n",
            "Epoch 18: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.9686 - accuracy: 0.7942 - val_loss: 0.9766 - val_accuracy: 0.7852\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.9302 - accuracy: 0.7921\n",
            "Epoch 19: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.9299 - accuracy: 0.7917 - val_loss: 0.9338 - val_accuracy: 0.7928\n",
            "Epoch 20/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.8794 - accuracy: 0.8209\n",
            "Epoch 20: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.8786 - accuracy: 0.8212 - val_loss: 0.8945 - val_accuracy: 0.7928\n",
            "Epoch 21/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.8417 - accuracy: 0.8331\n",
            "Epoch 21: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.8422 - accuracy: 0.8333 - val_loss: 0.8549 - val_accuracy: 0.8107\n",
            "Epoch 22/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.8004 - accuracy: 0.8405\n",
            "Epoch 22: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.8009 - accuracy: 0.8410 - val_loss: 0.8185 - val_accuracy: 0.8440\n",
            "Epoch 23/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 0.7699 - accuracy: 0.8730\n",
            "Epoch 23: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.7706 - accuracy: 0.8712 - val_loss: 0.7852 - val_accuracy: 0.8465\n",
            "Epoch 24/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.7334 - accuracy: 0.8866\n",
            "Epoch 24: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.7335 - accuracy: 0.8865 - val_loss: 0.7526 - val_accuracy: 0.8670\n",
            "Epoch 25/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 0.7085 - accuracy: 0.8975\n",
            "Epoch 25: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.7078 - accuracy: 0.8974 - val_loss: 0.7231 - val_accuracy: 0.8875\n",
            "Epoch 26/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.6772 - accuracy: 0.8976\n",
            "Epoch 26: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.6773 - accuracy: 0.8974 - val_loss: 0.6950 - val_accuracy: 0.9003\n",
            "Epoch 27/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.6509 - accuracy: 0.9178\n",
            "Epoch 27: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.6516 - accuracy: 0.9179 - val_loss: 0.6670 - val_accuracy: 0.9105\n",
            "Epoch 28/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 0.6304 - accuracy: 0.9239\n",
            "Epoch 28: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.6293 - accuracy: 0.9250 - val_loss: 0.6427 - val_accuracy: 0.9182\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6051 - accuracy: 0.9242\n",
            "Epoch 29: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.6045 - accuracy: 0.9237 - val_loss: 0.6220 - val_accuracy: 0.9182\n",
            "Epoch 30/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5803 - accuracy: 0.9417\n",
            "Epoch 30: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.5803 - accuracy: 0.9417 - val_loss: 0.5997 - val_accuracy: 0.9258\n",
            "Epoch 31/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5670 - accuracy: 0.9385\n",
            "Epoch 31: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.5670 - accuracy: 0.9385 - val_loss: 0.5745 - val_accuracy: 0.9361\n",
            "Epoch 32/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.5414 - accuracy: 0.9474\n",
            "Epoch 32: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.5418 - accuracy: 0.9481 - val_loss: 0.5606 - val_accuracy: 0.9335\n",
            "Epoch 33/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5255 - accuracy: 0.9514\n",
            "Epoch 33: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.5251 - accuracy: 0.9519 - val_loss: 0.5389 - val_accuracy: 0.9386\n",
            "Epoch 34/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.5063 - accuracy: 0.9566\n",
            "Epoch 34: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.5073 - accuracy: 0.9558 - val_loss: 0.5225 - val_accuracy: 0.9463\n",
            "Epoch 35/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4989 - accuracy: 0.9564\n",
            "Epoch 35: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.4989 - accuracy: 0.9564 - val_loss: 0.5088 - val_accuracy: 0.9488\n",
            "Epoch 36/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.4813 - accuracy: 0.9614\n",
            "Epoch 36: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.4820 - accuracy: 0.9609 - val_loss: 0.4934 - val_accuracy: 0.9540\n",
            "Epoch 37/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4680 - accuracy: 0.9659\n",
            "Epoch 37: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.4686 - accuracy: 0.9660 - val_loss: 0.4791 - val_accuracy: 0.9540\n",
            "Epoch 38/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.4571 - accuracy: 0.9686\n",
            "Epoch 38: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.4578 - accuracy: 0.9679 - val_loss: 0.4661 - val_accuracy: 0.9540\n",
            "Epoch 39/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4412 - accuracy: 0.9710\n",
            "Epoch 39: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.4408 - accuracy: 0.9712 - val_loss: 0.4522 - val_accuracy: 0.9591\n",
            "Epoch 40/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.4300 - accuracy: 0.9737\n",
            "Epoch 40: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.4307 - accuracy: 0.9737 - val_loss: 0.4445 - val_accuracy: 0.9616\n",
            "Epoch 41/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4199 - accuracy: 0.9723\n",
            "Epoch 41: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.4191 - accuracy: 0.9724 - val_loss: 0.4322 - val_accuracy: 0.9591\n",
            "Epoch 42/50\n",
            "188/195 [===========================>..] - ETA: 0s - loss: 0.4079 - accuracy: 0.9741\n",
            "Epoch 42: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.4091 - accuracy: 0.9737 - val_loss: 0.4240 - val_accuracy: 0.9616\n",
            "Epoch 43/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3967 - accuracy: 0.9773\n",
            "Epoch 43: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.3968 - accuracy: 0.9769 - val_loss: 0.4113 - val_accuracy: 0.9693\n",
            "Epoch 44/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 0.3907 - accuracy: 0.9749\n",
            "Epoch 44: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.3923 - accuracy: 0.9756 - val_loss: 0.4067 - val_accuracy: 0.9693\n",
            "Epoch 45/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.3795 - accuracy: 0.9809\n",
            "Epoch 45: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.3782 - accuracy: 0.9814 - val_loss: 0.3958 - val_accuracy: 0.9693\n",
            "Epoch 46/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3824 - accuracy: 0.9715\n",
            "Epoch 46: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.3835 - accuracy: 0.9712 - val_loss: 0.3880 - val_accuracy: 0.9719\n",
            "Epoch 47/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3687 - accuracy: 0.9780\n",
            "Epoch 47: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.3686 - accuracy: 0.9782 - val_loss: 0.3817 - val_accuracy: 0.9693\n",
            "Epoch 48/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3622 - accuracy: 0.9805\n",
            "Epoch 48: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.3615 - accuracy: 0.9808 - val_loss: 0.3720 - val_accuracy: 0.9719\n",
            "Epoch 49/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3550 - accuracy: 0.9814\n",
            "Epoch 49: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.3550 - accuracy: 0.9814 - val_loss: 0.3674 - val_accuracy: 0.9668\n",
            "Epoch 50/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 0.3465 - accuracy: 0.9821\n",
            "Epoch 50: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.3460 - accuracy: 0.9821 - val_loss: 0.3592 - val_accuracy: 0.9719\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/3/assets\n",
            "\n",
            "\n",
            "  2%|▏         | 4/200 [10:48<7:50:39, 144.08s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 2.4672 - accuracy: 0.3446\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 20ms/step - loss: 2.4664 - accuracy: 0.3442 - val_loss: 1.8779 - val_accuracy: 0.3632\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 2.0420 - accuracy: 0.4799\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 2.0388 - accuracy: 0.4821 - val_loss: 1.8347 - val_accuracy: 0.3657\n",
            "Epoch 3/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.8047 - accuracy: 0.5902\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 1.8034 - accuracy: 0.5910 - val_loss: 1.6922 - val_accuracy: 0.4092\n",
            "Epoch 4/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6305 - accuracy: 0.6615\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 1.6305 - accuracy: 0.6615 - val_loss: 1.4823 - val_accuracy: 0.6292\n",
            "Epoch 5/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.4883 - accuracy: 0.7109\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 1.4883 - accuracy: 0.7109 - val_loss: 1.3419 - val_accuracy: 0.7698\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.3564 - accuracy: 0.7604\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 1.3582 - accuracy: 0.7590 - val_loss: 1.2296 - val_accuracy: 0.8107\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.2382 - accuracy: 0.8089\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 1.2358 - accuracy: 0.8096 - val_loss: 1.1468 - val_accuracy: 0.8363\n",
            "Epoch 8/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.1522 - accuracy: 0.8409\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 1.1530 - accuracy: 0.8404 - val_loss: 1.0617 - val_accuracy: 0.8465\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.0814 - accuracy: 0.8549\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.0808 - accuracy: 0.8545 - val_loss: 0.9885 - val_accuracy: 0.8721\n",
            "Epoch 10/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.0096 - accuracy: 0.8808\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 1.0096 - accuracy: 0.8808 - val_loss: 0.9248 - val_accuracy: 0.9003\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.9577 - accuracy: 0.9028\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.9564 - accuracy: 0.9032 - val_loss: 0.8770 - val_accuracy: 0.9309\n",
            "Epoch 12/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.9034 - accuracy: 0.9137\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.9024 - accuracy: 0.9141 - val_loss: 0.8210 - val_accuracy: 0.9412\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8579 - accuracy: 0.9294\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.8568 - accuracy: 0.9301 - val_loss: 0.7808 - val_accuracy: 0.9463\n",
            "Epoch 14/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.8238 - accuracy: 0.9340\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.8238 - accuracy: 0.9340 - val_loss: 0.7512 - val_accuracy: 0.9642\n",
            "Epoch 15/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.7871 - accuracy: 0.9434\n",
            "Epoch 15: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.7867 - accuracy: 0.9436 - val_loss: 0.7216 - val_accuracy: 0.9668\n",
            "Epoch 16/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.7577 - accuracy: 0.9452\n",
            "Epoch 16: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.7578 - accuracy: 0.9455 - val_loss: 0.6969 - val_accuracy: 0.9668\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7213 - accuracy: 0.9650\n",
            "Epoch 17: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.7207 - accuracy: 0.9654 - val_loss: 0.6746 - val_accuracy: 0.9719\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7030 - accuracy: 0.9579\n",
            "Epoch 18: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.7025 - accuracy: 0.9583 - val_loss: 0.6519 - val_accuracy: 0.9795\n",
            "Epoch 19/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6810 - accuracy: 0.9679\n",
            "Epoch 19: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.6810 - accuracy: 0.9679 - val_loss: 0.6323 - val_accuracy: 0.9770\n",
            "Epoch 20/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6552 - accuracy: 0.9705\n",
            "Epoch 20: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.6552 - accuracy: 0.9705 - val_loss: 0.6151 - val_accuracy: 0.9770\n",
            "Epoch 21/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.6385 - accuracy: 0.9701\n",
            "Epoch 21: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.6373 - accuracy: 0.9705 - val_loss: 0.5934 - val_accuracy: 0.9795\n",
            "Epoch 22/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6168 - accuracy: 0.9737\n",
            "Epoch 22: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.6168 - accuracy: 0.9737 - val_loss: 0.5743 - val_accuracy: 0.9795\n",
            "Epoch 23/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.5997 - accuracy: 0.9781\n",
            "Epoch 23: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.5995 - accuracy: 0.9782 - val_loss: 0.5657 - val_accuracy: 0.9847\n",
            "Epoch 24/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5765 - accuracy: 0.9795\n",
            "Epoch 24: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.5765 - accuracy: 0.9795 - val_loss: 0.5482 - val_accuracy: 0.9821\n",
            "Epoch 25/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.5640 - accuracy: 0.9805\n",
            "Epoch 25: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.5641 - accuracy: 0.9808 - val_loss: 0.5359 - val_accuracy: 0.9847\n",
            "Epoch 26/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.5528 - accuracy: 0.9844\n",
            "Epoch 26: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.5533 - accuracy: 0.9846 - val_loss: 0.5203 - val_accuracy: 0.9847\n",
            "Epoch 27/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.5440 - accuracy: 0.9832\n",
            "Epoch 27: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.5435 - accuracy: 0.9833 - val_loss: 0.5168 - val_accuracy: 0.9847\n",
            "Epoch 28/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.5266 - accuracy: 0.9800\n",
            "Epoch 28: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.5260 - accuracy: 0.9801 - val_loss: 0.4980 - val_accuracy: 0.9898\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5194 - accuracy: 0.9870\n",
            "Epoch 29: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.5188 - accuracy: 0.9872 - val_loss: 0.4863 - val_accuracy: 0.9923\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4980 - accuracy: 0.9890\n",
            "Epoch 30: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.4976 - accuracy: 0.9891 - val_loss: 0.4748 - val_accuracy: 0.9872\n",
            "Epoch 31/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4934 - accuracy: 0.9885\n",
            "Epoch 31: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.4934 - accuracy: 0.9885 - val_loss: 0.4888 - val_accuracy: 0.9795\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4781 - accuracy: 0.9929\n",
            "Epoch 32: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.4779 - accuracy: 0.9929 - val_loss: 0.4610 - val_accuracy: 0.9923\n",
            "Epoch 33/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4706 - accuracy: 0.9878\n",
            "Epoch 33: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.4713 - accuracy: 0.9872 - val_loss: 0.4471 - val_accuracy: 0.9898\n",
            "Epoch 34/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.4536 - accuracy: 0.9948\n",
            "Epoch 34: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.4552 - accuracy: 0.9936 - val_loss: 0.4417 - val_accuracy: 0.9898\n",
            "Epoch 35/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4474 - accuracy: 0.9929\n",
            "Epoch 35: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.4470 - accuracy: 0.9929 - val_loss: 0.4340 - val_accuracy: 0.9923\n",
            "Epoch 36/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4437 - accuracy: 0.9878\n",
            "Epoch 36: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.4437 - accuracy: 0.9878 - val_loss: 0.4212 - val_accuracy: 0.9923\n",
            "Epoch 37/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4304 - accuracy: 0.9948\n",
            "Epoch 37: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.4301 - accuracy: 0.9949 - val_loss: 0.4133 - val_accuracy: 0.9923\n",
            "Epoch 38/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.4233 - accuracy: 0.9909\n",
            "Epoch 38: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.4227 - accuracy: 0.9910 - val_loss: 0.4038 - val_accuracy: 0.9923\n",
            "Epoch 39/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4155 - accuracy: 0.9929\n",
            "Epoch 39: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.4150 - accuracy: 0.9929 - val_loss: 0.4011 - val_accuracy: 0.9898\n",
            "Epoch 40/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4054 - accuracy: 0.9929\n",
            "Epoch 40: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.4054 - accuracy: 0.9929 - val_loss: 0.3940 - val_accuracy: 0.9923\n",
            "Epoch 41/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3964 - accuracy: 0.9942\n",
            "Epoch 41: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.3964 - accuracy: 0.9942 - val_loss: 0.3851 - val_accuracy: 0.9923\n",
            "Epoch 42/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3952 - accuracy: 0.9936\n",
            "Epoch 42: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.3952 - accuracy: 0.9936 - val_loss: 0.3797 - val_accuracy: 0.9923\n",
            "Epoch 43/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3860 - accuracy: 0.9936\n",
            "Epoch 43: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.3860 - accuracy: 0.9936 - val_loss: 0.3749 - val_accuracy: 0.9923\n",
            "Epoch 44/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3788 - accuracy: 0.9935\n",
            "Epoch 44: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.3788 - accuracy: 0.9936 - val_loss: 0.3735 - val_accuracy: 0.9923\n",
            "Epoch 45/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3708 - accuracy: 0.9936\n",
            "Epoch 45: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.3705 - accuracy: 0.9936 - val_loss: 0.3591 - val_accuracy: 0.9923\n",
            "Epoch 46/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3609 - accuracy: 0.9974\n",
            "Epoch 46: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.3609 - accuracy: 0.9974 - val_loss: 0.3530 - val_accuracy: 0.9923\n",
            "Epoch 47/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3595 - accuracy: 0.9961\n",
            "Epoch 47: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.3605 - accuracy: 0.9955 - val_loss: 0.3498 - val_accuracy: 0.9923\n",
            "Epoch 48/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3530 - accuracy: 0.9981\n",
            "Epoch 48: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.3533 - accuracy: 0.9981 - val_loss: 0.3492 - val_accuracy: 0.9923\n",
            "Epoch 49/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3480 - accuracy: 0.9967\n",
            "Epoch 49: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.3482 - accuracy: 0.9968 - val_loss: 0.3383 - val_accuracy: 0.9923\n",
            "Epoch 50/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3400 - accuracy: 0.9955\n",
            "Epoch 50: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.3411 - accuracy: 0.9955 - val_loss: 0.3314 - val_accuracy: 0.9923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/4/assets\n",
            "\n",
            "\n",
            "  2%|▎         | 5/200 [14:16<9:02:16, 166.85s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 2.0164 - accuracy: 0.2713\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 24ms/step - loss: 2.0152 - accuracy: 0.2718 - val_loss: 1.7506 - val_accuracy: 0.2634\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.7331 - accuracy: 0.2727\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 1.7325 - accuracy: 0.2718 - val_loss: 1.7021 - val_accuracy: 0.2864\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.7025 - accuracy: 0.2688\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 1.7013 - accuracy: 0.2712 - val_loss: 1.6853 - val_accuracy: 0.2864\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6801 - accuracy: 0.2707\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 1.6797 - accuracy: 0.2692 - val_loss: 1.6670 - val_accuracy: 0.2634\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6657 - accuracy: 0.2759\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6641 - accuracy: 0.2776 - val_loss: 1.6643 - val_accuracy: 0.2864\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6573 - accuracy: 0.2766\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6576 - accuracy: 0.2769 - val_loss: 1.6530 - val_accuracy: 0.2634\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6499 - accuracy: 0.2791\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6499 - accuracy: 0.2795 - val_loss: 1.6432 - val_accuracy: 0.2864\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6438 - accuracy: 0.2766\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6451 - accuracy: 0.2769 - val_loss: 1.6433 - val_accuracy: 0.2864\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6394 - accuracy: 0.2869\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6410 - accuracy: 0.2859 - val_loss: 1.6349 - val_accuracy: 0.2864\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6381 - accuracy: 0.2850\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6365 - accuracy: 0.2859 - val_loss: 1.6319 - val_accuracy: 0.2864\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6346 - accuracy: 0.2863\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6336 - accuracy: 0.2859 - val_loss: 1.6301 - val_accuracy: 0.2864\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6322 - accuracy: 0.2830\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6321 - accuracy: 0.2821 - val_loss: 1.6284 - val_accuracy: 0.2864\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6309 - accuracy: 0.2869\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 1.6303 - accuracy: 0.2859 - val_loss: 1.6273 - val_accuracy: 0.2864\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6284 - accuracy: 0.2837\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6289 - accuracy: 0.2859 - val_loss: 1.6263 - val_accuracy: 0.2864\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6296 - accuracy: 0.2759\n",
            "Epoch 15: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6289 - accuracy: 0.2776 - val_loss: 1.6255 - val_accuracy: 0.2864\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6280 - accuracy: 0.2785\n",
            "Epoch 16: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6283 - accuracy: 0.2782 - val_loss: 1.6249 - val_accuracy: 0.2864\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6276 - accuracy: 0.2869\n",
            "Epoch 17: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6275 - accuracy: 0.2859 - val_loss: 1.6245 - val_accuracy: 0.2864\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6274 - accuracy: 0.2740\n",
            "Epoch 18: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 1.6275 - accuracy: 0.2744 - val_loss: 1.6245 - val_accuracy: 0.2864\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6261 - accuracy: 0.2902\n",
            "Epoch 19: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6278 - accuracy: 0.2885 - val_loss: 1.6253 - val_accuracy: 0.2634\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6301 - accuracy: 0.2837\n",
            "Epoch 20: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 1.6278 - accuracy: 0.2827 - val_loss: 1.6243 - val_accuracy: 0.2864\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6259 - accuracy: 0.2876\n",
            "Epoch 21: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 1.6268 - accuracy: 0.2872 - val_loss: 1.6250 - val_accuracy: 0.2864\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6269 - accuracy: 0.2843\n",
            "Epoch 22: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 1.6264 - accuracy: 0.2833 - val_loss: 1.6253 - val_accuracy: 0.2864\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6322 - accuracy: 0.2759\n",
            "Epoch 23: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 1.6322 - accuracy: 0.2744 - val_loss: 1.6246 - val_accuracy: 0.2864\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6247 - accuracy: 0.2863\n",
            "Epoch 24: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 1.6267 - accuracy: 0.2859 - val_loss: 1.6246 - val_accuracy: 0.2864\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6276 - accuracy: 0.2863\n",
            "Epoch 25: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6269 - accuracy: 0.2859 - val_loss: 1.6241 - val_accuracy: 0.2864\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6271 - accuracy: 0.2785\n",
            "Epoch 26: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 1.6270 - accuracy: 0.2788 - val_loss: 1.6241 - val_accuracy: 0.2864\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6296 - accuracy: 0.2811\n",
            "Epoch 27: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6302 - accuracy: 0.2833 - val_loss: 1.6258 - val_accuracy: 0.2864\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6288 - accuracy: 0.2798\n",
            "Epoch 28: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6283 - accuracy: 0.2795 - val_loss: 1.6250 - val_accuracy: 0.2864\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6272 - accuracy: 0.2791\n",
            "Epoch 29: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6276 - accuracy: 0.2782 - val_loss: 1.6242 - val_accuracy: 0.2864\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6276 - accuracy: 0.2856\n",
            "Epoch 30: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6263 - accuracy: 0.2859 - val_loss: 1.6247 - val_accuracy: 0.2864\n",
            "Epoch 30: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/5/assets\n",
            "\n",
            "\n",
            "  3%|▎         | 6/200 [16:43<8:37:54, 160.18s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 2.0080 - accuracy: 0.6532\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 8s 32ms/step - loss: 2.0080 - accuracy: 0.6532 - val_loss: 1.9176 - val_accuracy: 0.2123\n",
            "Epoch 2/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.9914 - accuracy: 0.9494\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 30ms/step - loss: 0.9914 - accuracy: 0.9494 - val_loss: 1.7306 - val_accuracy: 0.8619\n",
            "Epoch 3/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.7271 - accuracy: 0.9801\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.7271 - accuracy: 0.9801 - val_loss: 1.0705 - val_accuracy: 0.9540\n",
            "Epoch 4/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5903 - accuracy: 0.9891\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 30ms/step - loss: 0.5903 - accuracy: 0.9891 - val_loss: 0.5680 - val_accuracy: 0.9795\n",
            "Epoch 5/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4812 - accuracy: 0.9904\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 30ms/step - loss: 0.4812 - accuracy: 0.9904 - val_loss: 0.4218 - val_accuracy: 0.9974\n",
            "Epoch 6/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4109 - accuracy: 0.9949\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 30ms/step - loss: 0.4109 - accuracy: 0.9949 - val_loss: 0.3655 - val_accuracy: 0.9923\n",
            "Epoch 7/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3663 - accuracy: 0.9929\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 30ms/step - loss: 0.3663 - accuracy: 0.9929 - val_loss: 0.3288 - val_accuracy: 0.9923\n",
            "Epoch 8/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3213 - accuracy: 0.9981\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.3213 - accuracy: 0.9981 - val_loss: 0.2921 - val_accuracy: 0.9949\n",
            "Epoch 9/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2899 - accuracy: 0.9962\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.2899 - accuracy: 0.9962 - val_loss: 0.3393 - val_accuracy: 0.9923\n",
            "Epoch 10/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2875 - accuracy: 0.9968\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.2875 - accuracy: 0.9968 - val_loss: 0.2539 - val_accuracy: 0.9974\n",
            "Epoch 11/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2507 - accuracy: 1.0000\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.2507 - accuracy: 1.0000 - val_loss: 0.2424 - val_accuracy: 0.9974\n",
            "Epoch 12/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2386 - accuracy: 0.9987\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.2386 - accuracy: 0.9987 - val_loss: 0.2307 - val_accuracy: 0.9974\n",
            "Epoch 13/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2294 - accuracy: 0.9987\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.2293 - accuracy: 0.9987 - val_loss: 0.2309 - val_accuracy: 0.9974\n",
            "Epoch 14/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2165 - accuracy: 0.9994\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.2165 - accuracy: 0.9994 - val_loss: 0.2329 - val_accuracy: 0.9923\n",
            "Epoch 15/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2071 - accuracy: 1.0000\n",
            "Epoch 15: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.2071 - accuracy: 1.0000 - val_loss: 0.2084 - val_accuracy: 0.9974\n",
            "Epoch 16/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2010 - accuracy: 1.0000\n",
            "Epoch 16: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.2010 - accuracy: 1.0000 - val_loss: 0.2068 - val_accuracy: 0.9974\n",
            "Epoch 17/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1930 - accuracy: 0.9994\n",
            "Epoch 17: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.1930 - accuracy: 0.9994 - val_loss: 0.1987 - val_accuracy: 0.9949\n",
            "Epoch 18/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1893 - accuracy: 0.9994\n",
            "Epoch 18: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.1892 - accuracy: 0.9994 - val_loss: 0.1917 - val_accuracy: 0.9974\n",
            "Epoch 19/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1845 - accuracy: 1.0000\n",
            "Epoch 19: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 30ms/step - loss: 0.1845 - accuracy: 1.0000 - val_loss: 0.1941 - val_accuracy: 0.9974\n",
            "Epoch 20/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1792 - accuracy: 1.0000\n",
            "Epoch 20: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.1792 - accuracy: 1.0000 - val_loss: 0.1921 - val_accuracy: 0.9974\n",
            "Epoch 21/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1713 - accuracy: 0.9994\n",
            "Epoch 21: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 30ms/step - loss: 0.1713 - accuracy: 0.9994 - val_loss: 0.1771 - val_accuracy: 0.9974\n",
            "Epoch 22/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1676 - accuracy: 1.0000\n",
            "Epoch 22: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.1676 - accuracy: 1.0000 - val_loss: 0.1824 - val_accuracy: 0.9949\n",
            "Epoch 23/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1688 - accuracy: 0.9994\n",
            "Epoch 23: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.1688 - accuracy: 0.9994 - val_loss: 0.1735 - val_accuracy: 0.9974\n",
            "Epoch 24/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1579 - accuracy: 1.0000\n",
            "Epoch 24: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.1579 - accuracy: 1.0000 - val_loss: 0.1673 - val_accuracy: 0.9974\n",
            "Epoch 25/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1586 - accuracy: 0.9994\n",
            "Epoch 25: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.1586 - accuracy: 0.9994 - val_loss: 0.1721 - val_accuracy: 0.9949\n",
            "Epoch 26/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1539 - accuracy: 0.9994\n",
            "Epoch 26: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.1539 - accuracy: 0.9994 - val_loss: 0.1854 - val_accuracy: 0.9847\n",
            "Epoch 27/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1475 - accuracy: 0.9994\n",
            "Epoch 27: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.1475 - accuracy: 0.9994 - val_loss: 0.1541 - val_accuracy: 0.9974\n",
            "Epoch 28/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1426 - accuracy: 1.0000\n",
            "Epoch 28: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.1425 - accuracy: 1.0000 - val_loss: 0.1500 - val_accuracy: 0.9974\n",
            "Epoch 29/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1391 - accuracy: 1.0000\n",
            "Epoch 29: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.1391 - accuracy: 1.0000 - val_loss: 0.1476 - val_accuracy: 0.9974\n",
            "Epoch 30/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1347 - accuracy: 1.0000\n",
            "Epoch 30: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.1347 - accuracy: 1.0000 - val_loss: 0.1463 - val_accuracy: 0.9949\n",
            "Epoch 31/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1313 - accuracy: 1.0000\n",
            "Epoch 31: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.1313 - accuracy: 1.0000 - val_loss: 0.1518 - val_accuracy: 0.9974\n",
            "Epoch 32/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1278 - accuracy: 1.0000\n",
            "Epoch 32: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.1278 - accuracy: 1.0000 - val_loss: 0.1323 - val_accuracy: 0.9974\n",
            "Epoch 33/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1229 - accuracy: 1.0000\n",
            "Epoch 33: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.1229 - accuracy: 1.0000 - val_loss: 0.1293 - val_accuracy: 0.9974\n",
            "Epoch 34/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1188 - accuracy: 1.0000\n",
            "Epoch 34: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.1188 - accuracy: 1.0000 - val_loss: 0.1262 - val_accuracy: 0.9974\n",
            "Epoch 35/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1165 - accuracy: 0.9994\n",
            "Epoch 35: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.1165 - accuracy: 0.9994 - val_loss: 0.1245 - val_accuracy: 0.9974\n",
            "Epoch 36/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1235 - accuracy: 0.9974\n",
            "Epoch 36: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.1235 - accuracy: 0.9974 - val_loss: 0.2294 - val_accuracy: 0.9693\n",
            "Epoch 37/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1309 - accuracy: 0.9968\n",
            "Epoch 37: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.1309 - accuracy: 0.9968 - val_loss: 0.1266 - val_accuracy: 0.9949\n",
            "Epoch 38/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1095 - accuracy: 1.0000\n",
            "Epoch 38: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.1095 - accuracy: 1.0000 - val_loss: 0.1176 - val_accuracy: 0.9949\n",
            "Epoch 39/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1047 - accuracy: 1.0000\n",
            "Epoch 39: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.1047 - accuracy: 1.0000 - val_loss: 0.1105 - val_accuracy: 0.9949\n",
            "Epoch 40/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0990 - accuracy: 1.0000\n",
            "Epoch 40: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 0.0990 - accuracy: 1.0000 - val_loss: 0.1043 - val_accuracy: 0.9949\n",
            "Epoch 41/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0960 - accuracy: 1.0000\n",
            "Epoch 41: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.0960 - accuracy: 1.0000 - val_loss: 0.1094 - val_accuracy: 0.9949\n",
            "Epoch 42/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0916 - accuracy: 1.0000\n",
            "Epoch 42: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.0916 - accuracy: 1.0000 - val_loss: 0.0994 - val_accuracy: 0.9974\n",
            "Epoch 43/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0871 - accuracy: 1.0000\n",
            "Epoch 43: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.0871 - accuracy: 1.0000 - val_loss: 0.0954 - val_accuracy: 0.9949\n",
            "Epoch 44/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0835 - accuracy: 1.0000\n",
            "Epoch 44: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.0835 - accuracy: 1.0000 - val_loss: 0.0923 - val_accuracy: 0.9974\n",
            "Epoch 45/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0794 - accuracy: 1.0000\n",
            "Epoch 45: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.0794 - accuracy: 1.0000 - val_loss: 0.0924 - val_accuracy: 0.9974\n",
            "Epoch 46/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0755 - accuracy: 1.0000\n",
            "Epoch 46: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.0755 - accuracy: 1.0000 - val_loss: 0.0837 - val_accuracy: 0.9974\n",
            "Epoch 47/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0713 - accuracy: 1.0000\n",
            "Epoch 47: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.0713 - accuracy: 1.0000 - val_loss: 0.0825 - val_accuracy: 0.9974\n",
            "Epoch 48/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0678 - accuracy: 1.0000\n",
            "Epoch 48: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.0678 - accuracy: 1.0000 - val_loss: 0.0782 - val_accuracy: 0.9949\n",
            "Epoch 49/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0642 - accuracy: 1.0000\n",
            "Epoch 49: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.0642 - accuracy: 1.0000 - val_loss: 0.0717 - val_accuracy: 0.9974\n",
            "Epoch 50/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0614 - accuracy: 1.0000\n",
            "Epoch 50: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.0614 - accuracy: 1.0000 - val_loss: 0.0687 - val_accuracy: 0.9974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/6/assets\n",
            "\n",
            "\n",
            "  4%|▎         | 7/200 [22:10<11:31:02, 214.83s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 2.5486 - accuracy: 0.2062\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 13ms/step - loss: 2.5464 - accuracy: 0.2064 - val_loss: 1.8331 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 2.0447 - accuracy: 0.3266\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 2.0434 - accuracy: 0.3263 - val_loss: 1.8137 - val_accuracy: 0.2864\n",
            "Epoch 3/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.8874 - accuracy: 0.3974\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.8874 - accuracy: 0.3974 - val_loss: 1.7418 - val_accuracy: 0.3606\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.7693 - accuracy: 0.4689\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 1.7709 - accuracy: 0.4686 - val_loss: 1.6724 - val_accuracy: 0.5013\n",
            "Epoch 5/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.6744 - accuracy: 0.5229\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 1.6761 - accuracy: 0.5224 - val_loss: 1.6071 - val_accuracy: 0.5678\n",
            "Epoch 6/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.5896 - accuracy: 0.5808\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.5896 - accuracy: 0.5808 - val_loss: 1.5296 - val_accuracy: 0.6010\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.5054 - accuracy: 0.6276\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 1.5058 - accuracy: 0.6269 - val_loss: 1.4561 - val_accuracy: 0.6471\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.4280 - accuracy: 0.6580\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 1.4259 - accuracy: 0.6603 - val_loss: 1.3850 - val_accuracy: 0.7008\n",
            "Epoch 9/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.3586 - accuracy: 0.6872\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.3586 - accuracy: 0.6872 - val_loss: 1.3161 - val_accuracy: 0.7315\n",
            "Epoch 10/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.2885 - accuracy: 0.7251\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 1.2875 - accuracy: 0.7250 - val_loss: 1.2529 - val_accuracy: 0.7442\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.2302 - accuracy: 0.7455\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 1.2314 - accuracy: 0.7436 - val_loss: 1.1997 - val_accuracy: 0.7545\n",
            "Epoch 12/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 1.1739 - accuracy: 0.7671\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.1721 - accuracy: 0.7692 - val_loss: 1.1447 - val_accuracy: 0.7698\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.1367 - accuracy: 0.7740\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.1354 - accuracy: 0.7737 - val_loss: 1.1005 - val_accuracy: 0.7877\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.0726 - accuracy: 0.8115\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 1.0707 - accuracy: 0.8128 - val_loss: 1.0560 - val_accuracy: 0.8056\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.0288 - accuracy: 0.8277\n",
            "Epoch 15: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 1.0285 - accuracy: 0.8288 - val_loss: 1.0152 - val_accuracy: 0.8159\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.9958 - accuracy: 0.8387\n",
            "Epoch 16: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.9971 - accuracy: 0.8385 - val_loss: 0.9794 - val_accuracy: 0.8338\n",
            "Epoch 17/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.9501 - accuracy: 0.8609\n",
            "Epoch 17: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.9501 - accuracy: 0.8609 - val_loss: 0.9465 - val_accuracy: 0.8414\n",
            "Epoch 18/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.9164 - accuracy: 0.8646\n",
            "Epoch 18: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.9154 - accuracy: 0.8647 - val_loss: 0.9136 - val_accuracy: 0.8465\n",
            "Epoch 19/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.8823 - accuracy: 0.8788\n",
            "Epoch 19: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.8823 - accuracy: 0.8788 - val_loss: 0.8857 - val_accuracy: 0.8645\n",
            "Epoch 20/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.8640 - accuracy: 0.8788\n",
            "Epoch 20: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.8640 - accuracy: 0.8788 - val_loss: 0.8598 - val_accuracy: 0.8645\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8350 - accuracy: 0.8899\n",
            "Epoch 21: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.8339 - accuracy: 0.8897 - val_loss: 0.8343 - val_accuracy: 0.8849\n",
            "Epoch 22/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.8024 - accuracy: 0.8943\n",
            "Epoch 22: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.8014 - accuracy: 0.8949 - val_loss: 0.8061 - val_accuracy: 0.9003\n",
            "Epoch 23/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.7782 - accuracy: 0.9026\n",
            "Epoch 23: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.7782 - accuracy: 0.9026 - val_loss: 0.7883 - val_accuracy: 0.8977\n",
            "Epoch 24/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.7581 - accuracy: 0.9108\n",
            "Epoch 24: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.7580 - accuracy: 0.9115 - val_loss: 0.7624 - val_accuracy: 0.9079\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7422 - accuracy: 0.9197\n",
            "Epoch 25: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.7417 - accuracy: 0.9199 - val_loss: 0.7451 - val_accuracy: 0.9105\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7158 - accuracy: 0.9236\n",
            "Epoch 26: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.7154 - accuracy: 0.9244 - val_loss: 0.7233 - val_accuracy: 0.9258\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6951 - accuracy: 0.9301\n",
            "Epoch 27: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.6950 - accuracy: 0.9295 - val_loss: 0.7078 - val_accuracy: 0.9309\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6775 - accuracy: 0.9378\n",
            "Epoch 28: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.6785 - accuracy: 0.9378 - val_loss: 0.6911 - val_accuracy: 0.9335\n",
            "Epoch 29/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.6675 - accuracy: 0.9310\n",
            "Epoch 29: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.6668 - accuracy: 0.9308 - val_loss: 0.6742 - val_accuracy: 0.9386\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6421 - accuracy: 0.9456\n",
            "Epoch 30: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.6413 - accuracy: 0.9462 - val_loss: 0.6605 - val_accuracy: 0.9386\n",
            "Epoch 31/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6248 - accuracy: 0.9456\n",
            "Epoch 31: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.6259 - accuracy: 0.9442 - val_loss: 0.6406 - val_accuracy: 0.9463\n",
            "Epoch 32/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.6155 - accuracy: 0.9444\n",
            "Epoch 32: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.6143 - accuracy: 0.9449 - val_loss: 0.6301 - val_accuracy: 0.9488\n",
            "Epoch 33/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.6035 - accuracy: 0.9463\n",
            "Epoch 33: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.6025 - accuracy: 0.9468 - val_loss: 0.6110 - val_accuracy: 0.9488\n",
            "Epoch 34/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5862 - accuracy: 0.9598\n",
            "Epoch 34: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.5850 - accuracy: 0.9603 - val_loss: 0.6071 - val_accuracy: 0.9463\n",
            "Epoch 35/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5808 - accuracy: 0.9579\n",
            "Epoch 35: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.5802 - accuracy: 0.9583 - val_loss: 0.5930 - val_accuracy: 0.9463\n",
            "Epoch 36/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.5653 - accuracy: 0.9579\n",
            "Epoch 36: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.5650 - accuracy: 0.9571 - val_loss: 0.5847 - val_accuracy: 0.9514\n",
            "Epoch 37/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5502 - accuracy: 0.9683\n",
            "Epoch 37: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.5497 - accuracy: 0.9686 - val_loss: 0.5679 - val_accuracy: 0.9463\n",
            "Epoch 38/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.5369 - accuracy: 0.9655\n",
            "Epoch 38: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.5363 - accuracy: 0.9660 - val_loss: 0.5567 - val_accuracy: 0.9514\n",
            "Epoch 39/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.5327 - accuracy: 0.9664\n",
            "Epoch 39: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.5314 - accuracy: 0.9667 - val_loss: 0.5425 - val_accuracy: 0.9565\n",
            "Epoch 40/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5094 - accuracy: 0.9756\n",
            "Epoch 40: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.5094 - accuracy: 0.9756 - val_loss: 0.5348 - val_accuracy: 0.9540\n",
            "Epoch 41/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5109 - accuracy: 0.9741\n",
            "Epoch 41: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.5106 - accuracy: 0.9744 - val_loss: 0.5259 - val_accuracy: 0.9488\n",
            "Epoch 42/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5037 - accuracy: 0.9756\n",
            "Epoch 42: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.5037 - accuracy: 0.9756 - val_loss: 0.5197 - val_accuracy: 0.9591\n",
            "Epoch 43/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.4898 - accuracy: 0.9784\n",
            "Epoch 43: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.4908 - accuracy: 0.9782 - val_loss: 0.5076 - val_accuracy: 0.9642\n",
            "Epoch 44/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4793 - accuracy: 0.9728\n",
            "Epoch 44: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.4792 - accuracy: 0.9731 - val_loss: 0.4977 - val_accuracy: 0.9668\n",
            "Epoch 45/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4781 - accuracy: 0.9709\n",
            "Epoch 45: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.4777 - accuracy: 0.9712 - val_loss: 0.4931 - val_accuracy: 0.9642\n",
            "Epoch 46/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.4539 - accuracy: 0.9849\n",
            "Epoch 46: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.4535 - accuracy: 0.9853 - val_loss: 0.4835 - val_accuracy: 0.9795\n",
            "Epoch 47/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4554 - accuracy: 0.9754\n",
            "Epoch 47: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.4557 - accuracy: 0.9756 - val_loss: 0.4754 - val_accuracy: 0.9795\n",
            "Epoch 48/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4467 - accuracy: 0.9812\n",
            "Epoch 48: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.4468 - accuracy: 0.9814 - val_loss: 0.4693 - val_accuracy: 0.9719\n",
            "Epoch 49/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4372 - accuracy: 0.9806\n",
            "Epoch 49: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.4367 - accuracy: 0.9808 - val_loss: 0.4632 - val_accuracy: 0.9770\n",
            "Epoch 50/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4257 - accuracy: 0.9884\n",
            "Epoch 50: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.4255 - accuracy: 0.9885 - val_loss: 0.4555 - val_accuracy: 0.9693\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/7/assets\n",
            "\n",
            "\n",
            "  4%|▍         | 8/200 [23:59<9:39:06, 180.97s/it] \u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.7797 - accuracy: 0.5894\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 17ms/step - loss: 1.7727 - accuracy: 0.5917 - val_loss: 1.8971 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.9080 - accuracy: 0.9093\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.9081 - accuracy: 0.9090 - val_loss: 2.2865 - val_accuracy: 0.3120\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6329 - accuracy: 0.9650\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.6324 - accuracy: 0.9654 - val_loss: 1.8573 - val_accuracy: 0.3529\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5221 - accuracy: 0.9786\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.5212 - accuracy: 0.9788 - val_loss: 0.5019 - val_accuracy: 0.9770\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4361 - accuracy: 0.9909\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.4355 - accuracy: 0.9910 - val_loss: 0.4183 - val_accuracy: 0.9821\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3862 - accuracy: 0.9922\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.3861 - accuracy: 0.9923 - val_loss: 0.3850 - val_accuracy: 0.9898\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3441 - accuracy: 0.9955\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.3431 - accuracy: 0.9955 - val_loss: 0.3406 - val_accuracy: 0.9923\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3186 - accuracy: 0.9935\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.3183 - accuracy: 0.9936 - val_loss: 0.3068 - val_accuracy: 0.9923\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2848 - accuracy: 0.9987\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.2842 - accuracy: 0.9987 - val_loss: 0.2848 - val_accuracy: 0.9898\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2685 - accuracy: 0.9929\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.2684 - accuracy: 0.9929 - val_loss: 0.2706 - val_accuracy: 0.9923\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2362 - accuracy: 0.9987\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.2359 - accuracy: 0.9987 - val_loss: 0.2389 - val_accuracy: 0.9949\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2204 - accuracy: 0.9994\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.2208 - accuracy: 0.9994 - val_loss: 0.2281 - val_accuracy: 0.9949\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2057 - accuracy: 0.9974\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.2058 - accuracy: 0.9974 - val_loss: 0.2350 - val_accuracy: 0.9898\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1941 - accuracy: 0.9981\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1939 - accuracy: 0.9981 - val_loss: 0.1993 - val_accuracy: 0.9949\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1808 - accuracy: 0.9994\n",
            "Epoch 15: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1808 - accuracy: 0.9994 - val_loss: 0.1850 - val_accuracy: 0.9923\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1669 - accuracy: 0.9987\n",
            "Epoch 16: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1670 - accuracy: 0.9987 - val_loss: 0.1754 - val_accuracy: 0.9949\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1597 - accuracy: 0.9994\n",
            "Epoch 17: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1597 - accuracy: 0.9994 - val_loss: 0.1979 - val_accuracy: 0.9898\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1508 - accuracy: 0.9994\n",
            "Epoch 18: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1506 - accuracy: 0.9994 - val_loss: 0.1596 - val_accuracy: 0.9923\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1439 - accuracy: 0.9994\n",
            "Epoch 19: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1441 - accuracy: 0.9994 - val_loss: 0.1554 - val_accuracy: 0.9949\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1379 - accuracy: 1.0000\n",
            "Epoch 20: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.1379 - accuracy: 1.0000 - val_loss: 0.1495 - val_accuracy: 0.9949\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1310 - accuracy: 1.0000\n",
            "Epoch 21: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1308 - accuracy: 1.0000 - val_loss: 0.1425 - val_accuracy: 0.9974\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1285 - accuracy: 0.9994\n",
            "Epoch 22: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.1284 - accuracy: 0.9994 - val_loss: 0.1391 - val_accuracy: 0.9923\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1218 - accuracy: 1.0000\n",
            "Epoch 23: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1217 - accuracy: 1.0000 - val_loss: 0.1518 - val_accuracy: 0.9898\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1180 - accuracy: 1.0000\n",
            "Epoch 24: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1178 - accuracy: 1.0000 - val_loss: 0.1327 - val_accuracy: 0.9974\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1183 - accuracy: 0.9987\n",
            "Epoch 25: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.1182 - accuracy: 0.9987 - val_loss: 0.1313 - val_accuracy: 0.9949\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1123 - accuracy: 1.0000\n",
            "Epoch 26: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1123 - accuracy: 1.0000 - val_loss: 0.1276 - val_accuracy: 0.9949\n",
            "Epoch 27/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1076 - accuracy: 1.0000\n",
            "Epoch 27: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.1077 - accuracy: 1.0000 - val_loss: 0.1277 - val_accuracy: 0.9923\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1039 - accuracy: 1.0000\n",
            "Epoch 28: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1040 - accuracy: 1.0000 - val_loss: 0.1190 - val_accuracy: 0.9974\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1025 - accuracy: 1.0000\n",
            "Epoch 29: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.1024 - accuracy: 1.0000 - val_loss: 0.1162 - val_accuracy: 0.9974\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1062 - accuracy: 0.9987\n",
            "Epoch 30: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1062 - accuracy: 0.9987 - val_loss: 0.1195 - val_accuracy: 0.9949\n",
            "Epoch 31/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0994 - accuracy: 1.0000\n",
            "Epoch 31: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0993 - accuracy: 1.0000 - val_loss: 0.1166 - val_accuracy: 0.9949\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0956 - accuracy: 1.0000\n",
            "Epoch 32: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0956 - accuracy: 1.0000 - val_loss: 0.1176 - val_accuracy: 0.9923\n",
            "Epoch 33/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0933 - accuracy: 1.0000\n",
            "Epoch 33: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0933 - accuracy: 1.0000 - val_loss: 0.1092 - val_accuracy: 0.9949\n",
            "Epoch 34/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0907 - accuracy: 1.0000\n",
            "Epoch 34: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0907 - accuracy: 1.0000 - val_loss: 0.1063 - val_accuracy: 0.9949\n",
            "Epoch 35/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0887 - accuracy: 1.0000\n",
            "Epoch 35: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0886 - accuracy: 1.0000 - val_loss: 0.1069 - val_accuracy: 0.9949\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0867 - accuracy: 1.0000\n",
            "Epoch 36: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0867 - accuracy: 1.0000 - val_loss: 0.1066 - val_accuracy: 0.9949\n",
            "Epoch 37/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0852 - accuracy: 1.0000\n",
            "Epoch 37: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0852 - accuracy: 1.0000 - val_loss: 0.1442 - val_accuracy: 0.9795\n",
            "Epoch 38/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0901 - accuracy: 0.9994\n",
            "Epoch 38: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0902 - accuracy: 0.9994 - val_loss: 0.1129 - val_accuracy: 0.9949\n",
            "Epoch 39/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0845 - accuracy: 1.0000\n",
            "Epoch 39: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0846 - accuracy: 1.0000 - val_loss: 0.1011 - val_accuracy: 0.9949\n",
            "Epoch 40/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0802 - accuracy: 1.0000\n",
            "Epoch 40: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0801 - accuracy: 1.0000 - val_loss: 0.1010 - val_accuracy: 0.9949\n",
            "Epoch 41/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0782 - accuracy: 1.0000\n",
            "Epoch 41: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0782 - accuracy: 1.0000 - val_loss: 0.0979 - val_accuracy: 0.9949\n",
            "Epoch 42/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0768 - accuracy: 1.0000\n",
            "Epoch 42: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0768 - accuracy: 1.0000 - val_loss: 0.0982 - val_accuracy: 0.9949\n",
            "Epoch 43/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0750 - accuracy: 1.0000\n",
            "Epoch 43: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0750 - accuracy: 1.0000 - val_loss: 0.0931 - val_accuracy: 0.9949\n",
            "Epoch 44/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0734 - accuracy: 1.0000\n",
            "Epoch 44: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0734 - accuracy: 1.0000 - val_loss: 0.0929 - val_accuracy: 0.9949\n",
            "Epoch 45/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0723 - accuracy: 1.0000\n",
            "Epoch 45: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0722 - accuracy: 1.0000 - val_loss: 0.0887 - val_accuracy: 0.9949\n",
            "Epoch 46/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0703 - accuracy: 1.0000\n",
            "Epoch 46: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0703 - accuracy: 1.0000 - val_loss: 0.0924 - val_accuracy: 0.9949\n",
            "Epoch 47/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0788 - accuracy: 0.9968\n",
            "Epoch 47: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0798 - accuracy: 0.9962 - val_loss: 0.2126 - val_accuracy: 0.9591\n",
            "Epoch 48/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1203 - accuracy: 0.9896\n",
            "Epoch 48: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.1199 - accuracy: 0.9897 - val_loss: 0.0933 - val_accuracy: 0.9949\n",
            "Epoch 49/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0749 - accuracy: 1.0000\n",
            "Epoch 49: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0749 - accuracy: 1.0000 - val_loss: 0.0901 - val_accuracy: 0.9949\n",
            "Epoch 50/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0716 - accuracy: 1.0000\n",
            "Epoch 50: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0716 - accuracy: 1.0000 - val_loss: 0.0887 - val_accuracy: 0.9923\n",
            "Epoch 50: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/8/assets\n",
            "\n",
            "\n",
            "  4%|▍         | 9/200 [26:27<9:04:05, 170.92s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 1.4454 - accuracy: 0.5053\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 12ms/step - loss: 1.4366 - accuracy: 0.5064 - val_loss: 1.4425 - val_accuracy: 0.5652\n",
            "Epoch 2/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.8864 - accuracy: 0.7637\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.8821 - accuracy: 0.7641 - val_loss: 7.5367 - val_accuracy: 0.3478\n",
            "Epoch 3/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.5767 - accuracy: 0.8653\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.5755 - accuracy: 0.8654 - val_loss: 0.7141 - val_accuracy: 0.8005\n",
            "Epoch 4/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.3968 - accuracy: 0.9182\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.3963 - accuracy: 0.9173 - val_loss: 0.5273 - val_accuracy: 0.8440\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3458 - accuracy: 0.9236\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.3478 - accuracy: 0.9237 - val_loss: 0.6689 - val_accuracy: 0.8133\n",
            "Epoch 6/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.2706 - accuracy: 0.9503\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.2677 - accuracy: 0.9513 - val_loss: 0.6475 - val_accuracy: 0.7596\n",
            "Epoch 7/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.2307 - accuracy: 0.9645\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.2377 - accuracy: 0.9635 - val_loss: 0.9766 - val_accuracy: 0.8542\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4209 - accuracy: 0.9139\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.4195 - accuracy: 0.9135 - val_loss: 0.3899 - val_accuracy: 0.8824\n",
            "Epoch 9/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2682 - accuracy: 0.9570\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.2695 - accuracy: 0.9564 - val_loss: 0.2119 - val_accuracy: 0.9744\n",
            "Epoch 10/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.2258 - accuracy: 0.9620\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.2259 - accuracy: 0.9622 - val_loss: 0.3333 - val_accuracy: 0.9514\n",
            "Epoch 11/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1844 - accuracy: 0.9750\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1844 - accuracy: 0.9750 - val_loss: 0.3768 - val_accuracy: 0.9079\n",
            "Epoch 12/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1287 - accuracy: 0.9856\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.1280 - accuracy: 0.9859 - val_loss: 0.1760 - val_accuracy: 0.9591\n",
            "Epoch 13/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1186 - accuracy: 0.9897\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1186 - accuracy: 0.9897 - val_loss: 0.1866 - val_accuracy: 0.9591\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.1754 - accuracy: 0.5816\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 1.1799 - accuracy: 0.5821 - val_loss: 1.7279 - val_accuracy: 0.3529\n",
            "Epoch 15/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.2753 - accuracy: 0.5373\n",
            "Epoch 15: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.2887 - accuracy: 0.5353 - val_loss: 1.3735 - val_accuracy: 0.4910\n",
            "Epoch 16/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.8098 - accuracy: 0.4891\n",
            "Epoch 16: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.8098 - accuracy: 0.4891 - val_loss: 1.6788 - val_accuracy: 0.3785\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.2794 - accuracy: 0.5214\n",
            "Epoch 17: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 1.2755 - accuracy: 0.5224 - val_loss: 1.2540 - val_accuracy: 0.5294\n",
            "Epoch 17: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/9/assets\n",
            "\n",
            "\n",
            "  5%|▌         | 10/200 [27:05<6:51:03, 129.81s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.0881 - accuracy: 0.7977\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 8s 31ms/step - loss: 1.0848 - accuracy: 0.7987 - val_loss: 1.9192 - val_accuracy: 0.2660\n",
            "Epoch 2/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3926 - accuracy: 0.9622\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.3926 - accuracy: 0.9622 - val_loss: 1.8129 - val_accuracy: 0.4322\n",
            "Epoch 3/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2673 - accuracy: 0.9910\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.2676 - accuracy: 0.9910 - val_loss: 0.7504 - val_accuracy: 0.9437\n",
            "Epoch 4/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3111 - accuracy: 0.9723\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.3106 - accuracy: 0.9724 - val_loss: 0.3807 - val_accuracy: 0.9719\n",
            "Epoch 5/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2482 - accuracy: 0.9917\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 0.2482 - accuracy: 0.9917 - val_loss: 0.4004 - val_accuracy: 0.9591\n",
            "Epoch 6/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2538 - accuracy: 0.9878\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.2535 - accuracy: 0.9878 - val_loss: 0.2995 - val_accuracy: 0.9719\n",
            "Epoch 7/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2275 - accuracy: 0.9859\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 0.2275 - accuracy: 0.9859 - val_loss: 0.2615 - val_accuracy: 0.9847\n",
            "Epoch 8/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1797 - accuracy: 0.9987\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.1797 - accuracy: 0.9987 - val_loss: 0.2157 - val_accuracy: 0.9949\n",
            "Epoch 9/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1616 - accuracy: 0.9994\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 0.1616 - accuracy: 0.9994 - val_loss: 0.2357 - val_accuracy: 0.9872\n",
            "Epoch 10/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1541 - accuracy: 0.9994\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.1540 - accuracy: 0.9994 - val_loss: 0.1782 - val_accuracy: 0.9949\n",
            "Epoch 11/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1367 - accuracy: 1.0000\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 0.1367 - accuracy: 1.0000 - val_loss: 0.1648 - val_accuracy: 0.9949\n",
            "Epoch 12/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1245 - accuracy: 1.0000\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.1245 - accuracy: 1.0000 - val_loss: 0.1455 - val_accuracy: 0.9949\n",
            "Epoch 13/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3544 - accuracy: 0.9462\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.3544 - accuracy: 0.9462 - val_loss: 2.8854 - val_accuracy: 0.5985\n",
            "Epoch 14/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3915 - accuracy: 0.9564\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.3915 - accuracy: 0.9564 - val_loss: 0.2792 - val_accuracy: 0.9795\n",
            "Epoch 15/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2004 - accuracy: 0.9955\n",
            "Epoch 15: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.2004 - accuracy: 0.9955 - val_loss: 0.6527 - val_accuracy: 0.9565\n",
            "Epoch 16/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2128 - accuracy: 0.9872\n",
            "Epoch 16: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.2128 - accuracy: 0.9872 - val_loss: 0.2000 - val_accuracy: 0.9923\n",
            "Epoch 17/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1542 - accuracy: 1.0000\n",
            "Epoch 17: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.1542 - accuracy: 1.0000 - val_loss: 0.1658 - val_accuracy: 0.9949\n",
            "Epoch 17: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/10/assets\n",
            "\n",
            "\n",
            "  6%|▌         | 11/200 [28:45<6:19:35, 120.50s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.9252 - accuracy: 0.2286\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 14ms/step - loss: 1.9278 - accuracy: 0.2269 - val_loss: 1.7899 - val_accuracy: 0.2634\n",
            "Epoch 2/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.7693 - accuracy: 0.3028\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.7691 - accuracy: 0.3038 - val_loss: 1.7477 - val_accuracy: 0.2455\n",
            "Epoch 3/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.7062 - accuracy: 0.3526\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.7062 - accuracy: 0.3526 - val_loss: 1.6653 - val_accuracy: 0.3069\n",
            "Epoch 4/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6460 - accuracy: 0.3956\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 1.6466 - accuracy: 0.3955 - val_loss: 1.6105 - val_accuracy: 0.3887\n",
            "Epoch 5/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 1.5961 - accuracy: 0.4467\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.5941 - accuracy: 0.4494 - val_loss: 1.5665 - val_accuracy: 0.4348\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.5365 - accuracy: 0.4974\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.5381 - accuracy: 0.4962 - val_loss: 1.5142 - val_accuracy: 0.4757\n",
            "Epoch 7/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.4724 - accuracy: 0.5314\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.4724 - accuracy: 0.5314 - val_loss: 1.4558 - val_accuracy: 0.5115\n",
            "Epoch 8/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.4169 - accuracy: 0.5593\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.4159 - accuracy: 0.5590 - val_loss: 1.3956 - val_accuracy: 0.5703\n",
            "Epoch 9/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.3568 - accuracy: 0.5921\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.3563 - accuracy: 0.5923 - val_loss: 1.3311 - val_accuracy: 0.6113\n",
            "Epoch 10/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.2876 - accuracy: 0.6374\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 1.2893 - accuracy: 0.6372 - val_loss: 1.2663 - val_accuracy: 0.6547\n",
            "Epoch 11/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.2265 - accuracy: 0.6624\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.2262 - accuracy: 0.6628 - val_loss: 1.2010 - val_accuracy: 0.6905\n",
            "Epoch 12/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.1614 - accuracy: 0.6898\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.1580 - accuracy: 0.6910 - val_loss: 1.1373 - val_accuracy: 0.7263\n",
            "Epoch 13/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.0917 - accuracy: 0.7223\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 1.0913 - accuracy: 0.7231 - val_loss: 1.0751 - val_accuracy: 0.7519\n",
            "Epoch 14/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.0363 - accuracy: 0.7384\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.0367 - accuracy: 0.7372 - val_loss: 1.0159 - val_accuracy: 0.7673\n",
            "Epoch 15/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.9904 - accuracy: 0.7480\n",
            "Epoch 15: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.9876 - accuracy: 0.7506 - val_loss: 0.9619 - val_accuracy: 0.7801\n",
            "Epoch 16/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.9307 - accuracy: 0.7769\n",
            "Epoch 16: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.9307 - accuracy: 0.7769 - val_loss: 0.9136 - val_accuracy: 0.8005\n",
            "Epoch 17/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.8849 - accuracy: 0.8045\n",
            "Epoch 17: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.8849 - accuracy: 0.8045 - val_loss: 0.8709 - val_accuracy: 0.8133\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8504 - accuracy: 0.8122\n",
            "Epoch 18: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.8493 - accuracy: 0.8128 - val_loss: 0.8271 - val_accuracy: 0.8159\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8087 - accuracy: 0.8271\n",
            "Epoch 19: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.8067 - accuracy: 0.8288 - val_loss: 0.7906 - val_accuracy: 0.8338\n",
            "Epoch 20/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.7778 - accuracy: 0.8409\n",
            "Epoch 20: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.7764 - accuracy: 0.8410 - val_loss: 0.7548 - val_accuracy: 0.8491\n",
            "Epoch 21/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.7510 - accuracy: 0.8404\n",
            "Epoch 21: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.7510 - accuracy: 0.8404 - val_loss: 0.7248 - val_accuracy: 0.8491\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7094 - accuracy: 0.8627\n",
            "Epoch 22: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.7105 - accuracy: 0.8628 - val_loss: 0.6965 - val_accuracy: 0.8619\n",
            "Epoch 23/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6890 - accuracy: 0.8609\n",
            "Epoch 23: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.6890 - accuracy: 0.8609 - val_loss: 0.6694 - val_accuracy: 0.8747\n",
            "Epoch 24/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6601 - accuracy: 0.8776\n",
            "Epoch 24: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.6601 - accuracy: 0.8776 - val_loss: 0.6440 - val_accuracy: 0.8747\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6302 - accuracy: 0.8880\n",
            "Epoch 25: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.6332 - accuracy: 0.8853 - val_loss: 0.6217 - val_accuracy: 0.8824\n",
            "Epoch 26/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.6147 - accuracy: 0.8815\n",
            "Epoch 26: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.6156 - accuracy: 0.8821 - val_loss: 0.6018 - val_accuracy: 0.8926\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5952 - accuracy: 0.8990\n",
            "Epoch 27: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.5948 - accuracy: 0.9000 - val_loss: 0.5814 - val_accuracy: 0.9003\n",
            "Epoch 28/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.5747 - accuracy: 0.9038\n",
            "Epoch 28: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.5740 - accuracy: 0.9038 - val_loss: 0.5656 - val_accuracy: 0.9028\n",
            "Epoch 29/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.5571 - accuracy: 0.9164\n",
            "Epoch 29: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.5554 - accuracy: 0.9179 - val_loss: 0.5449 - val_accuracy: 0.9182\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5435 - accuracy: 0.9158\n",
            "Epoch 30: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.5450 - accuracy: 0.9154 - val_loss: 0.5258 - val_accuracy: 0.9207\n",
            "Epoch 31/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.5227 - accuracy: 0.9225\n",
            "Epoch 31: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.5211 - accuracy: 0.9237 - val_loss: 0.5145 - val_accuracy: 0.9309\n",
            "Epoch 32/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.5091 - accuracy: 0.9278\n",
            "Epoch 32: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.5092 - accuracy: 0.9282 - val_loss: 0.5002 - val_accuracy: 0.9309\n",
            "Epoch 33/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.5004 - accuracy: 0.9330\n",
            "Epoch 33: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.5000 - accuracy: 0.9333 - val_loss: 0.4910 - val_accuracy: 0.9335\n",
            "Epoch 34/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4779 - accuracy: 0.9339\n",
            "Epoch 34: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.4785 - accuracy: 0.9333 - val_loss: 0.4778 - val_accuracy: 0.9309\n",
            "Epoch 35/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4737 - accuracy: 0.9398\n",
            "Epoch 35: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.4734 - accuracy: 0.9397 - val_loss: 0.4660 - val_accuracy: 0.9437\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4556 - accuracy: 0.9469\n",
            "Epoch 36: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.4563 - accuracy: 0.9468 - val_loss: 0.4544 - val_accuracy: 0.9463\n",
            "Epoch 37/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.4422 - accuracy: 0.9516\n",
            "Epoch 37: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.4403 - accuracy: 0.9526 - val_loss: 0.4407 - val_accuracy: 0.9565\n",
            "Epoch 38/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.4484 - accuracy: 0.9408\n",
            "Epoch 38: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.4481 - accuracy: 0.9410 - val_loss: 0.4311 - val_accuracy: 0.9565\n",
            "Epoch 39/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.4278 - accuracy: 0.9557\n",
            "Epoch 39: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.4298 - accuracy: 0.9551 - val_loss: 0.4251 - val_accuracy: 0.9591\n",
            "Epoch 40/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4210 - accuracy: 0.9521\n",
            "Epoch 40: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.4202 - accuracy: 0.9526 - val_loss: 0.4137 - val_accuracy: 0.9591\n",
            "Epoch 41/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4090 - accuracy: 0.9609\n",
            "Epoch 41: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.4090 - accuracy: 0.9609 - val_loss: 0.4070 - val_accuracy: 0.9591\n",
            "Epoch 42/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3971 - accuracy: 0.9603\n",
            "Epoch 42: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.3971 - accuracy: 0.9603 - val_loss: 0.3980 - val_accuracy: 0.9616\n",
            "Epoch 43/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.3824 - accuracy: 0.9673\n",
            "Epoch 43: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.3824 - accuracy: 0.9667 - val_loss: 0.3901 - val_accuracy: 0.9616\n",
            "Epoch 44/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.9684\n",
            "Epoch 44: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.3824 - accuracy: 0.9686 - val_loss: 0.3819 - val_accuracy: 0.9668\n",
            "Epoch 45/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3747 - accuracy: 0.9701\n",
            "Epoch 45: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.3738 - accuracy: 0.9705 - val_loss: 0.3762 - val_accuracy: 0.9616\n",
            "Epoch 46/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.3596 - accuracy: 0.9666\n",
            "Epoch 46: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.3608 - accuracy: 0.9660 - val_loss: 0.3676 - val_accuracy: 0.9668\n",
            "Epoch 47/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3591 - accuracy: 0.9686\n",
            "Epoch 47: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.3591 - accuracy: 0.9686 - val_loss: 0.3603 - val_accuracy: 0.9616\n",
            "Epoch 48/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3478 - accuracy: 0.9734\n",
            "Epoch 48: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.3484 - accuracy: 0.9731 - val_loss: 0.3530 - val_accuracy: 0.9668\n",
            "Epoch 49/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3360 - accuracy: 0.9793\n",
            "Epoch 49: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.3361 - accuracy: 0.9788 - val_loss: 0.3496 - val_accuracy: 0.9642\n",
            "Epoch 50/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3397 - accuracy: 0.9742\n",
            "Epoch 50: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.3391 - accuracy: 0.9744 - val_loss: 0.3428 - val_accuracy: 0.9693\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/11/assets\n",
            "\n",
            "\n",
            "  6%|▌         | 12/200 [30:41<6:14:03, 119.38s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.4602 - accuracy: 0.6412\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 7s 25ms/step - loss: 1.4551 - accuracy: 0.6436 - val_loss: 1.7196 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6122 - accuracy: 0.9566\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.6108 - accuracy: 0.9564 - val_loss: 1.9396 - val_accuracy: 0.2890\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4309 - accuracy: 0.9780\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.4312 - accuracy: 0.9776 - val_loss: 1.0504 - val_accuracy: 0.6343\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3349 - accuracy: 0.9948\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.3347 - accuracy: 0.9949 - val_loss: 0.3311 - val_accuracy: 0.9898\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2855 - accuracy: 0.9961\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.2850 - accuracy: 0.9962 - val_loss: 0.2902 - val_accuracy: 0.9898\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2505 - accuracy: 0.9968\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.2504 - accuracy: 0.9968 - val_loss: 0.3075 - val_accuracy: 0.9719\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2225 - accuracy: 0.9974\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.2228 - accuracy: 0.9974 - val_loss: 0.2433 - val_accuracy: 0.9898\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2068 - accuracy: 0.9974\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.2068 - accuracy: 0.9974 - val_loss: 0.2186 - val_accuracy: 0.9923\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1869 - accuracy: 0.9981\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.1868 - accuracy: 0.9981 - val_loss: 0.1906 - val_accuracy: 0.9949\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1763 - accuracy: 0.9981\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1760 - accuracy: 0.9981 - val_loss: 0.1900 - val_accuracy: 0.9872\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1608 - accuracy: 0.9987\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1608 - accuracy: 0.9987 - val_loss: 0.1688 - val_accuracy: 0.9974\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1495 - accuracy: 0.9994\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1494 - accuracy: 0.9994 - val_loss: 0.2598 - val_accuracy: 0.9565\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1449 - accuracy: 1.0000\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1451 - accuracy: 1.0000 - val_loss: 0.1641 - val_accuracy: 0.9974\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1367 - accuracy: 0.9987\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1367 - accuracy: 0.9987 - val_loss: 0.1530 - val_accuracy: 0.9923\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1295 - accuracy: 0.9994\n",
            "Epoch 15: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1293 - accuracy: 0.9994 - val_loss: 0.1508 - val_accuracy: 0.9898\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1257 - accuracy: 0.9987\n",
            "Epoch 16: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1256 - accuracy: 0.9987 - val_loss: 0.1431 - val_accuracy: 0.9923\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1442 - accuracy: 0.9948\n",
            "Epoch 17: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1439 - accuracy: 0.9949 - val_loss: 0.1524 - val_accuracy: 0.9949\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1220 - accuracy: 1.0000\n",
            "Epoch 18: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1218 - accuracy: 1.0000 - val_loss: 0.1324 - val_accuracy: 0.9949\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1124 - accuracy: 0.9994\n",
            "Epoch 19: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1124 - accuracy: 0.9994 - val_loss: 0.1244 - val_accuracy: 0.9923\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1092 - accuracy: 1.0000\n",
            "Epoch 20: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1092 - accuracy: 1.0000 - val_loss: 0.1495 - val_accuracy: 0.9821\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1049 - accuracy: 1.0000\n",
            "Epoch 21: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1049 - accuracy: 1.0000 - val_loss: 0.1192 - val_accuracy: 0.9923\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1015 - accuracy: 1.0000\n",
            "Epoch 22: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1016 - accuracy: 1.0000 - val_loss: 0.1232 - val_accuracy: 0.9923\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0981 - accuracy: 1.0000\n",
            "Epoch 23: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0981 - accuracy: 1.0000 - val_loss: 0.1179 - val_accuracy: 0.9923\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0989 - accuracy: 1.0000\n",
            "Epoch 24: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0988 - accuracy: 1.0000 - val_loss: 0.1259 - val_accuracy: 0.9898\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0950 - accuracy: 1.0000\n",
            "Epoch 25: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0950 - accuracy: 1.0000 - val_loss: 0.1140 - val_accuracy: 0.9923\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0924 - accuracy: 1.0000\n",
            "Epoch 26: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0924 - accuracy: 1.0000 - val_loss: 0.1205 - val_accuracy: 0.9923\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0962 - accuracy: 0.9987\n",
            "Epoch 27: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0963 - accuracy: 0.9987 - val_loss: 0.4577 - val_accuracy: 0.9079\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1190 - accuracy: 0.9942\n",
            "Epoch 28: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1187 - accuracy: 0.9942 - val_loss: 0.1319 - val_accuracy: 0.9923\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0929 - accuracy: 1.0000\n",
            "Epoch 29: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0928 - accuracy: 1.0000 - val_loss: 0.1174 - val_accuracy: 0.9898\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0873 - accuracy: 1.0000\n",
            "Epoch 30: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0873 - accuracy: 1.0000 - val_loss: 0.1106 - val_accuracy: 0.9923\n",
            "Epoch 31/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0874 - accuracy: 1.0000\n",
            "Epoch 31: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0873 - accuracy: 1.0000 - val_loss: 0.1084 - val_accuracy: 0.9923\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0837 - accuracy: 1.0000\n",
            "Epoch 32: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0837 - accuracy: 1.0000 - val_loss: 0.1089 - val_accuracy: 0.9923\n",
            "Epoch 33/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0822 - accuracy: 1.0000\n",
            "Epoch 33: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0823 - accuracy: 1.0000 - val_loss: 0.1079 - val_accuracy: 0.9923\n",
            "Epoch 34/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0800 - accuracy: 1.0000\n",
            "Epoch 34: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0800 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 0.9898\n",
            "Epoch 35/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0782 - accuracy: 1.0000\n",
            "Epoch 35: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0781 - accuracy: 1.0000 - val_loss: 0.1088 - val_accuracy: 0.9923\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0760 - accuracy: 1.0000\n",
            "Epoch 36: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0760 - accuracy: 1.0000 - val_loss: 0.1031 - val_accuracy: 0.9923\n",
            "Epoch 37/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0750 - accuracy: 1.0000\n",
            "Epoch 37: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0750 - accuracy: 1.0000 - val_loss: 0.1000 - val_accuracy: 0.9923\n",
            "Epoch 38/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0733 - accuracy: 1.0000\n",
            "Epoch 38: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0733 - accuracy: 1.0000 - val_loss: 0.1027 - val_accuracy: 0.9923\n",
            "Epoch 39/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0719 - accuracy: 1.0000\n",
            "Epoch 39: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0719 - accuracy: 1.0000 - val_loss: 0.0959 - val_accuracy: 0.9923\n",
            "Epoch 40/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0705 - accuracy: 1.0000\n",
            "Epoch 40: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0705 - accuracy: 1.0000 - val_loss: 0.0996 - val_accuracy: 0.9923\n",
            "Epoch 41/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0701 - accuracy: 1.0000\n",
            "Epoch 41: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0701 - accuracy: 1.0000 - val_loss: 0.0959 - val_accuracy: 0.9923\n",
            "Epoch 42/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0680 - accuracy: 1.0000\n",
            "Epoch 42: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0679 - accuracy: 1.0000 - val_loss: 0.0981 - val_accuracy: 0.9923\n",
            "Epoch 43/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0729 - accuracy: 0.9981\n",
            "Epoch 43: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0730 - accuracy: 0.9981 - val_loss: 0.1582 - val_accuracy: 0.9821\n",
            "Epoch 44/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1358 - accuracy: 0.9832\n",
            "Epoch 44: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1352 - accuracy: 0.9833 - val_loss: 0.1110 - val_accuracy: 0.9872\n",
            "Epoch 45/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0783 - accuracy: 1.0000\n",
            "Epoch 45: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0783 - accuracy: 1.0000 - val_loss: 0.0929 - val_accuracy: 0.9898\n",
            "Epoch 46/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0740 - accuracy: 1.0000\n",
            "Epoch 46: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0740 - accuracy: 1.0000 - val_loss: 0.0946 - val_accuracy: 0.9923\n",
            "Epoch 47/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0705 - accuracy: 1.0000\n",
            "Epoch 47: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0707 - accuracy: 1.0000 - val_loss: 0.0879 - val_accuracy: 0.9923\n",
            "Epoch 48/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0686 - accuracy: 1.0000\n",
            "Epoch 48: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0685 - accuracy: 1.0000 - val_loss: 0.0890 - val_accuracy: 0.9923\n",
            "Epoch 49/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0664 - accuracy: 1.0000\n",
            "Epoch 49: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0664 - accuracy: 1.0000 - val_loss: 0.0935 - val_accuracy: 0.9923\n",
            "Epoch 50/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0652 - accuracy: 1.0000\n",
            "Epoch 50: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0652 - accuracy: 1.0000 - val_loss: 0.0920 - val_accuracy: 0.9923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/12/assets\n",
            "\n",
            "\n",
            "  6%|▋         | 13/200 [35:09<8:31:41, 164.18s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 2.7245 - accuracy: 0.2701\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 12ms/step - loss: 2.7168 - accuracy: 0.2718 - val_loss: 1.7544 - val_accuracy: 0.2583\n",
            "Epoch 2/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 2.1621 - accuracy: 0.3318\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 2.1566 - accuracy: 0.3340 - val_loss: 1.7679 - val_accuracy: 0.2583\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.9808 - accuracy: 0.3685\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 1.9797 - accuracy: 0.3686 - val_loss: 1.7570 - val_accuracy: 0.3299\n",
            "Epoch 4/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 1.9033 - accuracy: 0.4021\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.9018 - accuracy: 0.4013 - val_loss: 1.7681 - val_accuracy: 0.4450\n",
            "Epoch 5/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.8238 - accuracy: 0.4543\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.8270 - accuracy: 0.4538 - val_loss: 1.7413 - val_accuracy: 0.4936\n",
            "Epoch 6/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.7637 - accuracy: 0.4679\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 1.7637 - accuracy: 0.4679 - val_loss: 1.6889 - val_accuracy: 0.5166\n",
            "Epoch 7/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.7098 - accuracy: 0.5147\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 1.7098 - accuracy: 0.5147 - val_loss: 1.6373 - val_accuracy: 0.5396\n",
            "Epoch 8/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6547 - accuracy: 0.5263\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.6547 - accuracy: 0.5263 - val_loss: 1.5886 - val_accuracy: 0.5499\n",
            "Epoch 9/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 1.6204 - accuracy: 0.5397\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.6144 - accuracy: 0.5423 - val_loss: 1.5416 - val_accuracy: 0.5882\n",
            "Epoch 10/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 1.5629 - accuracy: 0.5787\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 1.5672 - accuracy: 0.5750 - val_loss: 1.4934 - val_accuracy: 0.6113\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.5179 - accuracy: 0.5972\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 1.5169 - accuracy: 0.5968 - val_loss: 1.4531 - val_accuracy: 0.6138\n",
            "Epoch 12/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.4721 - accuracy: 0.6205\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.4721 - accuracy: 0.6205 - val_loss: 1.4065 - val_accuracy: 0.6368\n",
            "Epoch 13/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.4317 - accuracy: 0.6327\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.4327 - accuracy: 0.6327 - val_loss: 1.3641 - val_accuracy: 0.6496\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.3884 - accuracy: 0.6457\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 1.3873 - accuracy: 0.6462 - val_loss: 1.3247 - val_accuracy: 0.6650\n",
            "Epoch 15/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.3454 - accuracy: 0.6647\n",
            "Epoch 15: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 1.3472 - accuracy: 0.6654 - val_loss: 1.2823 - val_accuracy: 0.6803\n",
            "Epoch 16/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.3028 - accuracy: 0.6797\n",
            "Epoch 16: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.3051 - accuracy: 0.6808 - val_loss: 1.2386 - val_accuracy: 0.6880\n",
            "Epoch 17/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 1.2526 - accuracy: 0.7178\n",
            "Epoch 17: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.2561 - accuracy: 0.7167 - val_loss: 1.2020 - val_accuracy: 0.6982\n",
            "Epoch 18/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.2086 - accuracy: 0.7305\n",
            "Epoch 18: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 1.2072 - accuracy: 0.7308 - val_loss: 1.1636 - val_accuracy: 0.7238\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.1718 - accuracy: 0.7539\n",
            "Epoch 19: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.1706 - accuracy: 0.7545 - val_loss: 1.1216 - val_accuracy: 0.7340\n",
            "Epoch 20/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.1447 - accuracy: 0.7513\n",
            "Epoch 20: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.1447 - accuracy: 0.7513 - val_loss: 1.0871 - val_accuracy: 0.7570\n",
            "Epoch 21/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 1.0931 - accuracy: 0.7763\n",
            "Epoch 21: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.0933 - accuracy: 0.7769 - val_loss: 1.0485 - val_accuracy: 0.7698\n",
            "Epoch 22/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 1.0849 - accuracy: 0.7652\n",
            "Epoch 22: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.0813 - accuracy: 0.7686 - val_loss: 1.0242 - val_accuracy: 0.7749\n",
            "Epoch 23/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.0431 - accuracy: 0.7942\n",
            "Epoch 23: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.0431 - accuracy: 0.7942 - val_loss: 0.9906 - val_accuracy: 0.7852\n",
            "Epoch 24/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.9927 - accuracy: 0.8122\n",
            "Epoch 24: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.9965 - accuracy: 0.8109 - val_loss: 0.9606 - val_accuracy: 0.7903\n",
            "Epoch 25/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.9886 - accuracy: 0.8046\n",
            "Epoch 25: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.9883 - accuracy: 0.8038 - val_loss: 0.9337 - val_accuracy: 0.8031\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.9595 - accuracy: 0.8193\n",
            "Epoch 26: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.9594 - accuracy: 0.8192 - val_loss: 0.9070 - val_accuracy: 0.8261\n",
            "Epoch 27/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.9358 - accuracy: 0.8231\n",
            "Epoch 27: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.9358 - accuracy: 0.8231 - val_loss: 0.8811 - val_accuracy: 0.8338\n",
            "Epoch 28/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.9002 - accuracy: 0.8349\n",
            "Epoch 28: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.8999 - accuracy: 0.8353 - val_loss: 0.8583 - val_accuracy: 0.8465\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8804 - accuracy: 0.8510\n",
            "Epoch 29: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.8804 - accuracy: 0.8506 - val_loss: 0.8384 - val_accuracy: 0.8568\n",
            "Epoch 30/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.8610 - accuracy: 0.8501\n",
            "Epoch 30: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.8606 - accuracy: 0.8513 - val_loss: 0.8190 - val_accuracy: 0.8619\n",
            "Epoch 31/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.8370 - accuracy: 0.8547\n",
            "Epoch 31: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.8359 - accuracy: 0.8564 - val_loss: 0.8032 - val_accuracy: 0.8619\n",
            "Epoch 32/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.8151 - accuracy: 0.8606\n",
            "Epoch 32: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.8175 - accuracy: 0.8590 - val_loss: 0.7832 - val_accuracy: 0.8696\n",
            "Epoch 33/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.8055 - accuracy: 0.8737\n",
            "Epoch 33: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.8052 - accuracy: 0.8731 - val_loss: 0.7654 - val_accuracy: 0.8772\n",
            "Epoch 34/50\n",
            "188/195 [===========================>..] - ETA: 0s - loss: 0.7880 - accuracy: 0.8717\n",
            "Epoch 34: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.7876 - accuracy: 0.8718 - val_loss: 0.7507 - val_accuracy: 0.8798\n",
            "Epoch 35/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.7702 - accuracy: 0.8854\n",
            "Epoch 35: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.7684 - accuracy: 0.8872 - val_loss: 0.7344 - val_accuracy: 0.8900\n",
            "Epoch 36/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.7472 - accuracy: 0.8841\n",
            "Epoch 36: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.7481 - accuracy: 0.8840 - val_loss: 0.7234 - val_accuracy: 0.8875\n",
            "Epoch 37/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.7445 - accuracy: 0.8849\n",
            "Epoch 37: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.7426 - accuracy: 0.8853 - val_loss: 0.7093 - val_accuracy: 0.8875\n",
            "Epoch 38/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7151 - accuracy: 0.8957\n",
            "Epoch 38: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.7143 - accuracy: 0.8962 - val_loss: 0.6975 - val_accuracy: 0.9028\n",
            "Epoch 39/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.7149 - accuracy: 0.8955\n",
            "Epoch 39: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.7149 - accuracy: 0.8955 - val_loss: 0.6825 - val_accuracy: 0.9079\n",
            "Epoch 40/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 0.6902 - accuracy: 0.9028\n",
            "Epoch 40: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.6885 - accuracy: 0.9038 - val_loss: 0.6676 - val_accuracy: 0.9130\n",
            "Epoch 41/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6769 - accuracy: 0.9126\n",
            "Epoch 41: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.6768 - accuracy: 0.9115 - val_loss: 0.6597 - val_accuracy: 0.9130\n",
            "Epoch 42/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6565 - accuracy: 0.9145\n",
            "Epoch 42: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.6595 - accuracy: 0.9135 - val_loss: 0.6453 - val_accuracy: 0.9130\n",
            "Epoch 43/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.6522 - accuracy: 0.9158\n",
            "Epoch 43: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.6522 - accuracy: 0.9154 - val_loss: 0.6341 - val_accuracy: 0.9207\n",
            "Epoch 44/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.6433 - accuracy: 0.9134\n",
            "Epoch 44: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.6437 - accuracy: 0.9141 - val_loss: 0.6254 - val_accuracy: 0.9309\n",
            "Epoch 45/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.6330 - accuracy: 0.9171\n",
            "Epoch 45: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.6303 - accuracy: 0.9192 - val_loss: 0.6140 - val_accuracy: 0.9284\n",
            "Epoch 46/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6114 - accuracy: 0.9262\n",
            "Epoch 46: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.6123 - accuracy: 0.9256 - val_loss: 0.6062 - val_accuracy: 0.9335\n",
            "Epoch 47/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.6095 - accuracy: 0.9264\n",
            "Epoch 47: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.6088 - accuracy: 0.9269 - val_loss: 0.5992 - val_accuracy: 0.9361\n",
            "Epoch 48/50\n",
            "188/195 [===========================>..] - ETA: 0s - loss: 0.5980 - accuracy: 0.9289\n",
            "Epoch 48: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.5966 - accuracy: 0.9282 - val_loss: 0.5881 - val_accuracy: 0.9309\n",
            "Epoch 49/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.5778 - accuracy: 0.9382\n",
            "Epoch 49: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.5784 - accuracy: 0.9385 - val_loss: 0.5771 - val_accuracy: 0.9309\n",
            "Epoch 50/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.5809 - accuracy: 0.9298\n",
            "Epoch 50: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.5806 - accuracy: 0.9301 - val_loss: 0.5671 - val_accuracy: 0.9335\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/13/assets\n",
            "\n",
            "\n",
            "  7%|▋         | 14/200 [37:36<8:13:01, 159.04s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 2.0064 - accuracy: 0.2966\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 15ms/step - loss: 2.0041 - accuracy: 0.3000 - val_loss: 1.8040 - val_accuracy: 0.3095\n",
            "Epoch 2/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.8160 - accuracy: 0.3999\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 1.8158 - accuracy: 0.3994 - val_loss: 1.7622 - val_accuracy: 0.3043\n",
            "Epoch 3/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.7013 - accuracy: 0.4647\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 1.7013 - accuracy: 0.4654 - val_loss: 1.6497 - val_accuracy: 0.4808\n",
            "Epoch 4/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.5933 - accuracy: 0.5438\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 1.5929 - accuracy: 0.5429 - val_loss: 1.5192 - val_accuracy: 0.5780\n",
            "Epoch 5/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.4936 - accuracy: 0.6073\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 1.4933 - accuracy: 0.6090 - val_loss: 1.4367 - val_accuracy: 0.6317\n",
            "Epoch 6/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.4020 - accuracy: 0.6695\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 1.4015 - accuracy: 0.6667 - val_loss: 1.3527 - val_accuracy: 0.6777\n",
            "Epoch 7/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.3054 - accuracy: 0.7062\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 1.3071 - accuracy: 0.7026 - val_loss: 1.2727 - val_accuracy: 0.7161\n",
            "Epoch 8/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.2295 - accuracy: 0.7330\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 1.2288 - accuracy: 0.7327 - val_loss: 1.1903 - val_accuracy: 0.7519\n",
            "Epoch 9/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.1423 - accuracy: 0.7692\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 1.1423 - accuracy: 0.7692 - val_loss: 1.1164 - val_accuracy: 0.7852\n",
            "Epoch 10/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.0653 - accuracy: 0.7893\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 1.0666 - accuracy: 0.7897 - val_loss: 1.0430 - val_accuracy: 0.8159\n",
            "Epoch 11/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.9987 - accuracy: 0.8285\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.9950 - accuracy: 0.8301 - val_loss: 0.9754 - val_accuracy: 0.8363\n",
            "Epoch 12/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.9312 - accuracy: 0.8482\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.9273 - accuracy: 0.8506 - val_loss: 0.9116 - val_accuracy: 0.8645\n",
            "Epoch 13/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.8651 - accuracy: 0.8686\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.8638 - accuracy: 0.8692 - val_loss: 0.8555 - val_accuracy: 0.8875\n",
            "Epoch 14/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.8111 - accuracy: 0.8815\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.8122 - accuracy: 0.8821 - val_loss: 0.8027 - val_accuracy: 0.8951\n",
            "Epoch 15/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.7557 - accuracy: 0.9038\n",
            "Epoch 15: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.7557 - accuracy: 0.9038 - val_loss: 0.7543 - val_accuracy: 0.9054\n",
            "Epoch 16/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.7224 - accuracy: 0.9084\n",
            "Epoch 16: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.7225 - accuracy: 0.9077 - val_loss: 0.7108 - val_accuracy: 0.9233\n",
            "Epoch 17/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.6666 - accuracy: 0.9319\n",
            "Epoch 17: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.6645 - accuracy: 0.9327 - val_loss: 0.6697 - val_accuracy: 0.9361\n",
            "Epoch 18/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.6340 - accuracy: 0.9372\n",
            "Epoch 18: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.6342 - accuracy: 0.9378 - val_loss: 0.6345 - val_accuracy: 0.9335\n",
            "Epoch 19/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.5961 - accuracy: 0.9529\n",
            "Epoch 19: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.5952 - accuracy: 0.9538 - val_loss: 0.6025 - val_accuracy: 0.9463\n",
            "Epoch 20/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.5703 - accuracy: 0.9548\n",
            "Epoch 20: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.5695 - accuracy: 0.9551 - val_loss: 0.5739 - val_accuracy: 0.9514\n",
            "Epoch 21/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.5366 - accuracy: 0.9627\n",
            "Epoch 21: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.5362 - accuracy: 0.9628 - val_loss: 0.5487 - val_accuracy: 0.9540\n",
            "Epoch 22/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.5181 - accuracy: 0.9725\n",
            "Epoch 22: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.5183 - accuracy: 0.9731 - val_loss: 0.5283 - val_accuracy: 0.9565\n",
            "Epoch 23/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.5019 - accuracy: 0.9710\n",
            "Epoch 23: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.5019 - accuracy: 0.9705 - val_loss: 0.5082 - val_accuracy: 0.9693\n",
            "Epoch 24/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.4725 - accuracy: 0.9764\n",
            "Epoch 24: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.4716 - accuracy: 0.9763 - val_loss: 0.4863 - val_accuracy: 0.9744\n",
            "Epoch 25/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.4574 - accuracy: 0.9784\n",
            "Epoch 25: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.4567 - accuracy: 0.9788 - val_loss: 0.4671 - val_accuracy: 0.9693\n",
            "Epoch 26/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.4425 - accuracy: 0.9777\n",
            "Epoch 26: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.4418 - accuracy: 0.9776 - val_loss: 0.4515 - val_accuracy: 0.9821\n",
            "Epoch 27/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.4238 - accuracy: 0.9843\n",
            "Epoch 27: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.4258 - accuracy: 0.9827 - val_loss: 0.4412 - val_accuracy: 0.9795\n",
            "Epoch 28/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.4094 - accuracy: 0.9830\n",
            "Epoch 28: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.4090 - accuracy: 0.9827 - val_loss: 0.4227 - val_accuracy: 0.9847\n",
            "Epoch 29/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.4006 - accuracy: 0.9830\n",
            "Epoch 29: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.3998 - accuracy: 0.9833 - val_loss: 0.4125 - val_accuracy: 0.9770\n",
            "Epoch 30/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.3870 - accuracy: 0.9902\n",
            "Epoch 30: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.3881 - accuracy: 0.9897 - val_loss: 0.4015 - val_accuracy: 0.9847\n",
            "Epoch 31/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.3756 - accuracy: 0.9895\n",
            "Epoch 31: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.3754 - accuracy: 0.9897 - val_loss: 0.3904 - val_accuracy: 0.9898\n",
            "Epoch 32/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.3617 - accuracy: 0.9889\n",
            "Epoch 32: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.3609 - accuracy: 0.9891 - val_loss: 0.3810 - val_accuracy: 0.9847\n",
            "Epoch 33/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.3503 - accuracy: 0.9921\n",
            "Epoch 33: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.3505 - accuracy: 0.9917 - val_loss: 0.3661 - val_accuracy: 0.9898\n",
            "Epoch 34/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.3471 - accuracy: 0.9889\n",
            "Epoch 34: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.3467 - accuracy: 0.9891 - val_loss: 0.3591 - val_accuracy: 0.9872\n",
            "Epoch 35/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.3374 - accuracy: 0.9908\n",
            "Epoch 35: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.3368 - accuracy: 0.9910 - val_loss: 0.3486 - val_accuracy: 0.9898\n",
            "Epoch 36/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.3244 - accuracy: 0.9928\n",
            "Epoch 36: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.3247 - accuracy: 0.9929 - val_loss: 0.3397 - val_accuracy: 0.9898\n",
            "Epoch 37/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.3145 - accuracy: 0.9941\n",
            "Epoch 37: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.3150 - accuracy: 0.9942 - val_loss: 0.3324 - val_accuracy: 0.9949\n",
            "Epoch 38/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.3044 - accuracy: 0.9954\n",
            "Epoch 38: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.3037 - accuracy: 0.9955 - val_loss: 0.3227 - val_accuracy: 0.9923\n",
            "Epoch 39/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.3016 - accuracy: 0.9941\n",
            "Epoch 39: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.3024 - accuracy: 0.9936 - val_loss: 0.3153 - val_accuracy: 0.9923\n",
            "Epoch 40/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.2934 - accuracy: 0.9954\n",
            "Epoch 40: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.2939 - accuracy: 0.9949 - val_loss: 0.3109 - val_accuracy: 0.9949\n",
            "Epoch 41/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.2871 - accuracy: 0.9948\n",
            "Epoch 41: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.2866 - accuracy: 0.9949 - val_loss: 0.3022 - val_accuracy: 0.9949\n",
            "Epoch 42/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.2824 - accuracy: 0.9948\n",
            "Epoch 42: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.2830 - accuracy: 0.9949 - val_loss: 0.2941 - val_accuracy: 0.9949\n",
            "Epoch 43/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.2743 - accuracy: 0.9967\n",
            "Epoch 43: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.2742 - accuracy: 0.9968 - val_loss: 0.2929 - val_accuracy: 0.9923\n",
            "Epoch 44/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.2699 - accuracy: 0.9954\n",
            "Epoch 44: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.2694 - accuracy: 0.9955 - val_loss: 0.2853 - val_accuracy: 0.9949\n",
            "Epoch 45/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.2651 - accuracy: 0.9961\n",
            "Epoch 45: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.2656 - accuracy: 0.9962 - val_loss: 0.2798 - val_accuracy: 0.9949\n",
            "Epoch 46/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.2553 - accuracy: 0.9987\n",
            "Epoch 46: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.2549 - accuracy: 0.9987 - val_loss: 0.2779 - val_accuracy: 0.9949\n",
            "Epoch 47/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.2513 - accuracy: 0.9967\n",
            "Epoch 47: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.2522 - accuracy: 0.9968 - val_loss: 0.2681 - val_accuracy: 0.9949\n",
            "Epoch 48/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.2459 - accuracy: 0.9980\n",
            "Epoch 48: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.2464 - accuracy: 0.9974 - val_loss: 0.2626 - val_accuracy: 0.9949\n",
            "Epoch 49/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.2441 - accuracy: 0.9967\n",
            "Epoch 49: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.2437 - accuracy: 0.9968 - val_loss: 0.2578 - val_accuracy: 0.9949\n",
            "Epoch 50/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.2376 - accuracy: 0.9980\n",
            "Epoch 50: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.2382 - accuracy: 0.9981 - val_loss: 0.2544 - val_accuracy: 0.9949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/14/assets\n",
            "\n",
            "\n",
            "  8%|▊         | 15/200 [40:03<7:59:23, 155.48s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.0359 - accuracy: 0.7474\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 14ms/step - loss: 1.0269 - accuracy: 0.7506 - val_loss: 1.9618 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.3093 - accuracy: 0.9509\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.3145 - accuracy: 0.9487 - val_loss: 1.9459 - val_accuracy: 0.3223\n",
            "Epoch 3/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.2428 - accuracy: 0.9666\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.2414 - accuracy: 0.9673 - val_loss: 0.3939 - val_accuracy: 0.8900\n",
            "Epoch 4/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1586 - accuracy: 0.9876\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.1579 - accuracy: 0.9872 - val_loss: 0.2165 - val_accuracy: 0.9642\n",
            "Epoch 5/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1664 - accuracy: 0.9784\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.1650 - accuracy: 0.9788 - val_loss: 0.2245 - val_accuracy: 0.9668\n",
            "Epoch 6/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1076 - accuracy: 0.9921\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.1069 - accuracy: 0.9923 - val_loss: 0.1050 - val_accuracy: 0.9898\n",
            "Epoch 7/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0820 - accuracy: 0.9974\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0818 - accuracy: 0.9974 - val_loss: 0.1068 - val_accuracy: 0.9923\n",
            "Epoch 8/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0703 - accuracy: 0.9987\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0702 - accuracy: 0.9987 - val_loss: 0.1037 - val_accuracy: 0.9898\n",
            "Epoch 9/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0628 - accuracy: 1.0000\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0630 - accuracy: 1.0000 - val_loss: 0.0881 - val_accuracy: 0.9974\n",
            "Epoch 10/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0847 - accuracy: 0.9948\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0855 - accuracy: 0.9949 - val_loss: 1.3728 - val_accuracy: 0.7161\n",
            "Epoch 11/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.2323 - accuracy: 0.9679\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.2295 - accuracy: 0.9686 - val_loss: 0.1884 - val_accuracy: 0.9719\n",
            "Epoch 12/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0857 - accuracy: 0.9961\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0853 - accuracy: 0.9962 - val_loss: 0.1236 - val_accuracy: 0.9847\n",
            "Epoch 13/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0671 - accuracy: 0.9993\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.0669 - accuracy: 0.9994 - val_loss: 0.1092 - val_accuracy: 0.9795\n",
            "Epoch 14/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0582 - accuracy: 1.0000\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0581 - accuracy: 1.0000 - val_loss: 0.0893 - val_accuracy: 0.9898\n",
            "Epoch 14: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/15/assets\n",
            "\n",
            "\n",
            "  8%|▊         | 16/200 [40:42<6:09:13, 120.40s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 2.1881 - accuracy: 0.2365\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 14ms/step - loss: 2.1891 - accuracy: 0.2353 - val_loss: 1.7898 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 2.0118 - accuracy: 0.3141\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 2.0087 - accuracy: 0.3167 - val_loss: 1.7398 - val_accuracy: 0.2967\n",
            "Epoch 3/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.9012 - accuracy: 0.3809\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 1.8989 - accuracy: 0.3821 - val_loss: 1.6929 - val_accuracy: 0.3478\n",
            "Epoch 4/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.8047 - accuracy: 0.4319\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 1.8007 - accuracy: 0.4321 - val_loss: 1.6741 - val_accuracy: 0.4578\n",
            "Epoch 5/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.7053 - accuracy: 0.4869\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 1.7029 - accuracy: 0.4897 - val_loss: 1.6076 - val_accuracy: 0.5371\n",
            "Epoch 6/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.5932 - accuracy: 0.5589\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 1.5909 - accuracy: 0.5590 - val_loss: 1.5052 - val_accuracy: 0.6138\n",
            "Epoch 7/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.4849 - accuracy: 0.6237\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 1.4850 - accuracy: 0.6224 - val_loss: 1.3958 - val_accuracy: 0.6803\n",
            "Epoch 8/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.3715 - accuracy: 0.6754\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 1.3683 - accuracy: 0.6782 - val_loss: 1.3028 - val_accuracy: 0.7238\n",
            "Epoch 9/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.2862 - accuracy: 0.7168\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 1.2829 - accuracy: 0.7192 - val_loss: 1.2099 - val_accuracy: 0.7724\n",
            "Epoch 10/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.1979 - accuracy: 0.7677\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 1.1954 - accuracy: 0.7679 - val_loss: 1.1363 - val_accuracy: 0.7724\n",
            "Epoch 11/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.1160 - accuracy: 0.8004\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 1.1167 - accuracy: 0.7981 - val_loss: 1.0618 - val_accuracy: 0.7980\n",
            "Epoch 12/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.0438 - accuracy: 0.8320\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 1.0428 - accuracy: 0.8314 - val_loss: 0.9897 - val_accuracy: 0.8517\n",
            "Epoch 13/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.9627 - accuracy: 0.8521\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.9632 - accuracy: 0.8526 - val_loss: 0.9286 - val_accuracy: 0.8619\n",
            "Epoch 14/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.8938 - accuracy: 0.8763\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.8914 - accuracy: 0.8769 - val_loss: 0.8736 - val_accuracy: 0.8849\n",
            "Epoch 15/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.8394 - accuracy: 0.8933\n",
            "Epoch 15: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.8383 - accuracy: 0.8942 - val_loss: 0.8210 - val_accuracy: 0.9079\n",
            "Epoch 16/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.7877 - accuracy: 0.9182\n",
            "Epoch 16: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.7867 - accuracy: 0.9186 - val_loss: 0.7762 - val_accuracy: 0.9156\n",
            "Epoch 17/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.7405 - accuracy: 0.9293\n",
            "Epoch 17: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.7382 - accuracy: 0.9288 - val_loss: 0.7373 - val_accuracy: 0.9233\n",
            "Epoch 18/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.7017 - accuracy: 0.9391\n",
            "Epoch 18: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.7010 - accuracy: 0.9391 - val_loss: 0.6938 - val_accuracy: 0.9437\n",
            "Epoch 19/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.6605 - accuracy: 0.9535\n",
            "Epoch 19: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.6604 - accuracy: 0.9532 - val_loss: 0.6675 - val_accuracy: 0.9488\n",
            "Epoch 20/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.6265 - accuracy: 0.9603\n",
            "Epoch 20: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.6264 - accuracy: 0.9596 - val_loss: 0.6339 - val_accuracy: 0.9616\n",
            "Epoch 21/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.6030 - accuracy: 0.9634\n",
            "Epoch 21: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.6022 - accuracy: 0.9641 - val_loss: 0.6086 - val_accuracy: 0.9642\n",
            "Epoch 22/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.5787 - accuracy: 0.9673\n",
            "Epoch 22: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.5779 - accuracy: 0.9673 - val_loss: 0.5862 - val_accuracy: 0.9693\n",
            "Epoch 23/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.5601 - accuracy: 0.9701\n",
            "Epoch 23: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.5598 - accuracy: 0.9705 - val_loss: 0.5607 - val_accuracy: 0.9642\n",
            "Epoch 24/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.5348 - accuracy: 0.9777\n",
            "Epoch 24: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.5334 - accuracy: 0.9782 - val_loss: 0.5406 - val_accuracy: 0.9693\n",
            "Epoch 25/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.5096 - accuracy: 0.9771\n",
            "Epoch 25: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.5106 - accuracy: 0.9769 - val_loss: 0.5251 - val_accuracy: 0.9770\n",
            "Epoch 26/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.4983 - accuracy: 0.9785\n",
            "Epoch 26: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.4979 - accuracy: 0.9788 - val_loss: 0.5105 - val_accuracy: 0.9744\n",
            "Epoch 27/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.4761 - accuracy: 0.9843\n",
            "Epoch 27: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.4749 - accuracy: 0.9846 - val_loss: 0.4865 - val_accuracy: 0.9847\n",
            "Epoch 28/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.4586 - accuracy: 0.9849\n",
            "Epoch 28: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.4588 - accuracy: 0.9846 - val_loss: 0.4731 - val_accuracy: 0.9847\n",
            "Epoch 29/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.4486 - accuracy: 0.9810\n",
            "Epoch 29: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.4488 - accuracy: 0.9808 - val_loss: 0.4551 - val_accuracy: 0.9821\n",
            "Epoch 30/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.4320 - accuracy: 0.9863\n",
            "Epoch 30: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.4329 - accuracy: 0.9859 - val_loss: 0.4418 - val_accuracy: 0.9847\n",
            "Epoch 31/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.4229 - accuracy: 0.9869\n",
            "Epoch 31: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.4226 - accuracy: 0.9872 - val_loss: 0.4275 - val_accuracy: 0.9898\n",
            "Epoch 32/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.4075 - accuracy: 0.9908\n",
            "Epoch 32: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.4081 - accuracy: 0.9904 - val_loss: 0.4170 - val_accuracy: 0.9923\n",
            "Epoch 33/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.3924 - accuracy: 0.9869\n",
            "Epoch 33: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.3932 - accuracy: 0.9872 - val_loss: 0.4058 - val_accuracy: 0.9923\n",
            "Epoch 34/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.9908\n",
            "Epoch 34: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.3829 - accuracy: 0.9910 - val_loss: 0.3928 - val_accuracy: 0.9949\n",
            "Epoch 35/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.3770 - accuracy: 0.9902\n",
            "Epoch 35: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.3768 - accuracy: 0.9904 - val_loss: 0.3831 - val_accuracy: 0.9949\n",
            "Epoch 36/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.3660 - accuracy: 0.9915\n",
            "Epoch 36: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.3655 - accuracy: 0.9917 - val_loss: 0.3830 - val_accuracy: 0.9898\n",
            "Epoch 37/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.3530 - accuracy: 0.9921\n",
            "Epoch 37: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.3539 - accuracy: 0.9923 - val_loss: 0.3657 - val_accuracy: 0.9898\n",
            "Epoch 38/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3477 - accuracy: 0.9929\n",
            "Epoch 38: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.3477 - accuracy: 0.9929 - val_loss: 0.3563 - val_accuracy: 0.9949\n",
            "Epoch 39/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.3385 - accuracy: 0.9915\n",
            "Epoch 39: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.3380 - accuracy: 0.9917 - val_loss: 0.3509 - val_accuracy: 0.9949\n",
            "Epoch 40/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.3310 - accuracy: 0.9915\n",
            "Epoch 40: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.3307 - accuracy: 0.9917 - val_loss: 0.3419 - val_accuracy: 0.9949\n",
            "Epoch 41/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.3249 - accuracy: 0.9921\n",
            "Epoch 41: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.3243 - accuracy: 0.9923 - val_loss: 0.3331 - val_accuracy: 0.9949\n",
            "Epoch 42/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.3137 - accuracy: 0.9967\n",
            "Epoch 42: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.3135 - accuracy: 0.9968 - val_loss: 0.3255 - val_accuracy: 0.9949\n",
            "Epoch 43/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.3053 - accuracy: 0.9974\n",
            "Epoch 43: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.3054 - accuracy: 0.9974 - val_loss: 0.3255 - val_accuracy: 0.9898\n",
            "Epoch 44/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.3033 - accuracy: 0.9941\n",
            "Epoch 44: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.3025 - accuracy: 0.9942 - val_loss: 0.3136 - val_accuracy: 0.9949\n",
            "Epoch 45/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2908 - accuracy: 0.9962\n",
            "Epoch 45: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.2908 - accuracy: 0.9962 - val_loss: 0.3048 - val_accuracy: 0.9974\n",
            "Epoch 46/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.2887 - accuracy: 0.9967\n",
            "Epoch 46: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.2881 - accuracy: 0.9968 - val_loss: 0.2990 - val_accuracy: 0.9949\n",
            "Epoch 47/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.2817 - accuracy: 0.9961\n",
            "Epoch 47: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.2827 - accuracy: 0.9955 - val_loss: 0.2943 - val_accuracy: 0.9949\n",
            "Epoch 48/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2798 - accuracy: 0.9955\n",
            "Epoch 48: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.2798 - accuracy: 0.9955 - val_loss: 0.2865 - val_accuracy: 0.9949\n",
            "Epoch 49/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.2705 - accuracy: 0.9961\n",
            "Epoch 49: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.2703 - accuracy: 0.9962 - val_loss: 0.2965 - val_accuracy: 0.9898\n",
            "Epoch 50/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2692 - accuracy: 0.9961\n",
            "Epoch 50: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.2694 - accuracy: 0.9962 - val_loss: 0.2785 - val_accuracy: 0.9974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/16/assets\n",
            "\n",
            "\n",
            "  8%|▊         | 17/200 [43:09<6:31:52, 128.49s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 2.0598 - accuracy: 0.6147\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 7s 27ms/step - loss: 2.0575 - accuracy: 0.6160 - val_loss: 1.9483 - val_accuracy: 0.2992\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.9721 - accuracy: 0.9443\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.9717 - accuracy: 0.9429 - val_loss: 2.0076 - val_accuracy: 0.3299\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6858 - accuracy: 0.9819\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.6847 - accuracy: 0.9821 - val_loss: 0.9789 - val_accuracy: 0.8056\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5386 - accuracy: 0.9896\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.5388 - accuracy: 0.9897 - val_loss: 0.5160 - val_accuracy: 0.9898\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4554 - accuracy: 0.9955\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 25ms/step - loss: 0.4549 - accuracy: 0.9955 - val_loss: 0.4299 - val_accuracy: 0.9847\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3854 - accuracy: 0.9968\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.3856 - accuracy: 0.9968 - val_loss: 0.3762 - val_accuracy: 0.9923\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3378 - accuracy: 0.9981\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.3376 - accuracy: 0.9981 - val_loss: 0.3332 - val_accuracy: 0.9872\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2963 - accuracy: 0.9981\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.2958 - accuracy: 0.9981 - val_loss: 0.3035 - val_accuracy: 0.9923\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2698 - accuracy: 0.9994\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.2702 - accuracy: 0.9994 - val_loss: 0.2815 - val_accuracy: 0.9872\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2479 - accuracy: 0.9987\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.2479 - accuracy: 0.9987 - val_loss: 0.2516 - val_accuracy: 0.9949\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2300 - accuracy: 0.9994\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.2299 - accuracy: 0.9994 - val_loss: 0.2410 - val_accuracy: 0.9923\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2145 - accuracy: 1.0000\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.2145 - accuracy: 1.0000 - val_loss: 0.2280 - val_accuracy: 0.9923\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2068 - accuracy: 0.9987\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.2067 - accuracy: 0.9987 - val_loss: 0.2120 - val_accuracy: 0.9949\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1929 - accuracy: 1.0000\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.1927 - accuracy: 1.0000 - val_loss: 0.2054 - val_accuracy: 0.9949\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1856 - accuracy: 1.0000\n",
            "Epoch 15: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.1854 - accuracy: 1.0000 - val_loss: 0.1970 - val_accuracy: 0.9949\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1798 - accuracy: 1.0000\n",
            "Epoch 16: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1797 - accuracy: 1.0000 - val_loss: 0.1929 - val_accuracy: 0.9949\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1726 - accuracy: 1.0000\n",
            "Epoch 17: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1726 - accuracy: 1.0000 - val_loss: 0.1920 - val_accuracy: 0.9949\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1642 - accuracy: 1.0000\n",
            "Epoch 18: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1641 - accuracy: 1.0000 - val_loss: 0.1772 - val_accuracy: 0.9949\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1628 - accuracy: 0.9994\n",
            "Epoch 19: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1628 - accuracy: 0.9994 - val_loss: 0.1764 - val_accuracy: 0.9949\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1541 - accuracy: 1.0000\n",
            "Epoch 20: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1540 - accuracy: 1.0000 - val_loss: 0.1679 - val_accuracy: 0.9949\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1510 - accuracy: 1.0000\n",
            "Epoch 21: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.1511 - accuracy: 1.0000 - val_loss: 0.1740 - val_accuracy: 0.9949\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1458 - accuracy: 1.0000\n",
            "Epoch 22: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1458 - accuracy: 1.0000 - val_loss: 0.1647 - val_accuracy: 0.9949\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1419 - accuracy: 1.0000\n",
            "Epoch 23: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1420 - accuracy: 1.0000 - val_loss: 0.1619 - val_accuracy: 0.9949\n",
            "Epoch 24/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1382 - accuracy: 1.0000\n",
            "Epoch 24: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.1382 - accuracy: 1.0000 - val_loss: 0.1545 - val_accuracy: 0.9949\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1351 - accuracy: 1.0000\n",
            "Epoch 25: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.1351 - accuracy: 1.0000 - val_loss: 0.1593 - val_accuracy: 0.9949\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1318 - accuracy: 1.0000\n",
            "Epoch 26: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.1318 - accuracy: 1.0000 - val_loss: 0.1510 - val_accuracy: 0.9949\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1289 - accuracy: 1.0000\n",
            "Epoch 27: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1289 - accuracy: 1.0000 - val_loss: 0.1501 - val_accuracy: 0.9949\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1254 - accuracy: 1.0000\n",
            "Epoch 28: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.1254 - accuracy: 1.0000 - val_loss: 0.1427 - val_accuracy: 0.9949\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1225 - accuracy: 1.0000\n",
            "Epoch 29: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1225 - accuracy: 1.0000 - val_loss: 0.1410 - val_accuracy: 0.9923\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1185 - accuracy: 1.0000\n",
            "Epoch 30: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1185 - accuracy: 1.0000 - val_loss: 0.1359 - val_accuracy: 0.9949\n",
            "Epoch 31/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1153 - accuracy: 1.0000\n",
            "Epoch 31: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1153 - accuracy: 1.0000 - val_loss: 0.1353 - val_accuracy: 0.9949\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1123 - accuracy: 1.0000\n",
            "Epoch 32: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1123 - accuracy: 1.0000 - val_loss: 0.1386 - val_accuracy: 0.9949\n",
            "Epoch 33/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1084 - accuracy: 1.0000\n",
            "Epoch 33: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1084 - accuracy: 1.0000 - val_loss: 0.1290 - val_accuracy: 0.9949\n",
            "Epoch 34/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1052 - accuracy: 1.0000\n",
            "Epoch 34: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1052 - accuracy: 1.0000 - val_loss: 0.1262 - val_accuracy: 0.9949\n",
            "Epoch 35/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1024 - accuracy: 1.0000\n",
            "Epoch 35: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1023 - accuracy: 1.0000 - val_loss: 0.1207 - val_accuracy: 0.9949\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0987 - accuracy: 1.0000\n",
            "Epoch 36: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0987 - accuracy: 1.0000 - val_loss: 0.1219 - val_accuracy: 0.9949\n",
            "Epoch 37/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0957 - accuracy: 1.0000\n",
            "Epoch 37: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0957 - accuracy: 1.0000 - val_loss: 0.1149 - val_accuracy: 0.9949\n",
            "Epoch 38/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0927 - accuracy: 1.0000\n",
            "Epoch 38: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0927 - accuracy: 1.0000 - val_loss: 0.1178 - val_accuracy: 0.9949\n",
            "Epoch 39/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0884 - accuracy: 1.0000\n",
            "Epoch 39: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0884 - accuracy: 1.0000 - val_loss: 0.1081 - val_accuracy: 0.9949\n",
            "Epoch 40/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1093 - accuracy: 0.9968\n",
            "Epoch 40: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1090 - accuracy: 0.9968 - val_loss: 0.1177 - val_accuracy: 0.9949\n",
            "Epoch 41/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0877 - accuracy: 1.0000\n",
            "Epoch 41: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0877 - accuracy: 1.0000 - val_loss: 0.1071 - val_accuracy: 0.9949\n",
            "Epoch 42/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0829 - accuracy: 1.0000\n",
            "Epoch 42: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0828 - accuracy: 1.0000 - val_loss: 0.1047 - val_accuracy: 0.9949\n",
            "Epoch 43/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0787 - accuracy: 1.0000\n",
            "Epoch 43: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0787 - accuracy: 1.0000 - val_loss: 0.1043 - val_accuracy: 0.9923\n",
            "Epoch 44/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0751 - accuracy: 1.0000\n",
            "Epoch 44: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0750 - accuracy: 1.0000 - val_loss: 0.0955 - val_accuracy: 0.9949\n",
            "Epoch 45/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0717 - accuracy: 1.0000\n",
            "Epoch 45: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0717 - accuracy: 1.0000 - val_loss: 0.0949 - val_accuracy: 0.9949\n",
            "Epoch 46/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0683 - accuracy: 1.0000\n",
            "Epoch 46: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0683 - accuracy: 1.0000 - val_loss: 0.0891 - val_accuracy: 0.9949\n",
            "Epoch 47/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0650 - accuracy: 1.0000\n",
            "Epoch 47: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0650 - accuracy: 1.0000 - val_loss: 0.0861 - val_accuracy: 0.9949\n",
            "Epoch 48/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0617 - accuracy: 1.0000\n",
            "Epoch 48: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0617 - accuracy: 1.0000 - val_loss: 0.0812 - val_accuracy: 0.9949\n",
            "Epoch 49/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0584 - accuracy: 1.0000\n",
            "Epoch 49: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0583 - accuracy: 1.0000 - val_loss: 0.0789 - val_accuracy: 0.9949\n",
            "Epoch 50/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0549 - accuracy: 1.0000\n",
            "Epoch 50: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0549 - accuracy: 1.0000 - val_loss: 0.0762 - val_accuracy: 0.9949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/17/assets\n",
            "\n",
            "\n",
            "  9%|▉         | 18/200 [47:37<8:36:15, 170.20s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6225 - accuracy: 0.6077\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 24ms/step - loss: 1.6225 - accuracy: 0.6077 - val_loss: 1.9152 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7875 - accuracy: 0.9197\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.7856 - accuracy: 0.9205 - val_loss: 2.2778 - val_accuracy: 0.3120\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5671 - accuracy: 0.9637\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.5668 - accuracy: 0.9635 - val_loss: 0.9683 - val_accuracy: 0.7928\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4524 - accuracy: 0.9838\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.4534 - accuracy: 0.9833 - val_loss: 0.4562 - val_accuracy: 0.9770\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3940 - accuracy: 0.9877\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.3940 - accuracy: 0.9878 - val_loss: 0.3654 - val_accuracy: 0.9949\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3344 - accuracy: 0.9974\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.3349 - accuracy: 0.9974 - val_loss: 0.3177 - val_accuracy: 0.9923\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3071 - accuracy: 0.9955\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.3071 - accuracy: 0.9955 - val_loss: 0.2964 - val_accuracy: 0.9949\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2749 - accuracy: 0.9981\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.2752 - accuracy: 0.9981 - val_loss: 0.2707 - val_accuracy: 0.9949\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2535 - accuracy: 0.9981\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.2533 - accuracy: 0.9981 - val_loss: 0.2452 - val_accuracy: 0.9923\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2320 - accuracy: 0.9974\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2317 - accuracy: 0.9974 - val_loss: 0.2379 - val_accuracy: 0.9898\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2130 - accuracy: 0.9994\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2129 - accuracy: 0.9994 - val_loss: 0.2202 - val_accuracy: 0.9898\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2039 - accuracy: 0.9994\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2038 - accuracy: 0.9994 - val_loss: 0.2038 - val_accuracy: 0.9923\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1908 - accuracy: 0.9994\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1906 - accuracy: 0.9994 - val_loss: 0.2046 - val_accuracy: 0.9898\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1832 - accuracy: 0.9981\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1830 - accuracy: 0.9981 - val_loss: 0.1863 - val_accuracy: 0.9949\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1699 - accuracy: 0.9994\n",
            "Epoch 15: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1697 - accuracy: 0.9994 - val_loss: 0.1770 - val_accuracy: 0.9923\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1713 - accuracy: 0.9981\n",
            "Epoch 16: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1711 - accuracy: 0.9981 - val_loss: 0.1739 - val_accuracy: 0.9949\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1584 - accuracy: 0.9994\n",
            "Epoch 17: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1584 - accuracy: 0.9994 - val_loss: 0.1708 - val_accuracy: 0.9923\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1540 - accuracy: 1.0000\n",
            "Epoch 18: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1539 - accuracy: 1.0000 - val_loss: 0.1819 - val_accuracy: 0.9898\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1518 - accuracy: 0.9994\n",
            "Epoch 19: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1518 - accuracy: 0.9994 - val_loss: 0.1571 - val_accuracy: 0.9923\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1450 - accuracy: 1.0000\n",
            "Epoch 20: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1451 - accuracy: 1.0000 - val_loss: 0.1540 - val_accuracy: 0.9949\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1396 - accuracy: 1.0000\n",
            "Epoch 21: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1395 - accuracy: 1.0000 - val_loss: 0.1553 - val_accuracy: 0.9923\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1357 - accuracy: 0.9994\n",
            "Epoch 22: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1356 - accuracy: 0.9994 - val_loss: 0.1652 - val_accuracy: 0.9923\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1340 - accuracy: 1.0000\n",
            "Epoch 23: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1340 - accuracy: 1.0000 - val_loss: 0.1519 - val_accuracy: 0.9923\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1294 - accuracy: 1.0000\n",
            "Epoch 24: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1294 - accuracy: 1.0000 - val_loss: 0.1427 - val_accuracy: 0.9949\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1448 - accuracy: 0.9968\n",
            "Epoch 25: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1448 - accuracy: 0.9968 - val_loss: 0.1444 - val_accuracy: 0.9923\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1287 - accuracy: 1.0000\n",
            "Epoch 26: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1285 - accuracy: 1.0000 - val_loss: 0.1461 - val_accuracy: 0.9949\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1283 - accuracy: 0.9987\n",
            "Epoch 27: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1283 - accuracy: 0.9987 - val_loss: 0.1422 - val_accuracy: 0.9949\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1195 - accuracy: 1.0000\n",
            "Epoch 28: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1194 - accuracy: 1.0000 - val_loss: 0.1362 - val_accuracy: 0.9949\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1166 - accuracy: 1.0000\n",
            "Epoch 29: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1166 - accuracy: 1.0000 - val_loss: 0.1348 - val_accuracy: 0.9949\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1147 - accuracy: 1.0000\n",
            "Epoch 30: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1147 - accuracy: 1.0000 - val_loss: 0.1284 - val_accuracy: 0.9974\n",
            "Epoch 31/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1126 - accuracy: 1.0000\n",
            "Epoch 31: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1126 - accuracy: 1.0000 - val_loss: 0.1296 - val_accuracy: 0.9923\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1094 - accuracy: 1.0000\n",
            "Epoch 32: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1095 - accuracy: 1.0000 - val_loss: 0.1315 - val_accuracy: 0.9949\n",
            "Epoch 33/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1076 - accuracy: 1.0000\n",
            "Epoch 33: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1076 - accuracy: 1.0000 - val_loss: 0.1249 - val_accuracy: 0.9949\n",
            "Epoch 34/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1051 - accuracy: 1.0000\n",
            "Epoch 34: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1050 - accuracy: 1.0000 - val_loss: 0.1241 - val_accuracy: 0.9949\n",
            "Epoch 35/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1045 - accuracy: 1.0000\n",
            "Epoch 35: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1045 - accuracy: 1.0000 - val_loss: 0.1234 - val_accuracy: 0.9949\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1006 - accuracy: 1.0000\n",
            "Epoch 36: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1006 - accuracy: 1.0000 - val_loss: 0.1217 - val_accuracy: 0.9949\n",
            "Epoch 37/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0987 - accuracy: 1.0000\n",
            "Epoch 37: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0987 - accuracy: 1.0000 - val_loss: 0.1220 - val_accuracy: 0.9949\n",
            "Epoch 38/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0988 - accuracy: 1.0000\n",
            "Epoch 38: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0988 - accuracy: 1.0000 - val_loss: 0.1878 - val_accuracy: 0.9719\n",
            "Epoch 39/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1228 - accuracy: 0.9955\n",
            "Epoch 39: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1226 - accuracy: 0.9955 - val_loss: 0.1364 - val_accuracy: 0.9923\n",
            "Epoch 40/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1022 - accuracy: 1.0000\n",
            "Epoch 40: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1021 - accuracy: 1.0000 - val_loss: 0.1123 - val_accuracy: 0.9974\n",
            "Epoch 41/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0962 - accuracy: 1.0000\n",
            "Epoch 41: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0962 - accuracy: 1.0000 - val_loss: 0.1080 - val_accuracy: 0.9949\n",
            "Epoch 42/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0922 - accuracy: 1.0000\n",
            "Epoch 42: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0922 - accuracy: 1.0000 - val_loss: 0.1083 - val_accuracy: 0.9949\n",
            "Epoch 43/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0904 - accuracy: 1.0000\n",
            "Epoch 43: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0904 - accuracy: 1.0000 - val_loss: 0.1071 - val_accuracy: 0.9923\n",
            "Epoch 44/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0881 - accuracy: 1.0000\n",
            "Epoch 44: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0881 - accuracy: 1.0000 - val_loss: 0.1039 - val_accuracy: 0.9949\n",
            "Epoch 45/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0861 - accuracy: 1.0000\n",
            "Epoch 45: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0861 - accuracy: 1.0000 - val_loss: 0.1009 - val_accuracy: 0.9923\n",
            "Epoch 46/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0836 - accuracy: 1.0000\n",
            "Epoch 46: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0835 - accuracy: 1.0000 - val_loss: 0.1022 - val_accuracy: 0.9949\n",
            "Epoch 47/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0815 - accuracy: 1.0000\n",
            "Epoch 47: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0814 - accuracy: 1.0000 - val_loss: 0.1021 - val_accuracy: 0.9923\n",
            "Epoch 48/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0795 - accuracy: 1.0000\n",
            "Epoch 48: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0795 - accuracy: 1.0000 - val_loss: 0.1035 - val_accuracy: 0.9949\n",
            "Epoch 49/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0770 - accuracy: 1.0000\n",
            "Epoch 49: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0770 - accuracy: 1.0000 - val_loss: 0.0917 - val_accuracy: 0.9974\n",
            "Epoch 50/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0746 - accuracy: 1.0000\n",
            "Epoch 50: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0745 - accuracy: 1.0000 - val_loss: 0.0948 - val_accuracy: 0.9949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/18/assets\n",
            "\n",
            "\n",
            " 10%|▉         | 19/200 [51:20<9:21:46, 186.22s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.6183 - accuracy: 0.4987\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 15ms/step - loss: 1.6109 - accuracy: 0.5026 - val_loss: 1.6916 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.8461 - accuracy: 0.8436\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.8412 - accuracy: 0.8449 - val_loss: 1.8431 - val_accuracy: 0.4731\n",
            "Epoch 3/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.5008 - accuracy: 0.9575\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.4984 - accuracy: 0.9583 - val_loss: 1.3372 - val_accuracy: 0.5908\n",
            "Epoch 4/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.3741 - accuracy: 0.9836\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.3730 - accuracy: 0.9840 - val_loss: 0.3604 - val_accuracy: 0.9744\n",
            "Epoch 5/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.3088 - accuracy: 0.9889\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.3084 - accuracy: 0.9891 - val_loss: 0.3141 - val_accuracy: 0.9642\n",
            "Epoch 6/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.2674 - accuracy: 0.9935\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.2666 - accuracy: 0.9936 - val_loss: 0.2564 - val_accuracy: 0.9898\n",
            "Epoch 7/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.2367 - accuracy: 0.9935\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.2360 - accuracy: 0.9936 - val_loss: 0.2271 - val_accuracy: 0.9923\n",
            "Epoch 8/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.2133 - accuracy: 0.9948\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.2131 - accuracy: 0.9949 - val_loss: 0.2011 - val_accuracy: 0.9974\n",
            "Epoch 9/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1886 - accuracy: 0.9994\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.1886 - accuracy: 0.9994 - val_loss: 0.2031 - val_accuracy: 0.9898\n",
            "Epoch 10/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1732 - accuracy: 0.9980\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.1727 - accuracy: 0.9981 - val_loss: 0.1745 - val_accuracy: 0.9949\n",
            "Epoch 11/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1609 - accuracy: 0.9987\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.1609 - accuracy: 0.9987 - val_loss: 0.1641 - val_accuracy: 0.9949\n",
            "Epoch 12/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1475 - accuracy: 0.9987\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.1473 - accuracy: 0.9987 - val_loss: 0.1545 - val_accuracy: 0.9949\n",
            "Epoch 13/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1391 - accuracy: 0.9987\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.1391 - accuracy: 0.9987 - val_loss: 0.1610 - val_accuracy: 0.9898\n",
            "Epoch 14/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1296 - accuracy: 0.9987\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.1296 - accuracy: 0.9987 - val_loss: 0.1394 - val_accuracy: 0.9949\n",
            "Epoch 15/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1211 - accuracy: 1.0000\n",
            "Epoch 15: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.1209 - accuracy: 1.0000 - val_loss: 0.1245 - val_accuracy: 0.9974\n",
            "Epoch 16/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1156 - accuracy: 0.9987\n",
            "Epoch 16: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.1156 - accuracy: 0.9987 - val_loss: 0.1293 - val_accuracy: 0.9923\n",
            "Epoch 17/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1139 - accuracy: 0.9987\n",
            "Epoch 17: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.1135 - accuracy: 0.9987 - val_loss: 0.1195 - val_accuracy: 0.9949\n",
            "Epoch 18/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1022 - accuracy: 0.9994\n",
            "Epoch 18: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.1022 - accuracy: 0.9994 - val_loss: 0.1106 - val_accuracy: 0.9949\n",
            "Epoch 19/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0961 - accuracy: 1.0000\n",
            "Epoch 19: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0962 - accuracy: 1.0000 - val_loss: 0.1073 - val_accuracy: 0.9949\n",
            "Epoch 20/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0910 - accuracy: 1.0000\n",
            "Epoch 20: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0913 - accuracy: 1.0000 - val_loss: 0.1124 - val_accuracy: 0.9923\n",
            "Epoch 21/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0884 - accuracy: 0.9993\n",
            "Epoch 21: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0883 - accuracy: 0.9994 - val_loss: 0.1000 - val_accuracy: 0.9949\n",
            "Epoch 22/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0845 - accuracy: 1.0000\n",
            "Epoch 22: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.0845 - accuracy: 1.0000 - val_loss: 0.1077 - val_accuracy: 0.9898\n",
            "Epoch 23/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0826 - accuracy: 0.9993\n",
            "Epoch 23: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0824 - accuracy: 0.9994 - val_loss: 0.0995 - val_accuracy: 0.9923\n",
            "Epoch 24/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0785 - accuracy: 1.0000\n",
            "Epoch 24: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0787 - accuracy: 1.0000 - val_loss: 0.0909 - val_accuracy: 0.9949\n",
            "Epoch 25/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0736 - accuracy: 1.0000\n",
            "Epoch 25: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.0735 - accuracy: 1.0000 - val_loss: 0.0969 - val_accuracy: 0.9949\n",
            "Epoch 26/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0758 - accuracy: 0.9987\n",
            "Epoch 26: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0758 - accuracy: 0.9987 - val_loss: 0.1363 - val_accuracy: 0.9898\n",
            "Epoch 27/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0775 - accuracy: 0.9987\n",
            "Epoch 27: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0773 - accuracy: 0.9987 - val_loss: 0.1120 - val_accuracy: 0.9872\n",
            "Epoch 28/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0672 - accuracy: 1.0000\n",
            "Epoch 28: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.0673 - accuracy: 1.0000 - val_loss: 0.0876 - val_accuracy: 0.9923\n",
            "Epoch 29/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0663 - accuracy: 1.0000\n",
            "Epoch 29: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0663 - accuracy: 1.0000 - val_loss: 0.0868 - val_accuracy: 0.9923\n",
            "Epoch 30/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0678 - accuracy: 0.9993\n",
            "Epoch 30: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0676 - accuracy: 0.9994 - val_loss: 0.0827 - val_accuracy: 0.9923\n",
            "Epoch 31/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0612 - accuracy: 1.0000\n",
            "Epoch 31: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0612 - accuracy: 1.0000 - val_loss: 0.0802 - val_accuracy: 0.9949\n",
            "Epoch 32/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0617 - accuracy: 1.0000\n",
            "Epoch 32: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0617 - accuracy: 1.0000 - val_loss: 0.0935 - val_accuracy: 0.9898\n",
            "Epoch 33/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0606 - accuracy: 1.0000\n",
            "Epoch 33: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0606 - accuracy: 1.0000 - val_loss: 0.0761 - val_accuracy: 0.9923\n",
            "Epoch 34/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0579 - accuracy: 1.0000\n",
            "Epoch 34: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0578 - accuracy: 1.0000 - val_loss: 0.0740 - val_accuracy: 0.9949\n",
            "Epoch 35/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0555 - accuracy: 1.0000\n",
            "Epoch 35: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0555 - accuracy: 1.0000 - val_loss: 0.0780 - val_accuracy: 0.9974\n",
            "Epoch 36/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0534 - accuracy: 1.0000\n",
            "Epoch 36: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0534 - accuracy: 1.0000 - val_loss: 0.0753 - val_accuracy: 0.9949\n",
            "Epoch 37/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0523 - accuracy: 1.0000\n",
            "Epoch 37: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0525 - accuracy: 1.0000 - val_loss: 0.0742 - val_accuracy: 0.9949\n",
            "Epoch 38/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0541 - accuracy: 0.9993\n",
            "Epoch 38: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.0541 - accuracy: 0.9994 - val_loss: 0.0943 - val_accuracy: 0.9923\n",
            "Epoch 39/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0520 - accuracy: 1.0000\n",
            "Epoch 39: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0521 - accuracy: 1.0000 - val_loss: 0.0670 - val_accuracy: 0.9949\n",
            "Epoch 40/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0517 - accuracy: 0.9994\n",
            "Epoch 40: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.0517 - accuracy: 0.9994 - val_loss: 0.1067 - val_accuracy: 0.9847\n",
            "Epoch 41/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0702 - accuracy: 0.9935\n",
            "Epoch 41: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.0699 - accuracy: 0.9936 - val_loss: 0.0842 - val_accuracy: 0.9872\n",
            "Epoch 42/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0512 - accuracy: 1.0000\n",
            "Epoch 42: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0514 - accuracy: 1.0000 - val_loss: 0.0758 - val_accuracy: 0.9923\n",
            "Epoch 43/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0489 - accuracy: 1.0000\n",
            "Epoch 43: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.0489 - accuracy: 1.0000 - val_loss: 0.0761 - val_accuracy: 0.9898\n",
            "Epoch 44/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0467 - accuracy: 1.0000\n",
            "Epoch 44: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0467 - accuracy: 1.0000 - val_loss: 0.0677 - val_accuracy: 0.9949\n",
            "Epoch 44: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/19/assets\n",
            "\n",
            "\n",
            " 10%|█         | 20/200 [53:13<8:12:55, 164.31s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.9334 - accuracy: 0.3724\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 15ms/step - loss: 1.9281 - accuracy: 0.3718 - val_loss: 1.7693 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.6540 - accuracy: 0.3959\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 1.6494 - accuracy: 0.3981 - val_loss: 1.7249 - val_accuracy: 0.2634\n",
            "Epoch 3/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.5720 - accuracy: 0.4588\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 1.5714 - accuracy: 0.4583 - val_loss: 1.6115 - val_accuracy: 0.3555\n",
            "Epoch 4/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.3953 - accuracy: 0.5131\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 1.3924 - accuracy: 0.5160 - val_loss: 1.4888 - val_accuracy: 0.4706\n",
            "Epoch 5/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.1585 - accuracy: 0.6152\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 1.1567 - accuracy: 0.6167 - val_loss: 1.0131 - val_accuracy: 0.6957\n",
            "Epoch 6/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.8695 - accuracy: 0.7421\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.8615 - accuracy: 0.7455 - val_loss: 0.7127 - val_accuracy: 0.8338\n",
            "Epoch 7/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.6627 - accuracy: 0.8259\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.6719 - accuracy: 0.8244 - val_loss: 0.8865 - val_accuracy: 0.7647\n",
            "Epoch 8/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.5476 - accuracy: 0.8757\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.5503 - accuracy: 0.8763 - val_loss: 0.6316 - val_accuracy: 0.8235\n",
            "Epoch 9/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.5957 - accuracy: 0.8658\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.5902 - accuracy: 0.8667 - val_loss: 0.4330 - val_accuracy: 0.9207\n",
            "Epoch 10/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.3780 - accuracy: 0.9254\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.3786 - accuracy: 0.9250 - val_loss: 0.3520 - val_accuracy: 0.9437\n",
            "Epoch 11/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.8795 - accuracy: 0.8200\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.8846 - accuracy: 0.8167 - val_loss: 1.1286 - val_accuracy: 0.7263\n",
            "Epoch 12/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.5752 - accuracy: 0.8809\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.5719 - accuracy: 0.8821 - val_loss: 0.4914 - val_accuracy: 0.8951\n",
            "Epoch 13/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4518 - accuracy: 0.9160\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.4518 - accuracy: 0.9160 - val_loss: 0.6696 - val_accuracy: 0.8261\n",
            "Epoch 14/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4202 - accuracy: 0.9218\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.4202 - accuracy: 0.9218 - val_loss: 0.5563 - val_accuracy: 0.8772\n",
            "Epoch 15/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5040 - accuracy: 0.9167\n",
            "Epoch 15: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.5040 - accuracy: 0.9167 - val_loss: 0.9850 - val_accuracy: 0.8824\n",
            "Epoch 15: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/20/assets\n",
            "\n",
            "\n",
            " 10%|█         | 21/200 [53:56<6:20:49, 127.65s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 2.0169 - accuracy: 0.5987\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 23ms/step - loss: 2.0169 - accuracy: 0.5987 - val_loss: 1.8130 - val_accuracy: 0.3120\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.1717 - accuracy: 0.8731\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 1.1699 - accuracy: 0.8737 - val_loss: 2.0856 - val_accuracy: 0.3657\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8513 - accuracy: 0.9495\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.8497 - accuracy: 0.9500 - val_loss: 1.4448 - val_accuracy: 0.6829\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6773 - accuracy: 0.9812\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.6780 - accuracy: 0.9814 - val_loss: 0.6180 - val_accuracy: 0.9872\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5756 - accuracy: 0.9883\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.5753 - accuracy: 0.9878 - val_loss: 0.5956 - val_accuracy: 0.9514\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5107 - accuracy: 0.9903\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.5110 - accuracy: 0.9904 - val_loss: 0.4797 - val_accuracy: 0.9923\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4508 - accuracy: 0.9909\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.4513 - accuracy: 0.9910 - val_loss: 0.4526 - val_accuracy: 0.9847\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3993 - accuracy: 0.9955\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.4004 - accuracy: 0.9949 - val_loss: 0.4318 - val_accuracy: 0.9795\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3614 - accuracy: 0.9961\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.3615 - accuracy: 0.9962 - val_loss: 0.3497 - val_accuracy: 0.9949\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3376 - accuracy: 0.9968\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.3372 - accuracy: 0.9968 - val_loss: 0.3425 - val_accuracy: 0.9872\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3042 - accuracy: 0.9968\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.3043 - accuracy: 0.9968 - val_loss: 0.3452 - val_accuracy: 0.9770\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2822 - accuracy: 0.9981\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2820 - accuracy: 0.9981 - val_loss: 0.2847 - val_accuracy: 0.9949\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2631 - accuracy: 0.9987\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2629 - accuracy: 0.9987 - val_loss: 0.2687 - val_accuracy: 0.9923\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2495 - accuracy: 0.9981\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2493 - accuracy: 0.9981 - val_loss: 0.2549 - val_accuracy: 0.9923\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2369 - accuracy: 0.9994\n",
            "Epoch 15: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2367 - accuracy: 0.9994 - val_loss: 0.2420 - val_accuracy: 0.9949\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2277 - accuracy: 0.9981\n",
            "Epoch 16: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2275 - accuracy: 0.9981 - val_loss: 0.2388 - val_accuracy: 0.9923\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2150 - accuracy: 0.9987\n",
            "Epoch 17: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2148 - accuracy: 0.9987 - val_loss: 0.2273 - val_accuracy: 0.9923\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2055 - accuracy: 0.9994\n",
            "Epoch 18: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2056 - accuracy: 0.9994 - val_loss: 0.2206 - val_accuracy: 0.9949\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2009 - accuracy: 0.9994\n",
            "Epoch 19: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2010 - accuracy: 0.9994 - val_loss: 0.2222 - val_accuracy: 0.9949\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1939 - accuracy: 1.0000\n",
            "Epoch 20: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1940 - accuracy: 1.0000 - val_loss: 0.2075 - val_accuracy: 0.9949\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1863 - accuracy: 0.9994\n",
            "Epoch 21: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1860 - accuracy: 0.9994 - val_loss: 0.2084 - val_accuracy: 0.9923\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1800 - accuracy: 1.0000\n",
            "Epoch 22: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1799 - accuracy: 1.0000 - val_loss: 0.2025 - val_accuracy: 0.9923\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1828 - accuracy: 0.9987\n",
            "Epoch 23: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1827 - accuracy: 0.9987 - val_loss: 0.1941 - val_accuracy: 0.9949\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1717 - accuracy: 0.9994\n",
            "Epoch 24: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1717 - accuracy: 0.9994 - val_loss: 0.1921 - val_accuracy: 0.9949\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1717 - accuracy: 0.9994\n",
            "Epoch 25: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1716 - accuracy: 0.9994 - val_loss: 0.1861 - val_accuracy: 0.9923\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1635 - accuracy: 1.0000\n",
            "Epoch 26: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1634 - accuracy: 1.0000 - val_loss: 0.1855 - val_accuracy: 0.9923\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1594 - accuracy: 0.9994\n",
            "Epoch 27: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1594 - accuracy: 0.9994 - val_loss: 0.1884 - val_accuracy: 0.9949\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1601 - accuracy: 0.9987\n",
            "Epoch 28: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1600 - accuracy: 0.9987 - val_loss: 0.1858 - val_accuracy: 0.9923\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1547 - accuracy: 1.0000\n",
            "Epoch 29: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1547 - accuracy: 1.0000 - val_loss: 0.1826 - val_accuracy: 0.9949\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1502 - accuracy: 0.9994\n",
            "Epoch 30: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1503 - accuracy: 0.9994 - val_loss: 0.1825 - val_accuracy: 0.9949\n",
            "Epoch 31/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1450 - accuracy: 0.9994\n",
            "Epoch 31: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1450 - accuracy: 0.9994 - val_loss: 0.1768 - val_accuracy: 0.9923\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1410 - accuracy: 1.0000\n",
            "Epoch 32: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1409 - accuracy: 1.0000 - val_loss: 0.1748 - val_accuracy: 0.9898\n",
            "Epoch 33/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1380 - accuracy: 1.0000\n",
            "Epoch 33: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1379 - accuracy: 1.0000 - val_loss: 0.1672 - val_accuracy: 0.9923\n",
            "Epoch 34/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1359 - accuracy: 1.0000\n",
            "Epoch 34: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1359 - accuracy: 1.0000 - val_loss: 0.1754 - val_accuracy: 0.9898\n",
            "Epoch 35/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1333 - accuracy: 1.0000\n",
            "Epoch 35: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1332 - accuracy: 1.0000 - val_loss: 0.1613 - val_accuracy: 0.9923\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1307 - accuracy: 1.0000\n",
            "Epoch 36: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1307 - accuracy: 1.0000 - val_loss: 0.1847 - val_accuracy: 0.9872\n",
            "Epoch 37/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1280 - accuracy: 1.0000\n",
            "Epoch 37: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1280 - accuracy: 1.0000 - val_loss: 0.1571 - val_accuracy: 0.9923\n",
            "Epoch 38/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1251 - accuracy: 1.0000\n",
            "Epoch 38: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1251 - accuracy: 1.0000 - val_loss: 0.1570 - val_accuracy: 0.9949\n",
            "Epoch 39/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1300 - accuracy: 1.0000\n",
            "Epoch 39: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1300 - accuracy: 1.0000 - val_loss: 0.1599 - val_accuracy: 0.9923\n",
            "Epoch 40/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1213 - accuracy: 1.0000\n",
            "Epoch 40: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1212 - accuracy: 1.0000 - val_loss: 0.1435 - val_accuracy: 0.9923\n",
            "Epoch 41/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1152 - accuracy: 1.0000\n",
            "Epoch 41: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1152 - accuracy: 1.0000 - val_loss: 0.1416 - val_accuracy: 0.9923\n",
            "Epoch 42/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1117 - accuracy: 1.0000\n",
            "Epoch 42: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1117 - accuracy: 1.0000 - val_loss: 0.1440 - val_accuracy: 0.9923\n",
            "Epoch 43/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1081 - accuracy: 1.0000\n",
            "Epoch 43: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1082 - accuracy: 1.0000 - val_loss: 0.1419 - val_accuracy: 0.9898\n",
            "Epoch 44/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1059 - accuracy: 1.0000\n",
            "Epoch 44: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1059 - accuracy: 1.0000 - val_loss: 0.1381 - val_accuracy: 0.9923\n",
            "Epoch 45/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1019 - accuracy: 1.0000\n",
            "Epoch 45: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1019 - accuracy: 1.0000 - val_loss: 0.1345 - val_accuracy: 0.9923\n",
            "Epoch 46/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0984 - accuracy: 1.0000\n",
            "Epoch 46: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0984 - accuracy: 1.0000 - val_loss: 0.1350 - val_accuracy: 0.9949\n",
            "Epoch 47/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0968 - accuracy: 1.0000\n",
            "Epoch 47: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0968 - accuracy: 1.0000 - val_loss: 0.1215 - val_accuracy: 0.9923\n",
            "Epoch 48/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0918 - accuracy: 1.0000\n",
            "Epoch 48: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0917 - accuracy: 1.0000 - val_loss: 0.1303 - val_accuracy: 0.9898\n",
            "Epoch 49/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0888 - accuracy: 1.0000\n",
            "Epoch 49: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0888 - accuracy: 1.0000 - val_loss: 0.1203 - val_accuracy: 0.9923\n",
            "Epoch 50/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1213 - accuracy: 0.9903\n",
            "Epoch 50: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1211 - accuracy: 0.9904 - val_loss: 0.1303 - val_accuracy: 0.9949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/21/assets\n",
            "\n",
            "\n",
            " 11%|█         | 22/200 [57:17<7:24:41, 149.90s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 1.6579 - accuracy: 0.3882\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 12ms/step - loss: 1.6536 - accuracy: 0.3872 - val_loss: 3.6274 - val_accuracy: 0.2634\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.2099 - accuracy: 0.5946\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 1.2071 - accuracy: 0.5968 - val_loss: 1.3876 - val_accuracy: 0.5601\n",
            "Epoch 3/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.3869 - accuracy: 0.5078\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.3820 - accuracy: 0.5103 - val_loss: 1.9522 - val_accuracy: 0.2379\n",
            "Epoch 4/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.7968 - accuracy: 0.3041\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 1.7961 - accuracy: 0.3038 - val_loss: 1.5572 - val_accuracy: 0.4731\n",
            "Epoch 5/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.7700 - accuracy: 0.3402\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 1.7692 - accuracy: 0.3410 - val_loss: 1.7762 - val_accuracy: 0.2737\n",
            "Epoch 6/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.7176 - accuracy: 0.2764\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.7168 - accuracy: 0.2776 - val_loss: 1.7028 - val_accuracy: 0.2864\n",
            "Epoch 7/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.7023 - accuracy: 0.2709\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 1.6998 - accuracy: 0.2705 - val_loss: 1.6913 - val_accuracy: 0.2634\n",
            "Epoch 7: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/22/assets\n",
            "\n",
            "\n",
            " 12%|█▏        | 23/200 [57:37<5:27:07, 110.89s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.2377 - accuracy: 0.6914\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 21ms/step - loss: 1.2324 - accuracy: 0.6929 - val_loss: 1.7795 - val_accuracy: 0.2788\n",
            "Epoch 2/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3631 - accuracy: 0.9316\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.3611 - accuracy: 0.9327 - val_loss: 1.8018 - val_accuracy: 0.2864\n",
            "Epoch 3/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3082 - accuracy: 0.9558\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.3082 - accuracy: 0.9558 - val_loss: 0.6138 - val_accuracy: 0.8568\n",
            "Epoch 4/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1812 - accuracy: 0.9910\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1812 - accuracy: 0.9910 - val_loss: 0.2087 - val_accuracy: 0.9744\n",
            "Epoch 5/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1431 - accuracy: 0.9917\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1431 - accuracy: 0.9917 - val_loss: 0.2320 - val_accuracy: 0.9514\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1221 - accuracy: 0.9994\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.1219 - accuracy: 0.9994 - val_loss: 0.1437 - val_accuracy: 0.9923\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1107 - accuracy: 0.9987\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1114 - accuracy: 0.9981 - val_loss: 0.1610 - val_accuracy: 0.9795\n",
            "Epoch 8/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1159 - accuracy: 0.9974\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1158 - accuracy: 0.9974 - val_loss: 0.1957 - val_accuracy: 0.9719\n",
            "Epoch 9/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1537 - accuracy: 0.9878\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.1535 - accuracy: 0.9878 - val_loss: 0.4544 - val_accuracy: 0.9130\n",
            "Epoch 10/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1475 - accuracy: 0.9871\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1473 - accuracy: 0.9872 - val_loss: 0.2971 - val_accuracy: 0.9335\n",
            "Epoch 11/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1889 - accuracy: 0.9744\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1889 - accuracy: 0.9744 - val_loss: 0.4461 - val_accuracy: 0.9207\n",
            "Epoch 11: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/23/assets\n",
            "\n",
            "\n",
            " 12%|█▏        | 24/200 [58:23<4:28:11, 91.43s/it] \u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.9630 - accuracy: 0.4531\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 13ms/step - loss: 1.9542 - accuracy: 0.4564 - val_loss: 1.8880 - val_accuracy: 0.2634\n",
            "Epoch 2/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.1542 - accuracy: 0.7835\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.1520 - accuracy: 0.7840 - val_loss: 2.3122 - val_accuracy: 0.2634\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7477 - accuracy: 0.9171\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.7461 - accuracy: 0.9179 - val_loss: 1.3604 - val_accuracy: 0.5524\n",
            "Epoch 4/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5516 - accuracy: 0.9667\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.5516 - accuracy: 0.9667 - val_loss: 0.5017 - val_accuracy: 0.9744\n",
            "Epoch 5/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.4652 - accuracy: 0.9753\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.4648 - accuracy: 0.9750 - val_loss: 0.4066 - val_accuracy: 0.9847\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3998 - accuracy: 0.9838\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.3985 - accuracy: 0.9840 - val_loss: 0.3562 - val_accuracy: 0.9872\n",
            "Epoch 7/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.3434 - accuracy: 0.9928\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.3433 - accuracy: 0.9923 - val_loss: 0.3281 - val_accuracy: 0.9872\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3070 - accuracy: 0.9922\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.3062 - accuracy: 0.9923 - val_loss: 0.2858 - val_accuracy: 0.9898\n",
            "Epoch 9/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2686 - accuracy: 0.9936\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.2684 - accuracy: 0.9936 - val_loss: 0.2594 - val_accuracy: 0.9923\n",
            "Epoch 10/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2468 - accuracy: 0.9948\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.2467 - accuracy: 0.9949 - val_loss: 0.2272 - val_accuracy: 0.9949\n",
            "Epoch 11/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.2221 - accuracy: 0.9954\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.2217 - accuracy: 0.9955 - val_loss: 0.2116 - val_accuracy: 0.9898\n",
            "Epoch 12/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2012 - accuracy: 0.9962\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.2012 - accuracy: 0.9962 - val_loss: 0.1892 - val_accuracy: 0.9949\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1799 - accuracy: 0.9987\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.1799 - accuracy: 0.9987 - val_loss: 0.1725 - val_accuracy: 0.9923\n",
            "Epoch 14/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1664 - accuracy: 0.9987\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1661 - accuracy: 0.9987 - val_loss: 0.1604 - val_accuracy: 0.9949\n",
            "Epoch 15/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1560 - accuracy: 0.9974\n",
            "Epoch 15: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1560 - accuracy: 0.9974 - val_loss: 0.1478 - val_accuracy: 0.9949\n",
            "Epoch 16/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.1439 - accuracy: 0.9987\n",
            "Epoch 16: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.1440 - accuracy: 0.9987 - val_loss: 0.1508 - val_accuracy: 0.9923\n",
            "Epoch 17/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1332 - accuracy: 0.9994\n",
            "Epoch 17: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1332 - accuracy: 0.9994 - val_loss: 0.1564 - val_accuracy: 0.9872\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1263 - accuracy: 0.9981\n",
            "Epoch 18: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1267 - accuracy: 0.9981 - val_loss: 0.1295 - val_accuracy: 0.9949\n",
            "Epoch 19/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1189 - accuracy: 1.0000\n",
            "Epoch 19: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.1189 - accuracy: 1.0000 - val_loss: 0.1174 - val_accuracy: 0.9923\n",
            "Epoch 20/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.1113 - accuracy: 1.0000\n",
            "Epoch 20: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1112 - accuracy: 1.0000 - val_loss: 0.1182 - val_accuracy: 0.9949\n",
            "Epoch 21/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1059 - accuracy: 0.9994\n",
            "Epoch 21: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1059 - accuracy: 0.9994 - val_loss: 0.1085 - val_accuracy: 0.9949\n",
            "Epoch 22/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0997 - accuracy: 0.9994\n",
            "Epoch 22: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0997 - accuracy: 0.9994 - val_loss: 0.1017 - val_accuracy: 0.9923\n",
            "Epoch 23/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 0.0951 - accuracy: 0.9993\n",
            "Epoch 23: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0947 - accuracy: 0.9994 - val_loss: 0.1069 - val_accuracy: 0.9923\n",
            "Epoch 24/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.0898 - accuracy: 0.9993\n",
            "Epoch 24: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0904 - accuracy: 0.9987 - val_loss: 0.0976 - val_accuracy: 0.9949\n",
            "Epoch 25/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0881 - accuracy: 0.9987\n",
            "Epoch 25: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0881 - accuracy: 0.9987 - val_loss: 0.0928 - val_accuracy: 0.9923\n",
            "Epoch 26/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.0830 - accuracy: 1.0000\n",
            "Epoch 26: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0826 - accuracy: 1.0000 - val_loss: 0.0891 - val_accuracy: 0.9923\n",
            "Epoch 27/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0788 - accuracy: 1.0000\n",
            "Epoch 27: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0788 - accuracy: 1.0000 - val_loss: 0.0869 - val_accuracy: 0.9923\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0764 - accuracy: 0.9994\n",
            "Epoch 28: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0765 - accuracy: 0.9994 - val_loss: 0.0865 - val_accuracy: 0.9949\n",
            "Epoch 29/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0709 - accuracy: 1.0000\n",
            "Epoch 29: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0709 - accuracy: 1.0000 - val_loss: 0.0837 - val_accuracy: 0.9949\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0706 - accuracy: 0.9994\n",
            "Epoch 30: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0706 - accuracy: 0.9994 - val_loss: 0.0761 - val_accuracy: 0.9949\n",
            "Epoch 31/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0699 - accuracy: 0.9987\n",
            "Epoch 31: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0698 - accuracy: 0.9987 - val_loss: 0.0772 - val_accuracy: 0.9923\n",
            "Epoch 32/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0653 - accuracy: 1.0000\n",
            "Epoch 32: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0653 - accuracy: 1.0000 - val_loss: 0.0797 - val_accuracy: 0.9898\n",
            "Epoch 33/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0617 - accuracy: 1.0000\n",
            "Epoch 33: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0617 - accuracy: 1.0000 - val_loss: 0.0770 - val_accuracy: 0.9923\n",
            "Epoch 34/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.0604 - accuracy: 1.0000\n",
            "Epoch 34: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0603 - accuracy: 1.0000 - val_loss: 0.1036 - val_accuracy: 0.9847\n",
            "Epoch 35/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0588 - accuracy: 1.0000\n",
            "Epoch 35: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0588 - accuracy: 1.0000 - val_loss: 0.0764 - val_accuracy: 0.9923\n",
            "Epoch 35: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/24/assets\n",
            "\n",
            "\n",
            " 12%|█▎        | 25/200 [59:36<4:09:51, 85.67s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.0821 - accuracy: 0.7767\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 18ms/step - loss: 1.0725 - accuracy: 0.7788 - val_loss: 1.7066 - val_accuracy: 0.3248\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3328 - accuracy: 0.9637\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.3318 - accuracy: 0.9641 - val_loss: 1.5916 - val_accuracy: 0.5064\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2063 - accuracy: 0.9922\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.2058 - accuracy: 0.9923 - val_loss: 0.6978 - val_accuracy: 0.8389\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1492 - accuracy: 0.9994\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1491 - accuracy: 0.9994 - val_loss: 0.1791 - val_accuracy: 0.9847\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3154 - accuracy: 0.9482\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.3146 - accuracy: 0.9487 - val_loss: 0.3849 - val_accuracy: 0.9616\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1808 - accuracy: 0.9896\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1806 - accuracy: 0.9897 - val_loss: 0.1728 - val_accuracy: 0.9898\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1331 - accuracy: 0.9981\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1330 - accuracy: 0.9981 - val_loss: 0.1724 - val_accuracy: 0.9974\n",
            "Epoch 8/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1215 - accuracy: 0.9993\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1213 - accuracy: 0.9994 - val_loss: 0.1424 - val_accuracy: 0.9923\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1458 - accuracy: 0.9929\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1455 - accuracy: 0.9929 - val_loss: 0.3148 - val_accuracy: 0.9514\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1233 - accuracy: 0.9974\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1231 - accuracy: 0.9974 - val_loss: 0.1409 - val_accuracy: 0.9923\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1060 - accuracy: 0.9994\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1061 - accuracy: 0.9994 - val_loss: 0.5277 - val_accuracy: 0.8798\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1020 - accuracy: 0.9994\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1020 - accuracy: 0.9994 - val_loss: 0.1257 - val_accuracy: 0.9923\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0962 - accuracy: 1.0000\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0962 - accuracy: 1.0000 - val_loss: 0.1567 - val_accuracy: 0.9744\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3375 - accuracy: 0.9514\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.3461 - accuracy: 0.9494 - val_loss: 0.5671 - val_accuracy: 0.9182\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2153 - accuracy: 0.9780\n",
            "Epoch 15: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.2145 - accuracy: 0.9782 - val_loss: 0.2421 - val_accuracy: 0.9719\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1486 - accuracy: 0.9877\n",
            "Epoch 16: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1482 - accuracy: 0.9878 - val_loss: 0.1310 - val_accuracy: 0.9923\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1109 - accuracy: 0.9974\n",
            "Epoch 17: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1108 - accuracy: 0.9974 - val_loss: 0.1095 - val_accuracy: 0.9974\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0943 - accuracy: 0.9994\n",
            "Epoch 18: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0943 - accuracy: 0.9994 - val_loss: 0.1004 - val_accuracy: 0.9949\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0867 - accuracy: 1.0000\n",
            "Epoch 19: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0867 - accuracy: 1.0000 - val_loss: 0.0993 - val_accuracy: 0.9923\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0819 - accuracy: 0.9994\n",
            "Epoch 20: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0818 - accuracy: 0.9994 - val_loss: 0.0881 - val_accuracy: 0.9974\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0822 - accuracy: 0.9981\n",
            "Epoch 21: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0821 - accuracy: 0.9981 - val_loss: 0.1412 - val_accuracy: 0.9872\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0854 - accuracy: 0.9987\n",
            "Epoch 22: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0854 - accuracy: 0.9987 - val_loss: 0.1100 - val_accuracy: 0.9898\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0692 - accuracy: 1.0000\n",
            "Epoch 23: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0691 - accuracy: 1.0000 - val_loss: 0.1029 - val_accuracy: 0.9949\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0831 - accuracy: 0.9961\n",
            "Epoch 24: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0850 - accuracy: 0.9955 - val_loss: 0.3075 - val_accuracy: 0.9361\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2081 - accuracy: 0.9709\n",
            "Epoch 25: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.2112 - accuracy: 0.9705 - val_loss: 0.2021 - val_accuracy: 0.9719\n",
            "Epoch 25: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/25/assets\n",
            "\n",
            "\n",
            " 13%|█▎        | 26/200 [1:00:58<4:05:18, 84.59s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 2.0490 - accuracy: 0.5267\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 20ms/step - loss: 2.0433 - accuracy: 0.5282 - val_loss: 2.0977 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.0131 - accuracy: 0.9041\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 1.0099 - accuracy: 0.9051 - val_loss: 3.0331 - val_accuracy: 0.3299\n",
            "Epoch 3/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.7219 - accuracy: 0.9635\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.7219 - accuracy: 0.9635 - val_loss: 1.4018 - val_accuracy: 0.6624\n",
            "Epoch 4/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.5660 - accuracy: 0.9889\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.5654 - accuracy: 0.9891 - val_loss: 0.5690 - val_accuracy: 0.9642\n",
            "Epoch 5/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4810 - accuracy: 0.9903\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.4808 - accuracy: 0.9904 - val_loss: 0.4257 - val_accuracy: 0.9898\n",
            "Epoch 6/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.4126 - accuracy: 0.9941\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.4119 - accuracy: 0.9942 - val_loss: 0.3616 - val_accuracy: 0.9949\n",
            "Epoch 7/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3589 - accuracy: 0.9967\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.3585 - accuracy: 0.9968 - val_loss: 0.3180 - val_accuracy: 0.9949\n",
            "Epoch 8/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3183 - accuracy: 0.9955\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.3183 - accuracy: 0.9955 - val_loss: 0.2862 - val_accuracy: 0.9949\n",
            "Epoch 9/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2776 - accuracy: 0.9974\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.2773 - accuracy: 0.9974 - val_loss: 0.2610 - val_accuracy: 0.9974\n",
            "Epoch 10/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2490 - accuracy: 0.9974\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.2485 - accuracy: 0.9974 - val_loss: 0.2317 - val_accuracy: 0.9949\n",
            "Epoch 11/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2214 - accuracy: 0.9987\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.2214 - accuracy: 0.9987 - val_loss: 0.2121 - val_accuracy: 0.9949\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2050 - accuracy: 1.0000\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.2055 - accuracy: 0.9994 - val_loss: 0.1955 - val_accuracy: 0.9949\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1868 - accuracy: 1.0000\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.1864 - accuracy: 1.0000 - val_loss: 0.1910 - val_accuracy: 0.9923\n",
            "Epoch 14/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1752 - accuracy: 1.0000\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.1750 - accuracy: 1.0000 - val_loss: 0.1778 - val_accuracy: 0.9949\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1679 - accuracy: 0.9987\n",
            "Epoch 15: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.1681 - accuracy: 0.9987 - val_loss: 0.1671 - val_accuracy: 0.9949\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1558 - accuracy: 1.0000\n",
            "Epoch 16: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.1556 - accuracy: 1.0000 - val_loss: 0.1620 - val_accuracy: 0.9949\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1506 - accuracy: 1.0000\n",
            "Epoch 17: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.1506 - accuracy: 1.0000 - val_loss: 0.1503 - val_accuracy: 0.9949\n",
            "Epoch 18/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1421 - accuracy: 0.9993\n",
            "Epoch 18: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.1419 - accuracy: 0.9994 - val_loss: 0.1516 - val_accuracy: 0.9949\n",
            "Epoch 19/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1362 - accuracy: 1.0000\n",
            "Epoch 19: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.1361 - accuracy: 1.0000 - val_loss: 0.1422 - val_accuracy: 0.9949\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1321 - accuracy: 0.9987\n",
            "Epoch 20: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.1321 - accuracy: 0.9987 - val_loss: 0.1407 - val_accuracy: 0.9949\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1285 - accuracy: 0.9987\n",
            "Epoch 21: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.1285 - accuracy: 0.9987 - val_loss: 0.1353 - val_accuracy: 0.9949\n",
            "Epoch 22/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1225 - accuracy: 1.0000\n",
            "Epoch 22: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.1225 - accuracy: 1.0000 - val_loss: 0.1296 - val_accuracy: 0.9949\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1191 - accuracy: 1.0000\n",
            "Epoch 23: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1190 - accuracy: 1.0000 - val_loss: 0.1283 - val_accuracy: 0.9949\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1135 - accuracy: 1.0000\n",
            "Epoch 24: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.1135 - accuracy: 1.0000 - val_loss: 0.1233 - val_accuracy: 0.9949\n",
            "Epoch 25/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1094 - accuracy: 1.0000\n",
            "Epoch 25: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.1094 - accuracy: 1.0000 - val_loss: 0.1209 - val_accuracy: 0.9949\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1074 - accuracy: 1.0000\n",
            "Epoch 26: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.1073 - accuracy: 1.0000 - val_loss: 0.1224 - val_accuracy: 0.9949\n",
            "Epoch 27/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1061 - accuracy: 1.0000\n",
            "Epoch 27: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.1060 - accuracy: 1.0000 - val_loss: 0.1179 - val_accuracy: 0.9923\n",
            "Epoch 28/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1035 - accuracy: 0.9993\n",
            "Epoch 28: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.1035 - accuracy: 0.9994 - val_loss: 0.1163 - val_accuracy: 0.9949\n",
            "Epoch 29/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0990 - accuracy: 1.0000\n",
            "Epoch 29: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0990 - accuracy: 1.0000 - val_loss: 0.1153 - val_accuracy: 0.9949\n",
            "Epoch 30/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0963 - accuracy: 1.0000\n",
            "Epoch 30: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0962 - accuracy: 1.0000 - val_loss: 0.1127 - val_accuracy: 0.9949\n",
            "Epoch 31/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0935 - accuracy: 1.0000\n",
            "Epoch 31: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0935 - accuracy: 1.0000 - val_loss: 0.1083 - val_accuracy: 0.9949\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0916 - accuracy: 1.0000\n",
            "Epoch 32: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0917 - accuracy: 1.0000 - val_loss: 0.1078 - val_accuracy: 0.9949\n",
            "Epoch 33/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0890 - accuracy: 1.0000\n",
            "Epoch 33: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0890 - accuracy: 1.0000 - val_loss: 0.1046 - val_accuracy: 0.9949\n",
            "Epoch 34/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0883 - accuracy: 1.0000\n",
            "Epoch 34: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0883 - accuracy: 1.0000 - val_loss: 0.1007 - val_accuracy: 0.9949\n",
            "Epoch 35/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0859 - accuracy: 1.0000\n",
            "Epoch 35: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0860 - accuracy: 1.0000 - val_loss: 0.1039 - val_accuracy: 0.9923\n",
            "Epoch 36/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0827 - accuracy: 1.0000\n",
            "Epoch 36: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0827 - accuracy: 1.0000 - val_loss: 0.0949 - val_accuracy: 0.9974\n",
            "Epoch 37/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0803 - accuracy: 1.0000\n",
            "Epoch 37: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0803 - accuracy: 1.0000 - val_loss: 0.0994 - val_accuracy: 0.9949\n",
            "Epoch 38/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0798 - accuracy: 1.0000\n",
            "Epoch 38: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0798 - accuracy: 1.0000 - val_loss: 0.1026 - val_accuracy: 0.9949\n",
            "Epoch 39/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0774 - accuracy: 1.0000\n",
            "Epoch 39: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0773 - accuracy: 1.0000 - val_loss: 0.0961 - val_accuracy: 0.9949\n",
            "Epoch 40/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0738 - accuracy: 1.0000\n",
            "Epoch 40: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0737 - accuracy: 1.0000 - val_loss: 0.0892 - val_accuracy: 0.9949\n",
            "Epoch 41/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0713 - accuracy: 1.0000\n",
            "Epoch 41: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0713 - accuracy: 1.0000 - val_loss: 0.0871 - val_accuracy: 0.9949\n",
            "Epoch 42/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0693 - accuracy: 1.0000\n",
            "Epoch 42: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0693 - accuracy: 1.0000 - val_loss: 0.0864 - val_accuracy: 0.9949\n",
            "Epoch 43/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0676 - accuracy: 1.0000\n",
            "Epoch 43: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0676 - accuracy: 1.0000 - val_loss: 0.0891 - val_accuracy: 0.9949\n",
            "Epoch 44/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0645 - accuracy: 1.0000\n",
            "Epoch 44: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0645 - accuracy: 1.0000 - val_loss: 0.0807 - val_accuracy: 0.9949\n",
            "Epoch 45/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0622 - accuracy: 1.0000\n",
            "Epoch 45: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0622 - accuracy: 1.0000 - val_loss: 0.0748 - val_accuracy: 0.9949\n",
            "Epoch 46/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0624 - accuracy: 0.9994\n",
            "Epoch 46: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0624 - accuracy: 0.9994 - val_loss: 0.1050 - val_accuracy: 0.9898\n",
            "Epoch 47/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0620 - accuracy: 0.9994\n",
            "Epoch 47: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0620 - accuracy: 0.9994 - val_loss: 0.0797 - val_accuracy: 0.9949\n",
            "Epoch 48/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0564 - accuracy: 1.0000\n",
            "Epoch 48: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0564 - accuracy: 1.0000 - val_loss: 0.0712 - val_accuracy: 0.9949\n",
            "Epoch 49/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0540 - accuracy: 1.0000\n",
            "Epoch 49: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0540 - accuracy: 1.0000 - val_loss: 0.0787 - val_accuracy: 0.9949\n",
            "Epoch 50/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0515 - accuracy: 1.0000\n",
            "Epoch 50: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0515 - accuracy: 1.0000 - val_loss: 0.0686 - val_accuracy: 0.9949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/26/assets\n",
            "\n",
            "\n",
            " 14%|█▎        | 27/200 [1:04:25<5:49:58, 121.38s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6848 - accuracy: 0.4851\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 14ms/step - loss: 1.6798 - accuracy: 0.4872 - val_loss: 1.7376 - val_accuracy: 0.4220\n",
            "Epoch 2/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.8852 - accuracy: 0.8145\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.8796 - accuracy: 0.8154 - val_loss: 1.7948 - val_accuracy: 0.4297\n",
            "Epoch 3/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.5720 - accuracy: 0.9293\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.5709 - accuracy: 0.9282 - val_loss: 0.9805 - val_accuracy: 0.7289\n",
            "Epoch 4/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.4373 - accuracy: 0.9635\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.4364 - accuracy: 0.9641 - val_loss: 0.4828 - val_accuracy: 0.9463\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3542 - accuracy: 0.9864\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.3553 - accuracy: 0.9853 - val_loss: 0.3662 - val_accuracy: 0.9872\n",
            "Epoch 6/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3097 - accuracy: 0.9903\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.3099 - accuracy: 0.9904 - val_loss: 0.3292 - val_accuracy: 0.9847\n",
            "Epoch 7/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.2771 - accuracy: 0.9901\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.2765 - accuracy: 0.9904 - val_loss: 0.2973 - val_accuracy: 0.9821\n",
            "Epoch 8/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.2423 - accuracy: 0.9967\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.2424 - accuracy: 0.9962 - val_loss: 0.2733 - val_accuracy: 0.9847\n",
            "Epoch 9/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.2207 - accuracy: 0.9961\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.2202 - accuracy: 0.9962 - val_loss: 0.2506 - val_accuracy: 0.9923\n",
            "Epoch 10/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2068 - accuracy: 0.9981\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.2068 - accuracy: 0.9981 - val_loss: 0.2168 - val_accuracy: 0.9923\n",
            "Epoch 11/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1887 - accuracy: 0.9974\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.1881 - accuracy: 0.9974 - val_loss: 0.2000 - val_accuracy: 0.9949\n",
            "Epoch 12/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1727 - accuracy: 0.9987\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.1728 - accuracy: 0.9987 - val_loss: 0.1859 - val_accuracy: 0.9923\n",
            "Epoch 13/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1575 - accuracy: 0.9993\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.1577 - accuracy: 0.9994 - val_loss: 0.1771 - val_accuracy: 0.9898\n",
            "Epoch 14/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1499 - accuracy: 0.9993\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.1498 - accuracy: 0.9994 - val_loss: 0.1598 - val_accuracy: 0.9923\n",
            "Epoch 15/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1398 - accuracy: 0.9981\n",
            "Epoch 15: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.1397 - accuracy: 0.9981 - val_loss: 0.1647 - val_accuracy: 0.9923\n",
            "Epoch 16/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1333 - accuracy: 0.9987\n",
            "Epoch 16: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.1331 - accuracy: 0.9987 - val_loss: 0.1458 - val_accuracy: 0.9923\n",
            "Epoch 17/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1225 - accuracy: 0.9987\n",
            "Epoch 17: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.1222 - accuracy: 0.9987 - val_loss: 0.1450 - val_accuracy: 0.9898\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1155 - accuracy: 1.0000\n",
            "Epoch 18: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.1155 - accuracy: 1.0000 - val_loss: 0.1287 - val_accuracy: 0.9949\n",
            "Epoch 19/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1301 - accuracy: 0.9942\n",
            "Epoch 19: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.1301 - accuracy: 0.9942 - val_loss: 0.1299 - val_accuracy: 0.9923\n",
            "Epoch 20/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1054 - accuracy: 0.9994\n",
            "Epoch 20: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.1053 - accuracy: 0.9994 - val_loss: 0.1219 - val_accuracy: 0.9923\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0992 - accuracy: 1.0000\n",
            "Epoch 21: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0991 - accuracy: 1.0000 - val_loss: 0.1200 - val_accuracy: 0.9923\n",
            "Epoch 22/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0977 - accuracy: 0.9987\n",
            "Epoch 22: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0975 - accuracy: 0.9987 - val_loss: 0.1180 - val_accuracy: 0.9923\n",
            "Epoch 23/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0909 - accuracy: 1.0000\n",
            "Epoch 23: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0909 - accuracy: 1.0000 - val_loss: 0.1078 - val_accuracy: 0.9949\n",
            "Epoch 24/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0884 - accuracy: 0.9993\n",
            "Epoch 24: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0884 - accuracy: 0.9994 - val_loss: 0.1103 - val_accuracy: 0.9923\n",
            "Epoch 25/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0842 - accuracy: 1.0000\n",
            "Epoch 25: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0842 - accuracy: 1.0000 - val_loss: 0.1023 - val_accuracy: 0.9949\n",
            "Epoch 26/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0831 - accuracy: 0.9987\n",
            "Epoch 26: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0831 - accuracy: 0.9987 - val_loss: 0.1328 - val_accuracy: 0.9898\n",
            "Epoch 27/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.0800 - accuracy: 0.9993\n",
            "Epoch 27: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0799 - accuracy: 0.9994 - val_loss: 0.0965 - val_accuracy: 0.9949\n",
            "Epoch 28/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0737 - accuracy: 1.0000\n",
            "Epoch 28: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0738 - accuracy: 1.0000 - val_loss: 0.0962 - val_accuracy: 0.9949\n",
            "Epoch 29/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0757 - accuracy: 1.0000\n",
            "Epoch 29: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0757 - accuracy: 1.0000 - val_loss: 0.0901 - val_accuracy: 0.9949\n",
            "Epoch 30/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.0714 - accuracy: 1.0000\n",
            "Epoch 30: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0713 - accuracy: 1.0000 - val_loss: 0.0914 - val_accuracy: 0.9949\n",
            "Epoch 31/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0680 - accuracy: 1.0000\n",
            "Epoch 31: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0680 - accuracy: 1.0000 - val_loss: 0.0856 - val_accuracy: 0.9974\n",
            "Epoch 32/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.0677 - accuracy: 1.0000\n",
            "Epoch 32: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0674 - accuracy: 1.0000 - val_loss: 0.0860 - val_accuracy: 0.9949\n",
            "Epoch 33/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0635 - accuracy: 1.0000\n",
            "Epoch 33: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0634 - accuracy: 1.0000 - val_loss: 0.0901 - val_accuracy: 0.9923\n",
            "Epoch 34/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0634 - accuracy: 0.9993\n",
            "Epoch 34: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0634 - accuracy: 0.9994 - val_loss: 0.0813 - val_accuracy: 0.9974\n",
            "Epoch 35/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0601 - accuracy: 1.0000\n",
            "Epoch 35: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0601 - accuracy: 1.0000 - val_loss: 0.0800 - val_accuracy: 0.9974\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0580 - accuracy: 1.0000\n",
            "Epoch 36: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0580 - accuracy: 1.0000 - val_loss: 0.0797 - val_accuracy: 0.9949\n",
            "Epoch 37/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0569 - accuracy: 1.0000\n",
            "Epoch 37: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0571 - accuracy: 1.0000 - val_loss: 0.0956 - val_accuracy: 0.9949\n",
            "Epoch 38/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.0555 - accuracy: 1.0000\n",
            "Epoch 38: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0555 - accuracy: 1.0000 - val_loss: 0.0843 - val_accuracy: 0.9949\n",
            "Epoch 39/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0536 - accuracy: 1.0000\n",
            "Epoch 39: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0536 - accuracy: 1.0000 - val_loss: 0.0771 - val_accuracy: 0.9974\n",
            "Epoch 40/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0570 - accuracy: 0.9987\n",
            "Epoch 40: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0572 - accuracy: 0.9987 - val_loss: 0.1532 - val_accuracy: 0.9668\n",
            "Epoch 41/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0559 - accuracy: 1.0000\n",
            "Epoch 41: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0559 - accuracy: 1.0000 - val_loss: 0.0784 - val_accuracy: 0.9923\n",
            "Epoch 42/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0510 - accuracy: 1.0000\n",
            "Epoch 42: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0510 - accuracy: 1.0000 - val_loss: 0.0755 - val_accuracy: 0.9949\n",
            "Epoch 43/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0490 - accuracy: 1.0000\n",
            "Epoch 43: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0490 - accuracy: 1.0000 - val_loss: 0.0705 - val_accuracy: 0.9949\n",
            "Epoch 44/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0486 - accuracy: 1.0000\n",
            "Epoch 44: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0486 - accuracy: 1.0000 - val_loss: 0.0729 - val_accuracy: 0.9949\n",
            "Epoch 45/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0466 - accuracy: 1.0000\n",
            "Epoch 45: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0466 - accuracy: 1.0000 - val_loss: 0.0672 - val_accuracy: 0.9949\n",
            "Epoch 46/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0462 - accuracy: 1.0000\n",
            "Epoch 46: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0461 - accuracy: 1.0000 - val_loss: 0.0659 - val_accuracy: 0.9949\n",
            "Epoch 47/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0448 - accuracy: 1.0000\n",
            "Epoch 47: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0447 - accuracy: 1.0000 - val_loss: 0.0660 - val_accuracy: 0.9974\n",
            "Epoch 48/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0440 - accuracy: 1.0000\n",
            "Epoch 48: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0440 - accuracy: 1.0000 - val_loss: 0.0653 - val_accuracy: 0.9949\n",
            "Epoch 49/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.0443 - accuracy: 1.0000\n",
            "Epoch 49: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0458 - accuracy: 0.9994 - val_loss: 0.1299 - val_accuracy: 0.9668\n",
            "Epoch 50/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0492 - accuracy: 0.9994\n",
            "Epoch 50: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0491 - accuracy: 0.9994 - val_loss: 0.0653 - val_accuracy: 0.9974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/27/assets\n",
            "\n",
            "\n",
            " 14%|█▍        | 28/200 [1:06:21<5:43:44, 119.91s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.7397 - accuracy: 0.5092\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 14ms/step - loss: 1.7313 - accuracy: 0.5128 - val_loss: 1.7644 - val_accuracy: 0.4552\n",
            "Epoch 2/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 1.0187 - accuracy: 0.8178\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.0157 - accuracy: 0.8179 - val_loss: 2.2337 - val_accuracy: 0.2864\n",
            "Epoch 3/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.7035 - accuracy: 0.9267\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.7025 - accuracy: 0.9256 - val_loss: 1.5944 - val_accuracy: 0.5882\n",
            "Epoch 4/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.5700 - accuracy: 0.9594\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.5684 - accuracy: 0.9603 - val_loss: 0.5972 - val_accuracy: 0.9565\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4834 - accuracy: 0.9728\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.4827 - accuracy: 0.9731 - val_loss: 0.4517 - val_accuracy: 0.9693\n",
            "Epoch 6/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.4242 - accuracy: 0.9811\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.4264 - accuracy: 0.9801 - val_loss: 0.3989 - val_accuracy: 0.9923\n",
            "Epoch 7/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.3814 - accuracy: 0.9823\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.3804 - accuracy: 0.9827 - val_loss: 0.3606 - val_accuracy: 0.9898\n",
            "Epoch 8/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3440 - accuracy: 0.9878\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.3440 - accuracy: 0.9878 - val_loss: 0.3308 - val_accuracy: 0.9847\n",
            "Epoch 9/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3196 - accuracy: 0.9891\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.3196 - accuracy: 0.9891 - val_loss: 0.3408 - val_accuracy: 0.9770\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2922 - accuracy: 0.9961\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.2917 - accuracy: 0.9962 - val_loss: 0.2765 - val_accuracy: 0.9923\n",
            "Epoch 11/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.2694 - accuracy: 0.9947\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.2687 - accuracy: 0.9949 - val_loss: 0.2931 - val_accuracy: 0.9795\n",
            "Epoch 12/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2536 - accuracy: 0.9941\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.2534 - accuracy: 0.9942 - val_loss: 0.2523 - val_accuracy: 0.9923\n",
            "Epoch 13/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.2365 - accuracy: 0.9967\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.2360 - accuracy: 0.9968 - val_loss: 0.2330 - val_accuracy: 0.9923\n",
            "Epoch 14/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2213 - accuracy: 0.9962\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.2213 - accuracy: 0.9962 - val_loss: 0.2255 - val_accuracy: 0.9898\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2074 - accuracy: 0.9968\n",
            "Epoch 15: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.2075 - accuracy: 0.9968 - val_loss: 0.2043 - val_accuracy: 0.9898\n",
            "Epoch 16/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2004 - accuracy: 0.9961\n",
            "Epoch 16: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.2002 - accuracy: 0.9962 - val_loss: 0.1958 - val_accuracy: 0.9949\n",
            "Epoch 17/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1888 - accuracy: 0.9974\n",
            "Epoch 17: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.1886 - accuracy: 0.9974 - val_loss: 0.1965 - val_accuracy: 0.9923\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1760 - accuracy: 0.9987\n",
            "Epoch 18: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.1760 - accuracy: 0.9987 - val_loss: 0.1767 - val_accuracy: 0.9949\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1717 - accuracy: 0.9955\n",
            "Epoch 19: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.1717 - accuracy: 0.9955 - val_loss: 0.1682 - val_accuracy: 0.9949\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1575 - accuracy: 0.9987\n",
            "Epoch 20: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.1576 - accuracy: 0.9987 - val_loss: 0.1767 - val_accuracy: 0.9923\n",
            "Epoch 21/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1531 - accuracy: 0.9994\n",
            "Epoch 21: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.1535 - accuracy: 0.9994 - val_loss: 0.1561 - val_accuracy: 0.9923\n",
            "Epoch 22/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1472 - accuracy: 0.9974\n",
            "Epoch 22: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.1471 - accuracy: 0.9974 - val_loss: 0.1659 - val_accuracy: 0.9872\n",
            "Epoch 23/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1412 - accuracy: 0.9987\n",
            "Epoch 23: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.1411 - accuracy: 0.9987 - val_loss: 0.1508 - val_accuracy: 0.9923\n",
            "Epoch 24/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1373 - accuracy: 0.9980\n",
            "Epoch 24: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.1370 - accuracy: 0.9981 - val_loss: 0.1509 - val_accuracy: 0.9898\n",
            "Epoch 25/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1283 - accuracy: 0.9987\n",
            "Epoch 25: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.1283 - accuracy: 0.9987 - val_loss: 0.1431 - val_accuracy: 0.9898\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1260 - accuracy: 0.9981\n",
            "Epoch 26: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.1260 - accuracy: 0.9981 - val_loss: 0.1370 - val_accuracy: 0.9898\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1244 - accuracy: 0.9987\n",
            "Epoch 27: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.1242 - accuracy: 0.9987 - val_loss: 0.1353 - val_accuracy: 0.9872\n",
            "Epoch 28/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1169 - accuracy: 0.9994\n",
            "Epoch 28: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.1168 - accuracy: 0.9994 - val_loss: 0.1251 - val_accuracy: 0.9949\n",
            "Epoch 29/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1140 - accuracy: 0.9993\n",
            "Epoch 29: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.1140 - accuracy: 0.9994 - val_loss: 0.1231 - val_accuracy: 0.9949\n",
            "Epoch 30/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1100 - accuracy: 1.0000\n",
            "Epoch 30: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.1101 - accuracy: 1.0000 - val_loss: 0.1253 - val_accuracy: 0.9898\n",
            "Epoch 31/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1089 - accuracy: 0.9994\n",
            "Epoch 31: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.1089 - accuracy: 0.9994 - val_loss: 0.1269 - val_accuracy: 0.9898\n",
            "Epoch 32/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1042 - accuracy: 1.0000\n",
            "Epoch 32: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.1043 - accuracy: 1.0000 - val_loss: 0.1156 - val_accuracy: 0.9923\n",
            "Epoch 33/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1011 - accuracy: 1.0000\n",
            "Epoch 33: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.1011 - accuracy: 1.0000 - val_loss: 0.1127 - val_accuracy: 0.9923\n",
            "Epoch 34/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0996 - accuracy: 0.9994\n",
            "Epoch 34: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0996 - accuracy: 0.9994 - val_loss: 0.1104 - val_accuracy: 0.9949\n",
            "Epoch 35/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0962 - accuracy: 1.0000\n",
            "Epoch 35: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0962 - accuracy: 1.0000 - val_loss: 0.1128 - val_accuracy: 0.9923\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1002 - accuracy: 0.9987\n",
            "Epoch 36: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.1001 - accuracy: 0.9987 - val_loss: 0.1041 - val_accuracy: 0.9949\n",
            "Epoch 37/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0935 - accuracy: 1.0000\n",
            "Epoch 37: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0935 - accuracy: 1.0000 - val_loss: 0.1101 - val_accuracy: 0.9923\n",
            "Epoch 38/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0887 - accuracy: 1.0000\n",
            "Epoch 38: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0887 - accuracy: 1.0000 - val_loss: 0.1051 - val_accuracy: 0.9923\n",
            "Epoch 39/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0880 - accuracy: 0.9994\n",
            "Epoch 39: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0880 - accuracy: 0.9994 - val_loss: 0.0980 - val_accuracy: 0.9923\n",
            "Epoch 40/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.0850 - accuracy: 1.0000\n",
            "Epoch 40: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0849 - accuracy: 1.0000 - val_loss: 0.1006 - val_accuracy: 0.9923\n",
            "Epoch 41/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0841 - accuracy: 1.0000\n",
            "Epoch 41: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0841 - accuracy: 1.0000 - val_loss: 0.1014 - val_accuracy: 0.9923\n",
            "Epoch 42/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0809 - accuracy: 1.0000\n",
            "Epoch 42: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0809 - accuracy: 1.0000 - val_loss: 0.0979 - val_accuracy: 0.9923\n",
            "Epoch 43/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0805 - accuracy: 1.0000\n",
            "Epoch 43: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0804 - accuracy: 1.0000 - val_loss: 0.0996 - val_accuracy: 0.9898\n",
            "Epoch 44/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0800 - accuracy: 1.0000\n",
            "Epoch 44: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0800 - accuracy: 1.0000 - val_loss: 0.0979 - val_accuracy: 0.9898\n",
            "Epoch 45/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0781 - accuracy: 1.0000\n",
            "Epoch 45: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0782 - accuracy: 1.0000 - val_loss: 0.0981 - val_accuracy: 0.9923\n",
            "Epoch 46/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0749 - accuracy: 1.0000\n",
            "Epoch 46: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0749 - accuracy: 1.0000 - val_loss: 0.0929 - val_accuracy: 0.9923\n",
            "Epoch 47/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0736 - accuracy: 1.0000\n",
            "Epoch 47: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0735 - accuracy: 1.0000 - val_loss: 0.0994 - val_accuracy: 0.9872\n",
            "Epoch 48/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0728 - accuracy: 1.0000\n",
            "Epoch 48: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0727 - accuracy: 1.0000 - val_loss: 0.1042 - val_accuracy: 0.9872\n",
            "Epoch 49/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0713 - accuracy: 1.0000\n",
            "Epoch 49: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0713 - accuracy: 1.0000 - val_loss: 0.0903 - val_accuracy: 0.9923\n",
            "Epoch 50/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0730 - accuracy: 1.0000\n",
            "Epoch 50: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0730 - accuracy: 1.0000 - val_loss: 0.1014 - val_accuracy: 0.9872\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/28/assets\n",
            "\n",
            "\n",
            " 14%|█▍        | 29/200 [1:08:49<6:05:06, 128.11s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.9328 - accuracy: 0.3193\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 11ms/step - loss: 1.9276 - accuracy: 0.3231 - val_loss: 1.7383 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 1.4683 - accuracy: 0.5516\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 1.4667 - accuracy: 0.5513 - val_loss: 1.6516 - val_accuracy: 0.2890\n",
            "Epoch 3/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 1.1308 - accuracy: 0.7171\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.1284 - accuracy: 0.7179 - val_loss: 1.3794 - val_accuracy: 0.5090\n",
            "Epoch 4/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 0.8878 - accuracy: 0.8003\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.8862 - accuracy: 0.8032 - val_loss: 0.8322 - val_accuracy: 0.8107\n",
            "Epoch 5/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.7240 - accuracy: 0.8599\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.7221 - accuracy: 0.8609 - val_loss: 0.6813 - val_accuracy: 0.8721\n",
            "Epoch 6/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.6058 - accuracy: 0.9143\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.6051 - accuracy: 0.9147 - val_loss: 0.5789 - val_accuracy: 0.9054\n",
            "Epoch 7/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.5227 - accuracy: 0.9391\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.5221 - accuracy: 0.9397 - val_loss: 0.5198 - val_accuracy: 0.9182\n",
            "Epoch 8/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.4589 - accuracy: 0.9516\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.4584 - accuracy: 0.9519 - val_loss: 0.4539 - val_accuracy: 0.9488\n",
            "Epoch 9/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.3981 - accuracy: 0.9732\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.3983 - accuracy: 0.9731 - val_loss: 0.4267 - val_accuracy: 0.9540\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3663 - accuracy: 0.9780\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.3658 - accuracy: 0.9782 - val_loss: 0.3814 - val_accuracy: 0.9565\n",
            "Epoch 11/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.3321 - accuracy: 0.9836\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.3342 - accuracy: 0.9827 - val_loss: 0.3735 - val_accuracy: 0.9616\n",
            "Epoch 12/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.2995 - accuracy: 0.9908\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.3012 - accuracy: 0.9904 - val_loss: 0.3250 - val_accuracy: 0.9821\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2837 - accuracy: 0.9890\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.2835 - accuracy: 0.9891 - val_loss: 0.3090 - val_accuracy: 0.9744\n",
            "Epoch 14/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.2677 - accuracy: 0.9915\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.2673 - accuracy: 0.9917 - val_loss: 0.2938 - val_accuracy: 0.9719\n",
            "Epoch 15/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 0.2450 - accuracy: 0.9927\n",
            "Epoch 15: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.2439 - accuracy: 0.9929 - val_loss: 0.2816 - val_accuracy: 0.9770\n",
            "Epoch 16/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.2253 - accuracy: 0.9961\n",
            "Epoch 16: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.2254 - accuracy: 0.9962 - val_loss: 0.2746 - val_accuracy: 0.9616\n",
            "Epoch 17/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2194 - accuracy: 0.9948\n",
            "Epoch 17: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.2191 - accuracy: 0.9949 - val_loss: 0.2463 - val_accuracy: 0.9821\n",
            "Epoch 18/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.2029 - accuracy: 0.9947\n",
            "Epoch 18: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.2034 - accuracy: 0.9949 - val_loss: 0.2339 - val_accuracy: 0.9821\n",
            "Epoch 19/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1900 - accuracy: 0.9967\n",
            "Epoch 19: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.1908 - accuracy: 0.9968 - val_loss: 0.2292 - val_accuracy: 0.9847\n",
            "Epoch 20/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.1829 - accuracy: 0.9967\n",
            "Epoch 20: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.1824 - accuracy: 0.9968 - val_loss: 0.2324 - val_accuracy: 0.9770\n",
            "Epoch 21/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1759 - accuracy: 0.9981\n",
            "Epoch 21: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.1759 - accuracy: 0.9981 - val_loss: 0.2073 - val_accuracy: 0.9847\n",
            "Epoch 22/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 0.1671 - accuracy: 0.9967\n",
            "Epoch 22: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.1666 - accuracy: 0.9968 - val_loss: 0.1972 - val_accuracy: 0.9821\n",
            "Epoch 23/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1567 - accuracy: 0.9987\n",
            "Epoch 23: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.1567 - accuracy: 0.9987 - val_loss: 0.1927 - val_accuracy: 0.9847\n",
            "Epoch 24/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.1487 - accuracy: 0.9980\n",
            "Epoch 24: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.1484 - accuracy: 0.9981 - val_loss: 0.1856 - val_accuracy: 0.9898\n",
            "Epoch 25/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1477 - accuracy: 0.9955\n",
            "Epoch 25: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.1477 - accuracy: 0.9955 - val_loss: 0.1766 - val_accuracy: 0.9872\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1374 - accuracy: 0.9968\n",
            "Epoch 26: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.1375 - accuracy: 0.9968 - val_loss: 0.1690 - val_accuracy: 0.9898\n",
            "Epoch 27/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1301 - accuracy: 0.9994\n",
            "Epoch 27: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.1301 - accuracy: 0.9994 - val_loss: 0.1785 - val_accuracy: 0.9821\n",
            "Epoch 28/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1259 - accuracy: 0.9994\n",
            "Epoch 28: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.1259 - accuracy: 0.9994 - val_loss: 0.1570 - val_accuracy: 0.9898\n",
            "Epoch 29/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1218 - accuracy: 0.9987\n",
            "Epoch 29: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.1218 - accuracy: 0.9987 - val_loss: 0.1593 - val_accuracy: 0.9898\n",
            "Epoch 30/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1158 - accuracy: 0.9987\n",
            "Epoch 30: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.1157 - accuracy: 0.9987 - val_loss: 0.1590 - val_accuracy: 0.9872\n",
            "Epoch 31/50\n",
            "188/195 [===========================>..] - ETA: 0s - loss: 0.1088 - accuracy: 1.0000\n",
            "Epoch 31: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.1090 - accuracy: 1.0000 - val_loss: 0.1525 - val_accuracy: 0.9872\n",
            "Epoch 32/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1052 - accuracy: 0.9987\n",
            "Epoch 32: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.1051 - accuracy: 0.9987 - val_loss: 0.1400 - val_accuracy: 0.9898\n",
            "Epoch 33/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 0.1013 - accuracy: 1.0000\n",
            "Epoch 33: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.1013 - accuracy: 1.0000 - val_loss: 0.1352 - val_accuracy: 0.9923\n",
            "Epoch 34/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0987 - accuracy: 0.9993\n",
            "Epoch 34: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.0990 - accuracy: 0.9994 - val_loss: 0.1392 - val_accuracy: 0.9923\n",
            "Epoch 35/50\n",
            "188/195 [===========================>..] - ETA: 0s - loss: 0.0987 - accuracy: 0.9987\n",
            "Epoch 35: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.0987 - accuracy: 0.9987 - val_loss: 0.1349 - val_accuracy: 0.9898\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0905 - accuracy: 1.0000\n",
            "Epoch 36: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0904 - accuracy: 1.0000 - val_loss: 0.1316 - val_accuracy: 0.9898\n",
            "Epoch 37/50\n",
            "188/195 [===========================>..] - ETA: 0s - loss: 0.0870 - accuracy: 1.0000\n",
            "Epoch 37: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.0869 - accuracy: 1.0000 - val_loss: 0.1285 - val_accuracy: 0.9898\n",
            "Epoch 38/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0847 - accuracy: 1.0000\n",
            "Epoch 38: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.0848 - accuracy: 1.0000 - val_loss: 0.1260 - val_accuracy: 0.9898\n",
            "Epoch 39/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0820 - accuracy: 0.9994\n",
            "Epoch 39: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.0819 - accuracy: 0.9994 - val_loss: 0.1302 - val_accuracy: 0.9923\n",
            "Epoch 40/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0804 - accuracy: 1.0000\n",
            "Epoch 40: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0804 - accuracy: 1.0000 - val_loss: 0.1243 - val_accuracy: 0.9898\n",
            "Epoch 41/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 0.0779 - accuracy: 1.0000\n",
            "Epoch 41: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.0780 - accuracy: 1.0000 - val_loss: 0.1197 - val_accuracy: 0.9898\n",
            "Epoch 42/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0770 - accuracy: 0.9994\n",
            "Epoch 42: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.0770 - accuracy: 0.9994 - val_loss: 0.1279 - val_accuracy: 0.9872\n",
            "Epoch 43/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0742 - accuracy: 1.0000\n",
            "Epoch 43: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0742 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 0.9923\n",
            "Epoch 44/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0715 - accuracy: 1.0000\n",
            "Epoch 44: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0715 - accuracy: 1.0000 - val_loss: 0.1137 - val_accuracy: 0.9872\n",
            "Epoch 45/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0676 - accuracy: 1.0000\n",
            "Epoch 45: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.0686 - accuracy: 0.9994 - val_loss: 0.1249 - val_accuracy: 0.9898\n",
            "Epoch 46/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0698 - accuracy: 1.0000\n",
            "Epoch 46: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.0698 - accuracy: 1.0000 - val_loss: 0.1079 - val_accuracy: 0.9923\n",
            "Epoch 47/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0651 - accuracy: 1.0000\n",
            "Epoch 47: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0651 - accuracy: 1.0000 - val_loss: 0.1043 - val_accuracy: 0.9898\n",
            "Epoch 48/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0669 - accuracy: 1.0000\n",
            "Epoch 48: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.0669 - accuracy: 1.0000 - val_loss: 0.1038 - val_accuracy: 0.9872\n",
            "Epoch 49/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0626 - accuracy: 1.0000\n",
            "Epoch 49: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.0626 - accuracy: 1.0000 - val_loss: 0.1041 - val_accuracy: 0.9898\n",
            "Epoch 50/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0628 - accuracy: 1.0000\n",
            "Epoch 50: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.0628 - accuracy: 1.0000 - val_loss: 0.1558 - val_accuracy: 0.9744\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/29/assets\n",
            "\n",
            "\n",
            " 15%|█▌        | 30/200 [1:11:16<6:19:16, 133.86s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 2.4003 - accuracy: 0.2545\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 16ms/step - loss: 2.3987 - accuracy: 0.2551 - val_loss: 1.8312 - val_accuracy: 0.2634\n",
            "Epoch 2/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 2.0581 - accuracy: 0.3814\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 2.0581 - accuracy: 0.3814 - val_loss: 1.8215 - val_accuracy: 0.2992\n",
            "Epoch 3/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.8781 - accuracy: 0.4897\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 1.8781 - accuracy: 0.4897 - val_loss: 1.7167 - val_accuracy: 0.4962\n",
            "Epoch 4/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.7441 - accuracy: 0.5681\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 1.7416 - accuracy: 0.5699 - val_loss: 1.5744 - val_accuracy: 0.6624\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6068 - accuracy: 0.6231\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 1.6071 - accuracy: 0.6224 - val_loss: 1.4593 - val_accuracy: 0.7008\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.4892 - accuracy: 0.6820\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.4886 - accuracy: 0.6808 - val_loss: 1.3492 - val_accuracy: 0.7417\n",
            "Epoch 7/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.3923 - accuracy: 0.7068\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 1.3914 - accuracy: 0.7071 - val_loss: 1.2491 - val_accuracy: 0.7698\n",
            "Epoch 8/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.2856 - accuracy: 0.7494\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.2856 - accuracy: 0.7494 - val_loss: 1.1691 - val_accuracy: 0.7877\n",
            "Epoch 9/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.2071 - accuracy: 0.7643\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 1.2102 - accuracy: 0.7635 - val_loss: 1.0881 - val_accuracy: 0.8235\n",
            "Epoch 10/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.1402 - accuracy: 0.8006\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 1.1402 - accuracy: 0.8006 - val_loss: 1.0228 - val_accuracy: 0.8465\n",
            "Epoch 11/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.0743 - accuracy: 0.8148\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.0741 - accuracy: 0.8147 - val_loss: 0.9688 - val_accuracy: 0.8824\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.0211 - accuracy: 0.8355\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 1.0210 - accuracy: 0.8346 - val_loss: 0.9167 - val_accuracy: 0.8926\n",
            "Epoch 13/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.9672 - accuracy: 0.8666\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.9674 - accuracy: 0.8667 - val_loss: 0.8708 - val_accuracy: 0.8926\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.9207 - accuracy: 0.8847\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.9194 - accuracy: 0.8853 - val_loss: 0.8277 - val_accuracy: 0.9079\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8699 - accuracy: 0.9003\n",
            "Epoch 15: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.8712 - accuracy: 0.9000 - val_loss: 0.7913 - val_accuracy: 0.9233\n",
            "Epoch 16/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.8410 - accuracy: 0.9162\n",
            "Epoch 16: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.8392 - accuracy: 0.9167 - val_loss: 0.7623 - val_accuracy: 0.9335\n",
            "Epoch 17/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.8107 - accuracy: 0.9122\n",
            "Epoch 17: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.8107 - accuracy: 0.9122 - val_loss: 0.7365 - val_accuracy: 0.9258\n",
            "Epoch 18/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.7827 - accuracy: 0.9182\n",
            "Epoch 18: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.7818 - accuracy: 0.9186 - val_loss: 0.7051 - val_accuracy: 0.9361\n",
            "Epoch 19/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.7467 - accuracy: 0.9326\n",
            "Epoch 19: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.7483 - accuracy: 0.9321 - val_loss: 0.6847 - val_accuracy: 0.9488\n",
            "Epoch 20/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.7204 - accuracy: 0.9401\n",
            "Epoch 20: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.7195 - accuracy: 0.9410 - val_loss: 0.6602 - val_accuracy: 0.9514\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7016 - accuracy: 0.9462\n",
            "Epoch 21: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.7012 - accuracy: 0.9468 - val_loss: 0.6475 - val_accuracy: 0.9488\n",
            "Epoch 22/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.6731 - accuracy: 0.9557\n",
            "Epoch 22: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.6743 - accuracy: 0.9551 - val_loss: 0.6216 - val_accuracy: 0.9616\n",
            "Epoch 23/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.6524 - accuracy: 0.9548\n",
            "Epoch 23: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.6538 - accuracy: 0.9545 - val_loss: 0.6039 - val_accuracy: 0.9642\n",
            "Epoch 24/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6420 - accuracy: 0.9603\n",
            "Epoch 24: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.6420 - accuracy: 0.9603 - val_loss: 0.5996 - val_accuracy: 0.9642\n",
            "Epoch 25/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.6246 - accuracy: 0.9594\n",
            "Epoch 25: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.6241 - accuracy: 0.9596 - val_loss: 0.5803 - val_accuracy: 0.9642\n",
            "Epoch 26/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.6034 - accuracy: 0.9652\n",
            "Epoch 26: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.6046 - accuracy: 0.9647 - val_loss: 0.5640 - val_accuracy: 0.9693\n",
            "Epoch 27/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.5965 - accuracy: 0.9613\n",
            "Epoch 27: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.5969 - accuracy: 0.9609 - val_loss: 0.5508 - val_accuracy: 0.9693\n",
            "Epoch 28/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.5791 - accuracy: 0.9692\n",
            "Epoch 28: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.5786 - accuracy: 0.9699 - val_loss: 0.5395 - val_accuracy: 0.9719\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5620 - accuracy: 0.9728\n",
            "Epoch 29: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.5623 - accuracy: 0.9724 - val_loss: 0.5213 - val_accuracy: 0.9744\n",
            "Epoch 30/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.5450 - accuracy: 0.9729\n",
            "Epoch 30: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.5445 - accuracy: 0.9731 - val_loss: 0.5233 - val_accuracy: 0.9770\n",
            "Epoch 31/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.5380 - accuracy: 0.9798\n",
            "Epoch 31: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.5383 - accuracy: 0.9795 - val_loss: 0.5088 - val_accuracy: 0.9770\n",
            "Epoch 32/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5225 - accuracy: 0.9814\n",
            "Epoch 32: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.5225 - accuracy: 0.9814 - val_loss: 0.4869 - val_accuracy: 0.9821\n",
            "Epoch 33/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.5103 - accuracy: 0.9831\n",
            "Epoch 33: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.5114 - accuracy: 0.9827 - val_loss: 0.4796 - val_accuracy: 0.9821\n",
            "Epoch 34/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.5023 - accuracy: 0.9823\n",
            "Epoch 34: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.5032 - accuracy: 0.9827 - val_loss: 0.4699 - val_accuracy: 0.9821\n",
            "Epoch 35/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4879 - accuracy: 0.9807\n",
            "Epoch 35: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.4877 - accuracy: 0.9808 - val_loss: 0.4605 - val_accuracy: 0.9872\n",
            "Epoch 36/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4803 - accuracy: 0.9885\n",
            "Epoch 36: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.4803 - accuracy: 0.9885 - val_loss: 0.4503 - val_accuracy: 0.9847\n",
            "Epoch 37/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4710 - accuracy: 0.9852\n",
            "Epoch 37: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.4709 - accuracy: 0.9853 - val_loss: 0.4473 - val_accuracy: 0.9821\n",
            "Epoch 38/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4566 - accuracy: 0.9852\n",
            "Epoch 38: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.4567 - accuracy: 0.9853 - val_loss: 0.4420 - val_accuracy: 0.9821\n",
            "Epoch 39/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4520 - accuracy: 0.9878\n",
            "Epoch 39: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.4518 - accuracy: 0.9878 - val_loss: 0.4297 - val_accuracy: 0.9821\n",
            "Epoch 40/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4392 - accuracy: 0.9865\n",
            "Epoch 40: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.4388 - accuracy: 0.9865 - val_loss: 0.4213 - val_accuracy: 0.9847\n",
            "Epoch 41/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4339 - accuracy: 0.9871\n",
            "Epoch 41: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.4337 - accuracy: 0.9872 - val_loss: 0.4122 - val_accuracy: 0.9923\n",
            "Epoch 42/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4298 - accuracy: 0.9865\n",
            "Epoch 42: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.4295 - accuracy: 0.9865 - val_loss: 0.4057 - val_accuracy: 0.9898\n",
            "Epoch 43/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.4220 - accuracy: 0.9850\n",
            "Epoch 43: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.4224 - accuracy: 0.9846 - val_loss: 0.4071 - val_accuracy: 0.9872\n",
            "Epoch 44/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4097 - accuracy: 0.9904\n",
            "Epoch 44: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.4097 - accuracy: 0.9904 - val_loss: 0.3928 - val_accuracy: 0.9898\n",
            "Epoch 45/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.4002 - accuracy: 0.9922\n",
            "Epoch 45: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.3995 - accuracy: 0.9923 - val_loss: 0.3895 - val_accuracy: 0.9872\n",
            "Epoch 46/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3958 - accuracy: 0.9865\n",
            "Epoch 46: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.3958 - accuracy: 0.9865 - val_loss: 0.3814 - val_accuracy: 0.9923\n",
            "Epoch 47/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3876 - accuracy: 0.9916\n",
            "Epoch 47: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.3874 - accuracy: 0.9917 - val_loss: 0.3732 - val_accuracy: 0.9923\n",
            "Epoch 48/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3829 - accuracy: 0.9909\n",
            "Epoch 48: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.3832 - accuracy: 0.9910 - val_loss: 0.3661 - val_accuracy: 0.9923\n",
            "Epoch 49/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3739 - accuracy: 0.9941\n",
            "Epoch 49: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.3741 - accuracy: 0.9942 - val_loss: 0.3619 - val_accuracy: 0.9898\n",
            "Epoch 50/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.3729 - accuracy: 0.9921\n",
            "Epoch 50: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.3727 - accuracy: 0.9923 - val_loss: 0.3553 - val_accuracy: 0.9898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/30/assets\n",
            "\n",
            "\n",
            " 16%|█▌        | 31/200 [1:13:43<6:28:20, 137.87s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 2.6994 - accuracy: 0.4407\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 22ms/step - loss: 2.6954 - accuracy: 0.4404 - val_loss: 1.9275 - val_accuracy: 0.1535\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.4096 - accuracy: 0.6444\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 1.4047 - accuracy: 0.6468 - val_loss: 1.4677 - val_accuracy: 0.5652\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8861 - accuracy: 0.8083\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.8807 - accuracy: 0.8103 - val_loss: 1.5681 - val_accuracy: 0.6650\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6932 - accuracy: 0.8646\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.6904 - accuracy: 0.8654 - val_loss: 0.7148 - val_accuracy: 0.8849\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5615 - accuracy: 0.9022\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.5713 - accuracy: 0.8987 - val_loss: 2.3040 - val_accuracy: 0.4885\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8388 - accuracy: 0.8361\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.8342 - accuracy: 0.8378 - val_loss: 2.6105 - val_accuracy: 0.6650\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5352 - accuracy: 0.9113\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.5357 - accuracy: 0.9109 - val_loss: 0.5328 - val_accuracy: 0.8824\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5122 - accuracy: 0.8957\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.5159 - accuracy: 0.8955 - val_loss: 3.1672 - val_accuracy: 0.0230\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5772 - accuracy: 0.8763\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.5799 - accuracy: 0.8763 - val_loss: 0.5324 - val_accuracy: 0.8824\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3963 - accuracy: 0.9262\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.3982 - accuracy: 0.9250 - val_loss: 0.6584 - val_accuracy: 0.8338\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8820 - accuracy: 0.8096\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.8931 - accuracy: 0.8032 - val_loss: 1.9464 - val_accuracy: 0.1739\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.9248 - accuracy: 0.2662\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 1.9234 - accuracy: 0.2654 - val_loss: 1.8722 - val_accuracy: 0.2634\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.8539 - accuracy: 0.2824\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 1.8538 - accuracy: 0.2821 - val_loss: 1.8304 - val_accuracy: 0.2864\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.8193 - accuracy: 0.2843\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 1.8173 - accuracy: 0.2859 - val_loss: 1.7976 - val_accuracy: 0.2864\n",
            "Epoch 14: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/31/assets\n",
            "\n",
            "\n",
            " 16%|█▌        | 32/200 [1:14:43<5:20:49, 114.58s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 2.2318 - accuracy: 0.3099\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 23ms/step - loss: 2.2308 - accuracy: 0.3083 - val_loss: 1.7886 - val_accuracy: 0.3171\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.8973 - accuracy: 0.4035\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 1.8973 - accuracy: 0.4045 - val_loss: 1.7318 - val_accuracy: 0.3043\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.7023 - accuracy: 0.5712\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 1.7037 - accuracy: 0.5699 - val_loss: 1.5538 - val_accuracy: 0.5601\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.4807 - accuracy: 0.6962\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 1.4780 - accuracy: 0.6968 - val_loss: 1.3030 - val_accuracy: 0.7059\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.2654 - accuracy: 0.7545\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 1.2650 - accuracy: 0.7545 - val_loss: 1.1264 - val_accuracy: 0.7903\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.0956 - accuracy: 0.8063\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 1.0947 - accuracy: 0.8064 - val_loss: 0.9861 - val_accuracy: 0.8389\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.9757 - accuracy: 0.8491\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.9749 - accuracy: 0.8494 - val_loss: 0.8882 - val_accuracy: 0.8926\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8822 - accuracy: 0.8918\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.8796 - accuracy: 0.8929 - val_loss: 0.8065 - val_accuracy: 0.9207\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8025 - accuracy: 0.9171\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.8020 - accuracy: 0.9167 - val_loss: 0.7422 - val_accuracy: 0.9284\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7430 - accuracy: 0.9301\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.7425 - accuracy: 0.9295 - val_loss: 0.6905 - val_accuracy: 0.9463\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6868 - accuracy: 0.9437\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.6898 - accuracy: 0.9410 - val_loss: 0.6466 - val_accuracy: 0.9591\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6579 - accuracy: 0.9514\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.6576 - accuracy: 0.9513 - val_loss: 0.6215 - val_accuracy: 0.9540\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6184 - accuracy: 0.9605\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.6202 - accuracy: 0.9590 - val_loss: 0.5843 - val_accuracy: 0.9668\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5838 - accuracy: 0.9663\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.5856 - accuracy: 0.9660 - val_loss: 0.5555 - val_accuracy: 0.9719\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5582 - accuracy: 0.9728\n",
            "Epoch 15: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.5587 - accuracy: 0.9712 - val_loss: 0.5324 - val_accuracy: 0.9744\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5355 - accuracy: 0.9709\n",
            "Epoch 16: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.5371 - accuracy: 0.9699 - val_loss: 0.5075 - val_accuracy: 0.9795\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5121 - accuracy: 0.9734\n",
            "Epoch 17: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.5128 - accuracy: 0.9724 - val_loss: 0.4899 - val_accuracy: 0.9795\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4895 - accuracy: 0.9799\n",
            "Epoch 18: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.4912 - accuracy: 0.9801 - val_loss: 0.4729 - val_accuracy: 0.9872\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4757 - accuracy: 0.9806\n",
            "Epoch 19: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.4753 - accuracy: 0.9801 - val_loss: 0.4593 - val_accuracy: 0.9847\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4557 - accuracy: 0.9825\n",
            "Epoch 20: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.4559 - accuracy: 0.9827 - val_loss: 0.4531 - val_accuracy: 0.9847\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4419 - accuracy: 0.9870\n",
            "Epoch 21: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.4424 - accuracy: 0.9872 - val_loss: 0.4268 - val_accuracy: 0.9872\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4321 - accuracy: 0.9877\n",
            "Epoch 22: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.4314 - accuracy: 0.9878 - val_loss: 0.4165 - val_accuracy: 0.9847\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4125 - accuracy: 0.9903\n",
            "Epoch 23: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.4124 - accuracy: 0.9904 - val_loss: 0.4007 - val_accuracy: 0.9923\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3980 - accuracy: 0.9903\n",
            "Epoch 24: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.3972 - accuracy: 0.9904 - val_loss: 0.3957 - val_accuracy: 0.9872\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3870 - accuracy: 0.9922\n",
            "Epoch 25: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.3869 - accuracy: 0.9923 - val_loss: 0.3901 - val_accuracy: 0.9847\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3775 - accuracy: 0.9916\n",
            "Epoch 26: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.3769 - accuracy: 0.9917 - val_loss: 0.3790 - val_accuracy: 0.9847\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3648 - accuracy: 0.9916\n",
            "Epoch 27: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.3653 - accuracy: 0.9917 - val_loss: 0.3633 - val_accuracy: 0.9923\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3520 - accuracy: 0.9955\n",
            "Epoch 28: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.3516 - accuracy: 0.9955 - val_loss: 0.3534 - val_accuracy: 0.9898\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3442 - accuracy: 0.9935\n",
            "Epoch 29: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.3450 - accuracy: 0.9929 - val_loss: 0.3393 - val_accuracy: 0.9923\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3371 - accuracy: 0.9968\n",
            "Epoch 30: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.3381 - accuracy: 0.9962 - val_loss: 0.3456 - val_accuracy: 0.9847\n",
            "Epoch 31/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3255 - accuracy: 0.9922\n",
            "Epoch 31: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.3266 - accuracy: 0.9923 - val_loss: 0.3255 - val_accuracy: 0.9923\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3184 - accuracy: 0.9955\n",
            "Epoch 32: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.3188 - accuracy: 0.9955 - val_loss: 0.3314 - val_accuracy: 0.9847\n",
            "Epoch 33/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3127 - accuracy: 0.9968\n",
            "Epoch 33: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.3125 - accuracy: 0.9968 - val_loss: 0.3169 - val_accuracy: 0.9898\n",
            "Epoch 34/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3015 - accuracy: 0.9981\n",
            "Epoch 34: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.3012 - accuracy: 0.9981 - val_loss: 0.3084 - val_accuracy: 0.9898\n",
            "Epoch 35/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2998 - accuracy: 0.9935\n",
            "Epoch 35: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2997 - accuracy: 0.9936 - val_loss: 0.3071 - val_accuracy: 0.9872\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2870 - accuracy: 0.9987\n",
            "Epoch 36: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2865 - accuracy: 0.9987 - val_loss: 0.2940 - val_accuracy: 0.9923\n",
            "Epoch 37/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2847 - accuracy: 0.9974\n",
            "Epoch 37: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2844 - accuracy: 0.9974 - val_loss: 0.2872 - val_accuracy: 0.9898\n",
            "Epoch 38/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2762 - accuracy: 0.9955\n",
            "Epoch 38: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2770 - accuracy: 0.9955 - val_loss: 0.2811 - val_accuracy: 0.9949\n",
            "Epoch 39/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2709 - accuracy: 0.9961\n",
            "Epoch 39: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2711 - accuracy: 0.9962 - val_loss: 0.2759 - val_accuracy: 0.9949\n",
            "Epoch 40/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2640 - accuracy: 0.9968\n",
            "Epoch 40: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2645 - accuracy: 0.9968 - val_loss: 0.2681 - val_accuracy: 0.9949\n",
            "Epoch 41/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2564 - accuracy: 0.9974\n",
            "Epoch 41: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2568 - accuracy: 0.9974 - val_loss: 0.2645 - val_accuracy: 0.9923\n",
            "Epoch 42/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2526 - accuracy: 0.9981\n",
            "Epoch 42: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2525 - accuracy: 0.9981 - val_loss: 0.2577 - val_accuracy: 0.9949\n",
            "Epoch 43/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2459 - accuracy: 0.9987\n",
            "Epoch 43: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2465 - accuracy: 0.9987 - val_loss: 0.2543 - val_accuracy: 0.9923\n",
            "Epoch 44/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2411 - accuracy: 0.9987\n",
            "Epoch 44: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2407 - accuracy: 0.9987 - val_loss: 0.2497 - val_accuracy: 0.9949\n",
            "Epoch 45/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2356 - accuracy: 0.9981\n",
            "Epoch 45: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2355 - accuracy: 0.9981 - val_loss: 0.2426 - val_accuracy: 0.9923\n",
            "Epoch 46/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2322 - accuracy: 0.9994\n",
            "Epoch 46: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2327 - accuracy: 0.9994 - val_loss: 0.2422 - val_accuracy: 0.9923\n",
            "Epoch 47/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2277 - accuracy: 0.9981\n",
            "Epoch 47: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2278 - accuracy: 0.9981 - val_loss: 0.2337 - val_accuracy: 0.9923\n",
            "Epoch 48/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2228 - accuracy: 0.9987\n",
            "Epoch 48: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2226 - accuracy: 0.9987 - val_loss: 0.2321 - val_accuracy: 0.9923\n",
            "Epoch 49/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2167 - accuracy: 0.9994\n",
            "Epoch 49: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2169 - accuracy: 0.9994 - val_loss: 0.2235 - val_accuracy: 0.9949\n",
            "Epoch 50/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2138 - accuracy: 0.9994\n",
            "Epoch 50: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2137 - accuracy: 0.9994 - val_loss: 0.2218 - val_accuracy: 0.9949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/32/assets\n",
            "\n",
            "\n",
            " 16%|█▋        | 33/200 [1:18:11<6:36:18, 142.39s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 2.5637 - accuracy: 0.2702\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 19ms/step - loss: 2.5579 - accuracy: 0.2712 - val_loss: 1.8556 - val_accuracy: 0.2558\n",
            "Epoch 2/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 2.1466 - accuracy: 0.4388\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 2.1458 - accuracy: 0.4385 - val_loss: 1.8806 - val_accuracy: 0.3683\n",
            "Epoch 3/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.8981 - accuracy: 0.5768\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 1.8929 - accuracy: 0.5808 - val_loss: 1.7328 - val_accuracy: 0.6036\n",
            "Epoch 4/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.6963 - accuracy: 0.6888\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 1.6953 - accuracy: 0.6885 - val_loss: 1.5144 - val_accuracy: 0.7519\n",
            "Epoch 5/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.5249 - accuracy: 0.7363\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 1.5262 - accuracy: 0.7353 - val_loss: 1.3780 - val_accuracy: 0.8133\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.3852 - accuracy: 0.7856\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 1.3852 - accuracy: 0.7865 - val_loss: 1.2518 - val_accuracy: 0.8491\n",
            "Epoch 7/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.2627 - accuracy: 0.8170\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 1.2640 - accuracy: 0.8154 - val_loss: 1.1490 - val_accuracy: 0.8849\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.1640 - accuracy: 0.8484\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 1.1621 - accuracy: 0.8494 - val_loss: 1.0593 - val_accuracy: 0.9003\n",
            "Epoch 9/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.0788 - accuracy: 0.8750\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 1.0790 - accuracy: 0.8737 - val_loss: 0.9772 - val_accuracy: 0.9309\n",
            "Epoch 10/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.0129 - accuracy: 0.8900\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 1.0134 - accuracy: 0.8897 - val_loss: 0.9163 - val_accuracy: 0.9335\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.9440 - accuracy: 0.9145\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.9450 - accuracy: 0.9128 - val_loss: 0.8637 - val_accuracy: 0.9412\n",
            "Epoch 12/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.8917 - accuracy: 0.9207\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.8918 - accuracy: 0.9212 - val_loss: 0.8227 - val_accuracy: 0.9514\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8426 - accuracy: 0.9424\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.8422 - accuracy: 0.9423 - val_loss: 0.7697 - val_accuracy: 0.9616\n",
            "Epoch 14/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.8118 - accuracy: 0.9385\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.8118 - accuracy: 0.9385 - val_loss: 0.7300 - val_accuracy: 0.9591\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7849 - accuracy: 0.9482\n",
            "Epoch 15: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.7845 - accuracy: 0.9481 - val_loss: 0.7083 - val_accuracy: 0.9591\n",
            "Epoch 16/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.7471 - accuracy: 0.9545\n",
            "Epoch 16: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.7471 - accuracy: 0.9545 - val_loss: 0.6758 - val_accuracy: 0.9693\n",
            "Epoch 17/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.7173 - accuracy: 0.9577\n",
            "Epoch 17: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.7160 - accuracy: 0.9577 - val_loss: 0.6509 - val_accuracy: 0.9719\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6955 - accuracy: 0.9592\n",
            "Epoch 18: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.6949 - accuracy: 0.9596 - val_loss: 0.6292 - val_accuracy: 0.9744\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6693 - accuracy: 0.9683\n",
            "Epoch 19: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.6686 - accuracy: 0.9686 - val_loss: 0.6087 - val_accuracy: 0.9744\n",
            "Epoch 20/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.6440 - accuracy: 0.9681\n",
            "Epoch 20: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.6445 - accuracy: 0.9679 - val_loss: 0.6028 - val_accuracy: 0.9744\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6296 - accuracy: 0.9702\n",
            "Epoch 21: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.6288 - accuracy: 0.9705 - val_loss: 0.5821 - val_accuracy: 0.9821\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6125 - accuracy: 0.9747\n",
            "Epoch 22: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.6129 - accuracy: 0.9744 - val_loss: 0.5588 - val_accuracy: 0.9821\n",
            "Epoch 23/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5922 - accuracy: 0.9744\n",
            "Epoch 23: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.5922 - accuracy: 0.9744 - val_loss: 0.5441 - val_accuracy: 0.9770\n",
            "Epoch 24/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.5775 - accuracy: 0.9733\n",
            "Epoch 24: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.5772 - accuracy: 0.9731 - val_loss: 0.5326 - val_accuracy: 0.9821\n",
            "Epoch 25/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5654 - accuracy: 0.9756\n",
            "Epoch 25: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.5654 - accuracy: 0.9756 - val_loss: 0.5167 - val_accuracy: 0.9821\n",
            "Epoch 26/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.5459 - accuracy: 0.9792\n",
            "Epoch 26: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.5449 - accuracy: 0.9795 - val_loss: 0.5068 - val_accuracy: 0.9821\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5275 - accuracy: 0.9832\n",
            "Epoch 27: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.5265 - accuracy: 0.9833 - val_loss: 0.4947 - val_accuracy: 0.9795\n",
            "Epoch 28/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.5138 - accuracy: 0.9850\n",
            "Epoch 28: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.5134 - accuracy: 0.9853 - val_loss: 0.4860 - val_accuracy: 0.9847\n",
            "Epoch 29/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.5088 - accuracy: 0.9837\n",
            "Epoch 29: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.5089 - accuracy: 0.9833 - val_loss: 0.4749 - val_accuracy: 0.9872\n",
            "Epoch 30/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4965 - accuracy: 0.9878\n",
            "Epoch 30: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.4960 - accuracy: 0.9878 - val_loss: 0.4701 - val_accuracy: 0.9847\n",
            "Epoch 31/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4938 - accuracy: 0.9825\n",
            "Epoch 31: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.4936 - accuracy: 0.9827 - val_loss: 0.4553 - val_accuracy: 0.9872\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4727 - accuracy: 0.9877\n",
            "Epoch 32: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.4725 - accuracy: 0.9878 - val_loss: 0.4516 - val_accuracy: 0.9847\n",
            "Epoch 33/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4673 - accuracy: 0.9872\n",
            "Epoch 33: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.4673 - accuracy: 0.9872 - val_loss: 0.4358 - val_accuracy: 0.9898\n",
            "Epoch 34/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4538 - accuracy: 0.9890\n",
            "Epoch 34: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.4542 - accuracy: 0.9891 - val_loss: 0.4311 - val_accuracy: 0.9872\n",
            "Epoch 35/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.4435 - accuracy: 0.9883\n",
            "Epoch 35: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.4430 - accuracy: 0.9885 - val_loss: 0.4262 - val_accuracy: 0.9872\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4391 - accuracy: 0.9890\n",
            "Epoch 36: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.4383 - accuracy: 0.9891 - val_loss: 0.4225 - val_accuracy: 0.9872\n",
            "Epoch 37/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4287 - accuracy: 0.9897\n",
            "Epoch 37: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.4287 - accuracy: 0.9897 - val_loss: 0.4125 - val_accuracy: 0.9872\n",
            "Epoch 38/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.4210 - accuracy: 0.9915\n",
            "Epoch 38: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.4210 - accuracy: 0.9917 - val_loss: 0.3976 - val_accuracy: 0.9898\n",
            "Epoch 39/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4132 - accuracy: 0.9929\n",
            "Epoch 39: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.4134 - accuracy: 0.9929 - val_loss: 0.3946 - val_accuracy: 0.9872\n",
            "Epoch 40/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4040 - accuracy: 0.9891\n",
            "Epoch 40: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.4040 - accuracy: 0.9891 - val_loss: 0.3886 - val_accuracy: 0.9898\n",
            "Epoch 41/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3961 - accuracy: 0.9902\n",
            "Epoch 41: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.3963 - accuracy: 0.9904 - val_loss: 0.3805 - val_accuracy: 0.9898\n",
            "Epoch 42/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3913 - accuracy: 0.9936\n",
            "Epoch 42: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.3913 - accuracy: 0.9936 - val_loss: 0.3763 - val_accuracy: 0.9872\n",
            "Epoch 43/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3817 - accuracy: 0.9909\n",
            "Epoch 43: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.3813 - accuracy: 0.9910 - val_loss: 0.3720 - val_accuracy: 0.9898\n",
            "Epoch 44/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3780 - accuracy: 0.9902\n",
            "Epoch 44: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.3779 - accuracy: 0.9904 - val_loss: 0.3675 - val_accuracy: 0.9898\n",
            "Epoch 45/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3718 - accuracy: 0.9909\n",
            "Epoch 45: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.3711 - accuracy: 0.9910 - val_loss: 0.3571 - val_accuracy: 0.9898\n",
            "Epoch 46/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3658 - accuracy: 0.9942\n",
            "Epoch 46: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.3657 - accuracy: 0.9942 - val_loss: 0.3526 - val_accuracy: 0.9898\n",
            "Epoch 47/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3619 - accuracy: 0.9942\n",
            "Epoch 47: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.3615 - accuracy: 0.9942 - val_loss: 0.3451 - val_accuracy: 0.9898\n",
            "Epoch 48/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3571 - accuracy: 0.9910\n",
            "Epoch 48: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.3571 - accuracy: 0.9910 - val_loss: 0.3424 - val_accuracy: 0.9898\n",
            "Epoch 49/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3505 - accuracy: 0.9923\n",
            "Epoch 49: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.3505 - accuracy: 0.9923 - val_loss: 0.3404 - val_accuracy: 0.9923\n",
            "Epoch 50/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3427 - accuracy: 0.9942\n",
            "Epoch 50: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.3428 - accuracy: 0.9942 - val_loss: 0.3335 - val_accuracy: 0.9923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/33/assets\n",
            "\n",
            "\n",
            " 17%|█▋        | 34/200 [1:21:02<6:58:14, 151.17s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.3032 - accuracy: 0.6652\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 24ms/step - loss: 1.3010 - accuracy: 0.6660 - val_loss: 1.9806 - val_accuracy: 0.3325\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4862 - accuracy: 0.9605\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.4842 - accuracy: 0.9609 - val_loss: 2.6442 - val_accuracy: 0.4425\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3209 - accuracy: 0.9870\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.3203 - accuracy: 0.9872 - val_loss: 0.8988 - val_accuracy: 0.6880\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2619 - accuracy: 0.9903\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2614 - accuracy: 0.9904 - val_loss: 0.2300 - val_accuracy: 0.9923\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2058 - accuracy: 0.9974\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2056 - accuracy: 0.9974 - val_loss: 0.1919 - val_accuracy: 0.9949\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1774 - accuracy: 0.9974\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1776 - accuracy: 0.9974 - val_loss: 0.1651 - val_accuracy: 0.9949\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1574 - accuracy: 0.9981\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1573 - accuracy: 0.9981 - val_loss: 0.1462 - val_accuracy: 0.9949\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1432 - accuracy: 0.9974\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1438 - accuracy: 0.9968 - val_loss: 0.1371 - val_accuracy: 0.9949\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1266 - accuracy: 1.0000\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1263 - accuracy: 1.0000 - val_loss: 0.1292 - val_accuracy: 0.9949\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1168 - accuracy: 0.9994\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1167 - accuracy: 0.9994 - val_loss: 0.1166 - val_accuracy: 0.9949\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1114 - accuracy: 0.9987\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1113 - accuracy: 0.9987 - val_loss: 0.1217 - val_accuracy: 0.9898\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1024 - accuracy: 0.9987\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1023 - accuracy: 0.9987 - val_loss: 0.1077 - val_accuracy: 0.9974\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0935 - accuracy: 1.0000\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0935 - accuracy: 1.0000 - val_loss: 0.0961 - val_accuracy: 0.9974\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0893 - accuracy: 0.9994\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0892 - accuracy: 0.9994 - val_loss: 0.1333 - val_accuracy: 0.9872\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0823 - accuracy: 1.0000\n",
            "Epoch 15: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0823 - accuracy: 1.0000 - val_loss: 0.0936 - val_accuracy: 0.9974\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0858 - accuracy: 0.9981\n",
            "Epoch 16: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0861 - accuracy: 0.9981 - val_loss: 0.1106 - val_accuracy: 0.9872\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1132 - accuracy: 0.9929\n",
            "Epoch 17: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1129 - accuracy: 0.9929 - val_loss: 0.0991 - val_accuracy: 0.9923\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0767 - accuracy: 1.0000\n",
            "Epoch 18: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0767 - accuracy: 1.0000 - val_loss: 0.0857 - val_accuracy: 0.9974\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0707 - accuracy: 1.0000\n",
            "Epoch 19: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0707 - accuracy: 1.0000 - val_loss: 0.0830 - val_accuracy: 0.9974\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0679 - accuracy: 1.0000\n",
            "Epoch 20: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0680 - accuracy: 1.0000 - val_loss: 0.0774 - val_accuracy: 0.9974\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0664 - accuracy: 1.0000\n",
            "Epoch 21: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0663 - accuracy: 1.0000 - val_loss: 0.0781 - val_accuracy: 0.9949\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0643 - accuracy: 1.0000\n",
            "Epoch 22: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0643 - accuracy: 1.0000 - val_loss: 0.0776 - val_accuracy: 0.9949\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0613 - accuracy: 1.0000\n",
            "Epoch 23: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.0613 - accuracy: 1.0000 - val_loss: 0.0713 - val_accuracy: 0.9974\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0589 - accuracy: 1.0000\n",
            "Epoch 24: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0588 - accuracy: 1.0000 - val_loss: 0.0677 - val_accuracy: 0.9974\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0609 - accuracy: 0.9994\n",
            "Epoch 25: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0609 - accuracy: 0.9994 - val_loss: 0.0671 - val_accuracy: 0.9974\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0565 - accuracy: 1.0000\n",
            "Epoch 26: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0566 - accuracy: 1.0000 - val_loss: 0.0702 - val_accuracy: 0.9974\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0565 - accuracy: 1.0000\n",
            "Epoch 27: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0564 - accuracy: 1.0000 - val_loss: 0.0705 - val_accuracy: 0.9974\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0537 - accuracy: 1.0000\n",
            "Epoch 28: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0537 - accuracy: 1.0000 - val_loss: 0.0632 - val_accuracy: 0.9974\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0529 - accuracy: 1.0000\n",
            "Epoch 29: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0529 - accuracy: 1.0000 - val_loss: 0.0616 - val_accuracy: 0.9974\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0524 - accuracy: 1.0000\n",
            "Epoch 30: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0524 - accuracy: 1.0000 - val_loss: 0.0653 - val_accuracy: 0.9974\n",
            "Epoch 31/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0506 - accuracy: 1.0000\n",
            "Epoch 31: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.0507 - accuracy: 1.0000 - val_loss: 0.0685 - val_accuracy: 0.9949\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0479 - accuracy: 1.0000\n",
            "Epoch 32: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0479 - accuracy: 1.0000 - val_loss: 0.0577 - val_accuracy: 0.9974\n",
            "Epoch 33/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0474 - accuracy: 1.0000\n",
            "Epoch 33: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0474 - accuracy: 1.0000 - val_loss: 0.0540 - val_accuracy: 0.9974\n",
            "Epoch 34/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0478 - accuracy: 1.0000\n",
            "Epoch 34: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0478 - accuracy: 1.0000 - val_loss: 0.0614 - val_accuracy: 0.9974\n",
            "Epoch 35/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0446 - accuracy: 1.0000\n",
            "Epoch 35: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0445 - accuracy: 1.0000 - val_loss: 0.0567 - val_accuracy: 0.9974\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0450 - accuracy: 1.0000\n",
            "Epoch 36: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0450 - accuracy: 1.0000 - val_loss: 0.0624 - val_accuracy: 0.9949\n",
            "Epoch 37/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0434 - accuracy: 1.0000\n",
            "Epoch 37: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0434 - accuracy: 1.0000 - val_loss: 0.0586 - val_accuracy: 0.9923\n",
            "Epoch 38/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0430 - accuracy: 1.0000\n",
            "Epoch 38: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0429 - accuracy: 1.0000 - val_loss: 0.0494 - val_accuracy: 0.9974\n",
            "Epoch 39/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0411 - accuracy: 1.0000\n",
            "Epoch 39: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0411 - accuracy: 1.0000 - val_loss: 0.0566 - val_accuracy: 0.9923\n",
            "Epoch 40/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0400 - accuracy: 1.0000\n",
            "Epoch 40: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0400 - accuracy: 1.0000 - val_loss: 0.0685 - val_accuracy: 0.9923\n",
            "Epoch 41/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0393 - accuracy: 1.0000\n",
            "Epoch 41: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0393 - accuracy: 1.0000 - val_loss: 0.0587 - val_accuracy: 0.9923\n",
            "Epoch 42/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0382 - accuracy: 1.0000\n",
            "Epoch 42: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0382 - accuracy: 1.0000 - val_loss: 0.0507 - val_accuracy: 0.9974\n",
            "Epoch 43/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0411 - accuracy: 1.0000\n",
            "Epoch 43: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0411 - accuracy: 1.0000 - val_loss: 0.1008 - val_accuracy: 0.9898\n",
            "Epoch 43: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/34/assets\n",
            "\n",
            "\n",
            " 18%|█▊        | 35/200 [1:24:13<7:28:41, 163.16s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 1.2984 - accuracy: 0.5493\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 10ms/step - loss: 1.2906 - accuracy: 0.5526 - val_loss: 2.8101 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.7984 - accuracy: 0.7836\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.7902 - accuracy: 0.7846 - val_loss: 2.2916 - val_accuracy: 0.3581\n",
            "Epoch 3/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.6282 - accuracy: 0.8408\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.6203 - accuracy: 0.8436 - val_loss: 0.8687 - val_accuracy: 0.7238\n",
            "Epoch 4/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3102 - accuracy: 0.9298\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.3097 - accuracy: 0.9295 - val_loss: 0.2346 - val_accuracy: 0.9412\n",
            "Epoch 5/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2649 - accuracy: 0.9473\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.2631 - accuracy: 0.9481 - val_loss: 0.6569 - val_accuracy: 0.7928\n",
            "Epoch 6/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1859 - accuracy: 0.9588\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1855 - accuracy: 0.9590 - val_loss: 0.2545 - val_accuracy: 0.9309\n",
            "Epoch 7/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.1499 - accuracy: 0.9737\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.1494 - accuracy: 0.9737 - val_loss: 0.2687 - val_accuracy: 0.9693\n",
            "Epoch 8/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.2322 - accuracy: 0.9513\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.2318 - accuracy: 0.9506 - val_loss: 0.3127 - val_accuracy: 0.9156\n",
            "Epoch 9/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.1539 - accuracy: 0.9743\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.1532 - accuracy: 0.9744 - val_loss: 0.1413 - val_accuracy: 0.9719\n",
            "Epoch 10/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 0.3207 - accuracy: 0.9259\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.3368 - accuracy: 0.9224 - val_loss: 3.4181 - val_accuracy: 0.3402\n",
            "Epoch 11/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.7213 - accuracy: 0.8171\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.7114 - accuracy: 0.8205 - val_loss: 1.7602 - val_accuracy: 0.6905\n",
            "Epoch 12/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 0.6225 - accuracy: 0.8743\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.6099 - accuracy: 0.8776 - val_loss: 2.8459 - val_accuracy: 0.5806\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2137 - accuracy: 0.9637\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.2129 - accuracy: 0.9641 - val_loss: 0.3441 - val_accuracy: 0.9284\n",
            "Epoch 14/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.2575 - accuracy: 0.9503\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.2742 - accuracy: 0.9449 - val_loss: 2.1333 - val_accuracy: 0.4143\n",
            "Epoch 14: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/35/assets\n",
            "\n",
            "\n",
            " 18%|█▊        | 36/200 [1:24:43<5:36:23, 123.07s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.6957 - accuracy: 0.3652\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 20ms/step - loss: 1.6928 - accuracy: 0.3654 - val_loss: 1.7150 - val_accuracy: 0.4680\n",
            "Epoch 2/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.9885 - accuracy: 0.7155\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.9825 - accuracy: 0.7179 - val_loss: 1.3872 - val_accuracy: 0.5345\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7393 - accuracy: 0.8277\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.7393 - accuracy: 0.8269 - val_loss: 0.7157 - val_accuracy: 0.7852\n",
            "Epoch 4/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.5191 - accuracy: 0.8854\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.5201 - accuracy: 0.8846 - val_loss: 0.7140 - val_accuracy: 0.7980\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3662 - accuracy: 0.9255\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.3649 - accuracy: 0.9263 - val_loss: 0.5065 - val_accuracy: 0.8491\n",
            "Epoch 6/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3215 - accuracy: 0.9359\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.3215 - accuracy: 0.9359 - val_loss: 0.3095 - val_accuracy: 0.9514\n",
            "Epoch 7/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2954 - accuracy: 0.9429\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.2954 - accuracy: 0.9429 - val_loss: 0.2205 - val_accuracy: 0.9488\n",
            "Epoch 8/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.5223 - accuracy: 0.9141\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.5186 - accuracy: 0.9147 - val_loss: 0.5558 - val_accuracy: 0.8721\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3177 - accuracy: 0.9462\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.3164 - accuracy: 0.9468 - val_loss: 0.4493 - val_accuracy: 0.9284\n",
            "Epoch 10/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3459 - accuracy: 0.9543\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.3450 - accuracy: 0.9545 - val_loss: 1.0770 - val_accuracy: 0.6215\n",
            "Epoch 11/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2153 - accuracy: 0.9679\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.2153 - accuracy: 0.9679 - val_loss: 0.2229 - val_accuracy: 0.9795\n",
            "Epoch 12/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1789 - accuracy: 0.9814\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.1789 - accuracy: 0.9814 - val_loss: 0.7843 - val_accuracy: 0.7621\n",
            "Epoch 12: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/36/assets\n",
            "\n",
            "\n",
            " 18%|█▊        | 37/200 [1:25:30<4:32:42, 100.38s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.9601 - accuracy: 0.5960\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 25ms/step - loss: 1.9557 - accuracy: 0.5974 - val_loss: 1.7967 - val_accuracy: 0.4450\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.9248 - accuracy: 0.9339\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.9226 - accuracy: 0.9346 - val_loss: 1.6655 - val_accuracy: 0.4348\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6390 - accuracy: 0.9773\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.6374 - accuracy: 0.9776 - val_loss: 0.7769 - val_accuracy: 0.9642\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5042 - accuracy: 0.9942\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.5047 - accuracy: 0.9936 - val_loss: 0.4625 - val_accuracy: 0.9872\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4202 - accuracy: 0.9955\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.4201 - accuracy: 0.9955 - val_loss: 0.3836 - val_accuracy: 0.9923\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3584 - accuracy: 0.9942\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.3580 - accuracy: 0.9942 - val_loss: 0.3352 - val_accuracy: 0.9923\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3123 - accuracy: 0.9981\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.3122 - accuracy: 0.9981 - val_loss: 0.2926 - val_accuracy: 0.9949\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2744 - accuracy: 0.9987\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.2742 - accuracy: 0.9987 - val_loss: 0.2640 - val_accuracy: 0.9923\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2478 - accuracy: 0.9987\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2478 - accuracy: 0.9987 - val_loss: 0.2348 - val_accuracy: 0.9923\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2249 - accuracy: 0.9981\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2246 - accuracy: 0.9981 - val_loss: 0.2334 - val_accuracy: 0.9923\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2057 - accuracy: 1.0000\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2055 - accuracy: 1.0000 - val_loss: 0.1998 - val_accuracy: 0.9949\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1901 - accuracy: 0.9994\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1901 - accuracy: 0.9994 - val_loss: 0.1905 - val_accuracy: 0.9949\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1771 - accuracy: 0.9994\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1770 - accuracy: 0.9994 - val_loss: 0.1820 - val_accuracy: 0.9923\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1711 - accuracy: 1.0000\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1709 - accuracy: 1.0000 - val_loss: 0.1766 - val_accuracy: 0.9949\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1606 - accuracy: 1.0000\n",
            "Epoch 15: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1605 - accuracy: 1.0000 - val_loss: 0.1656 - val_accuracy: 0.9949\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1569 - accuracy: 0.9994\n",
            "Epoch 16: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1569 - accuracy: 0.9994 - val_loss: 0.1609 - val_accuracy: 0.9949\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1483 - accuracy: 1.0000\n",
            "Epoch 17: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1482 - accuracy: 1.0000 - val_loss: 0.1563 - val_accuracy: 0.9923\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1427 - accuracy: 0.9994\n",
            "Epoch 18: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1426 - accuracy: 0.9994 - val_loss: 0.1564 - val_accuracy: 0.9923\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1401 - accuracy: 1.0000\n",
            "Epoch 19: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1401 - accuracy: 1.0000 - val_loss: 0.1532 - val_accuracy: 0.9949\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1331 - accuracy: 1.0000\n",
            "Epoch 20: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1330 - accuracy: 1.0000 - val_loss: 0.1392 - val_accuracy: 0.9949\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1281 - accuracy: 1.0000\n",
            "Epoch 21: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1280 - accuracy: 1.0000 - val_loss: 0.1407 - val_accuracy: 0.9923\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1228 - accuracy: 1.0000\n",
            "Epoch 22: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1227 - accuracy: 1.0000 - val_loss: 0.1321 - val_accuracy: 0.9949\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1238 - accuracy: 1.0000\n",
            "Epoch 23: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1239 - accuracy: 1.0000 - val_loss: 0.1398 - val_accuracy: 0.9898\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1182 - accuracy: 1.0000\n",
            "Epoch 24: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1182 - accuracy: 1.0000 - val_loss: 0.1271 - val_accuracy: 0.9949\n",
            "Epoch 25/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1146 - accuracy: 1.0000\n",
            "Epoch 25: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1146 - accuracy: 1.0000 - val_loss: 0.1372 - val_accuracy: 0.9923\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1107 - accuracy: 1.0000\n",
            "Epoch 26: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1107 - accuracy: 1.0000 - val_loss: 0.1257 - val_accuracy: 0.9923\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1102 - accuracy: 1.0000\n",
            "Epoch 27: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1102 - accuracy: 1.0000 - val_loss: 0.1257 - val_accuracy: 0.9949\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1059 - accuracy: 1.0000\n",
            "Epoch 28: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1058 - accuracy: 1.0000 - val_loss: 0.1253 - val_accuracy: 0.9923\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1038 - accuracy: 1.0000\n",
            "Epoch 29: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1037 - accuracy: 1.0000 - val_loss: 0.1220 - val_accuracy: 0.9923\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1008 - accuracy: 1.0000\n",
            "Epoch 30: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1008 - accuracy: 1.0000 - val_loss: 0.1185 - val_accuracy: 0.9949\n",
            "Epoch 31/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0982 - accuracy: 1.0000\n",
            "Epoch 31: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0982 - accuracy: 1.0000 - val_loss: 0.1167 - val_accuracy: 0.9923\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0967 - accuracy: 1.0000\n",
            "Epoch 32: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0966 - accuracy: 1.0000 - val_loss: 0.1131 - val_accuracy: 0.9923\n",
            "Epoch 33/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0934 - accuracy: 1.0000\n",
            "Epoch 33: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0934 - accuracy: 1.0000 - val_loss: 0.1110 - val_accuracy: 0.9923\n",
            "Epoch 34/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0925 - accuracy: 1.0000\n",
            "Epoch 34: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0924 - accuracy: 1.0000 - val_loss: 0.1090 - val_accuracy: 0.9949\n",
            "Epoch 35/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0899 - accuracy: 1.0000\n",
            "Epoch 35: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0899 - accuracy: 1.0000 - val_loss: 0.1056 - val_accuracy: 0.9923\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0866 - accuracy: 1.0000\n",
            "Epoch 36: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0866 - accuracy: 1.0000 - val_loss: 0.1028 - val_accuracy: 0.9923\n",
            "Epoch 37/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0853 - accuracy: 1.0000\n",
            "Epoch 37: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0853 - accuracy: 1.0000 - val_loss: 0.1211 - val_accuracy: 0.9923\n",
            "Epoch 38/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0834 - accuracy: 1.0000\n",
            "Epoch 38: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0833 - accuracy: 1.0000 - val_loss: 0.0946 - val_accuracy: 0.9949\n",
            "Epoch 39/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0802 - accuracy: 1.0000\n",
            "Epoch 39: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0802 - accuracy: 1.0000 - val_loss: 0.0971 - val_accuracy: 0.9923\n",
            "Epoch 40/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0848 - accuracy: 0.9987\n",
            "Epoch 40: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0849 - accuracy: 0.9987 - val_loss: 0.1349 - val_accuracy: 0.9872\n",
            "Epoch 41/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0823 - accuracy: 1.0000\n",
            "Epoch 41: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0823 - accuracy: 1.0000 - val_loss: 0.0911 - val_accuracy: 0.9949\n",
            "Epoch 42/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0754 - accuracy: 1.0000\n",
            "Epoch 42: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0753 - accuracy: 1.0000 - val_loss: 0.0923 - val_accuracy: 0.9923\n",
            "Epoch 43/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0726 - accuracy: 1.0000\n",
            "Epoch 43: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0726 - accuracy: 1.0000 - val_loss: 0.0878 - val_accuracy: 0.9923\n",
            "Epoch 44/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0744 - accuracy: 1.0000\n",
            "Epoch 44: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0744 - accuracy: 1.0000 - val_loss: 0.0837 - val_accuracy: 0.9974\n",
            "Epoch 45/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0690 - accuracy: 1.0000\n",
            "Epoch 45: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0690 - accuracy: 1.0000 - val_loss: 0.0799 - val_accuracy: 0.9974\n",
            "Epoch 46/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0657 - accuracy: 1.0000\n",
            "Epoch 46: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0657 - accuracy: 1.0000 - val_loss: 0.0789 - val_accuracy: 0.9974\n",
            "Epoch 47/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0631 - accuracy: 1.0000\n",
            "Epoch 47: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0631 - accuracy: 1.0000 - val_loss: 0.0796 - val_accuracy: 0.9974\n",
            "Epoch 48/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0609 - accuracy: 1.0000\n",
            "Epoch 48: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0609 - accuracy: 1.0000 - val_loss: 0.0764 - val_accuracy: 0.9949\n",
            "Epoch 49/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0584 - accuracy: 1.0000\n",
            "Epoch 49: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0584 - accuracy: 1.0000 - val_loss: 0.0725 - val_accuracy: 0.9949\n",
            "Epoch 50/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0557 - accuracy: 1.0000\n",
            "Epoch 50: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0557 - accuracy: 1.0000 - val_loss: 0.0696 - val_accuracy: 0.9974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/37/assets\n",
            "\n",
            "\n",
            " 19%|█▉        | 38/200 [1:29:15<6:11:49, 137.71s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "188/195 [===========================>..] - ETA: 0s - loss: 1.1163 - accuracy: 0.6995\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 11ms/step - loss: 1.0955 - accuracy: 0.7077 - val_loss: 1.7293 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.3691 - accuracy: 0.9601\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.3677 - accuracy: 0.9603 - val_loss: 1.4996 - val_accuracy: 0.3990\n",
            "Epoch 3/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2200 - accuracy: 0.9859\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.2200 - accuracy: 0.9859 - val_loss: 0.9446 - val_accuracy: 0.7596\n",
            "Epoch 4/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1584 - accuracy: 0.9948\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.1585 - accuracy: 0.9949 - val_loss: 0.1808 - val_accuracy: 0.9872\n",
            "Epoch 5/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1205 - accuracy: 0.9994\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.1205 - accuracy: 0.9994 - val_loss: 0.1491 - val_accuracy: 0.9847\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0984 - accuracy: 0.9994\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0987 - accuracy: 0.9994 - val_loss: 0.1272 - val_accuracy: 0.9847\n",
            "Epoch 7/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0916 - accuracy: 0.9994\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0915 - accuracy: 0.9994 - val_loss: 0.1367 - val_accuracy: 0.9821\n",
            "Epoch 8/50\n",
            "188/195 [===========================>..] - ETA: 0s - loss: 0.0801 - accuracy: 1.0000\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.0798 - accuracy: 1.0000 - val_loss: 0.1021 - val_accuracy: 0.9949\n",
            "Epoch 9/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0762 - accuracy: 1.0000\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0762 - accuracy: 1.0000 - val_loss: 0.1048 - val_accuracy: 0.9923\n",
            "Epoch 10/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0693 - accuracy: 1.0000\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0693 - accuracy: 1.0000 - val_loss: 0.1213 - val_accuracy: 0.9821\n",
            "Epoch 11/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1986 - accuracy: 0.9665\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.1992 - accuracy: 0.9660 - val_loss: 0.5300 - val_accuracy: 0.8798\n",
            "Epoch 12/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 0.1334 - accuracy: 0.9921\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.1323 - accuracy: 0.9923 - val_loss: 0.2743 - val_accuracy: 0.9335\n",
            "Epoch 13/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 0.1269 - accuracy: 0.9907\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.1268 - accuracy: 0.9904 - val_loss: 0.1473 - val_accuracy: 0.9872\n",
            "Epoch 13: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/38/assets\n",
            "\n",
            "\n",
            " 20%|█▉        | 39/200 [1:29:43<4:40:58, 104.71s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.1208 - accuracy: 0.6658\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 16ms/step - loss: 1.1168 - accuracy: 0.6667 - val_loss: 2.6101 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3612 - accuracy: 0.9277\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.3589 - accuracy: 0.9288 - val_loss: 2.7815 - val_accuracy: 0.4373\n",
            "Epoch 3/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1917 - accuracy: 0.9768\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1914 - accuracy: 0.9769 - val_loss: 0.8893 - val_accuracy: 0.7340\n",
            "Epoch 4/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1246 - accuracy: 0.9889\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1241 - accuracy: 0.9891 - val_loss: 0.2019 - val_accuracy: 0.9668\n",
            "Epoch 5/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1052 - accuracy: 0.9967\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1048 - accuracy: 0.9968 - val_loss: 0.1319 - val_accuracy: 0.9770\n",
            "Epoch 6/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0887 - accuracy: 0.9955\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0885 - accuracy: 0.9955 - val_loss: 0.1634 - val_accuracy: 0.9693\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2462 - accuracy: 0.9585\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.2457 - accuracy: 0.9590 - val_loss: 0.6913 - val_accuracy: 0.8235\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0886 - accuracy: 0.9961\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0886 - accuracy: 0.9962 - val_loss: 0.2407 - val_accuracy: 0.9335\n",
            "Epoch 9/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0973 - accuracy: 0.9910\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0980 - accuracy: 0.9910 - val_loss: 0.2990 - val_accuracy: 0.9412\n",
            "Epoch 10/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0951 - accuracy: 0.9942\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0951 - accuracy: 0.9942 - val_loss: 0.1074 - val_accuracy: 0.9847\n",
            "Epoch 11/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0657 - accuracy: 0.9980\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0663 - accuracy: 0.9974 - val_loss: 0.2875 - val_accuracy: 0.9437\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1045 - accuracy: 0.9851\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.1040 - accuracy: 0.9853 - val_loss: 0.1934 - val_accuracy: 0.9642\n",
            "Epoch 13/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0648 - accuracy: 0.9980\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0645 - accuracy: 0.9981 - val_loss: 0.0904 - val_accuracy: 0.9898\n",
            "Epoch 14/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1344 - accuracy: 0.9827\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1344 - accuracy: 0.9827 - val_loss: 0.1597 - val_accuracy: 0.9821\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1140 - accuracy: 0.9825\n",
            "Epoch 15: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.1136 - accuracy: 0.9827 - val_loss: 0.1661 - val_accuracy: 0.9642\n",
            "Epoch 16/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0669 - accuracy: 0.9961\n",
            "Epoch 16: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0672 - accuracy: 0.9962 - val_loss: 0.1245 - val_accuracy: 0.9795\n",
            "Epoch 17/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0532 - accuracy: 0.9994\n",
            "Epoch 17: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0532 - accuracy: 0.9994 - val_loss: 0.0801 - val_accuracy: 0.9872\n",
            "Epoch 18/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0453 - accuracy: 1.0000\n",
            "Epoch 18: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0452 - accuracy: 1.0000 - val_loss: 0.0699 - val_accuracy: 0.9872\n",
            "Epoch 19/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0399 - accuracy: 1.0000\n",
            "Epoch 19: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0399 - accuracy: 1.0000 - val_loss: 0.0648 - val_accuracy: 0.9923\n",
            "Epoch 20/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0389 - accuracy: 1.0000\n",
            "Epoch 20: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0389 - accuracy: 1.0000 - val_loss: 0.0648 - val_accuracy: 0.9898\n",
            "Epoch 21/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0345 - accuracy: 1.0000\n",
            "Epoch 21: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0345 - accuracy: 1.0000 - val_loss: 0.0780 - val_accuracy: 0.9872\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0318 - accuracy: 1.0000\n",
            "Epoch 22: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0318 - accuracy: 1.0000 - val_loss: 0.0759 - val_accuracy: 0.9847\n",
            "Epoch 23/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0326 - accuracy: 1.0000\n",
            "Epoch 23: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0326 - accuracy: 1.0000 - val_loss: 0.0640 - val_accuracy: 0.9949\n",
            "Epoch 24/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0297 - accuracy: 1.0000\n",
            "Epoch 24: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 0.0541 - val_accuracy: 0.9949\n",
            "Epoch 25/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0659 - accuracy: 0.9922\n",
            "Epoch 25: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0709 - accuracy: 0.9910 - val_loss: 0.8993 - val_accuracy: 0.8849\n",
            "Epoch 26/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1874 - accuracy: 0.9712\n",
            "Epoch 26: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1874 - accuracy: 0.9712 - val_loss: 4.1613 - val_accuracy: 0.6777\n",
            "Epoch 27/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1076 - accuracy: 0.9845\n",
            "Epoch 27: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1073 - accuracy: 0.9846 - val_loss: 0.1796 - val_accuracy: 0.9719\n",
            "Epoch 28/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0558 - accuracy: 0.9981\n",
            "Epoch 28: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0558 - accuracy: 0.9981 - val_loss: 0.0929 - val_accuracy: 0.9898\n",
            "Epoch 29/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0441 - accuracy: 1.0000\n",
            "Epoch 29: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0441 - accuracy: 1.0000 - val_loss: 0.0820 - val_accuracy: 0.9923\n",
            "Epoch 29: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/39/assets\n",
            "\n",
            "\n",
            " 20%|██        | 40/200 [1:31:05<4:21:16, 97.98s/it] \u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.8151 - accuracy: 0.2564\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 15ms/step - loss: 1.8151 - accuracy: 0.2564 - val_loss: 1.7041 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.6912 - accuracy: 0.2736\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 1.6915 - accuracy: 0.2744 - val_loss: 1.6750 - val_accuracy: 0.2864\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6732 - accuracy: 0.2811\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 1.6742 - accuracy: 0.2808 - val_loss: 1.6552 - val_accuracy: 0.2864\n",
            "Epoch 4/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.6590 - accuracy: 0.2853\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 1.6590 - accuracy: 0.2846 - val_loss: 1.6461 - val_accuracy: 0.2864\n",
            "Epoch 5/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.6535 - accuracy: 0.2795\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 1.6500 - accuracy: 0.2808 - val_loss: 1.6416 - val_accuracy: 0.2864\n",
            "Epoch 6/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.6446 - accuracy: 0.2742\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 1.6464 - accuracy: 0.2744 - val_loss: 1.6346 - val_accuracy: 0.2864\n",
            "Epoch 7/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.6366 - accuracy: 0.2729\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 1.6352 - accuracy: 0.2756 - val_loss: 1.6306 - val_accuracy: 0.2864\n",
            "Epoch 8/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.6313 - accuracy: 0.2788\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 1.6319 - accuracy: 0.2788 - val_loss: 1.6286 - val_accuracy: 0.2864\n",
            "Epoch 9/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.6268 - accuracy: 0.2775\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 1.6304 - accuracy: 0.2750 - val_loss: 1.6282 - val_accuracy: 0.2864\n",
            "Epoch 10/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.6278 - accuracy: 0.2749\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 1.6299 - accuracy: 0.2763 - val_loss: 1.6263 - val_accuracy: 0.2864\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6295 - accuracy: 0.2733\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 1.6292 - accuracy: 0.2731 - val_loss: 1.6259 - val_accuracy: 0.2864\n",
            "Epoch 12/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.6282 - accuracy: 0.2742\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 1.6282 - accuracy: 0.2750 - val_loss: 1.6249 - val_accuracy: 0.2864\n",
            "Epoch 13/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6269 - accuracy: 0.2867\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 1.6276 - accuracy: 0.2859 - val_loss: 1.6249 - val_accuracy: 0.2864\n",
            "Epoch 14/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6270 - accuracy: 0.2854\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 1.6263 - accuracy: 0.2859 - val_loss: 1.6245 - val_accuracy: 0.2864\n",
            "Epoch 15/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.6267 - accuracy: 0.2795\n",
            "Epoch 15: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 1.6269 - accuracy: 0.2776 - val_loss: 1.6241 - val_accuracy: 0.2864\n",
            "Epoch 16/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6267 - accuracy: 0.2859\n",
            "Epoch 16: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 1.6267 - accuracy: 0.2859 - val_loss: 1.6241 - val_accuracy: 0.2864\n",
            "Epoch 17/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.6266 - accuracy: 0.2840\n",
            "Epoch 17: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 1.6272 - accuracy: 0.2821 - val_loss: 1.6236 - val_accuracy: 0.2864\n",
            "Epoch 18/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6258 - accuracy: 0.2872\n",
            "Epoch 18: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 1.6258 - accuracy: 0.2872 - val_loss: 1.6253 - val_accuracy: 0.2634\n",
            "Epoch 19/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.6284 - accuracy: 0.2788\n",
            "Epoch 19: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 1.6258 - accuracy: 0.2808 - val_loss: 1.6241 - val_accuracy: 0.2864\n",
            "Epoch 20/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.6264 - accuracy: 0.2755\n",
            "Epoch 20: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 1.6264 - accuracy: 0.2763 - val_loss: 1.6241 - val_accuracy: 0.2864\n",
            "Epoch 21/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.6243 - accuracy: 0.2860\n",
            "Epoch 21: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 1.6259 - accuracy: 0.2846 - val_loss: 1.6243 - val_accuracy: 0.2864\n",
            "Epoch 22/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.6265 - accuracy: 0.2840\n",
            "Epoch 22: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 1.6260 - accuracy: 0.2821 - val_loss: 1.6242 - val_accuracy: 0.2634\n",
            "Epoch 22: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/40/assets\n",
            "\n",
            "\n",
            " 20%|██        | 41/200 [1:32:05<3:49:32, 86.62s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 3.0334 - accuracy: 0.2737\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 25ms/step - loss: 3.0334 - accuracy: 0.2737 - val_loss: 1.8644 - val_accuracy: 0.2992\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 2.4143 - accuracy: 0.3912\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 2.4113 - accuracy: 0.3904 - val_loss: 1.9106 - val_accuracy: 0.3811\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 2.1396 - accuracy: 0.5091\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 2.1371 - accuracy: 0.5096 - val_loss: 1.8539 - val_accuracy: 0.5550\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.9402 - accuracy: 0.6082\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.9380 - accuracy: 0.6090 - val_loss: 1.7112 - val_accuracy: 0.6777\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.7697 - accuracy: 0.6690\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 1.7686 - accuracy: 0.6692 - val_loss: 1.5787 - val_accuracy: 0.7340\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6061 - accuracy: 0.7383\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6055 - accuracy: 0.7385 - val_loss: 1.4378 - val_accuracy: 0.7928\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.4648 - accuracy: 0.8005\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.4628 - accuracy: 0.8019 - val_loss: 1.3062 - val_accuracy: 0.8440\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.3295 - accuracy: 0.8452\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.3311 - accuracy: 0.8455 - val_loss: 1.1894 - val_accuracy: 0.8951\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.2366 - accuracy: 0.8672\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 1.2360 - accuracy: 0.8679 - val_loss: 1.0911 - val_accuracy: 0.9207\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.1498 - accuracy: 0.8983\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.1488 - accuracy: 0.8981 - val_loss: 1.0257 - val_accuracy: 0.9386\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.0655 - accuracy: 0.9255\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.0649 - accuracy: 0.9263 - val_loss: 0.9609 - val_accuracy: 0.9514\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.0119 - accuracy: 0.9320\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.0116 - accuracy: 0.9321 - val_loss: 0.9068 - val_accuracy: 0.9488\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.9533 - accuracy: 0.9469\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.9518 - accuracy: 0.9474 - val_loss: 0.8503 - val_accuracy: 0.9616\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.9028 - accuracy: 0.9540\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.9036 - accuracy: 0.9538 - val_loss: 0.8173 - val_accuracy: 0.9616\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8648 - accuracy: 0.9560\n",
            "Epoch 15: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.8671 - accuracy: 0.9551 - val_loss: 0.7934 - val_accuracy: 0.9591\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8362 - accuracy: 0.9585\n",
            "Epoch 16: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.8369 - accuracy: 0.9590 - val_loss: 0.7559 - val_accuracy: 0.9668\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8075 - accuracy: 0.9631\n",
            "Epoch 17: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.8063 - accuracy: 0.9635 - val_loss: 0.7235 - val_accuracy: 0.9744\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7725 - accuracy: 0.9670\n",
            "Epoch 18: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.7714 - accuracy: 0.9673 - val_loss: 0.7093 - val_accuracy: 0.9770\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7452 - accuracy: 0.9696\n",
            "Epoch 19: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.7437 - accuracy: 0.9699 - val_loss: 0.6778 - val_accuracy: 0.9821\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7263 - accuracy: 0.9734\n",
            "Epoch 20: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.7254 - accuracy: 0.9737 - val_loss: 0.6660 - val_accuracy: 0.9719\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6996 - accuracy: 0.9728\n",
            "Epoch 21: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.6982 - accuracy: 0.9731 - val_loss: 0.6373 - val_accuracy: 0.9847\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6743 - accuracy: 0.9793\n",
            "Epoch 22: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.6746 - accuracy: 0.9788 - val_loss: 0.6191 - val_accuracy: 0.9821\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6533 - accuracy: 0.9825\n",
            "Epoch 23: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.6535 - accuracy: 0.9821 - val_loss: 0.5989 - val_accuracy: 0.9821\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6394 - accuracy: 0.9773\n",
            "Epoch 24: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.6394 - accuracy: 0.9776 - val_loss: 0.5802 - val_accuracy: 0.9821\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6178 - accuracy: 0.9832\n",
            "Epoch 25: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.6173 - accuracy: 0.9833 - val_loss: 0.5698 - val_accuracy: 0.9821\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6009 - accuracy: 0.9825\n",
            "Epoch 26: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.6004 - accuracy: 0.9827 - val_loss: 0.5606 - val_accuracy: 0.9821\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5810 - accuracy: 0.9845\n",
            "Epoch 27: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.5806 - accuracy: 0.9846 - val_loss: 0.5416 - val_accuracy: 0.9847\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5729 - accuracy: 0.9870\n",
            "Epoch 28: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.5718 - accuracy: 0.9872 - val_loss: 0.5238 - val_accuracy: 0.9821\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5513 - accuracy: 0.9883\n",
            "Epoch 29: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.5507 - accuracy: 0.9885 - val_loss: 0.5204 - val_accuracy: 0.9847\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5378 - accuracy: 0.9903\n",
            "Epoch 30: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.5380 - accuracy: 0.9904 - val_loss: 0.5058 - val_accuracy: 0.9847\n",
            "Epoch 31/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5343 - accuracy: 0.9864\n",
            "Epoch 31: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.5345 - accuracy: 0.9865 - val_loss: 0.4922 - val_accuracy: 0.9847\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5163 - accuracy: 0.9890\n",
            "Epoch 32: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.5162 - accuracy: 0.9891 - val_loss: 0.4785 - val_accuracy: 0.9847\n",
            "Epoch 33/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5039 - accuracy: 0.9922\n",
            "Epoch 33: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.5039 - accuracy: 0.9923 - val_loss: 0.4701 - val_accuracy: 0.9847\n",
            "Epoch 34/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4906 - accuracy: 0.9870\n",
            "Epoch 34: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.4900 - accuracy: 0.9872 - val_loss: 0.4655 - val_accuracy: 0.9821\n",
            "Epoch 35/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4767 - accuracy: 0.9929\n",
            "Epoch 35: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.4779 - accuracy: 0.9929 - val_loss: 0.4488 - val_accuracy: 0.9847\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4705 - accuracy: 0.9922\n",
            "Epoch 36: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.4720 - accuracy: 0.9923 - val_loss: 0.4394 - val_accuracy: 0.9847\n",
            "Epoch 37/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4550 - accuracy: 0.9968\n",
            "Epoch 37: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.4554 - accuracy: 0.9968 - val_loss: 0.4393 - val_accuracy: 0.9898\n",
            "Epoch 38/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4491 - accuracy: 0.9929\n",
            "Epoch 38: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.4487 - accuracy: 0.9929 - val_loss: 0.4213 - val_accuracy: 0.9872\n",
            "Epoch 39/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4356 - accuracy: 0.9974\n",
            "Epoch 39: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.4359 - accuracy: 0.9974 - val_loss: 0.4179 - val_accuracy: 0.9872\n",
            "Epoch 40/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4262 - accuracy: 0.9942\n",
            "Epoch 40: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.4272 - accuracy: 0.9942 - val_loss: 0.4178 - val_accuracy: 0.9872\n",
            "Epoch 41/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4216 - accuracy: 0.9955\n",
            "Epoch 41: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.4211 - accuracy: 0.9955 - val_loss: 0.3925 - val_accuracy: 0.9923\n",
            "Epoch 42/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4105 - accuracy: 0.9935\n",
            "Epoch 42: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.4106 - accuracy: 0.9936 - val_loss: 0.3886 - val_accuracy: 0.9847\n",
            "Epoch 43/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4026 - accuracy: 0.9961\n",
            "Epoch 43: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.4019 - accuracy: 0.9962 - val_loss: 0.3790 - val_accuracy: 0.9898\n",
            "Epoch 44/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3932 - accuracy: 0.9974\n",
            "Epoch 44: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.3934 - accuracy: 0.9974 - val_loss: 0.3730 - val_accuracy: 0.9898\n",
            "Epoch 45/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3860 - accuracy: 0.9961\n",
            "Epoch 45: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.3855 - accuracy: 0.9962 - val_loss: 0.3748 - val_accuracy: 0.9898\n",
            "Epoch 46/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3795 - accuracy: 0.9961\n",
            "Epoch 46: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.3788 - accuracy: 0.9962 - val_loss: 0.3592 - val_accuracy: 0.9898\n",
            "Epoch 47/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3679 - accuracy: 0.9968\n",
            "Epoch 47: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.3685 - accuracy: 0.9968 - val_loss: 0.3507 - val_accuracy: 0.9898\n",
            "Epoch 48/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3657 - accuracy: 0.9955\n",
            "Epoch 48: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.3659 - accuracy: 0.9955 - val_loss: 0.3493 - val_accuracy: 0.9872\n",
            "Epoch 49/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3581 - accuracy: 0.9948\n",
            "Epoch 49: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.3585 - accuracy: 0.9949 - val_loss: 0.3437 - val_accuracy: 0.9898\n",
            "Epoch 50/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3512 - accuracy: 0.9942\n",
            "Epoch 50: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.3510 - accuracy: 0.9942 - val_loss: 0.3381 - val_accuracy: 0.9898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/41/assets\n",
            "\n",
            "\n",
            " 21%|██        | 42/200 [1:36:33<6:10:49, 140.82s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.7468 - accuracy: 0.7262\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 7s 25ms/step - loss: 1.7426 - accuracy: 0.7276 - val_loss: 1.9914 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8939 - accuracy: 0.9521\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.8936 - accuracy: 0.9526 - val_loss: 2.2782 - val_accuracy: 0.3223\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6653 - accuracy: 0.9903\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.6650 - accuracy: 0.9904 - val_loss: 1.4688 - val_accuracy: 0.6419\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5536 - accuracy: 0.9929\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.5539 - accuracy: 0.9923 - val_loss: 0.5443 - val_accuracy: 0.9719\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4773 - accuracy: 0.9974\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.4772 - accuracy: 0.9974 - val_loss: 0.4946 - val_accuracy: 0.9770\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4205 - accuracy: 0.9968\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.4203 - accuracy: 0.9968 - val_loss: 0.4172 - val_accuracy: 0.9923\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3779 - accuracy: 0.9981\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.3777 - accuracy: 0.9981 - val_loss: 0.3818 - val_accuracy: 0.9949\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3473 - accuracy: 0.9974\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.3468 - accuracy: 0.9974 - val_loss: 0.3619 - val_accuracy: 0.9847\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3096 - accuracy: 1.0000\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.3098 - accuracy: 1.0000 - val_loss: 0.3290 - val_accuracy: 0.9872\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2895 - accuracy: 0.9994\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.2893 - accuracy: 0.9994 - val_loss: 0.2997 - val_accuracy: 0.9898\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2712 - accuracy: 0.9994\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.2711 - accuracy: 0.9994 - val_loss: 0.2814 - val_accuracy: 0.9898\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2524 - accuracy: 0.9994\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.2523 - accuracy: 0.9994 - val_loss: 0.2697 - val_accuracy: 0.9898\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2418 - accuracy: 1.0000\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.2416 - accuracy: 1.0000 - val_loss: 0.2510 - val_accuracy: 0.9923\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2288 - accuracy: 0.9994\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.2288 - accuracy: 0.9994 - val_loss: 0.2413 - val_accuracy: 0.9872\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2229 - accuracy: 0.9994\n",
            "Epoch 15: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.2227 - accuracy: 0.9994 - val_loss: 0.2397 - val_accuracy: 0.9923\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2121 - accuracy: 1.0000\n",
            "Epoch 16: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.2121 - accuracy: 1.0000 - val_loss: 0.2313 - val_accuracy: 0.9923\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2042 - accuracy: 1.0000\n",
            "Epoch 17: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.2042 - accuracy: 1.0000 - val_loss: 0.2256 - val_accuracy: 0.9923\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2046 - accuracy: 0.9987\n",
            "Epoch 18: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.2045 - accuracy: 0.9987 - val_loss: 0.2209 - val_accuracy: 0.9974\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1929 - accuracy: 1.0000\n",
            "Epoch 19: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1929 - accuracy: 1.0000 - val_loss: 0.2176 - val_accuracy: 0.9898\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1878 - accuracy: 1.0000\n",
            "Epoch 20: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1878 - accuracy: 1.0000 - val_loss: 0.2079 - val_accuracy: 0.9898\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1828 - accuracy: 1.0000\n",
            "Epoch 21: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1828 - accuracy: 1.0000 - val_loss: 0.2039 - val_accuracy: 0.9898\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1798 - accuracy: 1.0000\n",
            "Epoch 22: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1797 - accuracy: 1.0000 - val_loss: 0.1970 - val_accuracy: 0.9923\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1749 - accuracy: 1.0000\n",
            "Epoch 23: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1749 - accuracy: 1.0000 - val_loss: 0.1967 - val_accuracy: 0.9923\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1723 - accuracy: 1.0000\n",
            "Epoch 24: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1725 - accuracy: 1.0000 - val_loss: 0.1975 - val_accuracy: 0.9898\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1682 - accuracy: 1.0000\n",
            "Epoch 25: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1681 - accuracy: 1.0000 - val_loss: 0.1876 - val_accuracy: 0.9923\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1632 - accuracy: 1.0000\n",
            "Epoch 26: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1635 - accuracy: 1.0000 - val_loss: 0.1874 - val_accuracy: 0.9898\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1596 - accuracy: 1.0000\n",
            "Epoch 27: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1595 - accuracy: 1.0000 - val_loss: 0.1914 - val_accuracy: 0.9923\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1573 - accuracy: 1.0000\n",
            "Epoch 28: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1573 - accuracy: 1.0000 - val_loss: 0.1858 - val_accuracy: 0.9898\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1744 - accuracy: 0.9968\n",
            "Epoch 29: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1743 - accuracy: 0.9968 - val_loss: 0.1939 - val_accuracy: 0.9898\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1609 - accuracy: 1.0000\n",
            "Epoch 30: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1608 - accuracy: 1.0000 - val_loss: 0.1820 - val_accuracy: 0.9923\n",
            "Epoch 31/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1512 - accuracy: 1.0000\n",
            "Epoch 31: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1512 - accuracy: 1.0000 - val_loss: 0.1867 - val_accuracy: 0.9872\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1471 - accuracy: 1.0000\n",
            "Epoch 32: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1470 - accuracy: 1.0000 - val_loss: 0.1766 - val_accuracy: 0.9898\n",
            "Epoch 33/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1433 - accuracy: 1.0000\n",
            "Epoch 33: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1433 - accuracy: 1.0000 - val_loss: 0.1689 - val_accuracy: 0.9923\n",
            "Epoch 34/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1404 - accuracy: 1.0000\n",
            "Epoch 34: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1404 - accuracy: 1.0000 - val_loss: 0.1699 - val_accuracy: 0.9923\n",
            "Epoch 35/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1368 - accuracy: 1.0000\n",
            "Epoch 35: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1368 - accuracy: 1.0000 - val_loss: 0.1624 - val_accuracy: 0.9923\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1334 - accuracy: 1.0000\n",
            "Epoch 36: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1334 - accuracy: 1.0000 - val_loss: 0.1688 - val_accuracy: 0.9923\n",
            "Epoch 37/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1321 - accuracy: 1.0000\n",
            "Epoch 37: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1321 - accuracy: 1.0000 - val_loss: 0.1615 - val_accuracy: 0.9923\n",
            "Epoch 38/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1274 - accuracy: 1.0000\n",
            "Epoch 38: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1273 - accuracy: 1.0000 - val_loss: 0.1541 - val_accuracy: 0.9949\n",
            "Epoch 39/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1232 - accuracy: 1.0000\n",
            "Epoch 39: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1231 - accuracy: 1.0000 - val_loss: 0.1507 - val_accuracy: 0.9923\n",
            "Epoch 40/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1196 - accuracy: 1.0000\n",
            "Epoch 40: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1196 - accuracy: 1.0000 - val_loss: 0.1500 - val_accuracy: 0.9923\n",
            "Epoch 41/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1160 - accuracy: 1.0000\n",
            "Epoch 41: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1160 - accuracy: 1.0000 - val_loss: 0.1449 - val_accuracy: 0.9949\n",
            "Epoch 42/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1115 - accuracy: 1.0000\n",
            "Epoch 42: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1115 - accuracy: 1.0000 - val_loss: 0.1403 - val_accuracy: 0.9949\n",
            "Epoch 43/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1075 - accuracy: 1.0000\n",
            "Epoch 43: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1075 - accuracy: 1.0000 - val_loss: 0.1420 - val_accuracy: 0.9923\n",
            "Epoch 44/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1030 - accuracy: 1.0000\n",
            "Epoch 44: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1030 - accuracy: 1.0000 - val_loss: 0.1328 - val_accuracy: 0.9923\n",
            "Epoch 45/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0989 - accuracy: 1.0000\n",
            "Epoch 45: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0989 - accuracy: 1.0000 - val_loss: 0.1319 - val_accuracy: 0.9923\n",
            "Epoch 46/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0942 - accuracy: 1.0000\n",
            "Epoch 46: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0942 - accuracy: 1.0000 - val_loss: 0.1283 - val_accuracy: 0.9923\n",
            "Epoch 47/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1793 - accuracy: 0.9806\n",
            "Epoch 47: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1786 - accuracy: 0.9808 - val_loss: 0.1598 - val_accuracy: 0.9821\n",
            "Epoch 48/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1051 - accuracy: 1.0000\n",
            "Epoch 48: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1051 - accuracy: 1.0000 - val_loss: 0.1261 - val_accuracy: 0.9898\n",
            "Epoch 49/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0983 - accuracy: 1.0000\n",
            "Epoch 49: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0983 - accuracy: 1.0000 - val_loss: 0.1203 - val_accuracy: 0.9923\n",
            "Epoch 50/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0949 - accuracy: 1.0000\n",
            "Epoch 50: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0948 - accuracy: 1.0000 - val_loss: 0.1176 - val_accuracy: 0.9898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/42/assets\n",
            "\n",
            "\n",
            " 22%|██▏       | 43/200 [1:41:00<7:47:41, 178.73s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 2.4167 - accuracy: 0.2676\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 20ms/step - loss: 2.4117 - accuracy: 0.2692 - val_loss: 1.8277 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.9426 - accuracy: 0.3827\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 1.9426 - accuracy: 0.3827 - val_loss: 1.8346 - val_accuracy: 0.3504\n",
            "Epoch 3/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.7762 - accuracy: 0.4955\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 1.7757 - accuracy: 0.4962 - val_loss: 1.7622 - val_accuracy: 0.4092\n",
            "Epoch 4/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.6418 - accuracy: 0.5664\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 1.6390 - accuracy: 0.5692 - val_loss: 1.5623 - val_accuracy: 0.5729\n",
            "Epoch 5/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.5050 - accuracy: 0.6456\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 1.5057 - accuracy: 0.6455 - val_loss: 1.4422 - val_accuracy: 0.6419\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.3921 - accuracy: 0.6924\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 1.3932 - accuracy: 0.6917 - val_loss: 1.3249 - val_accuracy: 0.7008\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.2669 - accuracy: 0.7481\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 1.2668 - accuracy: 0.7474 - val_loss: 1.2135 - val_accuracy: 0.7570\n",
            "Epoch 8/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.1667 - accuracy: 0.7865\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 1.1667 - accuracy: 0.7865 - val_loss: 1.1118 - val_accuracy: 0.8031\n",
            "Epoch 9/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.0680 - accuracy: 0.8255\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 1.0644 - accuracy: 0.8269 - val_loss: 1.0176 - val_accuracy: 0.8389\n",
            "Epoch 10/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.9882 - accuracy: 0.8595\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.9875 - accuracy: 0.8596 - val_loss: 0.9419 - val_accuracy: 0.8721\n",
            "Epoch 11/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.9321 - accuracy: 0.8743\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.9307 - accuracy: 0.8750 - val_loss: 0.8756 - val_accuracy: 0.8849\n",
            "Epoch 12/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.8704 - accuracy: 0.8932\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.8702 - accuracy: 0.8929 - val_loss: 0.8232 - val_accuracy: 0.9003\n",
            "Epoch 13/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.8171 - accuracy: 0.9026\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.8171 - accuracy: 0.9026 - val_loss: 0.7739 - val_accuracy: 0.9309\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7576 - accuracy: 0.9294\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.7570 - accuracy: 0.9295 - val_loss: 0.7276 - val_accuracy: 0.9437\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7259 - accuracy: 0.9301\n",
            "Epoch 15: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.7261 - accuracy: 0.9301 - val_loss: 0.6905 - val_accuracy: 0.9514\n",
            "Epoch 16/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.6915 - accuracy: 0.9401\n",
            "Epoch 16: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.6919 - accuracy: 0.9397 - val_loss: 0.6548 - val_accuracy: 0.9642\n",
            "Epoch 17/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.6543 - accuracy: 0.9472\n",
            "Epoch 17: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.6543 - accuracy: 0.9468 - val_loss: 0.6260 - val_accuracy: 0.9642\n",
            "Epoch 18/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.6311 - accuracy: 0.9518\n",
            "Epoch 18: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.6285 - accuracy: 0.9526 - val_loss: 0.5991 - val_accuracy: 0.9642\n",
            "Epoch 19/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5984 - accuracy: 0.9622\n",
            "Epoch 19: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.5984 - accuracy: 0.9622 - val_loss: 0.5788 - val_accuracy: 0.9642\n",
            "Epoch 20/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5723 - accuracy: 0.9654\n",
            "Epoch 20: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.5723 - accuracy: 0.9654 - val_loss: 0.5505 - val_accuracy: 0.9719\n",
            "Epoch 21/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.5544 - accuracy: 0.9652\n",
            "Epoch 21: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.5545 - accuracy: 0.9654 - val_loss: 0.5353 - val_accuracy: 0.9719\n",
            "Epoch 22/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5330 - accuracy: 0.9679\n",
            "Epoch 22: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.5330 - accuracy: 0.9679 - val_loss: 0.5143 - val_accuracy: 0.9744\n",
            "Epoch 23/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5142 - accuracy: 0.9705\n",
            "Epoch 23: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.5142 - accuracy: 0.9705 - val_loss: 0.4955 - val_accuracy: 0.9744\n",
            "Epoch 24/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.4953 - accuracy: 0.9753\n",
            "Epoch 24: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.4959 - accuracy: 0.9756 - val_loss: 0.4801 - val_accuracy: 0.9795\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4771 - accuracy: 0.9780\n",
            "Epoch 25: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.4769 - accuracy: 0.9782 - val_loss: 0.4674 - val_accuracy: 0.9821\n",
            "Epoch 26/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4663 - accuracy: 0.9820\n",
            "Epoch 26: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.4661 - accuracy: 0.9821 - val_loss: 0.4536 - val_accuracy: 0.9821\n",
            "Epoch 27/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.4519 - accuracy: 0.9837\n",
            "Epoch 27: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.4515 - accuracy: 0.9840 - val_loss: 0.4418 - val_accuracy: 0.9847\n",
            "Epoch 28/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4432 - accuracy: 0.9801\n",
            "Epoch 28: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.4432 - accuracy: 0.9801 - val_loss: 0.4304 - val_accuracy: 0.9872\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4214 - accuracy: 0.9864\n",
            "Epoch 29: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.4210 - accuracy: 0.9865 - val_loss: 0.4196 - val_accuracy: 0.9872\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4155 - accuracy: 0.9883\n",
            "Epoch 30: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.4153 - accuracy: 0.9885 - val_loss: 0.4088 - val_accuracy: 0.9872\n",
            "Epoch 31/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4030 - accuracy: 0.9871\n",
            "Epoch 31: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.4027 - accuracy: 0.9872 - val_loss: 0.3994 - val_accuracy: 0.9872\n",
            "Epoch 32/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3934 - accuracy: 0.9910\n",
            "Epoch 32: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.3934 - accuracy: 0.9910 - val_loss: 0.3873 - val_accuracy: 0.9872\n",
            "Epoch 33/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3803 - accuracy: 0.9936\n",
            "Epoch 33: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.3805 - accuracy: 0.9936 - val_loss: 0.3796 - val_accuracy: 0.9872\n",
            "Epoch 34/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3707 - accuracy: 0.9928\n",
            "Epoch 34: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.3708 - accuracy: 0.9929 - val_loss: 0.3722 - val_accuracy: 0.9872\n",
            "Epoch 35/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3586 - accuracy: 0.9961\n",
            "Epoch 35: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.3587 - accuracy: 0.9962 - val_loss: 0.3662 - val_accuracy: 0.9847\n",
            "Epoch 36/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3516 - accuracy: 0.9922\n",
            "Epoch 36: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.3511 - accuracy: 0.9923 - val_loss: 0.3648 - val_accuracy: 0.9847\n",
            "Epoch 37/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3483 - accuracy: 0.9916\n",
            "Epoch 37: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.3480 - accuracy: 0.9917 - val_loss: 0.3568 - val_accuracy: 0.9872\n",
            "Epoch 38/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3413 - accuracy: 0.9935\n",
            "Epoch 38: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.3415 - accuracy: 0.9936 - val_loss: 0.3453 - val_accuracy: 0.9872\n",
            "Epoch 39/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3278 - accuracy: 0.9981\n",
            "Epoch 39: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.3277 - accuracy: 0.9981 - val_loss: 0.3321 - val_accuracy: 0.9898\n",
            "Epoch 40/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3259 - accuracy: 0.9936\n",
            "Epoch 40: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.3259 - accuracy: 0.9936 - val_loss: 0.3291 - val_accuracy: 0.9872\n",
            "Epoch 41/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3124 - accuracy: 0.9968\n",
            "Epoch 41: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.3131 - accuracy: 0.9962 - val_loss: 0.3227 - val_accuracy: 0.9872\n",
            "Epoch 42/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3137 - accuracy: 0.9942\n",
            "Epoch 42: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.3137 - accuracy: 0.9942 - val_loss: 0.3161 - val_accuracy: 0.9872\n",
            "Epoch 43/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3031 - accuracy: 0.9968\n",
            "Epoch 43: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.3029 - accuracy: 0.9968 - val_loss: 0.3127 - val_accuracy: 0.9872\n",
            "Epoch 44/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3005 - accuracy: 0.9955\n",
            "Epoch 44: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.3005 - accuracy: 0.9955 - val_loss: 0.3048 - val_accuracy: 0.9898\n",
            "Epoch 45/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2929 - accuracy: 0.9961\n",
            "Epoch 45: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.2928 - accuracy: 0.9962 - val_loss: 0.3040 - val_accuracy: 0.9872\n",
            "Epoch 46/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2870 - accuracy: 0.9974\n",
            "Epoch 46: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.2869 - accuracy: 0.9974 - val_loss: 0.2936 - val_accuracy: 0.9898\n",
            "Epoch 47/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2823 - accuracy: 0.9955\n",
            "Epoch 47: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.2823 - accuracy: 0.9955 - val_loss: 0.2926 - val_accuracy: 0.9872\n",
            "Epoch 48/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2722 - accuracy: 0.9987\n",
            "Epoch 48: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.2720 - accuracy: 0.9987 - val_loss: 0.2841 - val_accuracy: 0.9872\n",
            "Epoch 49/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2697 - accuracy: 0.9981\n",
            "Epoch 49: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.2697 - accuracy: 0.9981 - val_loss: 0.2841 - val_accuracy: 0.9872\n",
            "Epoch 50/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2651 - accuracy: 0.9987\n",
            "Epoch 50: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.2657 - accuracy: 0.9987 - val_loss: 0.2766 - val_accuracy: 0.9898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/43/assets\n",
            "\n",
            "\n",
            " 22%|██▏       | 44/200 [1:44:00<7:45:39, 179.10s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.1274 - accuracy: 0.7085\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 12ms/step - loss: 1.1226 - accuracy: 0.7103 - val_loss: 1.9511 - val_accuracy: 0.2711\n",
            "Epoch 2/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3717 - accuracy: 0.9551\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.3717 - accuracy: 0.9551 - val_loss: 3.3899 - val_accuracy: 0.2634\n",
            "Epoch 3/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2197 - accuracy: 0.9846\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.2197 - accuracy: 0.9846 - val_loss: 1.8451 - val_accuracy: 0.4476\n",
            "Epoch 4/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.1775 - accuracy: 0.9862\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.1775 - accuracy: 0.9865 - val_loss: 0.2143 - val_accuracy: 0.9719\n",
            "Epoch 5/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1301 - accuracy: 0.9968\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1299 - accuracy: 0.9968 - val_loss: 0.1456 - val_accuracy: 0.9872\n",
            "Epoch 6/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1107 - accuracy: 0.9981\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.1105 - accuracy: 0.9981 - val_loss: 0.1473 - val_accuracy: 0.9847\n",
            "Epoch 7/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0998 - accuracy: 0.9994\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0998 - accuracy: 0.9994 - val_loss: 0.1203 - val_accuracy: 0.9923\n",
            "Epoch 8/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0914 - accuracy: 0.9994\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0914 - accuracy: 0.9994 - val_loss: 0.1182 - val_accuracy: 0.9898\n",
            "Epoch 9/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1479 - accuracy: 0.9792\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.1489 - accuracy: 0.9788 - val_loss: 1.1953 - val_accuracy: 0.7928\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1300 - accuracy: 0.9896\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.1296 - accuracy: 0.9897 - val_loss: 0.2122 - val_accuracy: 0.9514\n",
            "Epoch 11/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0861 - accuracy: 0.9980\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0859 - accuracy: 0.9981 - val_loss: 0.1346 - val_accuracy: 0.9821\n",
            "Epoch 12/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.0769 - accuracy: 0.9987\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0769 - accuracy: 0.9987 - val_loss: 0.1058 - val_accuracy: 0.9898\n",
            "Epoch 13/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.0669 - accuracy: 1.0000\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0673 - accuracy: 0.9994 - val_loss: 0.0827 - val_accuracy: 0.9949\n",
            "Epoch 14/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0651 - accuracy: 0.9993\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0651 - accuracy: 0.9994 - val_loss: 0.1100 - val_accuracy: 0.9923\n",
            "Epoch 15/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.0611 - accuracy: 1.0000\n",
            "Epoch 15: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0609 - accuracy: 1.0000 - val_loss: 0.0857 - val_accuracy: 0.9872\n",
            "Epoch 16/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1310 - accuracy: 0.9805\n",
            "Epoch 16: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.1311 - accuracy: 0.9808 - val_loss: 0.6695 - val_accuracy: 0.8670\n",
            "Epoch 17/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1894 - accuracy: 0.9723\n",
            "Epoch 17: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1889 - accuracy: 0.9724 - val_loss: 0.1980 - val_accuracy: 0.9693\n",
            "Epoch 18/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 0.0804 - accuracy: 0.9987\n",
            "Epoch 18: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0800 - accuracy: 0.9987 - val_loss: 0.1538 - val_accuracy: 0.9795\n",
            "Epoch 18: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/44/assets\n",
            "\n",
            "\n",
            " 22%|██▎       | 45/200 [1:44:38<5:53:25, 136.81s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6011 - accuracy: 0.6405\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 22ms/step - loss: 1.5959 - accuracy: 0.6423 - val_loss: 1.9003 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6519 - accuracy: 0.9605\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.6514 - accuracy: 0.9609 - val_loss: 1.8243 - val_accuracy: 0.4578\n",
            "Epoch 3/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4570 - accuracy: 0.9878\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.4568 - accuracy: 0.9878 - val_loss: 1.1203 - val_accuracy: 0.6445\n",
            "Epoch 4/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3748 - accuracy: 0.9916\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.3751 - accuracy: 0.9917 - val_loss: 0.3433 - val_accuracy: 0.9923\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3182 - accuracy: 0.9974\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.3182 - accuracy: 0.9974 - val_loss: 0.2993 - val_accuracy: 0.9847\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2786 - accuracy: 0.9961\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.2785 - accuracy: 0.9962 - val_loss: 0.2832 - val_accuracy: 0.9923\n",
            "Epoch 7/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2444 - accuracy: 0.9981\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.2444 - accuracy: 0.9981 - val_loss: 0.2439 - val_accuracy: 0.9898\n",
            "Epoch 8/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2168 - accuracy: 0.9994\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.2167 - accuracy: 0.9994 - val_loss: 0.2152 - val_accuracy: 0.9898\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1953 - accuracy: 0.9994\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1953 - accuracy: 0.9994 - val_loss: 0.2384 - val_accuracy: 0.9821\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1788 - accuracy: 0.9981\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1785 - accuracy: 0.9981 - val_loss: 0.1775 - val_accuracy: 0.9923\n",
            "Epoch 11/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1598 - accuracy: 0.9994\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1598 - accuracy: 0.9994 - val_loss: 0.1757 - val_accuracy: 0.9923\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1467 - accuracy: 0.9994\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1466 - accuracy: 0.9994 - val_loss: 0.1772 - val_accuracy: 0.9898\n",
            "Epoch 13/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1408 - accuracy: 0.9987\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1407 - accuracy: 0.9987 - val_loss: 0.1560 - val_accuracy: 0.9872\n",
            "Epoch 14/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1310 - accuracy: 0.9994\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1310 - accuracy: 0.9994 - val_loss: 0.1440 - val_accuracy: 0.9923\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1217 - accuracy: 1.0000\n",
            "Epoch 15: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1217 - accuracy: 1.0000 - val_loss: 0.1437 - val_accuracy: 0.9923\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1169 - accuracy: 0.9994\n",
            "Epoch 16: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1170 - accuracy: 0.9994 - val_loss: 0.1542 - val_accuracy: 0.9898\n",
            "Epoch 17/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1124 - accuracy: 1.0000\n",
            "Epoch 17: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1124 - accuracy: 1.0000 - val_loss: 0.1296 - val_accuracy: 0.9923\n",
            "Epoch 18/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1065 - accuracy: 1.0000\n",
            "Epoch 18: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1065 - accuracy: 1.0000 - val_loss: 0.1316 - val_accuracy: 0.9923\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1038 - accuracy: 1.0000\n",
            "Epoch 19: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1037 - accuracy: 1.0000 - val_loss: 0.1187 - val_accuracy: 0.9923\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1007 - accuracy: 1.0000\n",
            "Epoch 20: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1006 - accuracy: 1.0000 - val_loss: 0.1166 - val_accuracy: 0.9949\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0980 - accuracy: 1.0000\n",
            "Epoch 21: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0979 - accuracy: 1.0000 - val_loss: 0.1344 - val_accuracy: 0.9923\n",
            "Epoch 22/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0962 - accuracy: 1.0000\n",
            "Epoch 22: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0961 - accuracy: 1.0000 - val_loss: 0.1175 - val_accuracy: 0.9923\n",
            "Epoch 23/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0911 - accuracy: 1.0000\n",
            "Epoch 23: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0911 - accuracy: 1.0000 - val_loss: 0.1201 - val_accuracy: 0.9923\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0918 - accuracy: 1.0000\n",
            "Epoch 24: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0918 - accuracy: 1.0000 - val_loss: 0.1268 - val_accuracy: 0.9898\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0883 - accuracy: 1.0000\n",
            "Epoch 25: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0882 - accuracy: 1.0000 - val_loss: 0.1202 - val_accuracy: 0.9898\n",
            "Epoch 25: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/45/assets\n",
            "\n",
            "\n",
            " 23%|██▎       | 46/200 [1:46:17<5:22:10, 125.53s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 2.9450 - accuracy: 0.3750\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 7s 26ms/step - loss: 2.9450 - accuracy: 0.3750 - val_loss: 1.9492 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 2.2902 - accuracy: 0.5609\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 2.2890 - accuracy: 0.5622 - val_loss: 2.0159 - val_accuracy: 0.2941\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.9698 - accuracy: 0.6820\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.9658 - accuracy: 0.6833 - val_loss: 1.8859 - val_accuracy: 0.3325\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.7485 - accuracy: 0.7642\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 1.7496 - accuracy: 0.7641 - val_loss: 1.6054 - val_accuracy: 0.7059\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.5951 - accuracy: 0.8025\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 1.5921 - accuracy: 0.8045 - val_loss: 1.4647 - val_accuracy: 0.8338\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.4611 - accuracy: 0.8387\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 1.4611 - accuracy: 0.8378 - val_loss: 1.3563 - val_accuracy: 0.8619\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.3548 - accuracy: 0.8653\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 1.3547 - accuracy: 0.8654 - val_loss: 1.2607 - val_accuracy: 0.8875\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.2655 - accuracy: 0.8880\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 1.2663 - accuracy: 0.8872 - val_loss: 1.1735 - val_accuracy: 0.9258\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.1926 - accuracy: 0.9152\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 1.1920 - accuracy: 0.9147 - val_loss: 1.1019 - val_accuracy: 0.9335\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.1324 - accuracy: 0.9165\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 1.1309 - accuracy: 0.9173 - val_loss: 1.0514 - val_accuracy: 0.9642\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.0696 - accuracy: 0.9391\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 1.0685 - accuracy: 0.9397 - val_loss: 0.9957 - val_accuracy: 0.9642\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.0242 - accuracy: 0.9437\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 1.0245 - accuracy: 0.9442 - val_loss: 0.9688 - val_accuracy: 0.9642\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.9828 - accuracy: 0.9553\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.9815 - accuracy: 0.9558 - val_loss: 0.9142 - val_accuracy: 0.9719\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.9419 - accuracy: 0.9663\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.9400 - accuracy: 0.9667 - val_loss: 0.8809 - val_accuracy: 0.9744\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.9068 - accuracy: 0.9657\n",
            "Epoch 15: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.9078 - accuracy: 0.9660 - val_loss: 0.8552 - val_accuracy: 0.9795\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8677 - accuracy: 0.9715\n",
            "Epoch 16: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.8678 - accuracy: 0.9712 - val_loss: 0.8269 - val_accuracy: 0.9795\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8480 - accuracy: 0.9741\n",
            "Epoch 17: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.8477 - accuracy: 0.9744 - val_loss: 0.8040 - val_accuracy: 0.9821\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8182 - accuracy: 0.9806\n",
            "Epoch 18: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.8182 - accuracy: 0.9808 - val_loss: 0.7804 - val_accuracy: 0.9872\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7967 - accuracy: 0.9799\n",
            "Epoch 19: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.7966 - accuracy: 0.9801 - val_loss: 0.7505 - val_accuracy: 0.9821\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7705 - accuracy: 0.9832\n",
            "Epoch 20: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.7711 - accuracy: 0.9833 - val_loss: 0.7301 - val_accuracy: 0.9821\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7554 - accuracy: 0.9799\n",
            "Epoch 21: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.7547 - accuracy: 0.9801 - val_loss: 0.7106 - val_accuracy: 0.9898\n",
            "Epoch 22/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.7286 - accuracy: 0.9865\n",
            "Epoch 22: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.7286 - accuracy: 0.9865 - val_loss: 0.6956 - val_accuracy: 0.9872\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7108 - accuracy: 0.9870\n",
            "Epoch 23: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.7111 - accuracy: 0.9865 - val_loss: 0.6734 - val_accuracy: 0.9872\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6955 - accuracy: 0.9870\n",
            "Epoch 24: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.6955 - accuracy: 0.9872 - val_loss: 0.6578 - val_accuracy: 0.9872\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6709 - accuracy: 0.9890\n",
            "Epoch 25: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.6711 - accuracy: 0.9891 - val_loss: 0.6425 - val_accuracy: 0.9898\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6583 - accuracy: 0.9916\n",
            "Epoch 26: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.6579 - accuracy: 0.9917 - val_loss: 0.6329 - val_accuracy: 0.9898\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6473 - accuracy: 0.9890\n",
            "Epoch 27: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.6475 - accuracy: 0.9891 - val_loss: 0.6133 - val_accuracy: 0.9898\n",
            "Epoch 28/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6302 - accuracy: 0.9923\n",
            "Epoch 28: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.6302 - accuracy: 0.9923 - val_loss: 0.5997 - val_accuracy: 0.9898\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6120 - accuracy: 0.9942\n",
            "Epoch 29: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.6119 - accuracy: 0.9942 - val_loss: 0.5887 - val_accuracy: 0.9898\n",
            "Epoch 30/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6059 - accuracy: 0.9910\n",
            "Epoch 30: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.6059 - accuracy: 0.9910 - val_loss: 0.5831 - val_accuracy: 0.9923\n",
            "Epoch 31/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5926 - accuracy: 0.9916\n",
            "Epoch 31: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.5919 - accuracy: 0.9917 - val_loss: 0.5697 - val_accuracy: 0.9872\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5805 - accuracy: 0.9955\n",
            "Epoch 32: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.5811 - accuracy: 0.9955 - val_loss: 0.5603 - val_accuracy: 0.9872\n",
            "Epoch 33/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5692 - accuracy: 0.9935\n",
            "Epoch 33: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.5692 - accuracy: 0.9936 - val_loss: 0.5499 - val_accuracy: 0.9898\n",
            "Epoch 34/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5559 - accuracy: 0.9968\n",
            "Epoch 34: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.5555 - accuracy: 0.9968 - val_loss: 0.5430 - val_accuracy: 0.9898\n",
            "Epoch 35/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5489 - accuracy: 0.9955\n",
            "Epoch 35: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.5484 - accuracy: 0.9955 - val_loss: 0.5252 - val_accuracy: 0.9923\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5337 - accuracy: 0.9955\n",
            "Epoch 36: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.5329 - accuracy: 0.9955 - val_loss: 0.5140 - val_accuracy: 0.9949\n",
            "Epoch 37/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5230 - accuracy: 0.9974\n",
            "Epoch 37: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.5228 - accuracy: 0.9974 - val_loss: 0.5059 - val_accuracy: 0.9923\n",
            "Epoch 38/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5124 - accuracy: 0.9974\n",
            "Epoch 38: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.5122 - accuracy: 0.9974 - val_loss: 0.4979 - val_accuracy: 0.9923\n",
            "Epoch 39/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5064 - accuracy: 0.9981\n",
            "Epoch 39: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.5062 - accuracy: 0.9981 - val_loss: 0.4880 - val_accuracy: 0.9923\n",
            "Epoch 40/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4968 - accuracy: 0.9962\n",
            "Epoch 40: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.4968 - accuracy: 0.9962 - val_loss: 0.4812 - val_accuracy: 0.9923\n",
            "Epoch 41/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4868 - accuracy: 0.9968\n",
            "Epoch 41: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.4866 - accuracy: 0.9968 - val_loss: 0.4758 - val_accuracy: 0.9923\n",
            "Epoch 42/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4749 - accuracy: 0.9981\n",
            "Epoch 42: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.4755 - accuracy: 0.9981 - val_loss: 0.4630 - val_accuracy: 0.9923\n",
            "Epoch 43/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4716 - accuracy: 0.9968\n",
            "Epoch 43: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.4730 - accuracy: 0.9962 - val_loss: 0.4561 - val_accuracy: 0.9923\n",
            "Epoch 44/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4636 - accuracy: 0.9968\n",
            "Epoch 44: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.4636 - accuracy: 0.9968 - val_loss: 0.4540 - val_accuracy: 0.9898\n",
            "Epoch 45/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4599 - accuracy: 0.9974\n",
            "Epoch 45: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.4595 - accuracy: 0.9974 - val_loss: 0.4452 - val_accuracy: 0.9923\n",
            "Epoch 46/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4513 - accuracy: 0.9968\n",
            "Epoch 46: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.4509 - accuracy: 0.9968 - val_loss: 0.4366 - val_accuracy: 0.9923\n",
            "Epoch 47/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4424 - accuracy: 0.9981\n",
            "Epoch 47: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.4423 - accuracy: 0.9981 - val_loss: 0.4324 - val_accuracy: 0.9923\n",
            "Epoch 48/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4351 - accuracy: 0.9961\n",
            "Epoch 48: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.4350 - accuracy: 0.9962 - val_loss: 0.4328 - val_accuracy: 0.9923\n",
            "Epoch 49/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4247 - accuracy: 0.9981\n",
            "Epoch 49: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.4247 - accuracy: 0.9981 - val_loss: 0.4172 - val_accuracy: 0.9923\n",
            "Epoch 50/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4206 - accuracy: 0.9987\n",
            "Epoch 50: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.4202 - accuracy: 0.9987 - val_loss: 0.4111 - val_accuracy: 0.9923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/46/assets\n",
            "\n",
            "\n",
            " 24%|██▎       | 47/200 [1:50:44<7:08:32, 168.06s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.9473 - accuracy: 0.7636\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 18ms/step - loss: 0.9424 - accuracy: 0.7647 - val_loss: 1.7882 - val_accuracy: 0.3760\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2686 - accuracy: 0.9754\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.2696 - accuracy: 0.9744 - val_loss: 1.6566 - val_accuracy: 0.3376\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2035 - accuracy: 0.9793\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.2031 - accuracy: 0.9795 - val_loss: 2.1457 - val_accuracy: 0.4271\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1767 - accuracy: 0.9819\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1769 - accuracy: 0.9821 - val_loss: 1.1583 - val_accuracy: 0.6624\n",
            "Epoch 5/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1461 - accuracy: 0.9896\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1486 - accuracy: 0.9891 - val_loss: 0.2828 - val_accuracy: 0.9463\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1546 - accuracy: 0.9896\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1542 - accuracy: 0.9897 - val_loss: 0.2370 - val_accuracy: 0.9668\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2126 - accuracy: 0.9747\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.2154 - accuracy: 0.9737 - val_loss: 0.5748 - val_accuracy: 0.9258\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1405 - accuracy: 0.9909\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1410 - accuracy: 0.9904 - val_loss: 0.3379 - val_accuracy: 0.9463\n",
            "Epoch 9/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1108 - accuracy: 0.9961\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1104 - accuracy: 0.9962 - val_loss: 0.1285 - val_accuracy: 0.9898\n",
            "Epoch 10/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0930 - accuracy: 0.9981\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0930 - accuracy: 0.9981 - val_loss: 0.1287 - val_accuracy: 0.9923\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0971 - accuracy: 0.9961\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0970 - accuracy: 0.9962 - val_loss: 0.1607 - val_accuracy: 0.9872\n",
            "Epoch 12/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0913 - accuracy: 0.9981\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0913 - accuracy: 0.9981 - val_loss: 0.1217 - val_accuracy: 0.9898\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0758 - accuracy: 1.0000\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0758 - accuracy: 1.0000 - val_loss: 0.0970 - val_accuracy: 0.9949\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2771 - accuracy: 0.9488\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.2795 - accuracy: 0.9487 - val_loss: 0.4273 - val_accuracy: 0.8951\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1614 - accuracy: 0.9858\n",
            "Epoch 15: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1624 - accuracy: 0.9853 - val_loss: 0.1699 - val_accuracy: 0.9872\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1132 - accuracy: 0.9942\n",
            "Epoch 16: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1131 - accuracy: 0.9942 - val_loss: 0.1412 - val_accuracy: 0.9847\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0911 - accuracy: 0.9955\n",
            "Epoch 17: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0911 - accuracy: 0.9955 - val_loss: 0.1827 - val_accuracy: 0.9821\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1051 - accuracy: 0.9929\n",
            "Epoch 18: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1052 - accuracy: 0.9929 - val_loss: 0.1980 - val_accuracy: 0.9719\n",
            "Epoch 18: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/47/assets\n",
            "\n",
            "\n",
            " 24%|██▍       | 48/200 [1:52:12<6:04:21, 143.83s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 2.1349 - accuracy: 0.3455\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 17ms/step - loss: 2.1349 - accuracy: 0.3455 - val_loss: 1.7847 - val_accuracy: 0.3325\n",
            "Epoch 2/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.7778 - accuracy: 0.5477\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.7766 - accuracy: 0.5487 - val_loss: 1.7403 - val_accuracy: 0.3862\n",
            "Epoch 3/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.5206 - accuracy: 0.6759\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.5191 - accuracy: 0.6763 - val_loss: 1.4990 - val_accuracy: 0.6343\n",
            "Epoch 4/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.2891 - accuracy: 0.7983\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.2900 - accuracy: 0.7974 - val_loss: 1.1561 - val_accuracy: 0.8465\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.0945 - accuracy: 0.8698\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.0920 - accuracy: 0.8712 - val_loss: 0.9902 - val_accuracy: 0.8951\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.9336 - accuracy: 0.9119\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.9349 - accuracy: 0.9115 - val_loss: 0.8558 - val_accuracy: 0.9386\n",
            "Epoch 7/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.8234 - accuracy: 0.9356\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.8228 - accuracy: 0.9353 - val_loss: 0.7683 - val_accuracy: 0.9565\n",
            "Epoch 8/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.7369 - accuracy: 0.9652\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.7361 - accuracy: 0.9654 - val_loss: 0.6987 - val_accuracy: 0.9591\n",
            "Epoch 9/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.6808 - accuracy: 0.9681\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.6805 - accuracy: 0.9673 - val_loss: 0.6449 - val_accuracy: 0.9693\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6299 - accuracy: 0.9728\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.6303 - accuracy: 0.9724 - val_loss: 0.6008 - val_accuracy: 0.9744\n",
            "Epoch 11/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5850 - accuracy: 0.9827\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.5850 - accuracy: 0.9827 - val_loss: 0.5745 - val_accuracy: 0.9770\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5526 - accuracy: 0.9858\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.5520 - accuracy: 0.9859 - val_loss: 0.5360 - val_accuracy: 0.9898\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5220 - accuracy: 0.9896\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.5219 - accuracy: 0.9897 - val_loss: 0.5062 - val_accuracy: 0.9923\n",
            "Epoch 14/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4936 - accuracy: 0.9904\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.4936 - accuracy: 0.9904 - val_loss: 0.4847 - val_accuracy: 0.9898\n",
            "Epoch 15/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4743 - accuracy: 0.9903\n",
            "Epoch 15: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.4738 - accuracy: 0.9904 - val_loss: 0.4644 - val_accuracy: 0.9923\n",
            "Epoch 16/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.4483 - accuracy: 0.9948\n",
            "Epoch 16: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.4479 - accuracy: 0.9949 - val_loss: 0.4468 - val_accuracy: 0.9847\n",
            "Epoch 17/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4319 - accuracy: 0.9923\n",
            "Epoch 17: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.4319 - accuracy: 0.9923 - val_loss: 0.4371 - val_accuracy: 0.9872\n",
            "Epoch 18/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4137 - accuracy: 0.9949\n",
            "Epoch 18: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.4137 - accuracy: 0.9949 - val_loss: 0.4112 - val_accuracy: 0.9949\n",
            "Epoch 19/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4004 - accuracy: 0.9923\n",
            "Epoch 19: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.4008 - accuracy: 0.9923 - val_loss: 0.3977 - val_accuracy: 0.9949\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3868 - accuracy: 0.9942\n",
            "Epoch 20: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.3868 - accuracy: 0.9942 - val_loss: 0.3887 - val_accuracy: 0.9923\n",
            "Epoch 21/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3740 - accuracy: 0.9942\n",
            "Epoch 21: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.3740 - accuracy: 0.9942 - val_loss: 0.3736 - val_accuracy: 0.9923\n",
            "Epoch 22/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3608 - accuracy: 0.9981\n",
            "Epoch 22: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.3606 - accuracy: 0.9981 - val_loss: 0.3626 - val_accuracy: 0.9898\n",
            "Epoch 23/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3472 - accuracy: 0.9967\n",
            "Epoch 23: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.3475 - accuracy: 0.9968 - val_loss: 0.3533 - val_accuracy: 0.9923\n",
            "Epoch 24/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.3402 - accuracy: 0.9993\n",
            "Epoch 24: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.3396 - accuracy: 0.9994 - val_loss: 0.3393 - val_accuracy: 0.9923\n",
            "Epoch 25/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3259 - accuracy: 0.9961\n",
            "Epoch 25: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.3258 - accuracy: 0.9962 - val_loss: 0.3313 - val_accuracy: 0.9949\n",
            "Epoch 26/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3187 - accuracy: 0.9974\n",
            "Epoch 26: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.3188 - accuracy: 0.9974 - val_loss: 0.3250 - val_accuracy: 0.9949\n",
            "Epoch 27/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3063 - accuracy: 0.9974\n",
            "Epoch 27: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.3061 - accuracy: 0.9974 - val_loss: 0.3158 - val_accuracy: 0.9949\n",
            "Epoch 28/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3000 - accuracy: 0.9987\n",
            "Epoch 28: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.2997 - accuracy: 0.9987 - val_loss: 0.3031 - val_accuracy: 0.9923\n",
            "Epoch 29/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2926 - accuracy: 0.9974\n",
            "Epoch 29: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.2926 - accuracy: 0.9974 - val_loss: 0.2993 - val_accuracy: 0.9949\n",
            "Epoch 30/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2825 - accuracy: 0.9987\n",
            "Epoch 30: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.2826 - accuracy: 0.9987 - val_loss: 0.2869 - val_accuracy: 0.9923\n",
            "Epoch 31/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.2757 - accuracy: 0.9980\n",
            "Epoch 31: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.2762 - accuracy: 0.9981 - val_loss: 0.2839 - val_accuracy: 0.9949\n",
            "Epoch 32/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2694 - accuracy: 0.9994\n",
            "Epoch 32: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.2694 - accuracy: 0.9994 - val_loss: 0.2752 - val_accuracy: 0.9923\n",
            "Epoch 33/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.2639 - accuracy: 0.9980\n",
            "Epoch 33: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.2637 - accuracy: 0.9981 - val_loss: 0.2724 - val_accuracy: 0.9949\n",
            "Epoch 34/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2556 - accuracy: 0.9993\n",
            "Epoch 34: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.2565 - accuracy: 0.9994 - val_loss: 0.2627 - val_accuracy: 0.9923\n",
            "Epoch 35/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2488 - accuracy: 0.9987\n",
            "Epoch 35: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.2486 - accuracy: 0.9987 - val_loss: 0.2555 - val_accuracy: 0.9949\n",
            "Epoch 36/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2419 - accuracy: 0.9987\n",
            "Epoch 36: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.2419 - accuracy: 0.9987 - val_loss: 0.2525 - val_accuracy: 0.9923\n",
            "Epoch 37/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2375 - accuracy: 0.9987\n",
            "Epoch 37: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.2375 - accuracy: 0.9987 - val_loss: 0.2431 - val_accuracy: 0.9923\n",
            "Epoch 38/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2320 - accuracy: 0.9980\n",
            "Epoch 38: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.2319 - accuracy: 0.9981 - val_loss: 0.2399 - val_accuracy: 0.9923\n",
            "Epoch 39/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2260 - accuracy: 0.9994\n",
            "Epoch 39: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.2262 - accuracy: 0.9994 - val_loss: 0.2365 - val_accuracy: 0.9923\n",
            "Epoch 40/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2201 - accuracy: 0.9993\n",
            "Epoch 40: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.2202 - accuracy: 0.9994 - val_loss: 0.2337 - val_accuracy: 0.9898\n",
            "Epoch 41/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2152 - accuracy: 0.9994\n",
            "Epoch 41: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.2154 - accuracy: 0.9994 - val_loss: 0.2229 - val_accuracy: 0.9949\n",
            "Epoch 42/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2111 - accuracy: 0.9994\n",
            "Epoch 42: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.2113 - accuracy: 0.9994 - val_loss: 0.2188 - val_accuracy: 0.9923\n",
            "Epoch 43/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2070 - accuracy: 1.0000\n",
            "Epoch 43: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.2069 - accuracy: 1.0000 - val_loss: 0.2144 - val_accuracy: 0.9949\n",
            "Epoch 44/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2009 - accuracy: 0.9994\n",
            "Epoch 44: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.2012 - accuracy: 0.9994 - val_loss: 0.2129 - val_accuracy: 0.9923\n",
            "Epoch 45/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1985 - accuracy: 0.9994\n",
            "Epoch 45: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.1986 - accuracy: 0.9994 - val_loss: 0.2051 - val_accuracy: 0.9923\n",
            "Epoch 46/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1924 - accuracy: 0.9994\n",
            "Epoch 46: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.1929 - accuracy: 0.9994 - val_loss: 0.2041 - val_accuracy: 0.9949\n",
            "Epoch 47/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1904 - accuracy: 1.0000\n",
            "Epoch 47: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.1904 - accuracy: 1.0000 - val_loss: 0.2023 - val_accuracy: 0.9923\n",
            "Epoch 48/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1865 - accuracy: 0.9994\n",
            "Epoch 48: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.1865 - accuracy: 0.9994 - val_loss: 0.1950 - val_accuracy: 0.9923\n",
            "Epoch 49/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1811 - accuracy: 1.0000\n",
            "Epoch 49: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.1811 - accuracy: 1.0000 - val_loss: 0.1912 - val_accuracy: 0.9923\n",
            "Epoch 50/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1769 - accuracy: 1.0000\n",
            "Epoch 50: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.1768 - accuracy: 1.0000 - val_loss: 0.1871 - val_accuracy: 0.9949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/48/assets\n",
            "\n",
            "\n",
            " 24%|██▍       | 49/200 [1:54:36<6:02:13, 143.93s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 2.0817 - accuracy: 0.3019\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 25ms/step - loss: 2.0817 - accuracy: 0.3019 - val_loss: 1.8290 - val_accuracy: 0.3043\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.8001 - accuracy: 0.4573\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.7969 - accuracy: 0.4596 - val_loss: 1.7814 - val_accuracy: 0.3632\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6189 - accuracy: 0.5959\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6172 - accuracy: 0.5981 - val_loss: 1.6285 - val_accuracy: 0.4169\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.4559 - accuracy: 0.6755\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.4553 - accuracy: 0.6769 - val_loss: 1.3915 - val_accuracy: 0.6752\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.2932 - accuracy: 0.7565\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.2917 - accuracy: 0.7564 - val_loss: 1.2425 - val_accuracy: 0.7417\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.1583 - accuracy: 0.7876\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 1.1573 - accuracy: 0.7878 - val_loss: 1.1007 - val_accuracy: 0.8031\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.0322 - accuracy: 0.8284\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.0323 - accuracy: 0.8288 - val_loss: 0.9933 - val_accuracy: 0.8338\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.9299 - accuracy: 0.8685\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.9302 - accuracy: 0.8679 - val_loss: 0.9036 - val_accuracy: 0.8772\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8415 - accuracy: 0.8899\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.8432 - accuracy: 0.8891 - val_loss: 0.8245 - val_accuracy: 0.8977\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7824 - accuracy: 0.9152\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.7843 - accuracy: 0.9141 - val_loss: 0.7629 - val_accuracy: 0.9079\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7242 - accuracy: 0.9268\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.7239 - accuracy: 0.9263 - val_loss: 0.7193 - val_accuracy: 0.9412\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6854 - accuracy: 0.9372\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.6859 - accuracy: 0.9372 - val_loss: 0.6736 - val_accuracy: 0.9437\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6386 - accuracy: 0.9443\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.6413 - accuracy: 0.9429 - val_loss: 0.6348 - val_accuracy: 0.9514\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6036 - accuracy: 0.9611\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.6033 - accuracy: 0.9603 - val_loss: 0.6114 - val_accuracy: 0.9514\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5808 - accuracy: 0.9573\n",
            "Epoch 15: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.5801 - accuracy: 0.9571 - val_loss: 0.5808 - val_accuracy: 0.9616\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5524 - accuracy: 0.9637\n",
            "Epoch 16: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.5524 - accuracy: 0.9641 - val_loss: 0.5545 - val_accuracy: 0.9642\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5266 - accuracy: 0.9741\n",
            "Epoch 17: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.5258 - accuracy: 0.9737 - val_loss: 0.5335 - val_accuracy: 0.9668\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5031 - accuracy: 0.9786\n",
            "Epoch 18: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.5038 - accuracy: 0.9788 - val_loss: 0.5122 - val_accuracy: 0.9744\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4747 - accuracy: 0.9864\n",
            "Epoch 19: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.4746 - accuracy: 0.9865 - val_loss: 0.4925 - val_accuracy: 0.9795\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4645 - accuracy: 0.9845\n",
            "Epoch 20: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.4643 - accuracy: 0.9846 - val_loss: 0.4735 - val_accuracy: 0.9821\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4473 - accuracy: 0.9845\n",
            "Epoch 21: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.4464 - accuracy: 0.9846 - val_loss: 0.4623 - val_accuracy: 0.9847\n",
            "Epoch 22/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4326 - accuracy: 0.9846\n",
            "Epoch 22: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.4326 - accuracy: 0.9846 - val_loss: 0.4460 - val_accuracy: 0.9847\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4208 - accuracy: 0.9883\n",
            "Epoch 23: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.4214 - accuracy: 0.9885 - val_loss: 0.4366 - val_accuracy: 0.9872\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4021 - accuracy: 0.9909\n",
            "Epoch 24: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.4017 - accuracy: 0.9910 - val_loss: 0.4206 - val_accuracy: 0.9847\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3933 - accuracy: 0.9896\n",
            "Epoch 25: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.3935 - accuracy: 0.9897 - val_loss: 0.4130 - val_accuracy: 0.9821\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3797 - accuracy: 0.9935\n",
            "Epoch 26: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.3792 - accuracy: 0.9936 - val_loss: 0.4008 - val_accuracy: 0.9847\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3694 - accuracy: 0.9929\n",
            "Epoch 27: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.3697 - accuracy: 0.9929 - val_loss: 0.3893 - val_accuracy: 0.9847\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3545 - accuracy: 0.9948\n",
            "Epoch 28: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.3544 - accuracy: 0.9949 - val_loss: 0.3915 - val_accuracy: 0.9821\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3499 - accuracy: 0.9916\n",
            "Epoch 29: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.3493 - accuracy: 0.9917 - val_loss: 0.3708 - val_accuracy: 0.9872\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3402 - accuracy: 0.9948\n",
            "Epoch 30: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.3396 - accuracy: 0.9949 - val_loss: 0.3638 - val_accuracy: 0.9898\n",
            "Epoch 31/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3260 - accuracy: 0.9981\n",
            "Epoch 31: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.3267 - accuracy: 0.9981 - val_loss: 0.3513 - val_accuracy: 0.9898\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3219 - accuracy: 0.9955\n",
            "Epoch 32: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.3218 - accuracy: 0.9955 - val_loss: 0.3441 - val_accuracy: 0.9898\n",
            "Epoch 33/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3147 - accuracy: 0.9968\n",
            "Epoch 33: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.3147 - accuracy: 0.9968 - val_loss: 0.3378 - val_accuracy: 0.9872\n",
            "Epoch 34/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3066 - accuracy: 0.9968\n",
            "Epoch 34: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.3062 - accuracy: 0.9968 - val_loss: 0.3298 - val_accuracy: 0.9923\n",
            "Epoch 35/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2973 - accuracy: 0.9981\n",
            "Epoch 35: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2972 - accuracy: 0.9981 - val_loss: 0.3212 - val_accuracy: 0.9898\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2907 - accuracy: 0.9987\n",
            "Epoch 36: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2906 - accuracy: 0.9987 - val_loss: 0.3154 - val_accuracy: 0.9898\n",
            "Epoch 37/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2840 - accuracy: 0.9974\n",
            "Epoch 37: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2842 - accuracy: 0.9974 - val_loss: 0.3098 - val_accuracy: 0.9898\n",
            "Epoch 38/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2784 - accuracy: 0.9961\n",
            "Epoch 38: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2787 - accuracy: 0.9962 - val_loss: 0.3001 - val_accuracy: 0.9898\n",
            "Epoch 39/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2723 - accuracy: 0.9994\n",
            "Epoch 39: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2720 - accuracy: 0.9994 - val_loss: 0.3002 - val_accuracy: 0.9872\n",
            "Epoch 40/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2641 - accuracy: 0.9968\n",
            "Epoch 40: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2638 - accuracy: 0.9968 - val_loss: 0.2955 - val_accuracy: 0.9898\n",
            "Epoch 41/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2626 - accuracy: 0.9974\n",
            "Epoch 41: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2626 - accuracy: 0.9974 - val_loss: 0.2875 - val_accuracy: 0.9898\n",
            "Epoch 42/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2555 - accuracy: 0.9981\n",
            "Epoch 42: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2556 - accuracy: 0.9981 - val_loss: 0.2815 - val_accuracy: 0.9898\n",
            "Epoch 43/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2484 - accuracy: 0.9981\n",
            "Epoch 43: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2484 - accuracy: 0.9981 - val_loss: 0.2807 - val_accuracy: 0.9872\n",
            "Epoch 44/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2444 - accuracy: 0.9994\n",
            "Epoch 44: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.2443 - accuracy: 0.9994 - val_loss: 0.2722 - val_accuracy: 0.9872\n",
            "Epoch 45/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2393 - accuracy: 0.9994\n",
            "Epoch 45: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2393 - accuracy: 0.9994 - val_loss: 0.2624 - val_accuracy: 0.9898\n",
            "Epoch 46/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2370 - accuracy: 0.9961\n",
            "Epoch 46: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2368 - accuracy: 0.9962 - val_loss: 0.2592 - val_accuracy: 0.9872\n",
            "Epoch 47/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2309 - accuracy: 0.9987\n",
            "Epoch 47: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2311 - accuracy: 0.9987 - val_loss: 0.2547 - val_accuracy: 0.9872\n",
            "Epoch 48/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2263 - accuracy: 0.9987\n",
            "Epoch 48: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2262 - accuracy: 0.9987 - val_loss: 0.2512 - val_accuracy: 0.9898\n",
            "Epoch 49/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2224 - accuracy: 0.9994\n",
            "Epoch 49: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2222 - accuracy: 0.9994 - val_loss: 0.2512 - val_accuracy: 0.9872\n",
            "Epoch 50/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2196 - accuracy: 0.9994\n",
            "Epoch 50: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2196 - accuracy: 0.9994 - val_loss: 0.2455 - val_accuracy: 0.9872\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/49/assets\n",
            "\n",
            "\n",
            " 25%|██▌       | 50/200 [1:58:21<7:00:24, 168.16s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.0133 - accuracy: 0.7899\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 7s 29ms/step - loss: 1.0104 - accuracy: 0.7910 - val_loss: 1.8500 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3021 - accuracy: 0.9774\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.3019 - accuracy: 0.9776 - val_loss: 1.5857 - val_accuracy: 0.4680\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3179 - accuracy: 0.9650\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.3171 - accuracy: 0.9654 - val_loss: 0.6843 - val_accuracy: 0.7852\n",
            "Epoch 4/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2291 - accuracy: 0.9833\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.2291 - accuracy: 0.9833 - val_loss: 0.3015 - val_accuracy: 0.9565\n",
            "Epoch 5/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1770 - accuracy: 0.9955\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.1770 - accuracy: 0.9955 - val_loss: 0.4273 - val_accuracy: 0.9207\n",
            "Epoch 6/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1981 - accuracy: 0.9891\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.1981 - accuracy: 0.9891 - val_loss: 0.9884 - val_accuracy: 0.8005\n",
            "Epoch 7/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2641 - accuracy: 0.9718\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.2641 - accuracy: 0.9718 - val_loss: 0.2716 - val_accuracy: 0.9744\n",
            "Epoch 8/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2228 - accuracy: 0.9826\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.2226 - accuracy: 0.9827 - val_loss: 0.2354 - val_accuracy: 0.9744\n",
            "Epoch 9/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1492 - accuracy: 0.9974\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.1491 - accuracy: 0.9974 - val_loss: 0.1513 - val_accuracy: 0.9923\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1248 - accuracy: 1.0000\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.1250 - accuracy: 1.0000 - val_loss: 0.1429 - val_accuracy: 0.9949\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1169 - accuracy: 1.0000\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.1167 - accuracy: 1.0000 - val_loss: 0.1266 - val_accuracy: 0.9949\n",
            "Epoch 12/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1066 - accuracy: 1.0000\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.1066 - accuracy: 1.0000 - val_loss: 0.1441 - val_accuracy: 0.9821\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1005 - accuracy: 1.0000\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.1005 - accuracy: 1.0000 - val_loss: 0.1220 - val_accuracy: 0.9949\n",
            "Epoch 14/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1870 - accuracy: 0.9787\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.1869 - accuracy: 0.9788 - val_loss: 0.6063 - val_accuracy: 0.8491\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2941 - accuracy: 0.9598\n",
            "Epoch 15: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.2943 - accuracy: 0.9590 - val_loss: 0.4964 - val_accuracy: 0.9309\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1619 - accuracy: 0.9916\n",
            "Epoch 16: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.1615 - accuracy: 0.9917 - val_loss: 0.1914 - val_accuracy: 0.9795\n",
            "Epoch 17/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1177 - accuracy: 0.9987\n",
            "Epoch 17: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.1177 - accuracy: 0.9987 - val_loss: 0.1547 - val_accuracy: 0.9821\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1206 - accuracy: 0.9961\n",
            "Epoch 18: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.1204 - accuracy: 0.9962 - val_loss: 0.1445 - val_accuracy: 0.9898\n",
            "Epoch 18: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/50/assets\n",
            "\n",
            "\n",
            " 26%|██▌       | 51/200 [2:00:48<6:42:04, 161.91s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 2.5472 - accuracy: 0.4167\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 8s 31ms/step - loss: 2.5472 - accuracy: 0.4167 - val_loss: 1.8829 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.9135 - accuracy: 0.6411\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 1.9124 - accuracy: 0.6410 - val_loss: 1.8801 - val_accuracy: 0.2864\n",
            "Epoch 3/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.5542 - accuracy: 0.7583\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 1.5542 - accuracy: 0.7583 - val_loss: 1.5818 - val_accuracy: 0.4297\n",
            "Epoch 4/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.2979 - accuracy: 0.8295\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 30ms/step - loss: 1.2979 - accuracy: 0.8295 - val_loss: 1.1024 - val_accuracy: 0.9028\n",
            "Epoch 5/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.1028 - accuracy: 0.8955\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 30ms/step - loss: 1.1028 - accuracy: 0.8955 - val_loss: 0.9570 - val_accuracy: 0.9386\n",
            "Epoch 6/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.9746 - accuracy: 0.9333\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 30ms/step - loss: 0.9746 - accuracy: 0.9333 - val_loss: 0.8609 - val_accuracy: 0.9591\n",
            "Epoch 7/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.8744 - accuracy: 0.9538\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 30ms/step - loss: 0.8744 - accuracy: 0.9538 - val_loss: 0.7812 - val_accuracy: 0.9719\n",
            "Epoch 8/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.7954 - accuracy: 0.9678\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.7951 - accuracy: 0.9679 - val_loss: 0.7128 - val_accuracy: 0.9847\n",
            "Epoch 9/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.7255 - accuracy: 0.9821\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.7255 - accuracy: 0.9821 - val_loss: 0.6816 - val_accuracy: 0.9770\n",
            "Epoch 10/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6778 - accuracy: 0.9853\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.6778 - accuracy: 0.9853 - val_loss: 0.6299 - val_accuracy: 0.9923\n",
            "Epoch 11/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6469 - accuracy: 0.9872\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.6469 - accuracy: 0.9872 - val_loss: 0.5914 - val_accuracy: 0.9949\n",
            "Epoch 12/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6109 - accuracy: 0.9878\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.6109 - accuracy: 0.9878 - val_loss: 0.5676 - val_accuracy: 0.9923\n",
            "Epoch 13/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5725 - accuracy: 0.9923\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.5725 - accuracy: 0.9923 - val_loss: 0.5364 - val_accuracy: 0.9974\n",
            "Epoch 14/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5555 - accuracy: 0.9910\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.5555 - accuracy: 0.9910 - val_loss: 0.5190 - val_accuracy: 0.9949\n",
            "Epoch 15/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5299 - accuracy: 0.9949\n",
            "Epoch 15: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.5299 - accuracy: 0.9949 - val_loss: 0.4930 - val_accuracy: 0.9974\n",
            "Epoch 16/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5067 - accuracy: 0.9942\n",
            "Epoch 16: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.5067 - accuracy: 0.9942 - val_loss: 0.4907 - val_accuracy: 0.9923\n",
            "Epoch 17/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4882 - accuracy: 0.9949\n",
            "Epoch 17: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.4882 - accuracy: 0.9949 - val_loss: 0.4596 - val_accuracy: 0.9949\n",
            "Epoch 18/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4679 - accuracy: 0.9968\n",
            "Epoch 18: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.4679 - accuracy: 0.9968 - val_loss: 0.4433 - val_accuracy: 0.9949\n",
            "Epoch 19/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4553 - accuracy: 0.9962\n",
            "Epoch 19: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.4553 - accuracy: 0.9962 - val_loss: 0.4339 - val_accuracy: 0.9923\n",
            "Epoch 20/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4382 - accuracy: 0.9968\n",
            "Epoch 20: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.4382 - accuracy: 0.9968 - val_loss: 0.4188 - val_accuracy: 0.9974\n",
            "Epoch 21/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4263 - accuracy: 0.9968\n",
            "Epoch 21: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.4263 - accuracy: 0.9968 - val_loss: 0.4101 - val_accuracy: 0.9949\n",
            "Epoch 22/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4145 - accuracy: 0.9962\n",
            "Epoch 22: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 30ms/step - loss: 0.4145 - accuracy: 0.9962 - val_loss: 0.4012 - val_accuracy: 0.9949\n",
            "Epoch 23/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4026 - accuracy: 0.9962\n",
            "Epoch 23: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.4026 - accuracy: 0.9962 - val_loss: 0.3847 - val_accuracy: 0.9974\n",
            "Epoch 24/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3914 - accuracy: 0.9974\n",
            "Epoch 24: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.3914 - accuracy: 0.9974 - val_loss: 0.3796 - val_accuracy: 0.9923\n",
            "Epoch 25/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3773 - accuracy: 0.9994\n",
            "Epoch 25: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.3773 - accuracy: 0.9994 - val_loss: 0.3626 - val_accuracy: 0.9974\n",
            "Epoch 26/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3686 - accuracy: 0.9968\n",
            "Epoch 26: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.3686 - accuracy: 0.9968 - val_loss: 0.3566 - val_accuracy: 0.9949\n",
            "Epoch 27/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3584 - accuracy: 0.9987\n",
            "Epoch 27: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.3584 - accuracy: 0.9987 - val_loss: 0.3444 - val_accuracy: 0.9974\n",
            "Epoch 28/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3496 - accuracy: 0.9987\n",
            "Epoch 28: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.3496 - accuracy: 0.9987 - val_loss: 0.3392 - val_accuracy: 0.9974\n",
            "Epoch 29/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3415 - accuracy: 0.9974\n",
            "Epoch 29: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.3417 - accuracy: 0.9974 - val_loss: 0.3320 - val_accuracy: 0.9949\n",
            "Epoch 30/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3344 - accuracy: 0.9981\n",
            "Epoch 30: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.3344 - accuracy: 0.9981 - val_loss: 0.3222 - val_accuracy: 0.9974\n",
            "Epoch 31/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3242 - accuracy: 0.9987\n",
            "Epoch 31: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.3242 - accuracy: 0.9987 - val_loss: 0.3211 - val_accuracy: 0.9898\n",
            "Epoch 32/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3168 - accuracy: 0.9987\n",
            "Epoch 32: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.3168 - accuracy: 0.9987 - val_loss: 0.3104 - val_accuracy: 0.9949\n",
            "Epoch 33/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3131 - accuracy: 0.9974\n",
            "Epoch 33: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.3131 - accuracy: 0.9974 - val_loss: 0.3108 - val_accuracy: 0.9949\n",
            "Epoch 34/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3035 - accuracy: 0.9987\n",
            "Epoch 34: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.3035 - accuracy: 0.9987 - val_loss: 0.3035 - val_accuracy: 0.9949\n",
            "Epoch 35/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2953 - accuracy: 0.9994\n",
            "Epoch 35: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.2953 - accuracy: 0.9994 - val_loss: 0.2919 - val_accuracy: 0.9949\n",
            "Epoch 36/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2878 - accuracy: 1.0000\n",
            "Epoch 36: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.2878 - accuracy: 1.0000 - val_loss: 0.2818 - val_accuracy: 0.9949\n",
            "Epoch 37/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2816 - accuracy: 0.9994\n",
            "Epoch 37: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.2816 - accuracy: 0.9994 - val_loss: 0.2799 - val_accuracy: 0.9949\n",
            "Epoch 38/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2802 - accuracy: 0.9974\n",
            "Epoch 38: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.2802 - accuracy: 0.9974 - val_loss: 0.2803 - val_accuracy: 0.9923\n",
            "Epoch 39/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2700 - accuracy: 1.0000\n",
            "Epoch 39: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.2700 - accuracy: 1.0000 - val_loss: 0.2654 - val_accuracy: 0.9974\n",
            "Epoch 40/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2645 - accuracy: 0.9994\n",
            "Epoch 40: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.2644 - accuracy: 0.9994 - val_loss: 0.2680 - val_accuracy: 0.9949\n",
            "Epoch 41/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2590 - accuracy: 0.9994\n",
            "Epoch 41: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.2590 - accuracy: 0.9994 - val_loss: 0.2586 - val_accuracy: 0.9949\n",
            "Epoch 42/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2533 - accuracy: 0.9994\n",
            "Epoch 42: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.2533 - accuracy: 0.9994 - val_loss: 0.2510 - val_accuracy: 0.9949\n",
            "Epoch 43/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2471 - accuracy: 0.9994\n",
            "Epoch 43: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.2471 - accuracy: 0.9994 - val_loss: 0.2464 - val_accuracy: 0.9974\n",
            "Epoch 44/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2431 - accuracy: 0.9987\n",
            "Epoch 44: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.2431 - accuracy: 0.9987 - val_loss: 0.2448 - val_accuracy: 0.9923\n",
            "Epoch 45/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2368 - accuracy: 0.9994\n",
            "Epoch 45: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.2368 - accuracy: 0.9994 - val_loss: 0.2376 - val_accuracy: 0.9949\n",
            "Epoch 46/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2322 - accuracy: 0.9994\n",
            "Epoch 46: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.2322 - accuracy: 0.9994 - val_loss: 0.2369 - val_accuracy: 0.9949\n",
            "Epoch 47/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2282 - accuracy: 0.9994\n",
            "Epoch 47: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.2282 - accuracy: 0.9994 - val_loss: 0.2265 - val_accuracy: 0.9949\n",
            "Epoch 48/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2227 - accuracy: 1.0000\n",
            "Epoch 48: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.2227 - accuracy: 1.0000 - val_loss: 0.2249 - val_accuracy: 0.9949\n",
            "Epoch 49/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2195 - accuracy: 0.9994\n",
            "Epoch 49: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 30ms/step - loss: 0.2195 - accuracy: 0.9994 - val_loss: 0.2210 - val_accuracy: 0.9949\n",
            "Epoch 50/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2144 - accuracy: 1.0000\n",
            "Epoch 50: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.2144 - accuracy: 1.0000 - val_loss: 0.2182 - val_accuracy: 0.9949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/51/assets\n",
            "\n",
            "\n",
            " 26%|██▌       | 52/200 [2:05:38<8:14:29, 200.47s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.7666 - accuracy: 0.4865\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 13ms/step - loss: 1.7666 - accuracy: 0.4865 - val_loss: 1.7321 - val_accuracy: 0.2634\n",
            "Epoch 2/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.1363 - accuracy: 0.7871\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.1341 - accuracy: 0.7865 - val_loss: 2.2754 - val_accuracy: 0.4450\n",
            "Epoch 3/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.8127 - accuracy: 0.8908\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.8109 - accuracy: 0.8904 - val_loss: 1.7970 - val_accuracy: 0.4962\n",
            "Epoch 4/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.6642 - accuracy: 0.9342\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.6616 - accuracy: 0.9346 - val_loss: 0.6293 - val_accuracy: 0.9335\n",
            "Epoch 5/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.5573 - accuracy: 0.9596\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.5583 - accuracy: 0.9596 - val_loss: 0.5479 - val_accuracy: 0.9693\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5051 - accuracy: 0.9637\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.5053 - accuracy: 0.9635 - val_loss: 0.5089 - val_accuracy: 0.9591\n",
            "Epoch 7/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.4541 - accuracy: 0.9810\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.4529 - accuracy: 0.9814 - val_loss: 0.5359 - val_accuracy: 0.9412\n",
            "Epoch 8/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.4179 - accuracy: 0.9809\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.4166 - accuracy: 0.9808 - val_loss: 0.4710 - val_accuracy: 0.9361\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3689 - accuracy: 0.9903\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.3688 - accuracy: 0.9904 - val_loss: 0.3821 - val_accuracy: 0.9898\n",
            "Epoch 10/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3492 - accuracy: 0.9935\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.3495 - accuracy: 0.9936 - val_loss: 0.3563 - val_accuracy: 0.9821\n",
            "Epoch 11/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3226 - accuracy: 0.9948\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.3222 - accuracy: 0.9949 - val_loss: 0.3277 - val_accuracy: 0.9898\n",
            "Epoch 12/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.3011 - accuracy: 0.9947\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.3004 - accuracy: 0.9949 - val_loss: 0.3365 - val_accuracy: 0.9872\n",
            "Epoch 13/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2763 - accuracy: 0.9987\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.2764 - accuracy: 0.9987 - val_loss: 0.3097 - val_accuracy: 0.9744\n",
            "Epoch 14/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2692 - accuracy: 0.9954\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.2686 - accuracy: 0.9955 - val_loss: 0.2847 - val_accuracy: 0.9872\n",
            "Epoch 15/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2429 - accuracy: 0.9987\n",
            "Epoch 15: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.2427 - accuracy: 0.9987 - val_loss: 0.2650 - val_accuracy: 0.9872\n",
            "Epoch 16/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2297 - accuracy: 0.9987\n",
            "Epoch 16: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.2297 - accuracy: 0.9987 - val_loss: 0.2415 - val_accuracy: 0.9923\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2133 - accuracy: 0.9994\n",
            "Epoch 17: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.2142 - accuracy: 0.9987 - val_loss: 0.2314 - val_accuracy: 0.9923\n",
            "Epoch 18/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2056 - accuracy: 0.9981\n",
            "Epoch 18: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.2056 - accuracy: 0.9981 - val_loss: 0.2220 - val_accuracy: 0.9898\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1986 - accuracy: 0.9961\n",
            "Epoch 19: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1983 - accuracy: 0.9962 - val_loss: 0.2402 - val_accuracy: 0.9821\n",
            "Epoch 20/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1856 - accuracy: 0.9987\n",
            "Epoch 20: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.1859 - accuracy: 0.9987 - val_loss: 0.2055 - val_accuracy: 0.9923\n",
            "Epoch 21/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1728 - accuracy: 0.9994\n",
            "Epoch 21: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.1728 - accuracy: 0.9994 - val_loss: 0.1928 - val_accuracy: 0.9898\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1638 - accuracy: 0.9994\n",
            "Epoch 22: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1637 - accuracy: 0.9994 - val_loss: 0.1840 - val_accuracy: 0.9923\n",
            "Epoch 23/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.1557 - accuracy: 1.0000\n",
            "Epoch 23: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.1556 - accuracy: 1.0000 - val_loss: 0.1773 - val_accuracy: 0.9923\n",
            "Epoch 24/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1473 - accuracy: 1.0000\n",
            "Epoch 24: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.1473 - accuracy: 1.0000 - val_loss: 0.1690 - val_accuracy: 0.9898\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1434 - accuracy: 1.0000\n",
            "Epoch 25: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1433 - accuracy: 1.0000 - val_loss: 0.1738 - val_accuracy: 0.9898\n",
            "Epoch 26/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1362 - accuracy: 1.0000\n",
            "Epoch 26: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.1360 - accuracy: 1.0000 - val_loss: 0.1610 - val_accuracy: 0.9949\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1316 - accuracy: 0.9994\n",
            "Epoch 27: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1315 - accuracy: 0.9994 - val_loss: 0.1526 - val_accuracy: 0.9923\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1265 - accuracy: 1.0000\n",
            "Epoch 28: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.1267 - accuracy: 1.0000 - val_loss: 0.1516 - val_accuracy: 0.9923\n",
            "Epoch 29/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1227 - accuracy: 1.0000\n",
            "Epoch 29: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.1227 - accuracy: 1.0000 - val_loss: 0.1498 - val_accuracy: 0.9949\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1178 - accuracy: 1.0000\n",
            "Epoch 30: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1176 - accuracy: 1.0000 - val_loss: 0.1382 - val_accuracy: 0.9949\n",
            "Epoch 31/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1165 - accuracy: 1.0000\n",
            "Epoch 31: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.1163 - accuracy: 1.0000 - val_loss: 0.1316 - val_accuracy: 0.9949\n",
            "Epoch 32/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1094 - accuracy: 1.0000\n",
            "Epoch 32: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1093 - accuracy: 1.0000 - val_loss: 0.1272 - val_accuracy: 0.9923\n",
            "Epoch 33/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1060 - accuracy: 1.0000\n",
            "Epoch 33: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1060 - accuracy: 1.0000 - val_loss: 0.1277 - val_accuracy: 0.9949\n",
            "Epoch 34/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1035 - accuracy: 1.0000\n",
            "Epoch 34: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.1035 - accuracy: 1.0000 - val_loss: 0.1249 - val_accuracy: 0.9923\n",
            "Epoch 35/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0994 - accuracy: 1.0000\n",
            "Epoch 35: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0995 - accuracy: 1.0000 - val_loss: 0.1187 - val_accuracy: 0.9949\n",
            "Epoch 36/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0969 - accuracy: 1.0000\n",
            "Epoch 36: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0969 - accuracy: 1.0000 - val_loss: 0.1170 - val_accuracy: 0.9949\n",
            "Epoch 37/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0937 - accuracy: 1.0000\n",
            "Epoch 37: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0939 - accuracy: 1.0000 - val_loss: 0.1158 - val_accuracy: 0.9923\n",
            "Epoch 38/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0921 - accuracy: 1.0000\n",
            "Epoch 38: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0921 - accuracy: 1.0000 - val_loss: 0.1121 - val_accuracy: 0.9923\n",
            "Epoch 39/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0932 - accuracy: 1.0000\n",
            "Epoch 39: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0931 - accuracy: 1.0000 - val_loss: 0.1104 - val_accuracy: 0.9949\n",
            "Epoch 40/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0873 - accuracy: 1.0000\n",
            "Epoch 40: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0873 - accuracy: 1.0000 - val_loss: 0.1099 - val_accuracy: 0.9949\n",
            "Epoch 41/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0852 - accuracy: 1.0000\n",
            "Epoch 41: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0852 - accuracy: 1.0000 - val_loss: 0.1048 - val_accuracy: 0.9949\n",
            "Epoch 42/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0837 - accuracy: 1.0000\n",
            "Epoch 42: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0837 - accuracy: 1.0000 - val_loss: 0.1185 - val_accuracy: 0.9949\n",
            "Epoch 43/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0813 - accuracy: 1.0000\n",
            "Epoch 43: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0812 - accuracy: 1.0000 - val_loss: 0.1034 - val_accuracy: 0.9949\n",
            "Epoch 44/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0804 - accuracy: 1.0000\n",
            "Epoch 44: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0803 - accuracy: 1.0000 - val_loss: 0.1016 - val_accuracy: 0.9949\n",
            "Epoch 45/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.0769 - accuracy: 1.0000\n",
            "Epoch 45: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0768 - accuracy: 1.0000 - val_loss: 0.0979 - val_accuracy: 0.9949\n",
            "Epoch 46/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0754 - accuracy: 1.0000\n",
            "Epoch 46: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0754 - accuracy: 1.0000 - val_loss: 0.0980 - val_accuracy: 0.9949\n",
            "Epoch 47/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0742 - accuracy: 1.0000\n",
            "Epoch 47: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0742 - accuracy: 1.0000 - val_loss: 0.0983 - val_accuracy: 0.9949\n",
            "Epoch 48/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0722 - accuracy: 1.0000\n",
            "Epoch 48: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0722 - accuracy: 1.0000 - val_loss: 0.0938 - val_accuracy: 0.9949\n",
            "Epoch 49/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0760 - accuracy: 0.9993\n",
            "Epoch 49: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0759 - accuracy: 0.9994 - val_loss: 0.1043 - val_accuracy: 0.9898\n",
            "Epoch 50/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0709 - accuracy: 1.0000\n",
            "Epoch 50: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0709 - accuracy: 1.0000 - val_loss: 0.0960 - val_accuracy: 0.9923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/52/assets\n",
            "\n",
            "\n",
            " 26%|██▋       | 53/200 [2:08:06<7:32:06, 184.53s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.9469 - accuracy: 0.3769\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 22ms/step - loss: 1.9453 - accuracy: 0.3769 - val_loss: 1.7727 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6252 - accuracy: 0.5654\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.6237 - accuracy: 0.5654 - val_loss: 1.6865 - val_accuracy: 0.3913\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.3850 - accuracy: 0.6703\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.3826 - accuracy: 0.6712 - val_loss: 1.3920 - val_accuracy: 0.6419\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.1490 - accuracy: 0.7830\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 1.1469 - accuracy: 0.7833 - val_loss: 1.0303 - val_accuracy: 0.7928\n",
            "Epoch 5/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.9515 - accuracy: 0.8628\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.9511 - accuracy: 0.8628 - val_loss: 0.8555 - val_accuracy: 0.8721\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7859 - accuracy: 0.9158\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.7858 - accuracy: 0.9160 - val_loss: 0.7209 - val_accuracy: 0.9309\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6685 - accuracy: 0.9482\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.6663 - accuracy: 0.9487 - val_loss: 0.6209 - val_accuracy: 0.9565\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5918 - accuracy: 0.9618\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.5922 - accuracy: 0.9622 - val_loss: 0.5471 - val_accuracy: 0.9872\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5244 - accuracy: 0.9780\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.5248 - accuracy: 0.9782 - val_loss: 0.5034 - val_accuracy: 0.9898\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4849 - accuracy: 0.9786\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.4842 - accuracy: 0.9782 - val_loss: 0.4539 - val_accuracy: 0.9949\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4402 - accuracy: 0.9870\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.4411 - accuracy: 0.9865 - val_loss: 0.4227 - val_accuracy: 0.9923\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4063 - accuracy: 0.9916\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.4063 - accuracy: 0.9917 - val_loss: 0.4011 - val_accuracy: 0.9949\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3839 - accuracy: 0.9877\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.3841 - accuracy: 0.9878 - val_loss: 0.3808 - val_accuracy: 0.9872\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3594 - accuracy: 0.9929\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.3592 - accuracy: 0.9929 - val_loss: 0.3495 - val_accuracy: 0.9923\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3432 - accuracy: 0.9935\n",
            "Epoch 15: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.3428 - accuracy: 0.9936 - val_loss: 0.3291 - val_accuracy: 0.9949\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3194 - accuracy: 0.9961\n",
            "Epoch 16: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.3193 - accuracy: 0.9962 - val_loss: 0.3227 - val_accuracy: 0.9923\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3030 - accuracy: 0.9981\n",
            "Epoch 17: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.3024 - accuracy: 0.9981 - val_loss: 0.2996 - val_accuracy: 0.9974\n",
            "Epoch 18/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2912 - accuracy: 0.9948\n",
            "Epoch 18: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2914 - accuracy: 0.9949 - val_loss: 0.2936 - val_accuracy: 0.9923\n",
            "Epoch 19/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2805 - accuracy: 0.9961\n",
            "Epoch 19: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.2803 - accuracy: 0.9962 - val_loss: 0.2746 - val_accuracy: 0.9974\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2676 - accuracy: 0.9981\n",
            "Epoch 20: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.2676 - accuracy: 0.9981 - val_loss: 0.2672 - val_accuracy: 0.9949\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2552 - accuracy: 0.9974\n",
            "Epoch 21: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.2552 - accuracy: 0.9974 - val_loss: 0.2571 - val_accuracy: 0.9949\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2471 - accuracy: 0.9981\n",
            "Epoch 22: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.2472 - accuracy: 0.9981 - val_loss: 0.2460 - val_accuracy: 0.9949\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2372 - accuracy: 0.9987\n",
            "Epoch 23: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.2372 - accuracy: 0.9987 - val_loss: 0.2403 - val_accuracy: 0.9923\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2296 - accuracy: 0.9987\n",
            "Epoch 24: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.2295 - accuracy: 0.9987 - val_loss: 0.2359 - val_accuracy: 0.9949\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2212 - accuracy: 0.9994\n",
            "Epoch 25: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.2213 - accuracy: 0.9994 - val_loss: 0.2237 - val_accuracy: 0.9949\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2145 - accuracy: 0.9994\n",
            "Epoch 26: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.2145 - accuracy: 0.9994 - val_loss: 0.2178 - val_accuracy: 0.9974\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2097 - accuracy: 0.9981\n",
            "Epoch 27: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2110 - accuracy: 0.9974 - val_loss: 0.2187 - val_accuracy: 0.9949\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2038 - accuracy: 0.9981\n",
            "Epoch 28: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2038 - accuracy: 0.9981 - val_loss: 0.2073 - val_accuracy: 0.9949\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1969 - accuracy: 1.0000\n",
            "Epoch 29: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1966 - accuracy: 1.0000 - val_loss: 0.1967 - val_accuracy: 0.9974\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1884 - accuracy: 1.0000\n",
            "Epoch 30: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1894 - accuracy: 1.0000 - val_loss: 0.1936 - val_accuracy: 0.9949\n",
            "Epoch 31/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1868 - accuracy: 0.9974\n",
            "Epoch 31: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1868 - accuracy: 0.9974 - val_loss: 0.1914 - val_accuracy: 0.9974\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1817 - accuracy: 0.9987\n",
            "Epoch 32: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1816 - accuracy: 0.9987 - val_loss: 0.1832 - val_accuracy: 0.9974\n",
            "Epoch 33/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1744 - accuracy: 0.9994\n",
            "Epoch 33: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1743 - accuracy: 0.9994 - val_loss: 0.1790 - val_accuracy: 0.9974\n",
            "Epoch 34/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1707 - accuracy: 1.0000\n",
            "Epoch 34: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1707 - accuracy: 1.0000 - val_loss: 0.1746 - val_accuracy: 0.9949\n",
            "Epoch 35/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1657 - accuracy: 1.0000\n",
            "Epoch 35: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1657 - accuracy: 1.0000 - val_loss: 0.1714 - val_accuracy: 0.9949\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1626 - accuracy: 0.9994\n",
            "Epoch 36: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1627 - accuracy: 0.9994 - val_loss: 0.1690 - val_accuracy: 0.9974\n",
            "Epoch 37/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1585 - accuracy: 0.9987\n",
            "Epoch 37: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1585 - accuracy: 0.9987 - val_loss: 0.1646 - val_accuracy: 0.9974\n",
            "Epoch 38/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1547 - accuracy: 0.9987\n",
            "Epoch 38: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1546 - accuracy: 0.9987 - val_loss: 0.1629 - val_accuracy: 0.9923\n",
            "Epoch 39/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1507 - accuracy: 1.0000\n",
            "Epoch 39: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1506 - accuracy: 1.0000 - val_loss: 0.1582 - val_accuracy: 0.9923\n",
            "Epoch 40/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1467 - accuracy: 0.9994\n",
            "Epoch 40: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1467 - accuracy: 0.9994 - val_loss: 0.1514 - val_accuracy: 0.9974\n",
            "Epoch 41/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1433 - accuracy: 1.0000\n",
            "Epoch 41: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1435 - accuracy: 1.0000 - val_loss: 0.1500 - val_accuracy: 0.9949\n",
            "Epoch 42/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1405 - accuracy: 0.9994\n",
            "Epoch 42: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1404 - accuracy: 0.9994 - val_loss: 0.1491 - val_accuracy: 0.9949\n",
            "Epoch 43/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1360 - accuracy: 0.9994\n",
            "Epoch 43: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1361 - accuracy: 0.9994 - val_loss: 0.1459 - val_accuracy: 0.9923\n",
            "Epoch 44/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1361 - accuracy: 0.9987\n",
            "Epoch 44: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1360 - accuracy: 0.9987 - val_loss: 0.1381 - val_accuracy: 0.9974\n",
            "Epoch 45/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1318 - accuracy: 0.9994\n",
            "Epoch 45: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1316 - accuracy: 0.9994 - val_loss: 0.1359 - val_accuracy: 0.9974\n",
            "Epoch 46/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1283 - accuracy: 0.9994\n",
            "Epoch 46: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1284 - accuracy: 0.9994 - val_loss: 0.1376 - val_accuracy: 0.9923\n",
            "Epoch 47/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1255 - accuracy: 0.9994\n",
            "Epoch 47: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1254 - accuracy: 0.9994 - val_loss: 0.1317 - val_accuracy: 0.9949\n",
            "Epoch 48/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1235 - accuracy: 0.9994\n",
            "Epoch 48: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1235 - accuracy: 0.9994 - val_loss: 0.1365 - val_accuracy: 0.9923\n",
            "Epoch 49/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1200 - accuracy: 0.9994\n",
            "Epoch 49: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1200 - accuracy: 0.9994 - val_loss: 0.1299 - val_accuracy: 0.9949\n",
            "Epoch 50/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1186 - accuracy: 0.9994\n",
            "Epoch 50: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1185 - accuracy: 0.9994 - val_loss: 0.1268 - val_accuracy: 0.9949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/53/assets\n",
            "\n",
            "\n",
            " 27%|██▋       | 54/200 [2:11:23<7:38:11, 188.30s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.3047 - accuracy: 0.6418\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 25ms/step - loss: 1.3009 - accuracy: 0.6436 - val_loss: 1.5800 - val_accuracy: 0.5371\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4614 - accuracy: 0.9702\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.4606 - accuracy: 0.9699 - val_loss: 1.2214 - val_accuracy: 0.5243\n",
            "Epoch 3/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2921 - accuracy: 0.9929\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.2921 - accuracy: 0.9929 - val_loss: 0.4647 - val_accuracy: 0.9642\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2325 - accuracy: 0.9948\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2319 - accuracy: 0.9949 - val_loss: 0.2165 - val_accuracy: 0.9898\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1888 - accuracy: 0.9974\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1888 - accuracy: 0.9974 - val_loss: 0.1799 - val_accuracy: 0.9898\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1712 - accuracy: 0.9968\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1710 - accuracy: 0.9968 - val_loss: 0.1586 - val_accuracy: 0.9949\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1461 - accuracy: 0.9987\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1460 - accuracy: 0.9987 - val_loss: 0.1493 - val_accuracy: 0.9949\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1298 - accuracy: 0.9994\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1299 - accuracy: 0.9994 - val_loss: 0.1324 - val_accuracy: 0.9949\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1284 - accuracy: 0.9981\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1282 - accuracy: 0.9981 - val_loss: 0.1303 - val_accuracy: 0.9923\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1123 - accuracy: 0.9994\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1123 - accuracy: 0.9994 - val_loss: 0.1162 - val_accuracy: 0.9949\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1062 - accuracy: 0.9987\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1060 - accuracy: 0.9987 - val_loss: 0.1089 - val_accuracy: 0.9923\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0988 - accuracy: 0.9987\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0987 - accuracy: 0.9987 - val_loss: 0.1256 - val_accuracy: 0.9872\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0896 - accuracy: 1.0000\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0897 - accuracy: 1.0000 - val_loss: 0.1031 - val_accuracy: 0.9898\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0831 - accuracy: 0.9994\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0830 - accuracy: 0.9994 - val_loss: 0.0971 - val_accuracy: 0.9923\n",
            "Epoch 15/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0805 - accuracy: 0.9994\n",
            "Epoch 15: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0805 - accuracy: 0.9994 - val_loss: 0.1260 - val_accuracy: 0.9872\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0755 - accuracy: 1.0000\n",
            "Epoch 16: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0755 - accuracy: 1.0000 - val_loss: 0.0878 - val_accuracy: 0.9923\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0844 - accuracy: 0.9987\n",
            "Epoch 17: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0863 - accuracy: 0.9981 - val_loss: 0.0981 - val_accuracy: 0.9974\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0854 - accuracy: 0.9981\n",
            "Epoch 18: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0853 - accuracy: 0.9981 - val_loss: 0.0873 - val_accuracy: 0.9949\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0815 - accuracy: 0.9948\n",
            "Epoch 19: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0814 - accuracy: 0.9949 - val_loss: 0.0926 - val_accuracy: 0.9949\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0674 - accuracy: 1.0000\n",
            "Epoch 20: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0672 - accuracy: 1.0000 - val_loss: 0.0829 - val_accuracy: 0.9923\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0645 - accuracy: 0.9994\n",
            "Epoch 21: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0644 - accuracy: 0.9994 - val_loss: 0.0779 - val_accuracy: 0.9949\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0612 - accuracy: 1.0000\n",
            "Epoch 22: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0612 - accuracy: 1.0000 - val_loss: 0.0782 - val_accuracy: 0.9949\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0600 - accuracy: 1.0000\n",
            "Epoch 23: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0600 - accuracy: 1.0000 - val_loss: 0.0693 - val_accuracy: 0.9974\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0595 - accuracy: 1.0000\n",
            "Epoch 24: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0595 - accuracy: 1.0000 - val_loss: 0.0750 - val_accuracy: 0.9923\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0571 - accuracy: 1.0000\n",
            "Epoch 25: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0570 - accuracy: 1.0000 - val_loss: 0.0775 - val_accuracy: 0.9923\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0549 - accuracy: 1.0000\n",
            "Epoch 26: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0549 - accuracy: 1.0000 - val_loss: 0.0669 - val_accuracy: 0.9949\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0558 - accuracy: 1.0000\n",
            "Epoch 27: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0558 - accuracy: 1.0000 - val_loss: 0.0826 - val_accuracy: 0.9923\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0552 - accuracy: 1.0000\n",
            "Epoch 28: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0552 - accuracy: 1.0000 - val_loss: 0.0788 - val_accuracy: 0.9949\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0511 - accuracy: 1.0000\n",
            "Epoch 29: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0511 - accuracy: 1.0000 - val_loss: 0.0643 - val_accuracy: 0.9949\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0492 - accuracy: 1.0000\n",
            "Epoch 30: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0492 - accuracy: 1.0000 - val_loss: 0.0698 - val_accuracy: 0.9949\n",
            "Epoch 31/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0482 - accuracy: 1.0000\n",
            "Epoch 31: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0481 - accuracy: 1.0000 - val_loss: 0.0639 - val_accuracy: 0.9949\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0466 - accuracy: 1.0000\n",
            "Epoch 32: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0466 - accuracy: 1.0000 - val_loss: 0.0660 - val_accuracy: 0.9923\n",
            "Epoch 33/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0552 - accuracy: 0.9961\n",
            "Epoch 33: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0558 - accuracy: 0.9962 - val_loss: 0.0805 - val_accuracy: 0.9898\n",
            "Epoch 34/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0682 - accuracy: 0.9961\n",
            "Epoch 34: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0680 - accuracy: 0.9962 - val_loss: 0.0642 - val_accuracy: 0.9949\n",
            "Epoch 35/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0493 - accuracy: 0.9994\n",
            "Epoch 35: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0492 - accuracy: 0.9994 - val_loss: 0.0614 - val_accuracy: 0.9923\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0456 - accuracy: 1.0000\n",
            "Epoch 36: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0456 - accuracy: 1.0000 - val_loss: 0.0594 - val_accuracy: 0.9949\n",
            "Epoch 37/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0441 - accuracy: 1.0000\n",
            "Epoch 37: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0440 - accuracy: 1.0000 - val_loss: 0.0608 - val_accuracy: 0.9949\n",
            "Epoch 38/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0428 - accuracy: 1.0000\n",
            "Epoch 38: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0429 - accuracy: 1.0000 - val_loss: 0.0575 - val_accuracy: 0.9949\n",
            "Epoch 39/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0420 - accuracy: 1.0000\n",
            "Epoch 39: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0420 - accuracy: 1.0000 - val_loss: 0.0591 - val_accuracy: 0.9949\n",
            "Epoch 40/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0415 - accuracy: 1.0000\n",
            "Epoch 40: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0415 - accuracy: 1.0000 - val_loss: 0.0596 - val_accuracy: 0.9949\n",
            "Epoch 41/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0407 - accuracy: 1.0000\n",
            "Epoch 41: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0407 - accuracy: 1.0000 - val_loss: 0.0573 - val_accuracy: 0.9923\n",
            "Epoch 42/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0397 - accuracy: 1.0000\n",
            "Epoch 42: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0397 - accuracy: 1.0000 - val_loss: 0.0549 - val_accuracy: 0.9949\n",
            "Epoch 43/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0390 - accuracy: 1.0000\n",
            "Epoch 43: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0390 - accuracy: 1.0000 - val_loss: 0.0558 - val_accuracy: 0.9949\n",
            "Epoch 44/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0378 - accuracy: 1.0000\n",
            "Epoch 44: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0378 - accuracy: 1.0000 - val_loss: 0.0527 - val_accuracy: 0.9949\n",
            "Epoch 45/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0378 - accuracy: 1.0000\n",
            "Epoch 45: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0378 - accuracy: 1.0000 - val_loss: 0.0510 - val_accuracy: 0.9974\n",
            "Epoch 46/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0368 - accuracy: 1.0000\n",
            "Epoch 46: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0368 - accuracy: 1.0000 - val_loss: 0.0551 - val_accuracy: 0.9949\n",
            "Epoch 47/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0385 - accuracy: 1.0000\n",
            "Epoch 47: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0384 - accuracy: 1.0000 - val_loss: 0.0794 - val_accuracy: 0.9847\n",
            "Epoch 48/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0536 - accuracy: 0.9981\n",
            "Epoch 48: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0536 - accuracy: 0.9981 - val_loss: 0.0601 - val_accuracy: 0.9923\n",
            "Epoch 49/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0452 - accuracy: 0.9994\n",
            "Epoch 49: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0452 - accuracy: 0.9994 - val_loss: 0.0653 - val_accuracy: 0.9923\n",
            "Epoch 50/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0391 - accuracy: 1.0000\n",
            "Epoch 50: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0391 - accuracy: 1.0000 - val_loss: 0.0556 - val_accuracy: 0.9923\n",
            "Epoch 50: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/54/assets\n",
            "\n",
            "\n",
            " 28%|██▊       | 55/200 [2:15:08<8:02:00, 199.45s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.2353 - accuracy: 0.6908\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 15ms/step - loss: 1.2252 - accuracy: 0.6942 - val_loss: 1.7077 - val_accuracy: 0.2890\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4050 - accuracy: 0.9475\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.4056 - accuracy: 0.9468 - val_loss: 1.5849 - val_accuracy: 0.3376\n",
            "Epoch 3/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.2508 - accuracy: 0.9758\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.2500 - accuracy: 0.9763 - val_loss: 0.4015 - val_accuracy: 0.9412\n",
            "Epoch 4/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1731 - accuracy: 0.9928\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1728 - accuracy: 0.9929 - val_loss: 0.3337 - val_accuracy: 0.9207\n",
            "Epoch 5/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1717 - accuracy: 0.9902\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.1713 - accuracy: 0.9904 - val_loss: 0.2399 - val_accuracy: 0.9642\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1501 - accuracy: 0.9903\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1499 - accuracy: 0.9904 - val_loss: 0.4363 - val_accuracy: 0.9207\n",
            "Epoch 7/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2452 - accuracy: 0.9613\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.2448 - accuracy: 0.9615 - val_loss: 0.2379 - val_accuracy: 0.9668\n",
            "Epoch 8/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1264 - accuracy: 0.9961\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1264 - accuracy: 0.9962 - val_loss: 0.1536 - val_accuracy: 0.9847\n",
            "Epoch 9/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1091 - accuracy: 0.9981\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1091 - accuracy: 0.9981 - val_loss: 0.1313 - val_accuracy: 0.9898\n",
            "Epoch 10/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0934 - accuracy: 1.0000\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.0933 - accuracy: 1.0000 - val_loss: 0.1205 - val_accuracy: 0.9821\n",
            "Epoch 11/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0858 - accuracy: 1.0000\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0862 - accuracy: 1.0000 - val_loss: 0.1205 - val_accuracy: 0.9898\n",
            "Epoch 12/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0887 - accuracy: 1.0000\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.0886 - accuracy: 1.0000 - val_loss: 0.1070 - val_accuracy: 0.9949\n",
            "Epoch 13/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0787 - accuracy: 1.0000\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0787 - accuracy: 1.0000 - val_loss: 0.0930 - val_accuracy: 0.9974\n",
            "Epoch 14/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0713 - accuracy: 1.0000\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.0713 - accuracy: 1.0000 - val_loss: 0.0913 - val_accuracy: 0.9923\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0715 - accuracy: 0.9987\n",
            "Epoch 15: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0728 - accuracy: 0.9981 - val_loss: 0.2035 - val_accuracy: 0.9668\n",
            "Epoch 16/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.4420 - accuracy: 0.9202\n",
            "Epoch 16: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.4366 - accuracy: 0.9218 - val_loss: 0.4495 - val_accuracy: 0.9616\n",
            "Epoch 17/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1849 - accuracy: 0.9871\n",
            "Epoch 17: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1846 - accuracy: 0.9872 - val_loss: 0.1875 - val_accuracy: 0.9847\n",
            "Epoch 18/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1138 - accuracy: 0.9993\n",
            "Epoch 18: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1134 - accuracy: 0.9994 - val_loss: 0.1538 - val_accuracy: 0.9898\n",
            "Epoch 19/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1017 - accuracy: 0.9980\n",
            "Epoch 19: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.1014 - accuracy: 0.9981 - val_loss: 0.1116 - val_accuracy: 0.9923\n",
            "Epoch 19: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/55/assets\n",
            "\n",
            "\n",
            " 28%|██▊       | 56/200 [2:16:02<6:13:52, 155.78s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.7481 - accuracy: 0.4212\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 16ms/step - loss: 1.7481 - accuracy: 0.4212 - val_loss: 1.7815 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.4100 - accuracy: 0.5308\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 1.4073 - accuracy: 0.5321 - val_loss: 2.3348 - val_accuracy: 0.2916\n",
            "Epoch 3/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.2114 - accuracy: 0.6198\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 1.2076 - accuracy: 0.6212 - val_loss: 1.1721 - val_accuracy: 0.5627\n",
            "Epoch 4/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.0563 - accuracy: 0.6654\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 1.0563 - accuracy: 0.6654 - val_loss: 1.3535 - val_accuracy: 0.5448\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8032 - accuracy: 0.7817\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.8023 - accuracy: 0.7808 - val_loss: 1.1391 - val_accuracy: 0.6522\n",
            "Epoch 6/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.7161 - accuracy: 0.8288\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.7110 - accuracy: 0.8308 - val_loss: 0.6426 - val_accuracy: 0.8593\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6424 - accuracy: 0.8653\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.6437 - accuracy: 0.8647 - val_loss: 0.9310 - val_accuracy: 0.7366\n",
            "Epoch 8/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4990 - accuracy: 0.8833\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.4990 - accuracy: 0.8833 - val_loss: 0.5990 - val_accuracy: 0.8312\n",
            "Epoch 9/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.6299 - accuracy: 0.8634\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.6283 - accuracy: 0.8641 - val_loss: 3.9011 - val_accuracy: 0.4373\n",
            "Epoch 10/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.3873 - accuracy: 0.9234\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.3856 - accuracy: 0.9244 - val_loss: 0.3241 - val_accuracy: 0.9386\n",
            "Epoch 11/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2992 - accuracy: 0.9500\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.2992 - accuracy: 0.9500 - val_loss: 0.5227 - val_accuracy: 0.9079\n",
            "Epoch 12/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.3963 - accuracy: 0.9156\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.3995 - accuracy: 0.9154 - val_loss: 0.4553 - val_accuracy: 0.8798\n",
            "Epoch 13/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2723 - accuracy: 0.9536\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.2741 - accuracy: 0.9532 - val_loss: 0.3691 - val_accuracy: 0.9079\n",
            "Epoch 14/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2920 - accuracy: 0.9455\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.2920 - accuracy: 0.9455 - val_loss: 0.6738 - val_accuracy: 0.9003\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2901 - accuracy: 0.9443\n",
            "Epoch 15: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.2908 - accuracy: 0.9442 - val_loss: 0.3804 - val_accuracy: 0.9335\n",
            "Epoch 15: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/56/assets\n",
            "\n",
            "\n",
            " 28%|██▊       | 57/200 [2:16:46<4:51:32, 122.33s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.7553 - accuracy: 0.6049\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 18ms/step - loss: 1.7508 - accuracy: 0.6058 - val_loss: 1.7918 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.9926 - accuracy: 0.8782\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.9931 - accuracy: 0.8776 - val_loss: 1.6233 - val_accuracy: 0.5422\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7228 - accuracy: 0.9553\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.7212 - accuracy: 0.9558 - val_loss: 0.9575 - val_accuracy: 0.8721\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5983 - accuracy: 0.9722\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.5971 - accuracy: 0.9724 - val_loss: 0.5542 - val_accuracy: 0.9795\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5125 - accuracy: 0.9838\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.5123 - accuracy: 0.9840 - val_loss: 0.4901 - val_accuracy: 0.9898\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4476 - accuracy: 0.9935\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.4476 - accuracy: 0.9936 - val_loss: 0.4987 - val_accuracy: 0.9591\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4067 - accuracy: 0.9955\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.4065 - accuracy: 0.9955 - val_loss: 0.4088 - val_accuracy: 0.9898\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3746 - accuracy: 0.9929\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.3744 - accuracy: 0.9929 - val_loss: 0.3647 - val_accuracy: 0.9949\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3353 - accuracy: 0.9981\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.3351 - accuracy: 0.9981 - val_loss: 0.3497 - val_accuracy: 0.9847\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3093 - accuracy: 0.9981\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.3096 - accuracy: 0.9981 - val_loss: 0.3098 - val_accuracy: 0.9923\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2871 - accuracy: 0.9994\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.2872 - accuracy: 0.9994 - val_loss: 0.3125 - val_accuracy: 0.9898\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2685 - accuracy: 1.0000\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.2688 - accuracy: 1.0000 - val_loss: 0.2790 - val_accuracy: 0.9898\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2504 - accuracy: 0.9987\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.2508 - accuracy: 0.9981 - val_loss: 0.2675 - val_accuracy: 0.9872\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2345 - accuracy: 0.9974\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.2344 - accuracy: 0.9974 - val_loss: 0.2483 - val_accuracy: 0.9898\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2199 - accuracy: 1.0000\n",
            "Epoch 15: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.2196 - accuracy: 1.0000 - val_loss: 0.2340 - val_accuracy: 0.9923\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2097 - accuracy: 0.9987\n",
            "Epoch 16: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.2098 - accuracy: 0.9987 - val_loss: 0.2245 - val_accuracy: 0.9923\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1976 - accuracy: 0.9994\n",
            "Epoch 17: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1975 - accuracy: 0.9994 - val_loss: 0.2190 - val_accuracy: 0.9923\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1872 - accuracy: 1.0000\n",
            "Epoch 18: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1873 - accuracy: 1.0000 - val_loss: 0.2201 - val_accuracy: 0.9898\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1778 - accuracy: 0.9994\n",
            "Epoch 19: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1777 - accuracy: 0.9994 - val_loss: 0.1907 - val_accuracy: 0.9949\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1697 - accuracy: 1.0000\n",
            "Epoch 20: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1697 - accuracy: 1.0000 - val_loss: 0.1838 - val_accuracy: 0.9949\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1667 - accuracy: 0.9994\n",
            "Epoch 21: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1665 - accuracy: 0.9994 - val_loss: 0.1793 - val_accuracy: 0.9923\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1581 - accuracy: 1.0000\n",
            "Epoch 22: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1581 - accuracy: 1.0000 - val_loss: 0.1851 - val_accuracy: 0.9898\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1528 - accuracy: 1.0000\n",
            "Epoch 23: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1527 - accuracy: 1.0000 - val_loss: 0.1743 - val_accuracy: 0.9923\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1489 - accuracy: 0.9994\n",
            "Epoch 24: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1488 - accuracy: 0.9994 - val_loss: 0.1697 - val_accuracy: 0.9923\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1425 - accuracy: 1.0000\n",
            "Epoch 25: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1424 - accuracy: 1.0000 - val_loss: 0.1628 - val_accuracy: 0.9923\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1406 - accuracy: 1.0000\n",
            "Epoch 26: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1406 - accuracy: 1.0000 - val_loss: 0.1670 - val_accuracy: 0.9923\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1372 - accuracy: 1.0000\n",
            "Epoch 27: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1372 - accuracy: 1.0000 - val_loss: 0.1639 - val_accuracy: 0.9949\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1355 - accuracy: 1.0000\n",
            "Epoch 28: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1354 - accuracy: 1.0000 - val_loss: 0.1759 - val_accuracy: 0.9872\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1295 - accuracy: 1.0000\n",
            "Epoch 29: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1294 - accuracy: 1.0000 - val_loss: 0.1477 - val_accuracy: 0.9949\n",
            "Epoch 30/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1254 - accuracy: 1.0000\n",
            "Epoch 30: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1254 - accuracy: 1.0000 - val_loss: 0.1482 - val_accuracy: 0.9923\n",
            "Epoch 31/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1218 - accuracy: 1.0000\n",
            "Epoch 31: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1219 - accuracy: 1.0000 - val_loss: 0.1431 - val_accuracy: 0.9949\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1196 - accuracy: 1.0000\n",
            "Epoch 32: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1197 - accuracy: 1.0000 - val_loss: 0.1395 - val_accuracy: 0.9923\n",
            "Epoch 33/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1171 - accuracy: 1.0000\n",
            "Epoch 33: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1174 - accuracy: 1.0000 - val_loss: 0.1441 - val_accuracy: 0.9949\n",
            "Epoch 34/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1155 - accuracy: 1.0000\n",
            "Epoch 34: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1155 - accuracy: 1.0000 - val_loss: 0.1449 - val_accuracy: 0.9923\n",
            "Epoch 35/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1113 - accuracy: 1.0000\n",
            "Epoch 35: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1113 - accuracy: 1.0000 - val_loss: 0.1345 - val_accuracy: 0.9949\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1100 - accuracy: 1.0000\n",
            "Epoch 36: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1099 - accuracy: 1.0000 - val_loss: 0.1302 - val_accuracy: 0.9923\n",
            "Epoch 37/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1079 - accuracy: 1.0000\n",
            "Epoch 37: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1079 - accuracy: 1.0000 - val_loss: 0.1273 - val_accuracy: 0.9949\n",
            "Epoch 38/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1053 - accuracy: 1.0000\n",
            "Epoch 38: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1053 - accuracy: 1.0000 - val_loss: 0.1288 - val_accuracy: 0.9949\n",
            "Epoch 39/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1033 - accuracy: 1.0000\n",
            "Epoch 39: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1033 - accuracy: 1.0000 - val_loss: 0.1264 - val_accuracy: 0.9949\n",
            "Epoch 40/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1004 - accuracy: 1.0000\n",
            "Epoch 40: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1004 - accuracy: 1.0000 - val_loss: 0.1276 - val_accuracy: 0.9923\n",
            "Epoch 41/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0980 - accuracy: 1.0000\n",
            "Epoch 41: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0979 - accuracy: 1.0000 - val_loss: 0.1232 - val_accuracy: 0.9898\n",
            "Epoch 42/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1167 - accuracy: 0.9968\n",
            "Epoch 42: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1165 - accuracy: 0.9968 - val_loss: 0.1670 - val_accuracy: 0.9795\n",
            "Epoch 43/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1021 - accuracy: 1.0000\n",
            "Epoch 43: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1020 - accuracy: 1.0000 - val_loss: 0.1271 - val_accuracy: 0.9949\n",
            "Epoch 44/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0955 - accuracy: 1.0000\n",
            "Epoch 44: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0955 - accuracy: 1.0000 - val_loss: 0.1225 - val_accuracy: 0.9949\n",
            "Epoch 45/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0930 - accuracy: 1.0000\n",
            "Epoch 45: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0930 - accuracy: 1.0000 - val_loss: 0.1198 - val_accuracy: 0.9949\n",
            "Epoch 46/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0904 - accuracy: 1.0000\n",
            "Epoch 46: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0904 - accuracy: 1.0000 - val_loss: 0.1177 - val_accuracy: 0.9949\n",
            "Epoch 47/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0883 - accuracy: 1.0000\n",
            "Epoch 47: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0883 - accuracy: 1.0000 - val_loss: 0.1190 - val_accuracy: 0.9923\n",
            "Epoch 48/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0869 - accuracy: 1.0000\n",
            "Epoch 48: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0869 - accuracy: 1.0000 - val_loss: 0.1122 - val_accuracy: 0.9949\n",
            "Epoch 49/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0849 - accuracy: 1.0000\n",
            "Epoch 49: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0848 - accuracy: 1.0000 - val_loss: 0.1126 - val_accuracy: 0.9949\n",
            "Epoch 50/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0826 - accuracy: 1.0000\n",
            "Epoch 50: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0826 - accuracy: 1.0000 - val_loss: 0.1082 - val_accuracy: 0.9949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/57/assets\n",
            "\n",
            "\n",
            " 29%|██▉       | 58/200 [2:20:14<5:49:47, 147.80s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 2.3104 - accuracy: 0.2821\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 8s 34ms/step - loss: 2.3104 - accuracy: 0.2821 - val_loss: 1.9196 - val_accuracy: 0.2992\n",
            "Epoch 2/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.8491 - accuracy: 0.5327\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 32ms/step - loss: 1.8491 - accuracy: 0.5327 - val_loss: 1.9022 - val_accuracy: 0.3529\n",
            "Epoch 3/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6090 - accuracy: 0.6654\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 1.6090 - accuracy: 0.6654 - val_loss: 1.7063 - val_accuracy: 0.4834\n",
            "Epoch 4/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.3989 - accuracy: 0.7449\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 32ms/step - loss: 1.3989 - accuracy: 0.7449 - val_loss: 1.3052 - val_accuracy: 0.7954\n",
            "Epoch 5/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.2333 - accuracy: 0.8019\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 1.2333 - accuracy: 0.8019 - val_loss: 1.1256 - val_accuracy: 0.8542\n",
            "Epoch 6/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.0951 - accuracy: 0.8635\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 32ms/step - loss: 1.0951 - accuracy: 0.8635 - val_loss: 1.0023 - val_accuracy: 0.9003\n",
            "Epoch 7/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.9917 - accuracy: 0.8949\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 32ms/step - loss: 0.9917 - accuracy: 0.8949 - val_loss: 0.9070 - val_accuracy: 0.9233\n",
            "Epoch 8/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.9006 - accuracy: 0.9128\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 32ms/step - loss: 0.9006 - accuracy: 0.9128 - val_loss: 0.8399 - val_accuracy: 0.9642\n",
            "Epoch 9/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.8288 - accuracy: 0.9410\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 32ms/step - loss: 0.8288 - accuracy: 0.9410 - val_loss: 0.7795 - val_accuracy: 0.9719\n",
            "Epoch 10/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.7760 - accuracy: 0.9590\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 32ms/step - loss: 0.7760 - accuracy: 0.9590 - val_loss: 0.7289 - val_accuracy: 0.9668\n",
            "Epoch 11/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.7315 - accuracy: 0.9635\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 32ms/step - loss: 0.7315 - accuracy: 0.9635 - val_loss: 0.6887 - val_accuracy: 0.9795\n",
            "Epoch 12/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6960 - accuracy: 0.9724\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 32ms/step - loss: 0.6960 - accuracy: 0.9724 - val_loss: 0.6617 - val_accuracy: 0.9693\n",
            "Epoch 13/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6635 - accuracy: 0.9724\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 32ms/step - loss: 0.6635 - accuracy: 0.9724 - val_loss: 0.6300 - val_accuracy: 0.9795\n",
            "Epoch 14/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6289 - accuracy: 0.9801\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 32ms/step - loss: 0.6289 - accuracy: 0.9801 - val_loss: 0.6078 - val_accuracy: 0.9821\n",
            "Epoch 15/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6049 - accuracy: 0.9827\n",
            "Epoch 15: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 32ms/step - loss: 0.6049 - accuracy: 0.9827 - val_loss: 0.5838 - val_accuracy: 0.9821\n",
            "Epoch 16/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5842 - accuracy: 0.9821\n",
            "Epoch 16: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 32ms/step - loss: 0.5842 - accuracy: 0.9821 - val_loss: 0.5628 - val_accuracy: 0.9821\n",
            "Epoch 17/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5617 - accuracy: 0.9897\n",
            "Epoch 17: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 32ms/step - loss: 0.5617 - accuracy: 0.9897 - val_loss: 0.5465 - val_accuracy: 0.9821\n",
            "Epoch 18/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5410 - accuracy: 0.9833\n",
            "Epoch 18: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 32ms/step - loss: 0.5410 - accuracy: 0.9833 - val_loss: 0.5292 - val_accuracy: 0.9847\n",
            "Epoch 19/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5246 - accuracy: 0.9897\n",
            "Epoch 19: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 32ms/step - loss: 0.5246 - accuracy: 0.9897 - val_loss: 0.5159 - val_accuracy: 0.9847\n",
            "Epoch 20/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5120 - accuracy: 0.9936\n",
            "Epoch 20: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 32ms/step - loss: 0.5120 - accuracy: 0.9936 - val_loss: 0.5044 - val_accuracy: 0.9872\n",
            "Epoch 21/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4934 - accuracy: 0.9917\n",
            "Epoch 21: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 32ms/step - loss: 0.4934 - accuracy: 0.9917 - val_loss: 0.4886 - val_accuracy: 0.9898\n",
            "Epoch 22/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4794 - accuracy: 0.9929\n",
            "Epoch 22: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 32ms/step - loss: 0.4794 - accuracy: 0.9929 - val_loss: 0.4713 - val_accuracy: 0.9923\n",
            "Epoch 23/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4679 - accuracy: 0.9962\n",
            "Epoch 23: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 0.4679 - accuracy: 0.9962 - val_loss: 0.4613 - val_accuracy: 0.9898\n",
            "Epoch 24/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4571 - accuracy: 0.9923\n",
            "Epoch 24: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 32ms/step - loss: 0.4571 - accuracy: 0.9923 - val_loss: 0.4487 - val_accuracy: 0.9923\n",
            "Epoch 25/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4456 - accuracy: 0.9923\n",
            "Epoch 25: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 32ms/step - loss: 0.4456 - accuracy: 0.9923 - val_loss: 0.4414 - val_accuracy: 0.9923\n",
            "Epoch 26/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4364 - accuracy: 0.9962\n",
            "Epoch 26: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 32ms/step - loss: 0.4364 - accuracy: 0.9962 - val_loss: 0.4300 - val_accuracy: 0.9923\n",
            "Epoch 27/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4225 - accuracy: 0.9974\n",
            "Epoch 27: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 32ms/step - loss: 0.4225 - accuracy: 0.9974 - val_loss: 0.4185 - val_accuracy: 0.9949\n",
            "Epoch 28/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4150 - accuracy: 0.9942\n",
            "Epoch 28: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 32ms/step - loss: 0.4150 - accuracy: 0.9942 - val_loss: 0.4134 - val_accuracy: 0.9923\n",
            "Epoch 29/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4076 - accuracy: 0.9936\n",
            "Epoch 29: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 32ms/step - loss: 0.4076 - accuracy: 0.9936 - val_loss: 0.4075 - val_accuracy: 0.9898\n",
            "Epoch 30/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3976 - accuracy: 0.9955\n",
            "Epoch 30: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 32ms/step - loss: 0.3976 - accuracy: 0.9955 - val_loss: 0.3990 - val_accuracy: 0.9898\n",
            "Epoch 31/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3875 - accuracy: 0.9981\n",
            "Epoch 31: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 32ms/step - loss: 0.3875 - accuracy: 0.9981 - val_loss: 0.3859 - val_accuracy: 0.9949\n",
            "Epoch 32/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3814 - accuracy: 0.9955\n",
            "Epoch 32: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 32ms/step - loss: 0.3814 - accuracy: 0.9955 - val_loss: 0.3795 - val_accuracy: 0.9923\n",
            "Epoch 33/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3747 - accuracy: 0.9974\n",
            "Epoch 33: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 32ms/step - loss: 0.3747 - accuracy: 0.9974 - val_loss: 0.3709 - val_accuracy: 0.9949\n",
            "Epoch 34/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3664 - accuracy: 0.9968\n",
            "Epoch 34: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 32ms/step - loss: 0.3664 - accuracy: 0.9968 - val_loss: 0.3667 - val_accuracy: 0.9949\n",
            "Epoch 35/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3593 - accuracy: 0.9974\n",
            "Epoch 35: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 32ms/step - loss: 0.3593 - accuracy: 0.9974 - val_loss: 0.3615 - val_accuracy: 0.9923\n",
            "Epoch 36/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3510 - accuracy: 0.9994\n",
            "Epoch 36: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 32ms/step - loss: 0.3510 - accuracy: 0.9994 - val_loss: 0.3523 - val_accuracy: 0.9949\n",
            "Epoch 37/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3452 - accuracy: 0.9981\n",
            "Epoch 37: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 32ms/step - loss: 0.3452 - accuracy: 0.9981 - val_loss: 0.3500 - val_accuracy: 0.9949\n",
            "Epoch 38/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3402 - accuracy: 0.9981\n",
            "Epoch 38: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 32ms/step - loss: 0.3402 - accuracy: 0.9981 - val_loss: 0.3423 - val_accuracy: 0.9923\n",
            "Epoch 39/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3339 - accuracy: 0.9987\n",
            "Epoch 39: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 32ms/step - loss: 0.3339 - accuracy: 0.9987 - val_loss: 0.3386 - val_accuracy: 0.9923\n",
            "Epoch 40/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3304 - accuracy: 0.9981\n",
            "Epoch 40: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 32ms/step - loss: 0.3304 - accuracy: 0.9981 - val_loss: 0.3301 - val_accuracy: 0.9949\n",
            "Epoch 41/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3235 - accuracy: 0.9987\n",
            "Epoch 41: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 32ms/step - loss: 0.3235 - accuracy: 0.9987 - val_loss: 0.3324 - val_accuracy: 0.9923\n",
            "Epoch 42/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3175 - accuracy: 0.9994\n",
            "Epoch 42: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 32ms/step - loss: 0.3175 - accuracy: 0.9994 - val_loss: 0.3226 - val_accuracy: 0.9949\n",
            "Epoch 43/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3130 - accuracy: 0.9994\n",
            "Epoch 43: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 32ms/step - loss: 0.3130 - accuracy: 0.9994 - val_loss: 0.3140 - val_accuracy: 0.9949\n",
            "Epoch 44/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3086 - accuracy: 0.9994\n",
            "Epoch 44: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 32ms/step - loss: 0.3086 - accuracy: 0.9994 - val_loss: 0.3141 - val_accuracy: 0.9949\n",
            "Epoch 45/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3033 - accuracy: 0.9994\n",
            "Epoch 45: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 32ms/step - loss: 0.3033 - accuracy: 0.9994 - val_loss: 0.3067 - val_accuracy: 0.9974\n",
            "Epoch 46/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2997 - accuracy: 0.9994\n",
            "Epoch 46: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 32ms/step - loss: 0.2997 - accuracy: 0.9994 - val_loss: 0.3045 - val_accuracy: 0.9949\n",
            "Epoch 47/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2971 - accuracy: 0.9981\n",
            "Epoch 47: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 32ms/step - loss: 0.2971 - accuracy: 0.9981 - val_loss: 0.2992 - val_accuracy: 0.9949\n",
            "Epoch 48/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2924 - accuracy: 0.9981\n",
            "Epoch 48: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 32ms/step - loss: 0.2924 - accuracy: 0.9981 - val_loss: 0.2943 - val_accuracy: 0.9974\n",
            "Epoch 49/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2878 - accuracy: 0.9994\n",
            "Epoch 49: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 32ms/step - loss: 0.2878 - accuracy: 0.9994 - val_loss: 0.2891 - val_accuracy: 0.9974\n",
            "Epoch 50/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2838 - accuracy: 0.9987\n",
            "Epoch 50: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.2838 - accuracy: 0.9987 - val_loss: 0.2871 - val_accuracy: 0.9949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/58/assets\n",
            "\n",
            "\n",
            " 30%|██▉       | 59/200 [2:25:41<7:53:50, 201.63s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.7640 - accuracy: 0.5173\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 16ms/step - loss: 1.7640 - accuracy: 0.5173 - val_loss: 1.7922 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.9605 - accuracy: 0.8628\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.9605 - accuracy: 0.8628 - val_loss: 1.9627 - val_accuracy: 0.4066\n",
            "Epoch 3/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.6565 - accuracy: 0.9535\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.6551 - accuracy: 0.9545 - val_loss: 1.0943 - val_accuracy: 0.7008\n",
            "Epoch 4/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5312 - accuracy: 0.9737\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.5312 - accuracy: 0.9737 - val_loss: 0.4760 - val_accuracy: 0.9668\n",
            "Epoch 5/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4478 - accuracy: 0.9814\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.4478 - accuracy: 0.9814 - val_loss: 0.4216 - val_accuracy: 0.9872\n",
            "Epoch 6/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.9889\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.3842 - accuracy: 0.9878 - val_loss: 0.3760 - val_accuracy: 0.9795\n",
            "Epoch 7/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3475 - accuracy: 0.9915\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.3474 - accuracy: 0.9917 - val_loss: 0.3304 - val_accuracy: 0.9898\n",
            "Epoch 8/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3053 - accuracy: 0.9928\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.3051 - accuracy: 0.9929 - val_loss: 0.3000 - val_accuracy: 0.9898\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2756 - accuracy: 0.9955\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.2751 - accuracy: 0.9955 - val_loss: 0.2933 - val_accuracy: 0.9898\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2529 - accuracy: 0.9974\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.2526 - accuracy: 0.9974 - val_loss: 0.2582 - val_accuracy: 0.9949\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2321 - accuracy: 0.9994\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.2317 - accuracy: 0.9994 - val_loss: 0.2839 - val_accuracy: 0.9847\n",
            "Epoch 12/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2177 - accuracy: 0.9974\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.2173 - accuracy: 0.9974 - val_loss: 0.2267 - val_accuracy: 0.9923\n",
            "Epoch 13/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1984 - accuracy: 0.9980\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1988 - accuracy: 0.9981 - val_loss: 0.2091 - val_accuracy: 0.9974\n",
            "Epoch 14/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1860 - accuracy: 0.9993\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1868 - accuracy: 0.9987 - val_loss: 0.2079 - val_accuracy: 0.9923\n",
            "Epoch 15/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1776 - accuracy: 0.9994\n",
            "Epoch 15: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1776 - accuracy: 0.9994 - val_loss: 0.1800 - val_accuracy: 0.9974\n",
            "Epoch 16/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1607 - accuracy: 0.9993\n",
            "Epoch 16: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1606 - accuracy: 0.9994 - val_loss: 0.1869 - val_accuracy: 0.9898\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1541 - accuracy: 0.9994\n",
            "Epoch 17: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.1542 - accuracy: 0.9994 - val_loss: 0.1699 - val_accuracy: 0.9923\n",
            "Epoch 18/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1441 - accuracy: 1.0000\n",
            "Epoch 18: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.1442 - accuracy: 1.0000 - val_loss: 0.1569 - val_accuracy: 0.9923\n",
            "Epoch 19/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1407 - accuracy: 0.9987\n",
            "Epoch 19: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1405 - accuracy: 0.9987 - val_loss: 0.1524 - val_accuracy: 0.9898\n",
            "Epoch 20/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1301 - accuracy: 1.0000\n",
            "Epoch 20: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1300 - accuracy: 1.0000 - val_loss: 0.1474 - val_accuracy: 0.9923\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1259 - accuracy: 1.0000\n",
            "Epoch 21: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1259 - accuracy: 1.0000 - val_loss: 0.1501 - val_accuracy: 0.9923\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1225 - accuracy: 0.9987\n",
            "Epoch 22: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1228 - accuracy: 0.9987 - val_loss: 0.1365 - val_accuracy: 0.9923\n",
            "Epoch 23/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1166 - accuracy: 1.0000\n",
            "Epoch 23: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1166 - accuracy: 1.0000 - val_loss: 0.1416 - val_accuracy: 0.9923\n",
            "Epoch 24/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1116 - accuracy: 0.9987\n",
            "Epoch 24: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1116 - accuracy: 0.9987 - val_loss: 0.1430 - val_accuracy: 0.9898\n",
            "Epoch 25/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1076 - accuracy: 1.0000\n",
            "Epoch 25: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.1076 - accuracy: 1.0000 - val_loss: 0.1246 - val_accuracy: 0.9898\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1064 - accuracy: 0.9987\n",
            "Epoch 26: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1065 - accuracy: 0.9987 - val_loss: 0.1284 - val_accuracy: 0.9949\n",
            "Epoch 27/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1021 - accuracy: 1.0000\n",
            "Epoch 27: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1021 - accuracy: 1.0000 - val_loss: 0.1208 - val_accuracy: 0.9923\n",
            "Epoch 28/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0982 - accuracy: 1.0000\n",
            "Epoch 28: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0997 - accuracy: 0.9994 - val_loss: 0.1237 - val_accuracy: 0.9923\n",
            "Epoch 29/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0959 - accuracy: 1.0000\n",
            "Epoch 29: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0958 - accuracy: 1.0000 - val_loss: 0.1160 - val_accuracy: 0.9949\n",
            "Epoch 30/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0917 - accuracy: 1.0000\n",
            "Epoch 30: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0917 - accuracy: 1.0000 - val_loss: 0.1143 - val_accuracy: 0.9898\n",
            "Epoch 31/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0904 - accuracy: 1.0000\n",
            "Epoch 31: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0904 - accuracy: 1.0000 - val_loss: 0.1115 - val_accuracy: 0.9923\n",
            "Epoch 32/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0902 - accuracy: 1.0000\n",
            "Epoch 32: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.0901 - accuracy: 1.0000 - val_loss: 0.1118 - val_accuracy: 0.9923\n",
            "Epoch 33/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0871 - accuracy: 1.0000\n",
            "Epoch 33: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0871 - accuracy: 1.0000 - val_loss: 0.1085 - val_accuracy: 0.9949\n",
            "Epoch 34/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0832 - accuracy: 1.0000\n",
            "Epoch 34: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0833 - accuracy: 1.0000 - val_loss: 0.1054 - val_accuracy: 0.9923\n",
            "Epoch 35/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0810 - accuracy: 1.0000\n",
            "Epoch 35: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0809 - accuracy: 1.0000 - val_loss: 0.1134 - val_accuracy: 0.9898\n",
            "Epoch 36/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0804 - accuracy: 0.9993\n",
            "Epoch 36: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0804 - accuracy: 0.9994 - val_loss: 0.1066 - val_accuracy: 0.9923\n",
            "Epoch 37/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0774 - accuracy: 1.0000\n",
            "Epoch 37: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0774 - accuracy: 1.0000 - val_loss: 0.1049 - val_accuracy: 0.9872\n",
            "Epoch 38/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0783 - accuracy: 1.0000\n",
            "Epoch 38: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0783 - accuracy: 1.0000 - val_loss: 0.0996 - val_accuracy: 0.9923\n",
            "Epoch 39/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0763 - accuracy: 1.0000\n",
            "Epoch 39: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0762 - accuracy: 1.0000 - val_loss: 0.0998 - val_accuracy: 0.9898\n",
            "Epoch 40/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0729 - accuracy: 1.0000\n",
            "Epoch 40: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0729 - accuracy: 1.0000 - val_loss: 0.1035 - val_accuracy: 0.9923\n",
            "Epoch 41/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0733 - accuracy: 1.0000\n",
            "Epoch 41: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.0733 - accuracy: 1.0000 - val_loss: 0.0939 - val_accuracy: 0.9949\n",
            "Epoch 42/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0723 - accuracy: 1.0000\n",
            "Epoch 42: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0722 - accuracy: 1.0000 - val_loss: 0.0972 - val_accuracy: 0.9949\n",
            "Epoch 43/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0684 - accuracy: 1.0000\n",
            "Epoch 43: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0683 - accuracy: 1.0000 - val_loss: 0.0999 - val_accuracy: 0.9898\n",
            "Epoch 44/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0671 - accuracy: 1.0000\n",
            "Epoch 44: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0671 - accuracy: 1.0000 - val_loss: 0.1051 - val_accuracy: 0.9898\n",
            "Epoch 45/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0665 - accuracy: 1.0000\n",
            "Epoch 45: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0664 - accuracy: 1.0000 - val_loss: 0.0909 - val_accuracy: 0.9923\n",
            "Epoch 46/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0657 - accuracy: 1.0000\n",
            "Epoch 46: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0657 - accuracy: 1.0000 - val_loss: 0.1104 - val_accuracy: 0.9847\n",
            "Epoch 47/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0814 - accuracy: 0.9955\n",
            "Epoch 47: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0814 - accuracy: 0.9955 - val_loss: 0.1263 - val_accuracy: 0.9872\n",
            "Epoch 48/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0870 - accuracy: 0.9974\n",
            "Epoch 48: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0866 - accuracy: 0.9974 - val_loss: 0.1018 - val_accuracy: 0.9923\n",
            "Epoch 49/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0678 - accuracy: 1.0000\n",
            "Epoch 49: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0678 - accuracy: 1.0000 - val_loss: 0.0958 - val_accuracy: 0.9898\n",
            "Epoch 50/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0651 - accuracy: 1.0000\n",
            "Epoch 50: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.0651 - accuracy: 1.0000 - val_loss: 0.0911 - val_accuracy: 0.9923\n",
            "Epoch 50: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/59/assets\n",
            "\n",
            "\n",
            " 30%|███       | 60/200 [2:27:55<7:03:16, 181.40s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.8461 - accuracy: 0.2798\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 22ms/step - loss: 1.8463 - accuracy: 0.2801 - val_loss: 1.7177 - val_accuracy: 0.2634\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6936 - accuracy: 0.2636\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 1.6921 - accuracy: 0.2641 - val_loss: 1.6788 - val_accuracy: 0.2864\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6749 - accuracy: 0.2701\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.6740 - accuracy: 0.2705 - val_loss: 1.6544 - val_accuracy: 0.2864\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6561 - accuracy: 0.2837\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 1.6576 - accuracy: 0.2814 - val_loss: 1.6492 - val_accuracy: 0.2864\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6494 - accuracy: 0.2804\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 1.6503 - accuracy: 0.2795 - val_loss: 1.6431 - val_accuracy: 0.2864\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6418 - accuracy: 0.2830\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 1.6420 - accuracy: 0.2821 - val_loss: 1.6387 - val_accuracy: 0.2634\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6420 - accuracy: 0.2798\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 1.6402 - accuracy: 0.2821 - val_loss: 1.6345 - val_accuracy: 0.2864\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6340 - accuracy: 0.2791\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 1.6340 - accuracy: 0.2782 - val_loss: 1.6306 - val_accuracy: 0.2864\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6315 - accuracy: 0.2876\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 1.6325 - accuracy: 0.2859 - val_loss: 1.6285 - val_accuracy: 0.2864\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6323 - accuracy: 0.2869\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 1.6304 - accuracy: 0.2878 - val_loss: 1.6292 - val_accuracy: 0.2634\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6309 - accuracy: 0.2707\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 1.6307 - accuracy: 0.2705 - val_loss: 1.6268 - val_accuracy: 0.2864\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6270 - accuracy: 0.2785\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 1.6293 - accuracy: 0.2788 - val_loss: 1.6262 - val_accuracy: 0.2864\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6301 - accuracy: 0.2798\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 1.6299 - accuracy: 0.2801 - val_loss: 1.6259 - val_accuracy: 0.2864\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6301 - accuracy: 0.2759\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.6295 - accuracy: 0.2763 - val_loss: 1.6252 - val_accuracy: 0.2864\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6274 - accuracy: 0.2694\n",
            "Epoch 15: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.6283 - accuracy: 0.2679 - val_loss: 1.6254 - val_accuracy: 0.2864\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6253 - accuracy: 0.2766\n",
            "Epoch 16: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 1.6270 - accuracy: 0.2776 - val_loss: 1.6246 - val_accuracy: 0.2864\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6269 - accuracy: 0.2869\n",
            "Epoch 17: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.6283 - accuracy: 0.2859 - val_loss: 1.6248 - val_accuracy: 0.2864\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6281 - accuracy: 0.2863\n",
            "Epoch 18: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 1.6274 - accuracy: 0.2859 - val_loss: 1.6240 - val_accuracy: 0.2864\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6269 - accuracy: 0.2850\n",
            "Epoch 19: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 1.6266 - accuracy: 0.2859 - val_loss: 1.6243 - val_accuracy: 0.2864\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6274 - accuracy: 0.2811\n",
            "Epoch 20: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.6263 - accuracy: 0.2833 - val_loss: 1.6241 - val_accuracy: 0.2864\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6274 - accuracy: 0.2824\n",
            "Epoch 21: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 1.6262 - accuracy: 0.2833 - val_loss: 1.6248 - val_accuracy: 0.2634\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6262 - accuracy: 0.2714\n",
            "Epoch 22: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 1.6279 - accuracy: 0.2724 - val_loss: 1.6237 - val_accuracy: 0.2864\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6277 - accuracy: 0.2791\n",
            "Epoch 23: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.6269 - accuracy: 0.2808 - val_loss: 1.6240 - val_accuracy: 0.2864\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6268 - accuracy: 0.2869\n",
            "Epoch 24: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 1.6272 - accuracy: 0.2859 - val_loss: 1.6238 - val_accuracy: 0.2864\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6251 - accuracy: 0.2759\n",
            "Epoch 25: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.6270 - accuracy: 0.2756 - val_loss: 1.6242 - val_accuracy: 0.2864\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6264 - accuracy: 0.2798\n",
            "Epoch 26: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.6265 - accuracy: 0.2795 - val_loss: 1.6244 - val_accuracy: 0.2864\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6297 - accuracy: 0.2772\n",
            "Epoch 27: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 1.6277 - accuracy: 0.2788 - val_loss: 1.6250 - val_accuracy: 0.2864\n",
            "Epoch 27: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/60/assets\n",
            "\n",
            "\n",
            " 30%|███       | 61/200 [2:29:44<6:10:07, 159.77s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 2.2632 - accuracy: 0.2500\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 13ms/step - loss: 2.2632 - accuracy: 0.2500 - val_loss: 1.8147 - val_accuracy: 0.2634\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 2.0180 - accuracy: 0.3407\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 2.0177 - accuracy: 0.3410 - val_loss: 1.8138 - val_accuracy: 0.2609\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.8650 - accuracy: 0.4262\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.8656 - accuracy: 0.4256 - val_loss: 1.7476 - val_accuracy: 0.2788\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.7752 - accuracy: 0.4760\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 1.7747 - accuracy: 0.4763 - val_loss: 1.6516 - val_accuracy: 0.4757\n",
            "Epoch 5/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6955 - accuracy: 0.5231\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.6955 - accuracy: 0.5231 - val_loss: 1.5965 - val_accuracy: 0.5499\n",
            "Epoch 6/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6259 - accuracy: 0.5651\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.6250 - accuracy: 0.5660 - val_loss: 1.5329 - val_accuracy: 0.5882\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.5534 - accuracy: 0.6108\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 1.5528 - accuracy: 0.6128 - val_loss: 1.4714 - val_accuracy: 0.6215\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.4781 - accuracy: 0.6386\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 1.4819 - accuracy: 0.6378 - val_loss: 1.4137 - val_accuracy: 0.6496\n",
            "Epoch 9/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.4255 - accuracy: 0.6623\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.4256 - accuracy: 0.6628 - val_loss: 1.3482 - val_accuracy: 0.6701\n",
            "Epoch 10/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.3810 - accuracy: 0.6780\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 1.3824 - accuracy: 0.6769 - val_loss: 1.2917 - val_accuracy: 0.7187\n",
            "Epoch 11/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.3069 - accuracy: 0.7274\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.3064 - accuracy: 0.7282 - val_loss: 1.2417 - val_accuracy: 0.7315\n",
            "Epoch 12/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.2633 - accuracy: 0.7564\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.2633 - accuracy: 0.7564 - val_loss: 1.1874 - val_accuracy: 0.7545\n",
            "Epoch 13/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.2125 - accuracy: 0.7702\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 1.2138 - accuracy: 0.7705 - val_loss: 1.1425 - val_accuracy: 0.7596\n",
            "Epoch 14/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 1.1653 - accuracy: 0.7842\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 1.1635 - accuracy: 0.7853 - val_loss: 1.1023 - val_accuracy: 0.7775\n",
            "Epoch 15/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.1125 - accuracy: 0.7955\n",
            "Epoch 15: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.1125 - accuracy: 0.7955 - val_loss: 1.0599 - val_accuracy: 0.8159\n",
            "Epoch 16/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.0763 - accuracy: 0.8197\n",
            "Epoch 16: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 1.0751 - accuracy: 0.8186 - val_loss: 1.0255 - val_accuracy: 0.8184\n",
            "Epoch 17/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.0445 - accuracy: 0.8301\n",
            "Epoch 17: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.0444 - accuracy: 0.8295 - val_loss: 0.9863 - val_accuracy: 0.8338\n",
            "Epoch 18/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.0071 - accuracy: 0.8421\n",
            "Epoch 18: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.0061 - accuracy: 0.8429 - val_loss: 0.9537 - val_accuracy: 0.8619\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.9865 - accuracy: 0.8484\n",
            "Epoch 19: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.9844 - accuracy: 0.8494 - val_loss: 0.9299 - val_accuracy: 0.8491\n",
            "Epoch 20/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.9493 - accuracy: 0.8595\n",
            "Epoch 20: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.9490 - accuracy: 0.8596 - val_loss: 0.9001 - val_accuracy: 0.8645\n",
            "Epoch 21/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.9204 - accuracy: 0.8730\n",
            "Epoch 21: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.9171 - accuracy: 0.8750 - val_loss: 0.8785 - val_accuracy: 0.8670\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8891 - accuracy: 0.8756\n",
            "Epoch 22: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.8903 - accuracy: 0.8737 - val_loss: 0.8594 - val_accuracy: 0.8772\n",
            "Epoch 23/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.8593 - accuracy: 0.8855\n",
            "Epoch 23: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.8586 - accuracy: 0.8865 - val_loss: 0.8285 - val_accuracy: 0.8977\n",
            "Epoch 24/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.8484 - accuracy: 0.8999\n",
            "Epoch 24: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.8472 - accuracy: 0.8994 - val_loss: 0.8096 - val_accuracy: 0.8926\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8112 - accuracy: 0.9016\n",
            "Epoch 25: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.8103 - accuracy: 0.9026 - val_loss: 0.7897 - val_accuracy: 0.8977\n",
            "Epoch 26/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.7880 - accuracy: 0.9102\n",
            "Epoch 26: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.7899 - accuracy: 0.9090 - val_loss: 0.7707 - val_accuracy: 0.8951\n",
            "Epoch 27/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.7823 - accuracy: 0.9086\n",
            "Epoch 27: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.7805 - accuracy: 0.9083 - val_loss: 0.7519 - val_accuracy: 0.9105\n",
            "Epoch 28/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.7543 - accuracy: 0.9160\n",
            "Epoch 28: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.7541 - accuracy: 0.9154 - val_loss: 0.7354 - val_accuracy: 0.9258\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7310 - accuracy: 0.9268\n",
            "Epoch 29: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.7316 - accuracy: 0.9263 - val_loss: 0.7221 - val_accuracy: 0.9182\n",
            "Epoch 30/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.7190 - accuracy: 0.9232\n",
            "Epoch 30: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.7182 - accuracy: 0.9244 - val_loss: 0.7005 - val_accuracy: 0.9335\n",
            "Epoch 31/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7039 - accuracy: 0.9313\n",
            "Epoch 31: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.7039 - accuracy: 0.9314 - val_loss: 0.6892 - val_accuracy: 0.9284\n",
            "Epoch 32/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.6799 - accuracy: 0.9368\n",
            "Epoch 32: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.6802 - accuracy: 0.9372 - val_loss: 0.6716 - val_accuracy: 0.9437\n",
            "Epoch 33/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.6766 - accuracy: 0.9332\n",
            "Epoch 33: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.6771 - accuracy: 0.9333 - val_loss: 0.6600 - val_accuracy: 0.9463\n",
            "Epoch 34/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6640 - accuracy: 0.9411\n",
            "Epoch 34: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.6637 - accuracy: 0.9410 - val_loss: 0.6467 - val_accuracy: 0.9514\n",
            "Epoch 35/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.6440 - accuracy: 0.9473\n",
            "Epoch 35: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.6466 - accuracy: 0.9462 - val_loss: 0.6402 - val_accuracy: 0.9540\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6353 - accuracy: 0.9398\n",
            "Epoch 36: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.6360 - accuracy: 0.9397 - val_loss: 0.6200 - val_accuracy: 0.9540\n",
            "Epoch 37/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.6219 - accuracy: 0.9503\n",
            "Epoch 37: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.6224 - accuracy: 0.9494 - val_loss: 0.6120 - val_accuracy: 0.9642\n",
            "Epoch 38/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.6032 - accuracy: 0.9546\n",
            "Epoch 38: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.6055 - accuracy: 0.9519 - val_loss: 0.5925 - val_accuracy: 0.9693\n",
            "Epoch 39/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.5970 - accuracy: 0.9570\n",
            "Epoch 39: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.5964 - accuracy: 0.9571 - val_loss: 0.5889 - val_accuracy: 0.9719\n",
            "Epoch 40/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.5801 - accuracy: 0.9653\n",
            "Epoch 40: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.5798 - accuracy: 0.9654 - val_loss: 0.5747 - val_accuracy: 0.9693\n",
            "Epoch 41/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.5724 - accuracy: 0.9577\n",
            "Epoch 41: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.5727 - accuracy: 0.9571 - val_loss: 0.5655 - val_accuracy: 0.9719\n",
            "Epoch 42/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5586 - accuracy: 0.9657\n",
            "Epoch 42: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.5580 - accuracy: 0.9654 - val_loss: 0.5578 - val_accuracy: 0.9744\n",
            "Epoch 43/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5481 - accuracy: 0.9637\n",
            "Epoch 43: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.5488 - accuracy: 0.9635 - val_loss: 0.5449 - val_accuracy: 0.9795\n",
            "Epoch 44/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.5398 - accuracy: 0.9678\n",
            "Epoch 44: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.5396 - accuracy: 0.9679 - val_loss: 0.5355 - val_accuracy: 0.9795\n",
            "Epoch 45/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.5297 - accuracy: 0.9712\n",
            "Epoch 45: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.5290 - accuracy: 0.9712 - val_loss: 0.5233 - val_accuracy: 0.9770\n",
            "Epoch 46/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.5228 - accuracy: 0.9694\n",
            "Epoch 46: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.5223 - accuracy: 0.9692 - val_loss: 0.5216 - val_accuracy: 0.9795\n",
            "Epoch 47/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.5122 - accuracy: 0.9762\n",
            "Epoch 47: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.5119 - accuracy: 0.9763 - val_loss: 0.5092 - val_accuracy: 0.9821\n",
            "Epoch 48/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.5001 - accuracy: 0.9732\n",
            "Epoch 48: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.4993 - accuracy: 0.9737 - val_loss: 0.5004 - val_accuracy: 0.9847\n",
            "Epoch 49/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4950 - accuracy: 0.9750\n",
            "Epoch 49: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.4950 - accuracy: 0.9750 - val_loss: 0.4919 - val_accuracy: 0.9847\n",
            "Epoch 50/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.4857 - accuracy: 0.9770\n",
            "Epoch 50: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.4858 - accuracy: 0.9763 - val_loss: 0.4866 - val_accuracy: 0.9847\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/61/assets\n",
            "\n",
            "\n",
            " 31%|███       | 62/200 [2:32:12<5:58:52, 156.03s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 2.6763 - accuracy: 0.3788\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 22ms/step - loss: 2.6763 - accuracy: 0.3788 - val_loss: 1.8864 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 2.1179 - accuracy: 0.6108\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 2.1143 - accuracy: 0.6122 - val_loss: 1.9447 - val_accuracy: 0.2864\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.8013 - accuracy: 0.7170\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 1.8006 - accuracy: 0.7160 - val_loss: 1.7374 - val_accuracy: 0.4680\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.5519 - accuracy: 0.7863\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 1.5530 - accuracy: 0.7853 - val_loss: 1.4063 - val_accuracy: 0.7724\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.3650 - accuracy: 0.8478\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 1.3644 - accuracy: 0.8474 - val_loss: 1.2343 - val_accuracy: 0.8440\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.2023 - accuracy: 0.8912\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 1.2005 - accuracy: 0.8917 - val_loss: 1.0937 - val_accuracy: 0.8951\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.0926 - accuracy: 0.9197\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 1.0911 - accuracy: 0.9199 - val_loss: 0.9856 - val_accuracy: 0.9437\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.9884 - accuracy: 0.9437\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.9862 - accuracy: 0.9442 - val_loss: 0.9079 - val_accuracy: 0.9514\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.9172 - accuracy: 0.9566\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.9158 - accuracy: 0.9571 - val_loss: 0.8405 - val_accuracy: 0.9668\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8414 - accuracy: 0.9754\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.8408 - accuracy: 0.9756 - val_loss: 0.7948 - val_accuracy: 0.9744\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7994 - accuracy: 0.9728\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.7996 - accuracy: 0.9731 - val_loss: 0.7464 - val_accuracy: 0.9744\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7591 - accuracy: 0.9760\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.7592 - accuracy: 0.9763 - val_loss: 0.7110 - val_accuracy: 0.9821\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7159 - accuracy: 0.9858\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.7154 - accuracy: 0.9859 - val_loss: 0.6780 - val_accuracy: 0.9821\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6827 - accuracy: 0.9890\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.6825 - accuracy: 0.9891 - val_loss: 0.6407 - val_accuracy: 0.9923\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6473 - accuracy: 0.9896\n",
            "Epoch 15: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.6469 - accuracy: 0.9897 - val_loss: 0.6143 - val_accuracy: 0.9898\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6265 - accuracy: 0.9909\n",
            "Epoch 16: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.6256 - accuracy: 0.9910 - val_loss: 0.5912 - val_accuracy: 0.9898\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5948 - accuracy: 0.9929\n",
            "Epoch 17: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.5964 - accuracy: 0.9923 - val_loss: 0.5662 - val_accuracy: 0.9923\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5753 - accuracy: 0.9922\n",
            "Epoch 18: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.5761 - accuracy: 0.9923 - val_loss: 0.5481 - val_accuracy: 0.9949\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5535 - accuracy: 0.9942\n",
            "Epoch 19: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.5535 - accuracy: 0.9942 - val_loss: 0.5372 - val_accuracy: 0.9923\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5360 - accuracy: 0.9961\n",
            "Epoch 20: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.5353 - accuracy: 0.9962 - val_loss: 0.5336 - val_accuracy: 0.9821\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5189 - accuracy: 0.9948\n",
            "Epoch 21: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.5183 - accuracy: 0.9949 - val_loss: 0.4978 - val_accuracy: 0.9949\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5004 - accuracy: 0.9968\n",
            "Epoch 22: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.5002 - accuracy: 0.9968 - val_loss: 0.4813 - val_accuracy: 0.9949\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4837 - accuracy: 0.9974\n",
            "Epoch 23: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.4836 - accuracy: 0.9974 - val_loss: 0.4648 - val_accuracy: 0.9949\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4681 - accuracy: 0.9981\n",
            "Epoch 24: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.4678 - accuracy: 0.9981 - val_loss: 0.4581 - val_accuracy: 0.9923\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4554 - accuracy: 0.9981\n",
            "Epoch 25: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.4555 - accuracy: 0.9981 - val_loss: 0.4387 - val_accuracy: 0.9949\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4407 - accuracy: 0.9968\n",
            "Epoch 26: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.4403 - accuracy: 0.9968 - val_loss: 0.4287 - val_accuracy: 0.9949\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4331 - accuracy: 0.9961\n",
            "Epoch 27: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.4326 - accuracy: 0.9962 - val_loss: 0.4148 - val_accuracy: 0.9949\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4156 - accuracy: 0.9987\n",
            "Epoch 28: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.4158 - accuracy: 0.9987 - val_loss: 0.4019 - val_accuracy: 0.9949\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4066 - accuracy: 0.9981\n",
            "Epoch 29: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.4064 - accuracy: 0.9981 - val_loss: 0.3912 - val_accuracy: 0.9949\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3959 - accuracy: 0.9981\n",
            "Epoch 30: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.3957 - accuracy: 0.9981 - val_loss: 0.3799 - val_accuracy: 0.9949\n",
            "Epoch 31/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3849 - accuracy: 0.9974\n",
            "Epoch 31: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.3848 - accuracy: 0.9974 - val_loss: 0.3727 - val_accuracy: 0.9974\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3738 - accuracy: 0.9987\n",
            "Epoch 32: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.3735 - accuracy: 0.9987 - val_loss: 0.3616 - val_accuracy: 0.9949\n",
            "Epoch 33/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3631 - accuracy: 0.9987\n",
            "Epoch 33: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.3627 - accuracy: 0.9987 - val_loss: 0.3510 - val_accuracy: 0.9949\n",
            "Epoch 34/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3540 - accuracy: 0.9987\n",
            "Epoch 34: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.3539 - accuracy: 0.9987 - val_loss: 0.3418 - val_accuracy: 0.9949\n",
            "Epoch 35/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3445 - accuracy: 0.9987\n",
            "Epoch 35: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.3448 - accuracy: 0.9987 - val_loss: 0.3358 - val_accuracy: 0.9949\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3360 - accuracy: 0.9987\n",
            "Epoch 36: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.3365 - accuracy: 0.9987 - val_loss: 0.3273 - val_accuracy: 0.9949\n",
            "Epoch 37/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3313 - accuracy: 0.9974\n",
            "Epoch 37: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.3312 - accuracy: 0.9974 - val_loss: 0.3281 - val_accuracy: 0.9949\n",
            "Epoch 38/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3219 - accuracy: 0.9968\n",
            "Epoch 38: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.3222 - accuracy: 0.9968 - val_loss: 0.3142 - val_accuracy: 0.9949\n",
            "Epoch 39/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3110 - accuracy: 0.9987\n",
            "Epoch 39: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.3113 - accuracy: 0.9987 - val_loss: 0.3027 - val_accuracy: 0.9974\n",
            "Epoch 40/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3039 - accuracy: 0.9987\n",
            "Epoch 40: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.3040 - accuracy: 0.9987 - val_loss: 0.2983 - val_accuracy: 0.9949\n",
            "Epoch 41/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2990 - accuracy: 0.9987\n",
            "Epoch 41: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.2993 - accuracy: 0.9987 - val_loss: 0.2891 - val_accuracy: 0.9974\n",
            "Epoch 42/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2888 - accuracy: 0.9994\n",
            "Epoch 42: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.2889 - accuracy: 0.9994 - val_loss: 0.2879 - val_accuracy: 0.9974\n",
            "Epoch 43/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2800 - accuracy: 0.9994\n",
            "Epoch 43: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2799 - accuracy: 0.9994 - val_loss: 0.2812 - val_accuracy: 0.9974\n",
            "Epoch 44/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2753 - accuracy: 0.9994\n",
            "Epoch 44: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2753 - accuracy: 0.9994 - val_loss: 0.2691 - val_accuracy: 0.9974\n",
            "Epoch 45/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2692 - accuracy: 0.9974\n",
            "Epoch 45: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.2690 - accuracy: 0.9974 - val_loss: 0.2657 - val_accuracy: 0.9974\n",
            "Epoch 46/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2646 - accuracy: 0.9974\n",
            "Epoch 46: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2646 - accuracy: 0.9974 - val_loss: 0.2616 - val_accuracy: 0.9974\n",
            "Epoch 47/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2566 - accuracy: 0.9987\n",
            "Epoch 47: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2566 - accuracy: 0.9987 - val_loss: 0.2542 - val_accuracy: 0.9974\n",
            "Epoch 48/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2484 - accuracy: 1.0000\n",
            "Epoch 48: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2483 - accuracy: 1.0000 - val_loss: 0.2499 - val_accuracy: 0.9974\n",
            "Epoch 49/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2442 - accuracy: 0.9994\n",
            "Epoch 49: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2441 - accuracy: 0.9994 - val_loss: 0.2433 - val_accuracy: 0.9974\n",
            "Epoch 50/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2389 - accuracy: 1.0000\n",
            "Epoch 50: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.2387 - accuracy: 1.0000 - val_loss: 0.2370 - val_accuracy: 0.9974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/62/assets\n",
            "\n",
            "\n",
            " 32%|███▏      | 63/200 [2:35:39<6:31:16, 171.36s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.1250 - accuracy: 0.7294\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 22ms/step - loss: 1.1220 - accuracy: 0.7301 - val_loss: 1.8410 - val_accuracy: 0.2941\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3398 - accuracy: 0.9553\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.3402 - accuracy: 0.9545 - val_loss: 1.5127 - val_accuracy: 0.7110\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2417 - accuracy: 0.9806\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2413 - accuracy: 0.9808 - val_loss: 1.2009 - val_accuracy: 0.5294\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1956 - accuracy: 0.9903\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1950 - accuracy: 0.9904 - val_loss: 0.2111 - val_accuracy: 0.9770\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1909 - accuracy: 0.9845\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1904 - accuracy: 0.9846 - val_loss: 0.2295 - val_accuracy: 0.9744\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2504 - accuracy: 0.9663\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.2493 - accuracy: 0.9667 - val_loss: 0.2724 - val_accuracy: 0.9770\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1614 - accuracy: 0.9922\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1610 - accuracy: 0.9923 - val_loss: 0.3008 - val_accuracy: 0.9770\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1545 - accuracy: 0.9935\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1549 - accuracy: 0.9936 - val_loss: 0.1964 - val_accuracy: 0.9821\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1867 - accuracy: 0.9838\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1865 - accuracy: 0.9840 - val_loss: 0.2420 - val_accuracy: 0.9642\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1460 - accuracy: 0.9935\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1458 - accuracy: 0.9936 - val_loss: 0.2722 - val_accuracy: 0.9642\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1148 - accuracy: 0.9987\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1148 - accuracy: 0.9987 - val_loss: 0.1284 - val_accuracy: 0.9949\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1241 - accuracy: 0.9955\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1238 - accuracy: 0.9955 - val_loss: 0.1347 - val_accuracy: 0.9898\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1061 - accuracy: 0.9974\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1063 - accuracy: 0.9974 - val_loss: 0.2248 - val_accuracy: 0.9668\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0972 - accuracy: 1.0000\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0972 - accuracy: 1.0000 - val_loss: 0.1154 - val_accuracy: 0.9923\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0846 - accuracy: 1.0000\n",
            "Epoch 15: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0846 - accuracy: 1.0000 - val_loss: 0.1013 - val_accuracy: 0.9949\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0787 - accuracy: 1.0000\n",
            "Epoch 16: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0788 - accuracy: 1.0000 - val_loss: 0.1343 - val_accuracy: 0.9872\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0754 - accuracy: 1.0000\n",
            "Epoch 17: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0755 - accuracy: 1.0000 - val_loss: 0.1305 - val_accuracy: 0.9872\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3489 - accuracy: 0.9501\n",
            "Epoch 18: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.3515 - accuracy: 0.9487 - val_loss: 7.5412 - val_accuracy: 0.5627\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3307 - accuracy: 0.9495\n",
            "Epoch 19: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.3289 - accuracy: 0.9500 - val_loss: 0.5461 - val_accuracy: 0.8875\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1593 - accuracy: 0.9909\n",
            "Epoch 20: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1590 - accuracy: 0.9910 - val_loss: 0.1906 - val_accuracy: 0.9744\n",
            "Epoch 20: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/63/assets\n",
            "\n",
            "\n",
            " 32%|███▏      | 64/200 [2:37:04<5:29:48, 145.51s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.9941 - accuracy: 0.2938\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 16ms/step - loss: 1.9952 - accuracy: 0.2942 - val_loss: 1.8050 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.8278 - accuracy: 0.3904\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.8278 - accuracy: 0.3904 - val_loss: 1.7688 - val_accuracy: 0.2916\n",
            "Epoch 3/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6943 - accuracy: 0.5155\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6932 - accuracy: 0.5147 - val_loss: 1.6351 - val_accuracy: 0.3964\n",
            "Epoch 4/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.5412 - accuracy: 0.6103\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.5412 - accuracy: 0.6103 - val_loss: 1.4632 - val_accuracy: 0.6419\n",
            "Epoch 5/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.3899 - accuracy: 0.6715\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.3892 - accuracy: 0.6705 - val_loss: 1.3196 - val_accuracy: 0.6880\n",
            "Epoch 6/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.2407 - accuracy: 0.7340\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.2407 - accuracy: 0.7340 - val_loss: 1.1809 - val_accuracy: 0.7263\n",
            "Epoch 7/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.1094 - accuracy: 0.7674\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.1097 - accuracy: 0.7673 - val_loss: 1.0630 - val_accuracy: 0.7698\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.0232 - accuracy: 0.7876\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.0239 - accuracy: 0.7872 - val_loss: 0.9710 - val_accuracy: 0.8031\n",
            "Epoch 9/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.9368 - accuracy: 0.8216\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.9369 - accuracy: 0.8224 - val_loss: 0.9018 - val_accuracy: 0.8261\n",
            "Epoch 10/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.8584 - accuracy: 0.8620\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.8566 - accuracy: 0.8622 - val_loss: 0.8280 - val_accuracy: 0.8542\n",
            "Epoch 11/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.8059 - accuracy: 0.8827\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.8047 - accuracy: 0.8833 - val_loss: 0.7770 - val_accuracy: 0.8875\n",
            "Epoch 12/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.7550 - accuracy: 0.8950\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.7553 - accuracy: 0.8955 - val_loss: 0.7300 - val_accuracy: 0.9028\n",
            "Epoch 13/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.7135 - accuracy: 0.9103\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.7135 - accuracy: 0.9103 - val_loss: 0.6915 - val_accuracy: 0.9284\n",
            "Epoch 14/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6743 - accuracy: 0.9250\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.6743 - accuracy: 0.9250 - val_loss: 0.6540 - val_accuracy: 0.9309\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6293 - accuracy: 0.9437\n",
            "Epoch 15: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.6288 - accuracy: 0.9442 - val_loss: 0.6203 - val_accuracy: 0.9335\n",
            "Epoch 16/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.6067 - accuracy: 0.9431\n",
            "Epoch 16: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.6065 - accuracy: 0.9436 - val_loss: 0.5940 - val_accuracy: 0.9514\n",
            "Epoch 17/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5761 - accuracy: 0.9603\n",
            "Epoch 17: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.5761 - accuracy: 0.9603 - val_loss: 0.5703 - val_accuracy: 0.9540\n",
            "Epoch 18/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5666 - accuracy: 0.9494\n",
            "Epoch 18: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.5666 - accuracy: 0.9494 - val_loss: 0.5469 - val_accuracy: 0.9642\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5283 - accuracy: 0.9611\n",
            "Epoch 19: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.5308 - accuracy: 0.9596 - val_loss: 0.5280 - val_accuracy: 0.9642\n",
            "Epoch 20/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5150 - accuracy: 0.9628\n",
            "Epoch 20: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.5150 - accuracy: 0.9628 - val_loss: 0.5137 - val_accuracy: 0.9668\n",
            "Epoch 21/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4910 - accuracy: 0.9684\n",
            "Epoch 21: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.4920 - accuracy: 0.9686 - val_loss: 0.4901 - val_accuracy: 0.9719\n",
            "Epoch 22/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4703 - accuracy: 0.9731\n",
            "Epoch 22: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.4703 - accuracy: 0.9731 - val_loss: 0.4766 - val_accuracy: 0.9668\n",
            "Epoch 23/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4546 - accuracy: 0.9782\n",
            "Epoch 23: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.4546 - accuracy: 0.9782 - val_loss: 0.4542 - val_accuracy: 0.9719\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4376 - accuracy: 0.9793\n",
            "Epoch 24: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.4374 - accuracy: 0.9788 - val_loss: 0.4397 - val_accuracy: 0.9719\n",
            "Epoch 25/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.4344 - accuracy: 0.9779\n",
            "Epoch 25: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.4332 - accuracy: 0.9782 - val_loss: 0.4377 - val_accuracy: 0.9770\n",
            "Epoch 26/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4104 - accuracy: 0.9839\n",
            "Epoch 26: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.4108 - accuracy: 0.9840 - val_loss: 0.4139 - val_accuracy: 0.9847\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3976 - accuracy: 0.9838\n",
            "Epoch 27: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.3974 - accuracy: 0.9840 - val_loss: 0.4041 - val_accuracy: 0.9821\n",
            "Epoch 28/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3850 - accuracy: 0.9853\n",
            "Epoch 28: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.3850 - accuracy: 0.9853 - val_loss: 0.3877 - val_accuracy: 0.9847\n",
            "Epoch 29/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3726 - accuracy: 0.9885\n",
            "Epoch 29: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.3726 - accuracy: 0.9885 - val_loss: 0.3788 - val_accuracy: 0.9872\n",
            "Epoch 30/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3722 - accuracy: 0.9827\n",
            "Epoch 30: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.3722 - accuracy: 0.9827 - val_loss: 0.3714 - val_accuracy: 0.9847\n",
            "Epoch 31/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3495 - accuracy: 0.9904\n",
            "Epoch 31: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.3495 - accuracy: 0.9904 - val_loss: 0.3584 - val_accuracy: 0.9847\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3432 - accuracy: 0.9916\n",
            "Epoch 32: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.3425 - accuracy: 0.9917 - val_loss: 0.3461 - val_accuracy: 0.9847\n",
            "Epoch 33/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.3299 - accuracy: 0.9961\n",
            "Epoch 33: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.3296 - accuracy: 0.9962 - val_loss: 0.3397 - val_accuracy: 0.9847\n",
            "Epoch 34/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.3241 - accuracy: 0.9915\n",
            "Epoch 34: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.3245 - accuracy: 0.9917 - val_loss: 0.3296 - val_accuracy: 0.9847\n",
            "Epoch 35/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3177 - accuracy: 0.9923\n",
            "Epoch 35: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.3176 - accuracy: 0.9923 - val_loss: 0.3222 - val_accuracy: 0.9898\n",
            "Epoch 36/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3074 - accuracy: 0.9948\n",
            "Epoch 36: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.3068 - accuracy: 0.9949 - val_loss: 0.3198 - val_accuracy: 0.9847\n",
            "Epoch 37/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3013 - accuracy: 0.9936\n",
            "Epoch 37: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.3013 - accuracy: 0.9936 - val_loss: 0.3080 - val_accuracy: 0.9898\n",
            "Epoch 38/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2960 - accuracy: 0.9922\n",
            "Epoch 38: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.2959 - accuracy: 0.9923 - val_loss: 0.3043 - val_accuracy: 0.9872\n",
            "Epoch 39/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2859 - accuracy: 0.9941\n",
            "Epoch 39: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.2853 - accuracy: 0.9942 - val_loss: 0.2958 - val_accuracy: 0.9847\n",
            "Epoch 40/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2792 - accuracy: 0.9961\n",
            "Epoch 40: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.2787 - accuracy: 0.9962 - val_loss: 0.2908 - val_accuracy: 0.9847\n",
            "Epoch 41/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2750 - accuracy: 0.9968\n",
            "Epoch 41: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.2748 - accuracy: 0.9968 - val_loss: 0.2846 - val_accuracy: 0.9872\n",
            "Epoch 42/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2691 - accuracy: 0.9922\n",
            "Epoch 42: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.2692 - accuracy: 0.9923 - val_loss: 0.2783 - val_accuracy: 0.9923\n",
            "Epoch 43/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2616 - accuracy: 0.9981\n",
            "Epoch 43: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.2614 - accuracy: 0.9981 - val_loss: 0.2739 - val_accuracy: 0.9847\n",
            "Epoch 44/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.2584 - accuracy: 0.9954\n",
            "Epoch 44: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.2575 - accuracy: 0.9955 - val_loss: 0.2655 - val_accuracy: 0.9898\n",
            "Epoch 45/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2521 - accuracy: 0.9955\n",
            "Epoch 45: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.2521 - accuracy: 0.9955 - val_loss: 0.2656 - val_accuracy: 0.9847\n",
            "Epoch 46/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2508 - accuracy: 0.9935\n",
            "Epoch 46: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.2507 - accuracy: 0.9936 - val_loss: 0.2602 - val_accuracy: 0.9872\n",
            "Epoch 47/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2398 - accuracy: 0.9981\n",
            "Epoch 47: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.2396 - accuracy: 0.9981 - val_loss: 0.2546 - val_accuracy: 0.9872\n",
            "Epoch 48/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2360 - accuracy: 0.9968\n",
            "Epoch 48: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.2360 - accuracy: 0.9968 - val_loss: 0.2484 - val_accuracy: 0.9872\n",
            "Epoch 49/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2312 - accuracy: 0.9961\n",
            "Epoch 49: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.2312 - accuracy: 0.9962 - val_loss: 0.2428 - val_accuracy: 0.9923\n",
            "Epoch 50/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2233 - accuracy: 0.9974\n",
            "Epoch 50: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.2232 - accuracy: 0.9974 - val_loss: 0.2387 - val_accuracy: 0.9923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/64/assets\n",
            "\n",
            "\n",
            " 32%|███▎      | 65/200 [2:39:31<5:28:40, 146.08s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 2.3338 - accuracy: 0.2706\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 13ms/step - loss: 2.3316 - accuracy: 0.2712 - val_loss: 1.7805 - val_accuracy: 0.2609\n",
            "Epoch 2/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 2.0375 - accuracy: 0.4072\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 2.0374 - accuracy: 0.4071 - val_loss: 1.7437 - val_accuracy: 0.3376\n",
            "Epoch 3/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.8498 - accuracy: 0.5164\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.8466 - accuracy: 0.5186 - val_loss: 1.6523 - val_accuracy: 0.4246\n",
            "Epoch 4/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.6968 - accuracy: 0.5851\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 1.6931 - accuracy: 0.5885 - val_loss: 1.5721 - val_accuracy: 0.6138\n",
            "Epoch 5/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.5546 - accuracy: 0.6519\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.5546 - accuracy: 0.6519 - val_loss: 1.4845 - val_accuracy: 0.6931\n",
            "Epoch 6/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.4292 - accuracy: 0.7115\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.4292 - accuracy: 0.7115 - val_loss: 1.3707 - val_accuracy: 0.7340\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.2992 - accuracy: 0.7655\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.3008 - accuracy: 0.7647 - val_loss: 1.2543 - val_accuracy: 0.7724\n",
            "Epoch 8/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 1.1810 - accuracy: 0.8072\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.1793 - accuracy: 0.8077 - val_loss: 1.1413 - val_accuracy: 0.8312\n",
            "Epoch 9/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.0767 - accuracy: 0.8526\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.0767 - accuracy: 0.8526 - val_loss: 1.0442 - val_accuracy: 0.8645\n",
            "Epoch 10/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.9841 - accuracy: 0.8822\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.9836 - accuracy: 0.8814 - val_loss: 0.9581 - val_accuracy: 0.8900\n",
            "Epoch 11/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.9027 - accuracy: 0.9007\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.9019 - accuracy: 0.9006 - val_loss: 0.8891 - val_accuracy: 0.9054\n",
            "Epoch 12/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.8354 - accuracy: 0.9244\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.8354 - accuracy: 0.9244 - val_loss: 0.8231 - val_accuracy: 0.9207\n",
            "Epoch 13/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.7773 - accuracy: 0.9327\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.7773 - accuracy: 0.9327 - val_loss: 0.7715 - val_accuracy: 0.9258\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7307 - accuracy: 0.9534\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.7300 - accuracy: 0.9532 - val_loss: 0.7256 - val_accuracy: 0.9488\n",
            "Epoch 15/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.6863 - accuracy: 0.9555\n",
            "Epoch 15: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.6872 - accuracy: 0.9538 - val_loss: 0.6863 - val_accuracy: 0.9412\n",
            "Epoch 16/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.6483 - accuracy: 0.9626\n",
            "Epoch 16: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.6485 - accuracy: 0.9628 - val_loss: 0.6497 - val_accuracy: 0.9540\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6146 - accuracy: 0.9715\n",
            "Epoch 17: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.6147 - accuracy: 0.9712 - val_loss: 0.6225 - val_accuracy: 0.9514\n",
            "Epoch 18/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5874 - accuracy: 0.9788\n",
            "Epoch 18: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.5874 - accuracy: 0.9788 - val_loss: 0.5919 - val_accuracy: 0.9565\n",
            "Epoch 19/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.5594 - accuracy: 0.9805\n",
            "Epoch 19: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.5598 - accuracy: 0.9801 - val_loss: 0.5663 - val_accuracy: 0.9770\n",
            "Epoch 20/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.5329 - accuracy: 0.9832\n",
            "Epoch 20: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.5332 - accuracy: 0.9833 - val_loss: 0.5465 - val_accuracy: 0.9719\n",
            "Epoch 21/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.5147 - accuracy: 0.9831\n",
            "Epoch 21: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.5137 - accuracy: 0.9827 - val_loss: 0.5289 - val_accuracy: 0.9668\n",
            "Epoch 22/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4911 - accuracy: 0.9885\n",
            "Epoch 22: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.4911 - accuracy: 0.9885 - val_loss: 0.5086 - val_accuracy: 0.9693\n",
            "Epoch 23/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4753 - accuracy: 0.9878\n",
            "Epoch 23: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.4753 - accuracy: 0.9878 - val_loss: 0.4905 - val_accuracy: 0.9642\n",
            "Epoch 24/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4609 - accuracy: 0.9872\n",
            "Epoch 24: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.4609 - accuracy: 0.9872 - val_loss: 0.4731 - val_accuracy: 0.9847\n",
            "Epoch 25/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.4407 - accuracy: 0.9941\n",
            "Epoch 25: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.4401 - accuracy: 0.9942 - val_loss: 0.4562 - val_accuracy: 0.9821\n",
            "Epoch 26/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4276 - accuracy: 0.9923\n",
            "Epoch 26: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.4276 - accuracy: 0.9923 - val_loss: 0.4412 - val_accuracy: 0.9821\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4135 - accuracy: 0.9922\n",
            "Epoch 27: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.4133 - accuracy: 0.9923 - val_loss: 0.4291 - val_accuracy: 0.9923\n",
            "Epoch 28/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3976 - accuracy: 0.9954\n",
            "Epoch 28: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.3987 - accuracy: 0.9955 - val_loss: 0.4182 - val_accuracy: 0.9821\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3816 - accuracy: 0.9955\n",
            "Epoch 29: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.3827 - accuracy: 0.9949 - val_loss: 0.4083 - val_accuracy: 0.9795\n",
            "Epoch 30/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3734 - accuracy: 0.9974\n",
            "Epoch 30: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.3734 - accuracy: 0.9974 - val_loss: 0.3929 - val_accuracy: 0.9923\n",
            "Epoch 31/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3597 - accuracy: 0.9974\n",
            "Epoch 31: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.3592 - accuracy: 0.9974 - val_loss: 0.3815 - val_accuracy: 0.9872\n",
            "Epoch 32/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.3523 - accuracy: 0.9954\n",
            "Epoch 32: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.3524 - accuracy: 0.9955 - val_loss: 0.3740 - val_accuracy: 0.9872\n",
            "Epoch 33/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3422 - accuracy: 0.9961\n",
            "Epoch 33: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.3418 - accuracy: 0.9962 - val_loss: 0.3617 - val_accuracy: 0.9872\n",
            "Epoch 34/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.3303 - accuracy: 0.9980\n",
            "Epoch 34: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.3302 - accuracy: 0.9981 - val_loss: 0.3536 - val_accuracy: 0.9872\n",
            "Epoch 35/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3250 - accuracy: 0.9967\n",
            "Epoch 35: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.3250 - accuracy: 0.9968 - val_loss: 0.3470 - val_accuracy: 0.9872\n",
            "Epoch 36/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3162 - accuracy: 0.9980\n",
            "Epoch 36: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.3163 - accuracy: 0.9981 - val_loss: 0.3376 - val_accuracy: 0.9847\n",
            "Epoch 37/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3072 - accuracy: 1.0000\n",
            "Epoch 37: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.3066 - accuracy: 1.0000 - val_loss: 0.3274 - val_accuracy: 0.9949\n",
            "Epoch 38/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.3012 - accuracy: 0.9980\n",
            "Epoch 38: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.3005 - accuracy: 0.9981 - val_loss: 0.3211 - val_accuracy: 0.9872\n",
            "Epoch 39/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.2916 - accuracy: 0.9980\n",
            "Epoch 39: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.2912 - accuracy: 0.9981 - val_loss: 0.3138 - val_accuracy: 0.9923\n",
            "Epoch 40/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2839 - accuracy: 0.9994\n",
            "Epoch 40: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.2840 - accuracy: 0.9994 - val_loss: 0.3065 - val_accuracy: 0.9872\n",
            "Epoch 41/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2754 - accuracy: 0.9987\n",
            "Epoch 41: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.2760 - accuracy: 0.9987 - val_loss: 0.3010 - val_accuracy: 0.9847\n",
            "Epoch 42/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2717 - accuracy: 0.9968\n",
            "Epoch 42: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.2717 - accuracy: 0.9968 - val_loss: 0.2920 - val_accuracy: 0.9949\n",
            "Epoch 43/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.2657 - accuracy: 0.9987\n",
            "Epoch 43: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.2653 - accuracy: 0.9987 - val_loss: 0.2876 - val_accuracy: 0.9898\n",
            "Epoch 44/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2581 - accuracy: 1.0000\n",
            "Epoch 44: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.2584 - accuracy: 1.0000 - val_loss: 0.2809 - val_accuracy: 0.9949\n",
            "Epoch 45/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.2535 - accuracy: 0.9993\n",
            "Epoch 45: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.2536 - accuracy: 0.9994 - val_loss: 0.2746 - val_accuracy: 0.9923\n",
            "Epoch 46/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2469 - accuracy: 0.9981\n",
            "Epoch 46: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.2469 - accuracy: 0.9981 - val_loss: 0.2700 - val_accuracy: 0.9923\n",
            "Epoch 47/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2408 - accuracy: 0.9987\n",
            "Epoch 47: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.2410 - accuracy: 0.9987 - val_loss: 0.2643 - val_accuracy: 0.9923\n",
            "Epoch 48/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.2369 - accuracy: 0.9993\n",
            "Epoch 48: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.2365 - accuracy: 0.9994 - val_loss: 0.2598 - val_accuracy: 0.9872\n",
            "Epoch 49/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2285 - accuracy: 0.9994\n",
            "Epoch 49: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.2290 - accuracy: 0.9987 - val_loss: 0.2534 - val_accuracy: 0.9898\n",
            "Epoch 50/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2264 - accuracy: 0.9994\n",
            "Epoch 50: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.2261 - accuracy: 0.9994 - val_loss: 0.2487 - val_accuracy: 0.9898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/65/assets\n",
            "\n",
            "\n",
            " 33%|███▎      | 66/200 [2:41:23<5:03:01, 135.68s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6087 - accuracy: 0.5952\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 6s 23ms/step - loss: 1.6073 - accuracy: 0.5962 - val_loss: 1.8576 - val_accuracy: 0.3836\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8385 - accuracy: 0.9003\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.8360 - accuracy: 0.9013 - val_loss: 1.6980 - val_accuracy: 0.4910\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5754 - accuracy: 0.9637\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.5752 - accuracy: 0.9641 - val_loss: 1.0707 - val_accuracy: 0.7570\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4431 - accuracy: 0.9903\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.4421 - accuracy: 0.9904 - val_loss: 0.4554 - val_accuracy: 0.9821\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.9883\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.3827 - accuracy: 0.9885 - val_loss: 0.3628 - val_accuracy: 0.9898\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3296 - accuracy: 0.9942\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.3298 - accuracy: 0.9936 - val_loss: 0.3275 - val_accuracy: 0.9923\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2989 - accuracy: 0.9955\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2987 - accuracy: 0.9955 - val_loss: 0.2959 - val_accuracy: 0.9923\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2675 - accuracy: 0.9961\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2675 - accuracy: 0.9962 - val_loss: 0.2777 - val_accuracy: 0.9898\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2476 - accuracy: 0.9981\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2477 - accuracy: 0.9981 - val_loss: 0.2489 - val_accuracy: 0.9923\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2334 - accuracy: 0.9955\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2331 - accuracy: 0.9955 - val_loss: 0.2409 - val_accuracy: 0.9949\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2130 - accuracy: 0.9987\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2130 - accuracy: 0.9987 - val_loss: 0.2230 - val_accuracy: 0.9949\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2031 - accuracy: 0.9974\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2034 - accuracy: 0.9974 - val_loss: 0.2458 - val_accuracy: 0.9821\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1895 - accuracy: 0.9994\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1894 - accuracy: 0.9994 - val_loss: 0.2023 - val_accuracy: 0.9923\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1783 - accuracy: 0.9994\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1789 - accuracy: 0.9994 - val_loss: 0.1945 - val_accuracy: 0.9923\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1770 - accuracy: 0.9994\n",
            "Epoch 15: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1769 - accuracy: 0.9994 - val_loss: 0.1941 - val_accuracy: 0.9923\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1672 - accuracy: 1.0000\n",
            "Epoch 16: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1671 - accuracy: 1.0000 - val_loss: 0.1833 - val_accuracy: 0.9923\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1592 - accuracy: 0.9994\n",
            "Epoch 17: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1590 - accuracy: 0.9994 - val_loss: 0.1813 - val_accuracy: 0.9923\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1557 - accuracy: 1.0000\n",
            "Epoch 18: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1563 - accuracy: 1.0000 - val_loss: 0.1768 - val_accuracy: 0.9898\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1506 - accuracy: 0.9994\n",
            "Epoch 19: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1507 - accuracy: 0.9994 - val_loss: 0.1695 - val_accuracy: 0.9923\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1486 - accuracy: 0.9994\n",
            "Epoch 20: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1485 - accuracy: 0.9994 - val_loss: 0.1609 - val_accuracy: 0.9949\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1420 - accuracy: 0.9994\n",
            "Epoch 21: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1420 - accuracy: 0.9994 - val_loss: 0.1630 - val_accuracy: 0.9898\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1371 - accuracy: 1.0000\n",
            "Epoch 22: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1371 - accuracy: 1.0000 - val_loss: 0.1581 - val_accuracy: 0.9923\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1324 - accuracy: 1.0000\n",
            "Epoch 23: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1327 - accuracy: 1.0000 - val_loss: 0.1549 - val_accuracy: 0.9923\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1466 - accuracy: 0.9987\n",
            "Epoch 24: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1464 - accuracy: 0.9987 - val_loss: 0.1518 - val_accuracy: 0.9949\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1311 - accuracy: 1.0000\n",
            "Epoch 25: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1310 - accuracy: 1.0000 - val_loss: 0.1457 - val_accuracy: 0.9949\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1253 - accuracy: 1.0000\n",
            "Epoch 26: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1252 - accuracy: 1.0000 - val_loss: 0.1490 - val_accuracy: 0.9923\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1229 - accuracy: 1.0000\n",
            "Epoch 27: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1229 - accuracy: 1.0000 - val_loss: 0.1537 - val_accuracy: 0.9898\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1223 - accuracy: 1.0000\n",
            "Epoch 28: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1223 - accuracy: 1.0000 - val_loss: 0.1410 - val_accuracy: 0.9949\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1188 - accuracy: 1.0000\n",
            "Epoch 29: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1188 - accuracy: 1.0000 - val_loss: 0.1389 - val_accuracy: 0.9949\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1166 - accuracy: 1.0000\n",
            "Epoch 30: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1166 - accuracy: 1.0000 - val_loss: 0.1418 - val_accuracy: 0.9923\n",
            "Epoch 31/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1139 - accuracy: 1.0000\n",
            "Epoch 31: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1140 - accuracy: 1.0000 - val_loss: 0.1390 - val_accuracy: 0.9898\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1137 - accuracy: 0.9994\n",
            "Epoch 32: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1137 - accuracy: 0.9994 - val_loss: 0.2634 - val_accuracy: 0.9361\n",
            "Epoch 33/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1321 - accuracy: 0.9968\n",
            "Epoch 33: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1321 - accuracy: 0.9968 - val_loss: 0.1373 - val_accuracy: 0.9949\n",
            "Epoch 34/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1125 - accuracy: 1.0000\n",
            "Epoch 34: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1125 - accuracy: 1.0000 - val_loss: 0.1318 - val_accuracy: 0.9923\n",
            "Epoch 35/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1086 - accuracy: 1.0000\n",
            "Epoch 35: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1087 - accuracy: 1.0000 - val_loss: 0.1271 - val_accuracy: 0.9949\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1066 - accuracy: 1.0000\n",
            "Epoch 36: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1066 - accuracy: 1.0000 - val_loss: 0.1261 - val_accuracy: 0.9898\n",
            "Epoch 37/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1050 - accuracy: 1.0000\n",
            "Epoch 37: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1050 - accuracy: 1.0000 - val_loss: 0.1249 - val_accuracy: 0.9923\n",
            "Epoch 38/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1022 - accuracy: 1.0000\n",
            "Epoch 38: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1022 - accuracy: 1.0000 - val_loss: 0.1217 - val_accuracy: 0.9923\n",
            "Epoch 39/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1002 - accuracy: 1.0000\n",
            "Epoch 39: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1001 - accuracy: 1.0000 - val_loss: 0.1254 - val_accuracy: 0.9923\n",
            "Epoch 40/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0995 - accuracy: 1.0000\n",
            "Epoch 40: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0994 - accuracy: 1.0000 - val_loss: 0.1229 - val_accuracy: 0.9898\n",
            "Epoch 41/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0987 - accuracy: 1.0000\n",
            "Epoch 41: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0986 - accuracy: 1.0000 - val_loss: 0.1192 - val_accuracy: 0.9949\n",
            "Epoch 42/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0953 - accuracy: 1.0000\n",
            "Epoch 42: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0953 - accuracy: 1.0000 - val_loss: 0.1179 - val_accuracy: 0.9923\n",
            "Epoch 43/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0931 - accuracy: 1.0000\n",
            "Epoch 43: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0932 - accuracy: 1.0000 - val_loss: 0.1167 - val_accuracy: 0.9923\n",
            "Epoch 44/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0910 - accuracy: 1.0000\n",
            "Epoch 44: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0910 - accuracy: 1.0000 - val_loss: 0.1168 - val_accuracy: 0.9898\n",
            "Epoch 45/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1222 - accuracy: 0.9909\n",
            "Epoch 45: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1225 - accuracy: 0.9910 - val_loss: 0.1683 - val_accuracy: 0.9872\n",
            "Epoch 46/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1067 - accuracy: 0.9994\n",
            "Epoch 46: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1066 - accuracy: 0.9994 - val_loss: 0.1153 - val_accuracy: 0.9974\n",
            "Epoch 47/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0936 - accuracy: 1.0000\n",
            "Epoch 47: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0936 - accuracy: 1.0000 - val_loss: 0.1134 - val_accuracy: 0.9949\n",
            "Epoch 48/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0908 - accuracy: 1.0000\n",
            "Epoch 48: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0908 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 0.9949\n",
            "Epoch 49/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0888 - accuracy: 1.0000\n",
            "Epoch 49: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0888 - accuracy: 1.0000 - val_loss: 0.1068 - val_accuracy: 0.9923\n",
            "Epoch 50/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0868 - accuracy: 1.0000\n",
            "Epoch 50: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0867 - accuracy: 1.0000 - val_loss: 0.1068 - val_accuracy: 0.9923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/66/assets\n",
            "\n",
            "\n",
            " 34%|███▎      | 67/200 [2:44:50<5:48:16, 157.12s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8683 - accuracy: 0.7461\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 4s 15ms/step - loss: 0.8628 - accuracy: 0.7487 - val_loss: 1.9458 - val_accuracy: 0.2634\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2697 - accuracy: 0.9624\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.2701 - accuracy: 0.9615 - val_loss: 1.8439 - val_accuracy: 0.5345\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1953 - accuracy: 0.9825\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.1960 - accuracy: 0.9821 - val_loss: 0.3529 - val_accuracy: 0.9693\n",
            "Epoch 4/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1454 - accuracy: 0.9896\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.1451 - accuracy: 0.9897 - val_loss: 0.2442 - val_accuracy: 0.9540\n",
            "Epoch 5/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1083 - accuracy: 0.9948\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.1086 - accuracy: 0.9949 - val_loss: 0.4677 - val_accuracy: 0.8849\n",
            "Epoch 6/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0990 - accuracy: 0.9961\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0985 - accuracy: 0.9962 - val_loss: 0.1073 - val_accuracy: 0.9974\n",
            "Epoch 7/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1134 - accuracy: 0.9871\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.1134 - accuracy: 0.9872 - val_loss: 0.2944 - val_accuracy: 0.9540\n",
            "Epoch 8/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1039 - accuracy: 0.9936\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.1039 - accuracy: 0.9936 - val_loss: 0.1430 - val_accuracy: 0.9795\n",
            "Epoch 9/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0778 - accuracy: 0.9974\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0777 - accuracy: 0.9974 - val_loss: 0.1023 - val_accuracy: 0.9898\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0693 - accuracy: 0.9981\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0691 - accuracy: 0.9981 - val_loss: 0.1119 - val_accuracy: 0.9898\n",
            "Epoch 11/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0721 - accuracy: 0.9954\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0719 - accuracy: 0.9955 - val_loss: 0.0783 - val_accuracy: 0.9974\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0567 - accuracy: 1.0000\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0566 - accuracy: 1.0000 - val_loss: 0.0767 - val_accuracy: 0.9923\n",
            "Epoch 13/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0534 - accuracy: 0.9987\n",
            "Epoch 13: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0534 - accuracy: 0.9987 - val_loss: 0.1170 - val_accuracy: 0.9795\n",
            "Epoch 14/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1184 - accuracy: 0.9818\n",
            "Epoch 14: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.1211 - accuracy: 0.9808 - val_loss: 0.6849 - val_accuracy: 0.8977\n",
            "Epoch 15/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1482 - accuracy: 0.9820\n",
            "Epoch 15: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.1478 - accuracy: 0.9821 - val_loss: 0.1397 - val_accuracy: 0.9795\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0751 - accuracy: 0.9981\n",
            "Epoch 16: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0749 - accuracy: 0.9981 - val_loss: 0.0983 - val_accuracy: 0.9923\n",
            "Epoch 17/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0565 - accuracy: 1.0000\n",
            "Epoch 17: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0564 - accuracy: 1.0000 - val_loss: 0.0756 - val_accuracy: 0.9949\n",
            "Epoch 18/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0510 - accuracy: 1.0000\n",
            "Epoch 18: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0510 - accuracy: 1.0000 - val_loss: 0.0679 - val_accuracy: 0.9923\n",
            "Epoch 19/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0478 - accuracy: 1.0000\n",
            "Epoch 19: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0478 - accuracy: 1.0000 - val_loss: 0.0637 - val_accuracy: 0.9974\n",
            "Epoch 20/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0588 - accuracy: 0.9987\n",
            "Epoch 20: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0594 - accuracy: 0.9987 - val_loss: 0.2035 - val_accuracy: 0.9591\n",
            "Epoch 21/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0745 - accuracy: 0.9974\n",
            "Epoch 21: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0745 - accuracy: 0.9974 - val_loss: 0.1049 - val_accuracy: 0.9923\n",
            "Epoch 22/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0536 - accuracy: 1.0000\n",
            "Epoch 22: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0535 - accuracy: 1.0000 - val_loss: 0.0748 - val_accuracy: 0.9949\n",
            "Epoch 23/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0493 - accuracy: 0.9994\n",
            "Epoch 23: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0492 - accuracy: 0.9994 - val_loss: 0.0676 - val_accuracy: 0.9923\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0440 - accuracy: 1.0000\n",
            "Epoch 24: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0440 - accuracy: 1.0000 - val_loss: 0.0851 - val_accuracy: 0.9898\n",
            "Epoch 24: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/67/assets\n",
            "\n",
            "\n",
            " 34%|███▍      | 68/200 [2:46:17<4:59:26, 136.11s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.9132 - accuracy: 0.7784\n",
            "Epoch 1: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 5s 17ms/step - loss: 0.9110 - accuracy: 0.7795 - val_loss: 1.7920 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2722 - accuracy: 0.9689\n",
            "Epoch 2: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.2713 - accuracy: 0.9692 - val_loss: 1.9103 - val_accuracy: 0.2890\n",
            "Epoch 3/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1967 - accuracy: 0.9837\n",
            "Epoch 3: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1975 - accuracy: 0.9827 - val_loss: 0.6976 - val_accuracy: 0.7801\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1495 - accuracy: 0.9896\n",
            "Epoch 4: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1492 - accuracy: 0.9897 - val_loss: 0.2191 - val_accuracy: 0.9693\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2010 - accuracy: 0.9799\n",
            "Epoch 5: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.2022 - accuracy: 0.9788 - val_loss: 0.5133 - val_accuracy: 0.8568\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1514 - accuracy: 0.9903\n",
            "Epoch 6: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1512 - accuracy: 0.9904 - val_loss: 0.2829 - val_accuracy: 0.9335\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1645 - accuracy: 0.9812\n",
            "Epoch 7: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1643 - accuracy: 0.9814 - val_loss: 1.3573 - val_accuracy: 0.7673\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1595 - accuracy: 0.9858\n",
            "Epoch 8: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1595 - accuracy: 0.9859 - val_loss: 0.1295 - val_accuracy: 0.9949\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1018 - accuracy: 0.9994\n",
            "Epoch 9: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1016 - accuracy: 0.9994 - val_loss: 0.1157 - val_accuracy: 0.9898\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0838 - accuracy: 1.0000\n",
            "Epoch 10: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0838 - accuracy: 1.0000 - val_loss: 0.1021 - val_accuracy: 0.9923\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1954 - accuracy: 0.9709\n",
            "Epoch 11: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1949 - accuracy: 0.9712 - val_loss: 0.2433 - val_accuracy: 0.9514\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1332 - accuracy: 0.9903\n",
            "Epoch 12: val_accuracy did not improve from 0.99744\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1328 - accuracy: 0.9904 - val_loss: 0.1524 - val_accuracy: 0.9872\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0930 - accuracy: 0.9974\n",
            "Epoch 13: val_accuracy improved from 0.99744 to 1.00000, saving model to /content/drive/MyDrive/hyper_CNN.hdf5\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0929 - accuracy: 0.9974 - val_loss: 0.1062 - val_accuracy: 1.0000\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0835 - accuracy: 0.9994\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0834 - accuracy: 0.9994 - val_loss: 0.0973 - val_accuracy: 0.9923\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0719 - accuracy: 1.0000\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0719 - accuracy: 1.0000 - val_loss: 0.0857 - val_accuracy: 0.9923\n",
            "Epoch 16/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0664 - accuracy: 1.0000\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0664 - accuracy: 1.0000 - val_loss: 0.0764 - val_accuracy: 0.9923\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1232 - accuracy: 0.9883\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1229 - accuracy: 0.9885 - val_loss: 0.2666 - val_accuracy: 0.9488\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1230 - accuracy: 0.9870\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1283 - accuracy: 0.9859 - val_loss: 0.2502 - val_accuracy: 0.9488\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0895 - accuracy: 0.9948\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0893 - accuracy: 0.9949 - val_loss: 0.0959 - val_accuracy: 0.9898\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0763 - accuracy: 0.9974\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0765 - accuracy: 0.9974 - val_loss: 0.0926 - val_accuracy: 0.9923\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0788 - accuracy: 0.9961\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0786 - accuracy: 0.9962 - val_loss: 0.0952 - val_accuracy: 0.9949\n",
            "Epoch 21: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/68/assets\n",
            "\n",
            "\n",
            " 34%|███▍      | 69/200 [2:47:26<4:12:57, 115.86s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.0243 - accuracy: 0.8058\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 19ms/step - loss: 1.0243 - accuracy: 0.8058 - val_loss: 1.8284 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3680 - accuracy: 0.9646\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.3676 - accuracy: 0.9647 - val_loss: 1.7591 - val_accuracy: 0.3657\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2191 - accuracy: 0.9922\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.2186 - accuracy: 0.9923 - val_loss: 1.2692 - val_accuracy: 0.6445\n",
            "Epoch 4/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2393 - accuracy: 0.9772\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.2388 - accuracy: 0.9776 - val_loss: 0.3934 - val_accuracy: 0.9156\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1716 - accuracy: 0.9974\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1717 - accuracy: 0.9974 - val_loss: 0.2074 - val_accuracy: 0.9898\n",
            "Epoch 6/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1526 - accuracy: 0.9974\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.1525 - accuracy: 0.9974 - val_loss: 0.2535 - val_accuracy: 0.9591\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2527 - accuracy: 0.9741\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.2519 - accuracy: 0.9744 - val_loss: 0.4303 - val_accuracy: 0.9258\n",
            "Epoch 8/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1766 - accuracy: 0.9916\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.1764 - accuracy: 0.9917 - val_loss: 0.1950 - val_accuracy: 0.9847\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1301 - accuracy: 1.0000\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1301 - accuracy: 1.0000 - val_loss: 0.1467 - val_accuracy: 0.9949\n",
            "Epoch 10/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1176 - accuracy: 1.0000\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.1176 - accuracy: 1.0000 - val_loss: 0.1304 - val_accuracy: 0.9949\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1111 - accuracy: 1.0000\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1110 - accuracy: 1.0000 - val_loss: 0.1391 - val_accuracy: 0.9923\n",
            "Epoch 12/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1042 - accuracy: 1.0000\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.1043 - accuracy: 1.0000 - val_loss: 0.1200 - val_accuracy: 0.9923\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0978 - accuracy: 1.0000\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0977 - accuracy: 1.0000 - val_loss: 0.1127 - val_accuracy: 0.9974\n",
            "Epoch 14/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1264 - accuracy: 0.9929\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.1299 - accuracy: 0.9923 - val_loss: 1.9441 - val_accuracy: 0.6215\n",
            "Epoch 15/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3829 - accuracy: 0.9388\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.3799 - accuracy: 0.9397 - val_loss: 0.6676 - val_accuracy: 0.8235\n",
            "Epoch 16/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1653 - accuracy: 0.9917\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.1653 - accuracy: 0.9917 - val_loss: 0.2138 - val_accuracy: 0.9795\n",
            "Epoch 17/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1397 - accuracy: 0.9974\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1403 - accuracy: 0.9968 - val_loss: 0.3108 - val_accuracy: 0.9565\n",
            "Epoch 18/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1214 - accuracy: 0.9987\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1213 - accuracy: 0.9987 - val_loss: 0.1433 - val_accuracy: 0.9898\n",
            "Epoch 18: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/69/assets\n",
            "\n",
            "\n",
            " 35%|███▌      | 70/200 [2:48:30<3:37:19, 100.30s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.5166 - accuracy: 0.5129\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 14ms/step - loss: 1.5142 - accuracy: 0.5141 - val_loss: 1.7475 - val_accuracy: 0.3043\n",
            "Epoch 2/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.7814 - accuracy: 0.8512\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.7790 - accuracy: 0.8519 - val_loss: 2.4688 - val_accuracy: 0.4936\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4777 - accuracy: 0.9443\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.4777 - accuracy: 0.9436 - val_loss: 1.5979 - val_accuracy: 0.5780\n",
            "Epoch 4/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3521 - accuracy: 0.9795\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.3521 - accuracy: 0.9795 - val_loss: 0.3434 - val_accuracy: 0.9847\n",
            "Epoch 5/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2912 - accuracy: 0.9852\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.2910 - accuracy: 0.9853 - val_loss: 0.2796 - val_accuracy: 0.9898\n",
            "Epoch 6/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.2538 - accuracy: 0.9876\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.2532 - accuracy: 0.9878 - val_loss: 0.2410 - val_accuracy: 0.9898\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2190 - accuracy: 0.9929\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.2191 - accuracy: 0.9929 - val_loss: 0.2270 - val_accuracy: 0.9923\n",
            "Epoch 8/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1967 - accuracy: 0.9962\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.1967 - accuracy: 0.9962 - val_loss: 0.1984 - val_accuracy: 0.9923\n",
            "Epoch 9/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.1804 - accuracy: 0.9980\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.1803 - accuracy: 0.9981 - val_loss: 0.1886 - val_accuracy: 0.9949\n",
            "Epoch 10/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1636 - accuracy: 0.9974\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.1635 - accuracy: 0.9974 - val_loss: 0.1821 - val_accuracy: 0.9898\n",
            "Epoch 11/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1517 - accuracy: 0.9967\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.1512 - accuracy: 0.9968 - val_loss: 0.1591 - val_accuracy: 0.9949\n",
            "Epoch 12/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1443 - accuracy: 0.9974\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.1443 - accuracy: 0.9974 - val_loss: 0.1781 - val_accuracy: 0.9898\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1346 - accuracy: 0.9974\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.1346 - accuracy: 0.9974 - val_loss: 0.1485 - val_accuracy: 0.9898\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1224 - accuracy: 0.9987\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.1223 - accuracy: 0.9987 - val_loss: 0.1342 - val_accuracy: 0.9949\n",
            "Epoch 15/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1139 - accuracy: 1.0000\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.1137 - accuracy: 1.0000 - val_loss: 0.1308 - val_accuracy: 0.9949\n",
            "Epoch 16/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1101 - accuracy: 0.9993\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.1107 - accuracy: 0.9987 - val_loss: 0.1351 - val_accuracy: 0.9898\n",
            "Epoch 17/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1058 - accuracy: 0.9987\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.1057 - accuracy: 0.9987 - val_loss: 0.1177 - val_accuracy: 0.9949\n",
            "Epoch 18/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0971 - accuracy: 0.9994\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0971 - accuracy: 0.9994 - val_loss: 0.1163 - val_accuracy: 0.9923\n",
            "Epoch 19/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.0922 - accuracy: 1.0000\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0922 - accuracy: 1.0000 - val_loss: 0.1123 - val_accuracy: 0.9923\n",
            "Epoch 20/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0883 - accuracy: 1.0000\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0883 - accuracy: 1.0000 - val_loss: 0.1150 - val_accuracy: 0.9923\n",
            "Epoch 21/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0841 - accuracy: 1.0000\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0841 - accuracy: 1.0000 - val_loss: 0.1045 - val_accuracy: 0.9923\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0801 - accuracy: 0.9994\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0801 - accuracy: 0.9994 - val_loss: 0.1278 - val_accuracy: 0.9847\n",
            "Epoch 23/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0772 - accuracy: 1.0000\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0772 - accuracy: 1.0000 - val_loss: 0.0922 - val_accuracy: 0.9923\n",
            "Epoch 24/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0762 - accuracy: 0.9987\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0764 - accuracy: 0.9987 - val_loss: 0.1298 - val_accuracy: 0.9821\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0752 - accuracy: 1.0000\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0751 - accuracy: 1.0000 - val_loss: 0.0967 - val_accuracy: 0.9923\n",
            "Epoch 26/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0666 - accuracy: 1.0000\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0667 - accuracy: 1.0000 - val_loss: 0.0923 - val_accuracy: 0.9923\n",
            "Epoch 27/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0673 - accuracy: 1.0000\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0673 - accuracy: 1.0000 - val_loss: 0.0920 - val_accuracy: 0.9898\n",
            "Epoch 28/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0625 - accuracy: 1.0000\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0625 - accuracy: 1.0000 - val_loss: 0.0807 - val_accuracy: 0.9923\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0630 - accuracy: 1.0000\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0629 - accuracy: 1.0000 - val_loss: 0.0921 - val_accuracy: 0.9872\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0612 - accuracy: 0.9994\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0612 - accuracy: 0.9994 - val_loss: 0.0790 - val_accuracy: 0.9949\n",
            "Epoch 31/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0579 - accuracy: 1.0000\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0578 - accuracy: 1.0000 - val_loss: 0.0753 - val_accuracy: 0.9949\n",
            "Epoch 32/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0552 - accuracy: 1.0000\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0552 - accuracy: 1.0000 - val_loss: 0.0792 - val_accuracy: 0.9923\n",
            "Epoch 33/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0536 - accuracy: 1.0000\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0536 - accuracy: 1.0000 - val_loss: 0.0845 - val_accuracy: 0.9923\n",
            "Epoch 34/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0561 - accuracy: 1.0000\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0561 - accuracy: 1.0000 - val_loss: 0.0733 - val_accuracy: 0.9923\n",
            "Epoch 35/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0526 - accuracy: 1.0000\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0525 - accuracy: 1.0000 - val_loss: 0.0743 - val_accuracy: 0.9949\n",
            "Epoch 36/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0498 - accuracy: 1.0000\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0498 - accuracy: 1.0000 - val_loss: 0.0722 - val_accuracy: 0.9923\n",
            "Epoch 37/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0479 - accuracy: 1.0000\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0479 - accuracy: 1.0000 - val_loss: 0.0768 - val_accuracy: 0.9898\n",
            "Epoch 38/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0467 - accuracy: 1.0000\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0467 - accuracy: 1.0000 - val_loss: 0.0816 - val_accuracy: 0.9872\n",
            "Epoch 39/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0465 - accuracy: 1.0000\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0465 - accuracy: 1.0000 - val_loss: 0.0739 - val_accuracy: 0.9898\n",
            "Epoch 40/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0446 - accuracy: 1.0000\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.0446 - accuracy: 1.0000 - val_loss: 0.0677 - val_accuracy: 0.9898\n",
            "Epoch 41/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0435 - accuracy: 1.0000\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0435 - accuracy: 1.0000 - val_loss: 0.0632 - val_accuracy: 0.9974\n",
            "Epoch 42/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0427 - accuracy: 1.0000\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0427 - accuracy: 1.0000 - val_loss: 0.0650 - val_accuracy: 0.9949\n",
            "Epoch 43/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0430 - accuracy: 1.0000\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0430 - accuracy: 1.0000 - val_loss: 0.0772 - val_accuracy: 0.9872\n",
            "Epoch 44/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0422 - accuracy: 1.0000\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0422 - accuracy: 1.0000 - val_loss: 0.0600 - val_accuracy: 0.9949\n",
            "Epoch 45/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0413 - accuracy: 1.0000\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0412 - accuracy: 1.0000 - val_loss: 0.0614 - val_accuracy: 0.9898\n",
            "Epoch 46/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0477 - accuracy: 0.9974\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0478 - accuracy: 0.9974 - val_loss: 0.0874 - val_accuracy: 0.9923\n",
            "Epoch 47/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0517 - accuracy: 0.9994\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0517 - accuracy: 0.9994 - val_loss: 0.0791 - val_accuracy: 0.9898\n",
            "Epoch 48/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0431 - accuracy: 1.0000\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0431 - accuracy: 1.0000 - val_loss: 0.0607 - val_accuracy: 0.9923\n",
            "Epoch 49/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0411 - accuracy: 1.0000\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0411 - accuracy: 1.0000 - val_loss: 0.0660 - val_accuracy: 0.9898\n",
            "Epoch 49: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/70/assets\n",
            "\n",
            "\n",
            " 36%|███▌      | 71/200 [2:50:28<3:47:35, 105.86s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.9491 - accuracy: 0.4864\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 15ms/step - loss: 1.9413 - accuracy: 0.4904 - val_loss: 1.7508 - val_accuracy: 0.3990\n",
            "Epoch 2/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.1053 - accuracy: 0.7929\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 1.1053 - accuracy: 0.7929 - val_loss: 1.6894 - val_accuracy: 0.3095\n",
            "Epoch 3/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.7232 - accuracy: 0.9254\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.7228 - accuracy: 0.9256 - val_loss: 1.1455 - val_accuracy: 0.5831\n",
            "Epoch 4/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5367 - accuracy: 0.9731\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.5367 - accuracy: 0.9731 - val_loss: 0.5033 - val_accuracy: 0.9770\n",
            "Epoch 5/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.4523 - accuracy: 0.9824\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.4515 - accuracy: 0.9827 - val_loss: 0.4285 - val_accuracy: 0.9847\n",
            "Epoch 6/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3858 - accuracy: 0.9904\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.3858 - accuracy: 0.9904 - val_loss: 0.3812 - val_accuracy: 0.9872\n",
            "Epoch 7/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3365 - accuracy: 0.9981\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.3365 - accuracy: 0.9981 - val_loss: 0.3482 - val_accuracy: 0.9872\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3024 - accuracy: 0.9968\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.3020 - accuracy: 0.9968 - val_loss: 0.3098 - val_accuracy: 0.9923\n",
            "Epoch 9/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.2798 - accuracy: 0.9961\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.2795 - accuracy: 0.9962 - val_loss: 0.2829 - val_accuracy: 0.9923\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2563 - accuracy: 0.9968\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.2562 - accuracy: 0.9968 - val_loss: 0.2715 - val_accuracy: 0.9898\n",
            "Epoch 11/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.2354 - accuracy: 0.9961\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.2351 - accuracy: 0.9962 - val_loss: 0.2454 - val_accuracy: 0.9898\n",
            "Epoch 12/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.2117 - accuracy: 0.9993\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.2113 - accuracy: 0.9994 - val_loss: 0.2265 - val_accuracy: 0.9923\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1982 - accuracy: 0.9994\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.1982 - accuracy: 0.9994 - val_loss: 0.2143 - val_accuracy: 0.9923\n",
            "Epoch 14/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1849 - accuracy: 0.9974\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.1852 - accuracy: 0.9974 - val_loss: 0.1957 - val_accuracy: 0.9923\n",
            "Epoch 15/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1701 - accuracy: 1.0000\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.1697 - accuracy: 1.0000 - val_loss: 0.1857 - val_accuracy: 0.9923\n",
            "Epoch 16/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1611 - accuracy: 0.9987\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.1610 - accuracy: 0.9987 - val_loss: 0.1754 - val_accuracy: 0.9923\n",
            "Epoch 17/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1538 - accuracy: 0.9987\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.1534 - accuracy: 0.9987 - val_loss: 0.1688 - val_accuracy: 0.9923\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1441 - accuracy: 0.9981\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.1442 - accuracy: 0.9981 - val_loss: 0.1576 - val_accuracy: 0.9923\n",
            "Epoch 19/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1353 - accuracy: 0.9987\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.1351 - accuracy: 0.9987 - val_loss: 0.1516 - val_accuracy: 0.9923\n",
            "Epoch 20/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1297 - accuracy: 0.9993\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.1313 - accuracy: 0.9994 - val_loss: 0.1517 - val_accuracy: 0.9898\n",
            "Epoch 21/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1247 - accuracy: 1.0000\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.1246 - accuracy: 1.0000 - val_loss: 0.1631 - val_accuracy: 0.9847\n",
            "Epoch 22/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1178 - accuracy: 0.9993\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.1176 - accuracy: 0.9994 - val_loss: 0.1379 - val_accuracy: 0.9923\n",
            "Epoch 23/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1185 - accuracy: 0.9994\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.1185 - accuracy: 0.9994 - val_loss: 0.1446 - val_accuracy: 0.9898\n",
            "Epoch 24/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1082 - accuracy: 1.0000\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.1081 - accuracy: 1.0000 - val_loss: 0.1533 - val_accuracy: 0.9872\n",
            "Epoch 25/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1052 - accuracy: 1.0000\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.1053 - accuracy: 1.0000 - val_loss: 0.1391 - val_accuracy: 0.9872\n",
            "Epoch 26/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1020 - accuracy: 1.0000\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.1021 - accuracy: 1.0000 - val_loss: 0.1346 - val_accuracy: 0.9898\n",
            "Epoch 27/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0996 - accuracy: 0.9987\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0996 - accuracy: 0.9987 - val_loss: 0.1780 - val_accuracy: 0.9847\n",
            "Epoch 28/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0958 - accuracy: 0.9993\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0957 - accuracy: 0.9994 - val_loss: 0.1176 - val_accuracy: 0.9898\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0902 - accuracy: 1.0000\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.0903 - accuracy: 1.0000 - val_loss: 0.1126 - val_accuracy: 0.9923\n",
            "Epoch 30/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0893 - accuracy: 0.9993\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0894 - accuracy: 0.9994 - val_loss: 0.1217 - val_accuracy: 0.9898\n",
            "Epoch 31/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0861 - accuracy: 1.0000\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0861 - accuracy: 1.0000 - val_loss: 0.1180 - val_accuracy: 0.9923\n",
            "Epoch 32/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0829 - accuracy: 1.0000\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0829 - accuracy: 1.0000 - val_loss: 0.1170 - val_accuracy: 0.9898\n",
            "Epoch 33/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0810 - accuracy: 1.0000\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0811 - accuracy: 1.0000 - val_loss: 0.1078 - val_accuracy: 0.9923\n",
            "Epoch 34/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0804 - accuracy: 1.0000\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0804 - accuracy: 1.0000 - val_loss: 0.1114 - val_accuracy: 0.9923\n",
            "Epoch 35/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0774 - accuracy: 1.0000\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0776 - accuracy: 1.0000 - val_loss: 0.1074 - val_accuracy: 0.9949\n",
            "Epoch 36/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0796 - accuracy: 0.9993\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0795 - accuracy: 0.9994 - val_loss: 0.1142 - val_accuracy: 0.9923\n",
            "Epoch 37/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0739 - accuracy: 1.0000\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.0739 - accuracy: 1.0000 - val_loss: 0.1049 - val_accuracy: 0.9923\n",
            "Epoch 38/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0719 - accuracy: 1.0000\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0719 - accuracy: 1.0000 - val_loss: 0.0983 - val_accuracy: 0.9923\n",
            "Epoch 39/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0697 - accuracy: 1.0000\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0697 - accuracy: 1.0000 - val_loss: 0.1015 - val_accuracy: 0.9923\n",
            "Epoch 40/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0691 - accuracy: 1.0000\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0691 - accuracy: 1.0000 - val_loss: 0.1047 - val_accuracy: 0.9923\n",
            "Epoch 41/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0664 - accuracy: 1.0000\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0664 - accuracy: 1.0000 - val_loss: 0.0968 - val_accuracy: 0.9898\n",
            "Epoch 42/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0657 - accuracy: 1.0000\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0657 - accuracy: 1.0000 - val_loss: 0.0945 - val_accuracy: 0.9923\n",
            "Epoch 43/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0791 - accuracy: 0.9987\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0790 - accuracy: 0.9987 - val_loss: 0.1444 - val_accuracy: 0.9744\n",
            "Epoch 44/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0760 - accuracy: 0.9980\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0762 - accuracy: 0.9981 - val_loss: 0.0926 - val_accuracy: 0.9923\n",
            "Epoch 45/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0645 - accuracy: 1.0000\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0644 - accuracy: 1.0000 - val_loss: 0.0905 - val_accuracy: 0.9923\n",
            "Epoch 46/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0625 - accuracy: 1.0000\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0625 - accuracy: 1.0000 - val_loss: 0.0877 - val_accuracy: 0.9949\n",
            "Epoch 47/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0623 - accuracy: 1.0000\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0623 - accuracy: 1.0000 - val_loss: 0.0887 - val_accuracy: 0.9923\n",
            "Epoch 48/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0604 - accuracy: 1.0000\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0604 - accuracy: 1.0000 - val_loss: 0.0860 - val_accuracy: 0.9923\n",
            "Epoch 49/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0595 - accuracy: 1.0000\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0595 - accuracy: 1.0000 - val_loss: 0.0891 - val_accuracy: 0.9898\n",
            "Epoch 50/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0578 - accuracy: 1.0000\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0577 - accuracy: 1.0000 - val_loss: 0.0846 - val_accuracy: 0.9898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/71/assets\n",
            "\n",
            "\n",
            " 36%|███▌      | 72/200 [2:52:56<4:12:18, 118.27s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 2.5105 - accuracy: 0.4534\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 22ms/step - loss: 2.5047 - accuracy: 0.4532 - val_loss: 2.0648 - val_accuracy: 0.1714\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6078 - accuracy: 0.5486\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 1.6049 - accuracy: 0.5513 - val_loss: 1.9794 - val_accuracy: 0.2864\n",
            "Epoch 3/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.7905 - accuracy: 0.4635\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 1.7905 - accuracy: 0.4635 - val_loss: 2.2345 - val_accuracy: 0.2916\n",
            "Epoch 4/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.4055 - accuracy: 0.5705\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 1.4055 - accuracy: 0.5705 - val_loss: 1.5026 - val_accuracy: 0.4706\n",
            "Epoch 5/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.1891 - accuracy: 0.6706\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.1889 - accuracy: 0.6705 - val_loss: 3.3781 - val_accuracy: 0.5652\n",
            "Epoch 6/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.3133 - accuracy: 0.6462\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 1.3133 - accuracy: 0.6462 - val_loss: 2.0471 - val_accuracy: 0.6164\n",
            "Epoch 7/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.0664 - accuracy: 0.7835\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.0708 - accuracy: 0.7833 - val_loss: 1.2528 - val_accuracy: 0.6445\n",
            "Epoch 8/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.9973 - accuracy: 0.7835\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.9962 - accuracy: 0.7840 - val_loss: 0.8346 - val_accuracy: 0.8824\n",
            "Epoch 9/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5793 - accuracy: 0.9353\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.5793 - accuracy: 0.9353 - val_loss: 0.4661 - val_accuracy: 0.9565\n",
            "Epoch 10/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4416 - accuracy: 0.9549\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.4443 - accuracy: 0.9538 - val_loss: 1.1888 - val_accuracy: 0.6138\n",
            "Epoch 11/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 2.4711 - accuracy: 0.4263\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 2.4711 - accuracy: 0.4263 - val_loss: 2.0577 - val_accuracy: 0.2864\n",
            "Epoch 12/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.7681 - accuracy: 0.3929\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.7681 - accuracy: 0.3929 - val_loss: 1.6243 - val_accuracy: 0.4297\n",
            "Epoch 13/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6620 - accuracy: 0.4446\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 1.6626 - accuracy: 0.4442 - val_loss: 1.5603 - val_accuracy: 0.4399\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.8413 - accuracy: 0.4482\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 1.8399 - accuracy: 0.4462 - val_loss: 1.5882 - val_accuracy: 0.4118\n",
            "Epoch 14: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/72/assets\n",
            "\n",
            "\n",
            " 36%|███▋      | 73/200 [2:53:53<3:31:38, 99.99s/it] \u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 2.6762 - accuracy: 0.4291\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 30ms/step - loss: 2.6703 - accuracy: 0.4295 - val_loss: 2.0166 - val_accuracy: 0.1714\n",
            "Epoch 2/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.5924 - accuracy: 0.4846\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 1.5924 - accuracy: 0.4846 - val_loss: 1.7702 - val_accuracy: 0.3887\n",
            "Epoch 3/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.3593 - accuracy: 0.5712\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 1.3593 - accuracy: 0.5712 - val_loss: 1.3461 - val_accuracy: 0.5729\n",
            "Epoch 4/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.3430 - accuracy: 0.6160\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 1.3419 - accuracy: 0.6154 - val_loss: 1.2228 - val_accuracy: 0.6803\n",
            "Epoch 5/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.1528 - accuracy: 0.6727\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 1.1532 - accuracy: 0.6724 - val_loss: 5.2259 - val_accuracy: 0.4425\n",
            "Epoch 6/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.8836 - accuracy: 0.5301\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 1.8836 - accuracy: 0.5301 - val_loss: 2.0941 - val_accuracy: 0.2864\n",
            "Epoch 7/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6974 - accuracy: 0.4427\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 1.6972 - accuracy: 0.4423 - val_loss: 1.4792 - val_accuracy: 0.5115\n",
            "Epoch 8/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.2727 - accuracy: 0.6308\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 1.2717 - accuracy: 0.6301 - val_loss: 1.1283 - val_accuracy: 0.6829\n",
            "Epoch 9/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.0811 - accuracy: 0.7088\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 1.0793 - accuracy: 0.7096 - val_loss: 1.0036 - val_accuracy: 0.7263\n",
            "Epoch 10/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.9205 - accuracy: 0.7590\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.9205 - accuracy: 0.7590 - val_loss: 1.4748 - val_accuracy: 0.4834\n",
            "Epoch 11/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.0604 - accuracy: 0.6869\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 1.0593 - accuracy: 0.6878 - val_loss: 0.9561 - val_accuracy: 0.7519\n",
            "Epoch 12/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.9113 - accuracy: 0.7494\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.9087 - accuracy: 0.7506 - val_loss: 0.8597 - val_accuracy: 0.7775\n",
            "Epoch 13/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.7783 - accuracy: 0.8071\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.7783 - accuracy: 0.8071 - val_loss: 1.7757 - val_accuracy: 0.5703\n",
            "Epoch 14/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.7831 - accuracy: 0.8167\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.7831 - accuracy: 0.8167 - val_loss: 1.8414 - val_accuracy: 0.6419\n",
            "Epoch 15/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.8985 - accuracy: 0.7854\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.8984 - accuracy: 0.7859 - val_loss: 0.7516 - val_accuracy: 0.8363\n",
            "Epoch 16/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6179 - accuracy: 0.8718\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.6179 - accuracy: 0.8718 - val_loss: 0.7918 - val_accuracy: 0.7801\n",
            "Epoch 17/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.5455 - accuracy: 0.8814\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.5468 - accuracy: 0.8814 - val_loss: 0.5582 - val_accuracy: 0.8747\n",
            "Epoch 18/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4997 - accuracy: 0.8962\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.4997 - accuracy: 0.8962 - val_loss: 0.9319 - val_accuracy: 0.7161\n",
            "Epoch 19/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.3345 - accuracy: 0.6566\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 1.3345 - accuracy: 0.6571 - val_loss: 1.5772 - val_accuracy: 0.4655\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.0572 - accuracy: 0.7558\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 1.0518 - accuracy: 0.7571 - val_loss: 1.7281 - val_accuracy: 0.7391\n",
            "Epoch 21/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5274 - accuracy: 0.9212\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 0.5274 - accuracy: 0.9212 - val_loss: 0.6335 - val_accuracy: 0.8798\n",
            "Epoch 22/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.6812 - accuracy: 0.8602\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.6809 - accuracy: 0.8603 - val_loss: 0.5981 - val_accuracy: 0.8798\n",
            "Epoch 22: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/73/assets\n",
            "\n",
            "\n",
            " 37%|███▋      | 74/200 [2:55:59<3:46:09, 107.69s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.4882 - accuracy: 0.6791\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 26ms/step - loss: 1.4846 - accuracy: 0.6808 - val_loss: 1.7409 - val_accuracy: 0.3120\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6335 - accuracy: 0.9696\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.6322 - accuracy: 0.9699 - val_loss: 1.4523 - val_accuracy: 0.5269\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4447 - accuracy: 0.9935\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.4440 - accuracy: 0.9936 - val_loss: 0.6661 - val_accuracy: 0.9207\n",
            "Epoch 4/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3629 - accuracy: 0.9961\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.3628 - accuracy: 0.9962 - val_loss: 0.4269 - val_accuracy: 0.9514\n",
            "Epoch 5/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2979 - accuracy: 0.9981\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.2976 - accuracy: 0.9981 - val_loss: 0.2880 - val_accuracy: 0.9949\n",
            "Epoch 6/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2596 - accuracy: 0.9981\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.2597 - accuracy: 0.9981 - val_loss: 0.2509 - val_accuracy: 0.9949\n",
            "Epoch 7/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2244 - accuracy: 0.9987\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.2245 - accuracy: 0.9987 - val_loss: 0.2206 - val_accuracy: 0.9949\n",
            "Epoch 8/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1997 - accuracy: 0.9994\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1996 - accuracy: 0.9994 - val_loss: 0.1960 - val_accuracy: 0.9974\n",
            "Epoch 9/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1815 - accuracy: 1.0000\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 25ms/step - loss: 0.1813 - accuracy: 1.0000 - val_loss: 0.1891 - val_accuracy: 0.9949\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1664 - accuracy: 0.9994\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1663 - accuracy: 0.9994 - val_loss: 0.1801 - val_accuracy: 0.9923\n",
            "Epoch 11/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1533 - accuracy: 0.9987\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1533 - accuracy: 0.9987 - val_loss: 0.1794 - val_accuracy: 0.9898\n",
            "Epoch 12/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1485 - accuracy: 0.9994\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1485 - accuracy: 0.9994 - val_loss: 0.1654 - val_accuracy: 0.9898\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1373 - accuracy: 0.9994\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1373 - accuracy: 0.9994 - val_loss: 0.1527 - val_accuracy: 0.9949\n",
            "Epoch 14/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1298 - accuracy: 0.9994\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1298 - accuracy: 0.9994 - val_loss: 0.1411 - val_accuracy: 0.9923\n",
            "Epoch 15/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1247 - accuracy: 0.9994\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1247 - accuracy: 0.9994 - val_loss: 0.1415 - val_accuracy: 0.9923\n",
            "Epoch 16/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1202 - accuracy: 1.0000\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1202 - accuracy: 1.0000 - val_loss: 0.1347 - val_accuracy: 0.9923\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1146 - accuracy: 1.0000\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1145 - accuracy: 1.0000 - val_loss: 0.1280 - val_accuracy: 0.9923\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1098 - accuracy: 1.0000\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1098 - accuracy: 1.0000 - val_loss: 0.1329 - val_accuracy: 0.9923\n",
            "Epoch 19/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1114 - accuracy: 0.9994\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1114 - accuracy: 0.9994 - val_loss: 0.1272 - val_accuracy: 0.9949\n",
            "Epoch 20/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1030 - accuracy: 1.0000\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1030 - accuracy: 1.0000 - val_loss: 0.1222 - val_accuracy: 0.9949\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1002 - accuracy: 1.0000\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1002 - accuracy: 1.0000 - val_loss: 0.1244 - val_accuracy: 0.9923\n",
            "Epoch 22/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1029 - accuracy: 0.9987\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1029 - accuracy: 0.9987 - val_loss: 0.1395 - val_accuracy: 0.9923\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1051 - accuracy: 0.9981\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1053 - accuracy: 0.9981 - val_loss: 0.1181 - val_accuracy: 0.9949\n",
            "Epoch 24/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0947 - accuracy: 1.0000\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0947 - accuracy: 1.0000 - val_loss: 0.1132 - val_accuracy: 0.9898\n",
            "Epoch 25/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0913 - accuracy: 1.0000\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0914 - accuracy: 1.0000 - val_loss: 0.1226 - val_accuracy: 0.9923\n",
            "Epoch 26/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0893 - accuracy: 1.0000\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0893 - accuracy: 1.0000 - val_loss: 0.1098 - val_accuracy: 0.9923\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0866 - accuracy: 1.0000\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0865 - accuracy: 1.0000 - val_loss: 0.1063 - val_accuracy: 0.9923\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0845 - accuracy: 1.0000\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0845 - accuracy: 1.0000 - val_loss: 0.1011 - val_accuracy: 0.9949\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0830 - accuracy: 1.0000\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0830 - accuracy: 1.0000 - val_loss: 0.1012 - val_accuracy: 0.9923\n",
            "Epoch 30/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0817 - accuracy: 1.0000\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0817 - accuracy: 1.0000 - val_loss: 0.1001 - val_accuracy: 0.9949\n",
            "Epoch 31/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0788 - accuracy: 1.0000\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0788 - accuracy: 1.0000 - val_loss: 0.0959 - val_accuracy: 0.9949\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0769 - accuracy: 1.0000\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0769 - accuracy: 1.0000 - val_loss: 0.0967 - val_accuracy: 0.9923\n",
            "Epoch 33/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0751 - accuracy: 1.0000\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0751 - accuracy: 1.0000 - val_loss: 0.0993 - val_accuracy: 0.9949\n",
            "Epoch 34/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0730 - accuracy: 1.0000\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0730 - accuracy: 1.0000 - val_loss: 0.0888 - val_accuracy: 0.9949\n",
            "Epoch 35/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0712 - accuracy: 1.0000\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0712 - accuracy: 1.0000 - val_loss: 0.1026 - val_accuracy: 0.9923\n",
            "Epoch 36/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0695 - accuracy: 1.0000\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0695 - accuracy: 1.0000 - val_loss: 0.0989 - val_accuracy: 0.9923\n",
            "Epoch 37/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0678 - accuracy: 1.0000\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0678 - accuracy: 1.0000 - val_loss: 0.0860 - val_accuracy: 0.9949\n",
            "Epoch 38/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0647 - accuracy: 1.0000\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0647 - accuracy: 1.0000 - val_loss: 0.0864 - val_accuracy: 0.9949\n",
            "Epoch 39/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0633 - accuracy: 1.0000\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0633 - accuracy: 1.0000 - val_loss: 0.0843 - val_accuracy: 0.9923\n",
            "Epoch 40/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1208 - accuracy: 0.9870\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 25ms/step - loss: 0.1204 - accuracy: 0.9872 - val_loss: 0.1571 - val_accuracy: 0.9821\n",
            "Epoch 41/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0829 - accuracy: 0.9981\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0829 - accuracy: 0.9981 - val_loss: 0.0875 - val_accuracy: 0.9974\n",
            "Epoch 42/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0676 - accuracy: 1.0000\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0676 - accuracy: 1.0000 - val_loss: 0.0804 - val_accuracy: 0.9974\n",
            "Epoch 43/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0637 - accuracy: 1.0000\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0636 - accuracy: 1.0000 - val_loss: 0.0762 - val_accuracy: 0.9974\n",
            "Epoch 44/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0610 - accuracy: 1.0000\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0610 - accuracy: 1.0000 - val_loss: 0.0750 - val_accuracy: 0.9974\n",
            "Epoch 45/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0595 - accuracy: 1.0000\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0595 - accuracy: 1.0000 - val_loss: 0.0744 - val_accuracy: 0.9974\n",
            "Epoch 46/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0579 - accuracy: 1.0000\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0579 - accuracy: 1.0000 - val_loss: 0.0720 - val_accuracy: 0.9974\n",
            "Epoch 47/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0567 - accuracy: 1.0000\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0567 - accuracy: 1.0000 - val_loss: 0.0730 - val_accuracy: 0.9974\n",
            "Epoch 48/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0553 - accuracy: 1.0000\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0553 - accuracy: 1.0000 - val_loss: 0.0720 - val_accuracy: 0.9949\n",
            "Epoch 49/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0540 - accuracy: 1.0000\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0540 - accuracy: 1.0000 - val_loss: 0.0713 - val_accuracy: 0.9949\n",
            "Epoch 50/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0527 - accuracy: 1.0000\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0527 - accuracy: 1.0000 - val_loss: 0.0689 - val_accuracy: 0.9974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/74/assets\n",
            "\n",
            "\n",
            " 38%|███▊      | 75/200 [2:59:59<5:07:27, 147.58s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6454 - accuracy: 0.4501\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 15ms/step - loss: 1.6415 - accuracy: 0.4538 - val_loss: 1.7400 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.9858 - accuracy: 0.7746\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.9839 - accuracy: 0.7750 - val_loss: 2.3535 - val_accuracy: 0.2992\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6180 - accuracy: 0.9113\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.6166 - accuracy: 0.9115 - val_loss: 1.9382 - val_accuracy: 0.5422\n",
            "Epoch 4/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4749 - accuracy: 0.9564\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.4749 - accuracy: 0.9564 - val_loss: 0.5157 - val_accuracy: 0.9156\n",
            "Epoch 5/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3879 - accuracy: 0.9750\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.3879 - accuracy: 0.9750 - val_loss: 0.3520 - val_accuracy: 0.9795\n",
            "Epoch 6/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3397 - accuracy: 0.9814\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.3397 - accuracy: 0.9814 - val_loss: 0.3221 - val_accuracy: 0.9795\n",
            "Epoch 7/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.2999 - accuracy: 0.9882\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.3005 - accuracy: 0.9885 - val_loss: 0.2820 - val_accuracy: 0.9923\n",
            "Epoch 8/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2615 - accuracy: 0.9929\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.2615 - accuracy: 0.9929 - val_loss: 0.2503 - val_accuracy: 0.9949\n",
            "Epoch 9/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.2434 - accuracy: 0.9902\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.2430 - accuracy: 0.9904 - val_loss: 0.2320 - val_accuracy: 0.9898\n",
            "Epoch 10/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2240 - accuracy: 0.9915\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.2245 - accuracy: 0.9910 - val_loss: 0.2140 - val_accuracy: 0.9898\n",
            "Epoch 11/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2090 - accuracy: 0.9942\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.2089 - accuracy: 0.9942 - val_loss: 0.2190 - val_accuracy: 0.9923\n",
            "Epoch 12/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1892 - accuracy: 0.9955\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.1892 - accuracy: 0.9955 - val_loss: 0.1846 - val_accuracy: 0.9949\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1783 - accuracy: 0.9948\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1790 - accuracy: 0.9949 - val_loss: 0.1731 - val_accuracy: 0.9949\n",
            "Epoch 14/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1666 - accuracy: 0.9968\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.1666 - accuracy: 0.9968 - val_loss: 0.1604 - val_accuracy: 0.9923\n",
            "Epoch 15/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1563 - accuracy: 0.9974\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.1563 - accuracy: 0.9974 - val_loss: 0.1565 - val_accuracy: 0.9949\n",
            "Epoch 16/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1462 - accuracy: 0.9968\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.1463 - accuracy: 0.9968 - val_loss: 0.1484 - val_accuracy: 0.9949\n",
            "Epoch 17/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1396 - accuracy: 0.9987\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.1396 - accuracy: 0.9987 - val_loss: 0.1502 - val_accuracy: 0.9872\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1314 - accuracy: 0.9974\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1315 - accuracy: 0.9974 - val_loss: 0.1361 - val_accuracy: 0.9949\n",
            "Epoch 19/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1237 - accuracy: 0.9993\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.1237 - accuracy: 0.9994 - val_loss: 0.1292 - val_accuracy: 0.9923\n",
            "Epoch 20/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1169 - accuracy: 0.9994\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.1169 - accuracy: 0.9994 - val_loss: 0.1260 - val_accuracy: 0.9949\n",
            "Epoch 21/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1119 - accuracy: 0.9974\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1122 - accuracy: 0.9974 - val_loss: 0.1201 - val_accuracy: 0.9949\n",
            "Epoch 22/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1068 - accuracy: 1.0000\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.1068 - accuracy: 1.0000 - val_loss: 0.1177 - val_accuracy: 0.9949\n",
            "Epoch 23/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1016 - accuracy: 0.9993\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1016 - accuracy: 0.9994 - val_loss: 0.1100 - val_accuracy: 0.9949\n",
            "Epoch 24/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1014 - accuracy: 0.9974\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.1013 - accuracy: 0.9974 - val_loss: 0.1095 - val_accuracy: 0.9949\n",
            "Epoch 25/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0955 - accuracy: 1.0000\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.0954 - accuracy: 1.0000 - val_loss: 0.1067 - val_accuracy: 0.9949\n",
            "Epoch 26/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0908 - accuracy: 0.9993\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0906 - accuracy: 0.9994 - val_loss: 0.1028 - val_accuracy: 0.9949\n",
            "Epoch 27/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0881 - accuracy: 0.9993\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0880 - accuracy: 0.9994 - val_loss: 0.1042 - val_accuracy: 0.9949\n",
            "Epoch 28/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0824 - accuracy: 0.9994\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.0825 - accuracy: 0.9994 - val_loss: 0.0981 - val_accuracy: 0.9949\n",
            "Epoch 29/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0806 - accuracy: 0.9994\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.0806 - accuracy: 0.9994 - val_loss: 0.0941 - val_accuracy: 0.9949\n",
            "Epoch 30/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0778 - accuracy: 1.0000\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0777 - accuracy: 1.0000 - val_loss: 0.0893 - val_accuracy: 0.9949\n",
            "Epoch 31/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0758 - accuracy: 1.0000\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0758 - accuracy: 1.0000 - val_loss: 0.0892 - val_accuracy: 0.9949\n",
            "Epoch 32/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0742 - accuracy: 1.0000\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0742 - accuracy: 1.0000 - val_loss: 0.0921 - val_accuracy: 0.9923\n",
            "Epoch 33/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0727 - accuracy: 0.9987\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.0727 - accuracy: 0.9987 - val_loss: 0.0906 - val_accuracy: 0.9949\n",
            "Epoch 34/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0712 - accuracy: 0.9993\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0711 - accuracy: 0.9994 - val_loss: 0.0856 - val_accuracy: 0.9923\n",
            "Epoch 35/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0679 - accuracy: 0.9993\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0678 - accuracy: 0.9994 - val_loss: 0.0838 - val_accuracy: 0.9949\n",
            "Epoch 36/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0677 - accuracy: 0.9994\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.0677 - accuracy: 0.9994 - val_loss: 0.0890 - val_accuracy: 0.9949\n",
            "Epoch 37/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0640 - accuracy: 1.0000\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.0639 - accuracy: 1.0000 - val_loss: 0.0805 - val_accuracy: 0.9949\n",
            "Epoch 38/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0625 - accuracy: 1.0000\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0624 - accuracy: 1.0000 - val_loss: 0.0803 - val_accuracy: 0.9923\n",
            "Epoch 39/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0612 - accuracy: 1.0000\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0612 - accuracy: 1.0000 - val_loss: 0.0803 - val_accuracy: 0.9923\n",
            "Epoch 40/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0595 - accuracy: 1.0000\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0595 - accuracy: 1.0000 - val_loss: 0.0811 - val_accuracy: 0.9949\n",
            "Epoch 41/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0584 - accuracy: 1.0000\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.0584 - accuracy: 1.0000 - val_loss: 0.0758 - val_accuracy: 0.9949\n",
            "Epoch 42/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0563 - accuracy: 1.0000\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.0564 - accuracy: 1.0000 - val_loss: 0.0915 - val_accuracy: 0.9949\n",
            "Epoch 43/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0558 - accuracy: 1.0000\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0558 - accuracy: 1.0000 - val_loss: 0.0774 - val_accuracy: 0.9923\n",
            "Epoch 44/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0544 - accuracy: 1.0000\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0543 - accuracy: 1.0000 - val_loss: 0.0725 - val_accuracy: 0.9949\n",
            "Epoch 45/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0549 - accuracy: 1.0000\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0549 - accuracy: 1.0000 - val_loss: 0.0707 - val_accuracy: 0.9923\n",
            "Epoch 46/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0536 - accuracy: 1.0000\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0536 - accuracy: 1.0000 - val_loss: 0.0802 - val_accuracy: 0.9949\n",
            "Epoch 47/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0515 - accuracy: 1.0000\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.0515 - accuracy: 1.0000 - val_loss: 0.0657 - val_accuracy: 0.9949\n",
            "Epoch 48/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0496 - accuracy: 1.0000\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0496 - accuracy: 1.0000 - val_loss: 0.0763 - val_accuracy: 0.9949\n",
            "Epoch 49/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0506 - accuracy: 1.0000\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0506 - accuracy: 1.0000 - val_loss: 0.1020 - val_accuracy: 0.9795\n",
            "Epoch 50/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0577 - accuracy: 0.9994\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0577 - accuracy: 0.9994 - val_loss: 0.0669 - val_accuracy: 0.9949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/75/assets\n",
            "\n",
            "\n",
            " 38%|███▊      | 76/200 [3:02:27<5:04:48, 147.49s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.4525 - accuracy: 0.5506\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 22ms/step - loss: 1.4525 - accuracy: 0.5506 - val_loss: 1.7788 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7676 - accuracy: 0.8459\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.7638 - accuracy: 0.8474 - val_loss: 1.7453 - val_accuracy: 0.2864\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5176 - accuracy: 0.9249\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.5191 - accuracy: 0.9244 - val_loss: 1.2000 - val_accuracy: 0.5831\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3886 - accuracy: 0.9728\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.3878 - accuracy: 0.9731 - val_loss: 0.4107 - val_accuracy: 0.9668\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3316 - accuracy: 0.9741\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.3313 - accuracy: 0.9744 - val_loss: 0.3027 - val_accuracy: 0.9770\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2896 - accuracy: 0.9851\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2890 - accuracy: 0.9853 - val_loss: 0.2774 - val_accuracy: 0.9872\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2565 - accuracy: 0.9877\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.2559 - accuracy: 0.9878 - val_loss: 0.2523 - val_accuracy: 0.9923\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2364 - accuracy: 0.9858\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.2360 - accuracy: 0.9859 - val_loss: 0.2224 - val_accuracy: 0.9974\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2065 - accuracy: 0.9935\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2073 - accuracy: 0.9936 - val_loss: 0.1993 - val_accuracy: 0.9974\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1935 - accuracy: 0.9922\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1931 - accuracy: 0.9923 - val_loss: 0.1894 - val_accuracy: 0.9949\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1817 - accuracy: 0.9942\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1832 - accuracy: 0.9936 - val_loss: 0.1881 - val_accuracy: 0.9949\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1715 - accuracy: 0.9935\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1714 - accuracy: 0.9936 - val_loss: 0.1760 - val_accuracy: 0.9974\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1652 - accuracy: 0.9922\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1652 - accuracy: 0.9923 - val_loss: 0.1610 - val_accuracy: 0.9974\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1474 - accuracy: 0.9987\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1472 - accuracy: 0.9987 - val_loss: 0.1477 - val_accuracy: 0.9974\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1403 - accuracy: 0.9974\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1401 - accuracy: 0.9974 - val_loss: 0.1646 - val_accuracy: 0.9923\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1338 - accuracy: 0.9974\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1338 - accuracy: 0.9974 - val_loss: 0.1556 - val_accuracy: 0.9974\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1328 - accuracy: 0.9961\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1324 - accuracy: 0.9962 - val_loss: 0.1368 - val_accuracy: 0.9974\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1227 - accuracy: 0.9968\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1226 - accuracy: 0.9968 - val_loss: 0.1581 - val_accuracy: 0.9847\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1142 - accuracy: 0.9994\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1142 - accuracy: 0.9994 - val_loss: 0.1281 - val_accuracy: 0.9949\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1090 - accuracy: 0.9994\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1089 - accuracy: 0.9994 - val_loss: 0.1168 - val_accuracy: 0.9974\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1108 - accuracy: 0.9981\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1110 - accuracy: 0.9981 - val_loss: 0.1467 - val_accuracy: 0.9847\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1021 - accuracy: 1.0000\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1021 - accuracy: 1.0000 - val_loss: 0.1111 - val_accuracy: 0.9974\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0976 - accuracy: 0.9987\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0977 - accuracy: 0.9987 - val_loss: 0.1066 - val_accuracy: 0.9974\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0960 - accuracy: 0.9981\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0960 - accuracy: 0.9981 - val_loss: 0.1065 - val_accuracy: 0.9974\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0895 - accuracy: 0.9994\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0895 - accuracy: 0.9994 - val_loss: 0.1075 - val_accuracy: 0.9949\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0889 - accuracy: 0.9987\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0888 - accuracy: 0.9987 - val_loss: 0.1016 - val_accuracy: 0.9949\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0865 - accuracy: 0.9987\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0874 - accuracy: 0.9981 - val_loss: 0.1034 - val_accuracy: 0.9949\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0848 - accuracy: 0.9981\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0847 - accuracy: 0.9981 - val_loss: 0.0964 - val_accuracy: 0.9949\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0844 - accuracy: 0.9981\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0844 - accuracy: 0.9981 - val_loss: 0.0876 - val_accuracy: 0.9949\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0780 - accuracy: 1.0000\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0779 - accuracy: 1.0000 - val_loss: 0.0866 - val_accuracy: 0.9949\n",
            "Epoch 31/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0755 - accuracy: 0.9994\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0756 - accuracy: 0.9994 - val_loss: 0.0865 - val_accuracy: 0.9974\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0736 - accuracy: 1.0000\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0736 - accuracy: 1.0000 - val_loss: 0.0996 - val_accuracy: 0.9923\n",
            "Epoch 33/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0735 - accuracy: 0.9981\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0735 - accuracy: 0.9981 - val_loss: 0.1087 - val_accuracy: 0.9872\n",
            "Epoch 34/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0725 - accuracy: 1.0000\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0726 - accuracy: 1.0000 - val_loss: 0.0853 - val_accuracy: 0.9949\n",
            "Epoch 35/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0681 - accuracy: 1.0000\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0681 - accuracy: 1.0000 - val_loss: 0.0791 - val_accuracy: 0.9949\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0662 - accuracy: 1.0000\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0662 - accuracy: 1.0000 - val_loss: 0.0808 - val_accuracy: 0.9949\n",
            "Epoch 37/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0638 - accuracy: 1.0000\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0637 - accuracy: 1.0000 - val_loss: 0.0790 - val_accuracy: 0.9949\n",
            "Epoch 38/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0619 - accuracy: 1.0000\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0620 - accuracy: 1.0000 - val_loss: 0.0850 - val_accuracy: 0.9923\n",
            "Epoch 39/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0785 - accuracy: 0.9968\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0784 - accuracy: 0.9968 - val_loss: 0.0843 - val_accuracy: 0.9949\n",
            "Epoch 40/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0639 - accuracy: 1.0000\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0640 - accuracy: 1.0000 - val_loss: 0.0773 - val_accuracy: 0.9923\n",
            "Epoch 41/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0613 - accuracy: 0.9994\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0613 - accuracy: 0.9994 - val_loss: 0.0756 - val_accuracy: 0.9974\n",
            "Epoch 42/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0610 - accuracy: 1.0000\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0610 - accuracy: 1.0000 - val_loss: 0.0801 - val_accuracy: 0.9949\n",
            "Epoch 43/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0575 - accuracy: 1.0000\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0575 - accuracy: 1.0000 - val_loss: 0.0713 - val_accuracy: 0.9949\n",
            "Epoch 44/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0570 - accuracy: 1.0000\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0570 - accuracy: 1.0000 - val_loss: 0.0697 - val_accuracy: 0.9949\n",
            "Epoch 45/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0575 - accuracy: 0.9994\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0577 - accuracy: 0.9994 - val_loss: 0.0818 - val_accuracy: 0.9923\n",
            "Epoch 46/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0567 - accuracy: 1.0000\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0566 - accuracy: 1.0000 - val_loss: 0.0654 - val_accuracy: 0.9974\n",
            "Epoch 47/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0541 - accuracy: 1.0000\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0542 - accuracy: 1.0000 - val_loss: 0.0693 - val_accuracy: 0.9949\n",
            "Epoch 48/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0526 - accuracy: 1.0000\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0527 - accuracy: 1.0000 - val_loss: 0.0670 - val_accuracy: 0.9949\n",
            "Epoch 49/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0538 - accuracy: 1.0000\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0539 - accuracy: 1.0000 - val_loss: 0.0805 - val_accuracy: 0.9949\n",
            "Epoch 50/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0523 - accuracy: 1.0000\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0525 - accuracy: 1.0000 - val_loss: 0.0670 - val_accuracy: 0.9923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/76/assets\n",
            "\n",
            "\n",
            " 38%|███▊      | 77/200 [3:05:54<5:39:07, 165.43s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 2.8173 - accuracy: 0.1684\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 17ms/step - loss: 2.8100 - accuracy: 0.1679 - val_loss: 1.8361 - val_accuracy: 0.1637\n",
            "Epoch 2/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 2.0373 - accuracy: 0.2467\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 2.0352 - accuracy: 0.2494 - val_loss: 1.8272 - val_accuracy: 0.2353\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.8955 - accuracy: 0.3251\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.8943 - accuracy: 0.3256 - val_loss: 1.7927 - val_accuracy: 0.2839\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.8216 - accuracy: 0.3588\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.8234 - accuracy: 0.3583 - val_loss: 1.7577 - val_accuracy: 0.3760\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.7621 - accuracy: 0.4301\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.7628 - accuracy: 0.4282 - val_loss: 1.7174 - val_accuracy: 0.4731\n",
            "Epoch 6/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.6978 - accuracy: 0.4811\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.6969 - accuracy: 0.4821 - val_loss: 1.6583 - val_accuracy: 0.5294\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6330 - accuracy: 0.5544\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.6328 - accuracy: 0.5545 - val_loss: 1.5925 - val_accuracy: 0.6010\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.5746 - accuracy: 0.5887\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 1.5748 - accuracy: 0.5878 - val_loss: 1.5283 - val_accuracy: 0.6394\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.4974 - accuracy: 0.6457\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.4958 - accuracy: 0.6462 - val_loss: 1.4642 - val_accuracy: 0.6726\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.4279 - accuracy: 0.6729\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.4295 - accuracy: 0.6724 - val_loss: 1.3950 - val_accuracy: 0.7008\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.3638 - accuracy: 0.7085\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.3635 - accuracy: 0.7090 - val_loss: 1.3294 - val_accuracy: 0.7391\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.3038 - accuracy: 0.7468\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.3047 - accuracy: 0.7468 - val_loss: 1.2677 - val_accuracy: 0.7545\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.2282 - accuracy: 0.7662\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.2293 - accuracy: 0.7660 - val_loss: 1.2047 - val_accuracy: 0.7698\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.1828 - accuracy: 0.7740\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.1822 - accuracy: 0.7744 - val_loss: 1.1426 - val_accuracy: 0.7852\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.1252 - accuracy: 0.8012\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.1256 - accuracy: 0.8006 - val_loss: 1.0857 - val_accuracy: 0.8005\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.0671 - accuracy: 0.8174\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.0713 - accuracy: 0.8154 - val_loss: 1.0352 - val_accuracy: 0.8159\n",
            "Epoch 17/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.0229 - accuracy: 0.8229\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.0214 - accuracy: 0.8237 - val_loss: 0.9901 - val_accuracy: 0.8363\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.9750 - accuracy: 0.8510\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.9742 - accuracy: 0.8513 - val_loss: 0.9399 - val_accuracy: 0.8772\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.9381 - accuracy: 0.8472\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.9389 - accuracy: 0.8474 - val_loss: 0.9042 - val_accuracy: 0.8696\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.9169 - accuracy: 0.8510\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.9197 - accuracy: 0.8500 - val_loss: 0.8639 - val_accuracy: 0.8824\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8833 - accuracy: 0.8672\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.8836 - accuracy: 0.8679 - val_loss: 0.8302 - val_accuracy: 0.9028\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8506 - accuracy: 0.8756\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.8520 - accuracy: 0.8744 - val_loss: 0.7984 - val_accuracy: 0.9079\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8199 - accuracy: 0.8802\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.8195 - accuracy: 0.8795 - val_loss: 0.7808 - val_accuracy: 0.8951\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7908 - accuracy: 0.8899\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.7906 - accuracy: 0.8897 - val_loss: 0.7441 - val_accuracy: 0.9182\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7600 - accuracy: 0.9035\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.7626 - accuracy: 0.9026 - val_loss: 0.7177 - val_accuracy: 0.9233\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7477 - accuracy: 0.9074\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.7485 - accuracy: 0.9071 - val_loss: 0.6952 - val_accuracy: 0.9335\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7150 - accuracy: 0.9113\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.7152 - accuracy: 0.9115 - val_loss: 0.6737 - val_accuracy: 0.9309\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6964 - accuracy: 0.9106\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.6962 - accuracy: 0.9109 - val_loss: 0.6473 - val_accuracy: 0.9437\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6732 - accuracy: 0.9307\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.6734 - accuracy: 0.9301 - val_loss: 0.6317 - val_accuracy: 0.9514\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6558 - accuracy: 0.9307\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.6558 - accuracy: 0.9314 - val_loss: 0.6112 - val_accuracy: 0.9514\n",
            "Epoch 31/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6349 - accuracy: 0.9301\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.6352 - accuracy: 0.9295 - val_loss: 0.5928 - val_accuracy: 0.9642\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6132 - accuracy: 0.9411\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.6126 - accuracy: 0.9417 - val_loss: 0.5720 - val_accuracy: 0.9642\n",
            "Epoch 33/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5958 - accuracy: 0.9411\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.5964 - accuracy: 0.9410 - val_loss: 0.5582 - val_accuracy: 0.9770\n",
            "Epoch 34/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5892 - accuracy: 0.9462\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.5888 - accuracy: 0.9468 - val_loss: 0.5421 - val_accuracy: 0.9795\n",
            "Epoch 35/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5686 - accuracy: 0.9482\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.5678 - accuracy: 0.9481 - val_loss: 0.5358 - val_accuracy: 0.9719\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5552 - accuracy: 0.9534\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.5551 - accuracy: 0.9538 - val_loss: 0.5174 - val_accuracy: 0.9821\n",
            "Epoch 37/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5415 - accuracy: 0.9566\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.5415 - accuracy: 0.9564 - val_loss: 0.4995 - val_accuracy: 0.9872\n",
            "Epoch 38/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5195 - accuracy: 0.9657\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.5183 - accuracy: 0.9660 - val_loss: 0.4890 - val_accuracy: 0.9898\n",
            "Epoch 39/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.5100 - accuracy: 0.9674\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.5098 - accuracy: 0.9667 - val_loss: 0.4833 - val_accuracy: 0.9872\n",
            "Epoch 40/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4976 - accuracy: 0.9683\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.4979 - accuracy: 0.9679 - val_loss: 0.4656 - val_accuracy: 0.9872\n",
            "Epoch 41/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4888 - accuracy: 0.9663\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.4891 - accuracy: 0.9667 - val_loss: 0.4574 - val_accuracy: 0.9795\n",
            "Epoch 42/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4706 - accuracy: 0.9780\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.4712 - accuracy: 0.9776 - val_loss: 0.4468 - val_accuracy: 0.9898\n",
            "Epoch 43/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4652 - accuracy: 0.9773\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.4674 - accuracy: 0.9756 - val_loss: 0.4354 - val_accuracy: 0.9898\n",
            "Epoch 44/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4488 - accuracy: 0.9767\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.4487 - accuracy: 0.9763 - val_loss: 0.4267 - val_accuracy: 0.9898\n",
            "Epoch 45/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4388 - accuracy: 0.9793\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.4389 - accuracy: 0.9795 - val_loss: 0.4171 - val_accuracy: 0.9872\n",
            "Epoch 46/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4390 - accuracy: 0.9741\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.4379 - accuracy: 0.9744 - val_loss: 0.4033 - val_accuracy: 0.9898\n",
            "Epoch 47/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4239 - accuracy: 0.9786\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.4242 - accuracy: 0.9782 - val_loss: 0.3972 - val_accuracy: 0.9898\n",
            "Epoch 48/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4182 - accuracy: 0.9806\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.4182 - accuracy: 0.9808 - val_loss: 0.3941 - val_accuracy: 0.9872\n",
            "Epoch 49/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4074 - accuracy: 0.9819\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.4072 - accuracy: 0.9814 - val_loss: 0.3835 - val_accuracy: 0.9898\n",
            "Epoch 50/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.4006 - accuracy: 0.9837\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.4017 - accuracy: 0.9833 - val_loss: 0.3758 - val_accuracy: 0.9923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/77/assets\n",
            "\n",
            "\n",
            " 39%|███▉      | 78/200 [3:08:28<5:29:16, 161.94s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 2.4684 - accuracy: 0.2053\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 11ms/step - loss: 2.4594 - accuracy: 0.2064 - val_loss: 1.7575 - val_accuracy: 0.2532\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 2.1465 - accuracy: 0.2817\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 2.1482 - accuracy: 0.2808 - val_loss: 1.7760 - val_accuracy: 0.2839\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 2.0092 - accuracy: 0.3057\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 2.0112 - accuracy: 0.3058 - val_loss: 1.7341 - val_accuracy: 0.3171\n",
            "Epoch 4/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 1.8911 - accuracy: 0.3479\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.8924 - accuracy: 0.3474 - val_loss: 1.7133 - val_accuracy: 0.3708\n",
            "Epoch 5/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.8026 - accuracy: 0.3929\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.8026 - accuracy: 0.3929 - val_loss: 1.6816 - val_accuracy: 0.4501\n",
            "Epoch 6/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.7178 - accuracy: 0.4506\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.7178 - accuracy: 0.4506 - val_loss: 1.6207 - val_accuracy: 0.5064\n",
            "Epoch 7/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6568 - accuracy: 0.4890\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 1.6564 - accuracy: 0.4891 - val_loss: 1.5534 - val_accuracy: 0.5499\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.5915 - accuracy: 0.5330\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.5908 - accuracy: 0.5340 - val_loss: 1.4979 - val_accuracy: 0.5780\n",
            "Epoch 9/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 1.5204 - accuracy: 0.5827\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.5274 - accuracy: 0.5795 - val_loss: 1.4401 - val_accuracy: 0.6061\n",
            "Epoch 10/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.4672 - accuracy: 0.5995\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 1.4670 - accuracy: 0.5994 - val_loss: 1.3904 - val_accuracy: 0.6317\n",
            "Epoch 11/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 1.4200 - accuracy: 0.6270\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.4192 - accuracy: 0.6295 - val_loss: 1.3426 - val_accuracy: 0.6522\n",
            "Epoch 12/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.3746 - accuracy: 0.6458\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.3746 - accuracy: 0.6468 - val_loss: 1.2958 - val_accuracy: 0.6803\n",
            "Epoch 13/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.3406 - accuracy: 0.6501\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.3388 - accuracy: 0.6513 - val_loss: 1.2552 - val_accuracy: 0.7008\n",
            "Epoch 14/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 1.2733 - accuracy: 0.6993\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 1.2721 - accuracy: 0.7006 - val_loss: 1.2085 - val_accuracy: 0.7238\n",
            "Epoch 15/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.2370 - accuracy: 0.7129\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.2340 - accuracy: 0.7147 - val_loss: 1.1682 - val_accuracy: 0.7315\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.1880 - accuracy: 0.7319\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.1861 - accuracy: 0.7333 - val_loss: 1.1236 - val_accuracy: 0.7749\n",
            "Epoch 17/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.1389 - accuracy: 0.7615\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.1389 - accuracy: 0.7615 - val_loss: 1.0875 - val_accuracy: 0.7724\n",
            "Epoch 18/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.0928 - accuracy: 0.7758\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 1.0918 - accuracy: 0.7763 - val_loss: 1.0410 - val_accuracy: 0.7928\n",
            "Epoch 19/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.0399 - accuracy: 0.8000\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.0399 - accuracy: 0.8000 - val_loss: 1.0007 - val_accuracy: 0.8082\n",
            "Epoch 20/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.0002 - accuracy: 0.8229\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.0038 - accuracy: 0.8192 - val_loss: 0.9662 - val_accuracy: 0.8159\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.9574 - accuracy: 0.8374\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.9584 - accuracy: 0.8372 - val_loss: 0.9259 - val_accuracy: 0.8465\n",
            "Epoch 22/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 0.9214 - accuracy: 0.8399\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.9196 - accuracy: 0.8410 - val_loss: 0.8870 - val_accuracy: 0.8593\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8843 - accuracy: 0.8627\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.8840 - accuracy: 0.8628 - val_loss: 0.8577 - val_accuracy: 0.8619\n",
            "Epoch 24/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.8538 - accuracy: 0.8664\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.8483 - accuracy: 0.8699 - val_loss: 0.8207 - val_accuracy: 0.8824\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8237 - accuracy: 0.8828\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.8234 - accuracy: 0.8821 - val_loss: 0.7965 - val_accuracy: 0.8849\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7908 - accuracy: 0.8925\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.7909 - accuracy: 0.8923 - val_loss: 0.7689 - val_accuracy: 0.8900\n",
            "Epoch 27/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.7570 - accuracy: 0.9051\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.7572 - accuracy: 0.9051 - val_loss: 0.7421 - val_accuracy: 0.8977\n",
            "Epoch 28/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.7331 - accuracy: 0.9143\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.7323 - accuracy: 0.9141 - val_loss: 0.7136 - val_accuracy: 0.9079\n",
            "Epoch 29/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.7062 - accuracy: 0.9221\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.7067 - accuracy: 0.9212 - val_loss: 0.6885 - val_accuracy: 0.9207\n",
            "Epoch 30/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6882 - accuracy: 0.9250\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.6882 - accuracy: 0.9250 - val_loss: 0.6768 - val_accuracy: 0.9207\n",
            "Epoch 31/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.6612 - accuracy: 0.9441\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.6642 - accuracy: 0.9417 - val_loss: 0.6521 - val_accuracy: 0.9309\n",
            "Epoch 32/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.6443 - accuracy: 0.9381\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.6439 - accuracy: 0.9385 - val_loss: 0.6318 - val_accuracy: 0.9386\n",
            "Epoch 33/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.6257 - accuracy: 0.9459\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.6255 - accuracy: 0.9455 - val_loss: 0.6096 - val_accuracy: 0.9463\n",
            "Epoch 34/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.6029 - accuracy: 0.9575\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.6031 - accuracy: 0.9577 - val_loss: 0.5991 - val_accuracy: 0.9463\n",
            "Epoch 35/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5873 - accuracy: 0.9551\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.5873 - accuracy: 0.9551 - val_loss: 0.5837 - val_accuracy: 0.9514\n",
            "Epoch 36/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.5750 - accuracy: 0.9620\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.5739 - accuracy: 0.9622 - val_loss: 0.5682 - val_accuracy: 0.9540\n",
            "Epoch 37/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 0.5526 - accuracy: 0.9563\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.5522 - accuracy: 0.9577 - val_loss: 0.5514 - val_accuracy: 0.9591\n",
            "Epoch 38/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5481 - accuracy: 0.9609\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.5481 - accuracy: 0.9609 - val_loss: 0.5371 - val_accuracy: 0.9642\n",
            "Epoch 39/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.5328 - accuracy: 0.9653\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.5320 - accuracy: 0.9654 - val_loss: 0.5237 - val_accuracy: 0.9668\n",
            "Epoch 40/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.5159 - accuracy: 0.9727\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.5145 - accuracy: 0.9731 - val_loss: 0.5156 - val_accuracy: 0.9744\n",
            "Epoch 41/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5096 - accuracy: 0.9715\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.5089 - accuracy: 0.9718 - val_loss: 0.5070 - val_accuracy: 0.9668\n",
            "Epoch 42/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 0.4910 - accuracy: 0.9769\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.4951 - accuracy: 0.9750 - val_loss: 0.4883 - val_accuracy: 0.9795\n",
            "Epoch 43/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.4834 - accuracy: 0.9753\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.4848 - accuracy: 0.9750 - val_loss: 0.4799 - val_accuracy: 0.9744\n",
            "Epoch 44/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.4755 - accuracy: 0.9772\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.4744 - accuracy: 0.9776 - val_loss: 0.4739 - val_accuracy: 0.9744\n",
            "Epoch 45/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 0.4631 - accuracy: 0.9729\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.4649 - accuracy: 0.9731 - val_loss: 0.4605 - val_accuracy: 0.9847\n",
            "Epoch 46/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.4518 - accuracy: 0.9757\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.4507 - accuracy: 0.9763 - val_loss: 0.4515 - val_accuracy: 0.9770\n",
            "Epoch 47/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.4405 - accuracy: 0.9804\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.4413 - accuracy: 0.9788 - val_loss: 0.4481 - val_accuracy: 0.9744\n",
            "Epoch 48/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4370 - accuracy: 0.9776\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.4370 - accuracy: 0.9776 - val_loss: 0.4370 - val_accuracy: 0.9795\n",
            "Epoch 49/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4258 - accuracy: 0.9864\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.4267 - accuracy: 0.9859 - val_loss: 0.4303 - val_accuracy: 0.9795\n",
            "Epoch 50/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.4171 - accuracy: 0.9870\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.4168 - accuracy: 0.9872 - val_loss: 0.4203 - val_accuracy: 0.9795\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/78/assets\n",
            "\n",
            "\n",
            " 40%|███▉      | 79/200 [3:10:55<5:17:42, 157.54s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 2.1959 - accuracy: 0.2623\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 25ms/step - loss: 2.1943 - accuracy: 0.2622 - val_loss: 1.8548 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.9431 - accuracy: 0.3860\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 1.9408 - accuracy: 0.3872 - val_loss: 1.8357 - val_accuracy: 0.2864\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.7710 - accuracy: 0.4922\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 1.7701 - accuracy: 0.4929 - val_loss: 1.7350 - val_accuracy: 0.2864\n",
            "Epoch 4/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6541 - accuracy: 0.5583\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 1.6541 - accuracy: 0.5583 - val_loss: 1.5420 - val_accuracy: 0.5934\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.5362 - accuracy: 0.6354\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 1.5384 - accuracy: 0.6346 - val_loss: 1.4266 - val_accuracy: 0.6905\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.4199 - accuracy: 0.6924\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 1.4180 - accuracy: 0.6942 - val_loss: 1.3171 - val_accuracy: 0.7519\n",
            "Epoch 7/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.3095 - accuracy: 0.7167\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 1.3095 - accuracy: 0.7167 - val_loss: 1.2181 - val_accuracy: 0.7928\n",
            "Epoch 8/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.2077 - accuracy: 0.7731\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 1.2077 - accuracy: 0.7731 - val_loss: 1.1272 - val_accuracy: 0.8235\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.1265 - accuracy: 0.8096\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 1.1242 - accuracy: 0.8096 - val_loss: 1.0441 - val_accuracy: 0.8389\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.0467 - accuracy: 0.8154\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 1.0465 - accuracy: 0.8160 - val_loss: 0.9737 - val_accuracy: 0.8721\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.9723 - accuracy: 0.8536\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.9753 - accuracy: 0.8532 - val_loss: 0.9117 - val_accuracy: 0.8875\n",
            "Epoch 12/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.9166 - accuracy: 0.8737\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.9166 - accuracy: 0.8737 - val_loss: 0.8574 - val_accuracy: 0.9079\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8553 - accuracy: 0.8964\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.8550 - accuracy: 0.8968 - val_loss: 0.8035 - val_accuracy: 0.9079\n",
            "Epoch 14/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.8102 - accuracy: 0.9141\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.8102 - accuracy: 0.9141 - val_loss: 0.7644 - val_accuracy: 0.9207\n",
            "Epoch 15/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.7659 - accuracy: 0.9224\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.7659 - accuracy: 0.9224 - val_loss: 0.7262 - val_accuracy: 0.9335\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7412 - accuracy: 0.9281\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.7415 - accuracy: 0.9282 - val_loss: 0.6869 - val_accuracy: 0.9540\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7068 - accuracy: 0.9411\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.7068 - accuracy: 0.9404 - val_loss: 0.6610 - val_accuracy: 0.9488\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6750 - accuracy: 0.9424\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.6745 - accuracy: 0.9429 - val_loss: 0.6313 - val_accuracy: 0.9616\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6445 - accuracy: 0.9482\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.6445 - accuracy: 0.9487 - val_loss: 0.6029 - val_accuracy: 0.9642\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6111 - accuracy: 0.9605\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.6121 - accuracy: 0.9609 - val_loss: 0.5863 - val_accuracy: 0.9719\n",
            "Epoch 21/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5927 - accuracy: 0.9545\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.5927 - accuracy: 0.9545 - val_loss: 0.5536 - val_accuracy: 0.9795\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5669 - accuracy: 0.9585\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.5670 - accuracy: 0.9590 - val_loss: 0.5358 - val_accuracy: 0.9821\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5523 - accuracy: 0.9624\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.5516 - accuracy: 0.9628 - val_loss: 0.5214 - val_accuracy: 0.9898\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5349 - accuracy: 0.9741\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.5350 - accuracy: 0.9744 - val_loss: 0.5029 - val_accuracy: 0.9847\n",
            "Epoch 25/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5161 - accuracy: 0.9756\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.5161 - accuracy: 0.9756 - val_loss: 0.4875 - val_accuracy: 0.9872\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5027 - accuracy: 0.9741\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.5038 - accuracy: 0.9737 - val_loss: 0.4747 - val_accuracy: 0.9898\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4896 - accuracy: 0.9734\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.4905 - accuracy: 0.9731 - val_loss: 0.4614 - val_accuracy: 0.9872\n",
            "Epoch 28/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4778 - accuracy: 0.9769\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.4778 - accuracy: 0.9769 - val_loss: 0.4637 - val_accuracy: 0.9821\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4566 - accuracy: 0.9845\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.4567 - accuracy: 0.9846 - val_loss: 0.4410 - val_accuracy: 0.9872\n",
            "Epoch 30/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4451 - accuracy: 0.9808\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.4451 - accuracy: 0.9808 - val_loss: 0.4277 - val_accuracy: 0.9898\n",
            "Epoch 31/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4324 - accuracy: 0.9845\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.4340 - accuracy: 0.9833 - val_loss: 0.4262 - val_accuracy: 0.9821\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4232 - accuracy: 0.9845\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.4232 - accuracy: 0.9840 - val_loss: 0.4071 - val_accuracy: 0.9872\n",
            "Epoch 33/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4131 - accuracy: 0.9865\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.4132 - accuracy: 0.9865 - val_loss: 0.3975 - val_accuracy: 0.9898\n",
            "Epoch 34/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4046 - accuracy: 0.9870\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.4043 - accuracy: 0.9872 - val_loss: 0.3901 - val_accuracy: 0.9898\n",
            "Epoch 35/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3954 - accuracy: 0.9864\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.3946 - accuracy: 0.9865 - val_loss: 0.3835 - val_accuracy: 0.9872\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3909 - accuracy: 0.9864\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.3908 - accuracy: 0.9865 - val_loss: 0.3755 - val_accuracy: 0.9872\n",
            "Epoch 37/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3800 - accuracy: 0.9890\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.3794 - accuracy: 0.9891 - val_loss: 0.3654 - val_accuracy: 0.9898\n",
            "Epoch 38/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3675 - accuracy: 0.9917\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.3675 - accuracy: 0.9917 - val_loss: 0.3591 - val_accuracy: 0.9872\n",
            "Epoch 39/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3623 - accuracy: 0.9904\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.3623 - accuracy: 0.9904 - val_loss: 0.3621 - val_accuracy: 0.9872\n",
            "Epoch 40/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3560 - accuracy: 0.9922\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.3556 - accuracy: 0.9923 - val_loss: 0.3467 - val_accuracy: 0.9898\n",
            "Epoch 41/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3492 - accuracy: 0.9903\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.3489 - accuracy: 0.9904 - val_loss: 0.3427 - val_accuracy: 0.9898\n",
            "Epoch 42/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3396 - accuracy: 0.9948\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.3406 - accuracy: 0.9949 - val_loss: 0.3326 - val_accuracy: 0.9898\n",
            "Epoch 43/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3410 - accuracy: 0.9904\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.3410 - accuracy: 0.9904 - val_loss: 0.3297 - val_accuracy: 0.9898\n",
            "Epoch 44/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3296 - accuracy: 0.9936\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.3296 - accuracy: 0.9936 - val_loss: 0.3252 - val_accuracy: 0.9898\n",
            "Epoch 45/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3255 - accuracy: 0.9922\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.3252 - accuracy: 0.9923 - val_loss: 0.3263 - val_accuracy: 0.9872\n",
            "Epoch 46/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3206 - accuracy: 0.9955\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.3211 - accuracy: 0.9949 - val_loss: 0.3159 - val_accuracy: 0.9898\n",
            "Epoch 47/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3173 - accuracy: 0.9942\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.3173 - accuracy: 0.9942 - val_loss: 0.3153 - val_accuracy: 0.9898\n",
            "Epoch 48/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3107 - accuracy: 0.9948\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.3107 - accuracy: 0.9949 - val_loss: 0.3088 - val_accuracy: 0.9898\n",
            "Epoch 49/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2988 - accuracy: 0.9968\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.2991 - accuracy: 0.9968 - val_loss: 0.2993 - val_accuracy: 0.9923\n",
            "Epoch 50/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3012 - accuracy: 0.9929\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.3012 - accuracy: 0.9929 - val_loss: 0.2989 - val_accuracy: 0.9898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/79/assets\n",
            "\n",
            "\n",
            " 40%|████      | 80/200 [3:14:49<6:01:00, 180.51s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 2.7142 - accuracy: 0.3802\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 18ms/step - loss: 2.7138 - accuracy: 0.3795 - val_loss: 1.8075 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.4873 - accuracy: 0.5298\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.4849 - accuracy: 0.5321 - val_loss: 1.7527 - val_accuracy: 0.2916\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.3205 - accuracy: 0.5706\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 1.3195 - accuracy: 0.5718 - val_loss: 1.4969 - val_accuracy: 0.3939\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.3824 - accuracy: 0.5415\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.3826 - accuracy: 0.5423 - val_loss: 2.0591 - val_accuracy: 0.3760\n",
            "Epoch 5/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.4489 - accuracy: 0.5534\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 1.4442 - accuracy: 0.5558 - val_loss: 1.4589 - val_accuracy: 0.4425\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.4353 - accuracy: 0.4858\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.4354 - accuracy: 0.4853 - val_loss: 1.1826 - val_accuracy: 0.5575\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.1840 - accuracy: 0.5887\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 1.1849 - accuracy: 0.5859 - val_loss: 1.3686 - val_accuracy: 0.5038\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.1791 - accuracy: 0.6205\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 1.1759 - accuracy: 0.6218 - val_loss: 1.2231 - val_accuracy: 0.5422\n",
            "Epoch 9/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.1250 - accuracy: 0.6224\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 1.1235 - accuracy: 0.6237 - val_loss: 1.3463 - val_accuracy: 0.5959\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.2253 - accuracy: 0.5803\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 1.2277 - accuracy: 0.5782 - val_loss: 1.2453 - val_accuracy: 0.5473\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.2740 - accuracy: 0.5408\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 1.2734 - accuracy: 0.5404 - val_loss: 1.1550 - val_accuracy: 0.5806\n",
            "Epoch 12/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.1103 - accuracy: 0.6549\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 1.1110 - accuracy: 0.6526 - val_loss: 1.1020 - val_accuracy: 0.6036\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.0620 - accuracy: 0.6833\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 1.0645 - accuracy: 0.6833 - val_loss: 1.2927 - val_accuracy: 0.5320\n",
            "Epoch 14/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.0391 - accuracy: 0.6842\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 1.0409 - accuracy: 0.6827 - val_loss: 1.1782 - val_accuracy: 0.6624\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.9266 - accuracy: 0.7157\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.9291 - accuracy: 0.7154 - val_loss: 1.5977 - val_accuracy: 0.6522\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 2.0098 - accuracy: 0.6697\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 1.9958 - accuracy: 0.6724 - val_loss: 1.0886 - val_accuracy: 0.6573\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.4262 - accuracy: 0.6069\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.4248 - accuracy: 0.6077 - val_loss: 1.2725 - val_accuracy: 0.6292\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.1784 - accuracy: 0.6807\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 1.1750 - accuracy: 0.6827 - val_loss: 1.2529 - val_accuracy: 0.6343\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.2451 - accuracy: 0.6289\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.2448 - accuracy: 0.6282 - val_loss: 1.5252 - val_accuracy: 0.4527\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.1997 - accuracy: 0.6859\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 1.1956 - accuracy: 0.6872 - val_loss: 1.2129 - val_accuracy: 0.6010\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.0743 - accuracy: 0.7098\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.0705 - accuracy: 0.7109 - val_loss: 1.2253 - val_accuracy: 0.6113\n",
            "Epoch 21: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/80/assets\n",
            "\n",
            "\n",
            " 40%|████      | 81/200 [3:15:59<4:52:18, 147.38s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 2.0076 - accuracy: 0.5972\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 18ms/step - loss: 2.0011 - accuracy: 0.5994 - val_loss: 1.9782 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.0033 - accuracy: 0.9152\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 1.0023 - accuracy: 0.9160 - val_loss: 2.3137 - val_accuracy: 0.5192\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7050 - accuracy: 0.9806\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.7037 - accuracy: 0.9808 - val_loss: 1.4215 - val_accuracy: 0.6854\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5545 - accuracy: 0.9877\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.5538 - accuracy: 0.9878 - val_loss: 0.5170 - val_accuracy: 0.9847\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4633 - accuracy: 0.9948\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.4628 - accuracy: 0.9949 - val_loss: 0.4477 - val_accuracy: 0.9872\n",
            "Epoch 6/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3955 - accuracy: 0.9961\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.3957 - accuracy: 0.9962 - val_loss: 0.4006 - val_accuracy: 0.9898\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3491 - accuracy: 0.9961\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.3488 - accuracy: 0.9962 - val_loss: 0.3420 - val_accuracy: 0.9872\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3069 - accuracy: 0.9981\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.3070 - accuracy: 0.9974 - val_loss: 0.3090 - val_accuracy: 0.9872\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2713 - accuracy: 0.9987\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.2711 - accuracy: 0.9987 - val_loss: 0.2780 - val_accuracy: 0.9872\n",
            "Epoch 10/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2420 - accuracy: 1.0000\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.2417 - accuracy: 1.0000 - val_loss: 0.2509 - val_accuracy: 0.9898\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2210 - accuracy: 1.0000\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.2208 - accuracy: 1.0000 - val_loss: 0.2303 - val_accuracy: 0.9898\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2019 - accuracy: 0.9987\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.2018 - accuracy: 0.9987 - val_loss: 0.2183 - val_accuracy: 0.9949\n",
            "Epoch 13/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1858 - accuracy: 0.9993\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1855 - accuracy: 0.9994 - val_loss: 0.2161 - val_accuracy: 0.9923\n",
            "Epoch 14/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1747 - accuracy: 1.0000\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1745 - accuracy: 1.0000 - val_loss: 0.1957 - val_accuracy: 0.9949\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1639 - accuracy: 0.9994\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1638 - accuracy: 0.9994 - val_loss: 0.1798 - val_accuracy: 0.9898\n",
            "Epoch 16/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1541 - accuracy: 1.0000\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1541 - accuracy: 1.0000 - val_loss: 0.1645 - val_accuracy: 0.9949\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1465 - accuracy: 1.0000\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1465 - accuracy: 1.0000 - val_loss: 0.1591 - val_accuracy: 0.9949\n",
            "Epoch 18/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1430 - accuracy: 0.9993\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1429 - accuracy: 0.9994 - val_loss: 0.1595 - val_accuracy: 0.9898\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1351 - accuracy: 1.0000\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1349 - accuracy: 1.0000 - val_loss: 0.1482 - val_accuracy: 0.9923\n",
            "Epoch 20/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1276 - accuracy: 1.0000\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1277 - accuracy: 1.0000 - val_loss: 0.1509 - val_accuracy: 0.9923\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1234 - accuracy: 1.0000\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1234 - accuracy: 1.0000 - val_loss: 0.1387 - val_accuracy: 0.9949\n",
            "Epoch 22/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1183 - accuracy: 1.0000\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1183 - accuracy: 1.0000 - val_loss: 0.1311 - val_accuracy: 0.9949\n",
            "Epoch 23/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1157 - accuracy: 1.0000\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1155 - accuracy: 1.0000 - val_loss: 0.1299 - val_accuracy: 0.9949\n",
            "Epoch 24/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1103 - accuracy: 1.0000\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1103 - accuracy: 1.0000 - val_loss: 0.1267 - val_accuracy: 0.9949\n",
            "Epoch 25/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1069 - accuracy: 1.0000\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1069 - accuracy: 1.0000 - val_loss: 0.1277 - val_accuracy: 0.9949\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1037 - accuracy: 1.0000\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1037 - accuracy: 1.0000 - val_loss: 0.1242 - val_accuracy: 0.9949\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1017 - accuracy: 1.0000\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1016 - accuracy: 1.0000 - val_loss: 0.1181 - val_accuracy: 0.9949\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0982 - accuracy: 1.0000\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0981 - accuracy: 1.0000 - val_loss: 0.1149 - val_accuracy: 0.9949\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0950 - accuracy: 1.0000\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0951 - accuracy: 1.0000 - val_loss: 0.1114 - val_accuracy: 0.9949\n",
            "Epoch 30/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0927 - accuracy: 1.0000\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0928 - accuracy: 1.0000 - val_loss: 0.1117 - val_accuracy: 0.9949\n",
            "Epoch 31/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0902 - accuracy: 1.0000\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0902 - accuracy: 1.0000 - val_loss: 0.1116 - val_accuracy: 0.9949\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0887 - accuracy: 1.0000\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0886 - accuracy: 1.0000 - val_loss: 0.1075 - val_accuracy: 0.9949\n",
            "Epoch 33/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0856 - accuracy: 1.0000\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0855 - accuracy: 1.0000 - val_loss: 0.1042 - val_accuracy: 0.9949\n",
            "Epoch 34/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0834 - accuracy: 1.0000\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0833 - accuracy: 1.0000 - val_loss: 0.1015 - val_accuracy: 0.9949\n",
            "Epoch 35/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0817 - accuracy: 1.0000\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0816 - accuracy: 1.0000 - val_loss: 0.1025 - val_accuracy: 0.9949\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0788 - accuracy: 1.0000\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0788 - accuracy: 1.0000 - val_loss: 0.1010 - val_accuracy: 0.9949\n",
            "Epoch 37/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0782 - accuracy: 1.0000\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0782 - accuracy: 1.0000 - val_loss: 0.0959 - val_accuracy: 0.9949\n",
            "Epoch 38/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0751 - accuracy: 1.0000\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0751 - accuracy: 1.0000 - val_loss: 0.1103 - val_accuracy: 0.9923\n",
            "Epoch 39/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0726 - accuracy: 1.0000\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0726 - accuracy: 1.0000 - val_loss: 0.0931 - val_accuracy: 0.9949\n",
            "Epoch 40/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0707 - accuracy: 1.0000\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0707 - accuracy: 1.0000 - val_loss: 0.0905 - val_accuracy: 0.9949\n",
            "Epoch 41/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0681 - accuracy: 1.0000\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0681 - accuracy: 1.0000 - val_loss: 0.0859 - val_accuracy: 0.9949\n",
            "Epoch 42/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0661 - accuracy: 1.0000\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0661 - accuracy: 1.0000 - val_loss: 0.0871 - val_accuracy: 0.9949\n",
            "Epoch 43/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0642 - accuracy: 1.0000\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0642 - accuracy: 1.0000 - val_loss: 0.0867 - val_accuracy: 0.9949\n",
            "Epoch 44/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0620 - accuracy: 1.0000\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0620 - accuracy: 1.0000 - val_loss: 0.0798 - val_accuracy: 0.9949\n",
            "Epoch 45/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0596 - accuracy: 1.0000\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0595 - accuracy: 1.0000 - val_loss: 0.0798 - val_accuracy: 0.9949\n",
            "Epoch 46/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0577 - accuracy: 1.0000\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0577 - accuracy: 1.0000 - val_loss: 0.0803 - val_accuracy: 0.9949\n",
            "Epoch 47/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0554 - accuracy: 1.0000\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0554 - accuracy: 1.0000 - val_loss: 0.0777 - val_accuracy: 0.9949\n",
            "Epoch 48/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0529 - accuracy: 1.0000\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0528 - accuracy: 1.0000 - val_loss: 0.0708 - val_accuracy: 0.9949\n",
            "Epoch 49/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0800 - accuracy: 0.9909\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0796 - accuracy: 0.9910 - val_loss: 0.0910 - val_accuracy: 0.9923\n",
            "Epoch 50/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0593 - accuracy: 0.9987\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0596 - accuracy: 0.9987 - val_loss: 0.0989 - val_accuracy: 0.9898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/81/assets\n",
            "\n",
            "\n",
            " 41%|████      | 82/200 [3:19:26<5:25:06, 165.31s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.9556 - accuracy: 0.7436\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 21ms/step - loss: 0.9531 - accuracy: 0.7449 - val_loss: 1.9728 - val_accuracy: 0.3223\n",
            "Epoch 2/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3333 - accuracy: 0.9513\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.3333 - accuracy: 0.9513 - val_loss: 2.0562 - val_accuracy: 0.3504\n",
            "Epoch 3/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2131 - accuracy: 0.9776\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.2131 - accuracy: 0.9776 - val_loss: 1.7198 - val_accuracy: 0.4348\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1578 - accuracy: 0.9903\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1574 - accuracy: 0.9904 - val_loss: 0.2334 - val_accuracy: 0.9744\n",
            "Epoch 5/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1959 - accuracy: 0.9746\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1957 - accuracy: 0.9750 - val_loss: 0.3202 - val_accuracy: 0.9437\n",
            "Epoch 6/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1384 - accuracy: 0.9904\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1384 - accuracy: 0.9904 - val_loss: 0.2288 - val_accuracy: 0.9693\n",
            "Epoch 7/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1145 - accuracy: 0.9968\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1144 - accuracy: 0.9968 - val_loss: 0.1440 - val_accuracy: 0.9898\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1267 - accuracy: 0.9890\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1264 - accuracy: 0.9891 - val_loss: 0.3290 - val_accuracy: 0.9361\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1300 - accuracy: 0.9890\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1299 - accuracy: 0.9891 - val_loss: 0.1249 - val_accuracy: 0.9949\n",
            "Epoch 10/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0882 - accuracy: 0.9994\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0882 - accuracy: 0.9994 - val_loss: 0.1004 - val_accuracy: 0.9923\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0819 - accuracy: 1.0000\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0818 - accuracy: 1.0000 - val_loss: 0.0962 - val_accuracy: 0.9974\n",
            "Epoch 12/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0778 - accuracy: 0.9987\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0778 - accuracy: 0.9987 - val_loss: 0.1155 - val_accuracy: 0.9821\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0771 - accuracy: 0.9994\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0770 - accuracy: 0.9994 - val_loss: 0.1616 - val_accuracy: 0.9770\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0725 - accuracy: 1.0000\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0728 - accuracy: 1.0000 - val_loss: 0.1520 - val_accuracy: 0.9693\n",
            "Epoch 15/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0736 - accuracy: 0.9994\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0735 - accuracy: 0.9994 - val_loss: 0.0857 - val_accuracy: 0.9949\n",
            "Epoch 16/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2094 - accuracy: 0.9620\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.2092 - accuracy: 0.9622 - val_loss: 0.6831 - val_accuracy: 0.8235\n",
            "Epoch 17/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1466 - accuracy: 0.9870\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1460 - accuracy: 0.9872 - val_loss: 0.1834 - val_accuracy: 0.9821\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1263 - accuracy: 0.9896\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1259 - accuracy: 0.9897 - val_loss: 0.1919 - val_accuracy: 0.9719\n",
            "Epoch 19/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0917 - accuracy: 1.0000\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.0917 - accuracy: 1.0000 - val_loss: 0.1095 - val_accuracy: 0.9898\n",
            "Epoch 20/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0806 - accuracy: 0.9981\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0806 - accuracy: 0.9981 - val_loss: 0.0993 - val_accuracy: 0.9949\n",
            "Epoch 20: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/82/assets\n",
            "\n",
            "\n",
            " 42%|████▏     | 83/200 [3:20:46<4:32:25, 139.71s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 2.3042 - accuracy: 0.1950\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 13ms/step - loss: 2.3010 - accuracy: 0.1962 - val_loss: 1.8098 - val_accuracy: 0.1918\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 2.0672 - accuracy: 0.2934\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 2.0653 - accuracy: 0.2936 - val_loss: 1.8012 - val_accuracy: 0.2583\n",
            "Epoch 3/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.9414 - accuracy: 0.3331\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.9411 - accuracy: 0.3333 - val_loss: 1.7726 - val_accuracy: 0.3043\n",
            "Epoch 4/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.8479 - accuracy: 0.3991\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 1.8510 - accuracy: 0.3962 - val_loss: 1.7596 - val_accuracy: 0.3708\n",
            "Epoch 5/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.7659 - accuracy: 0.4642\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.7690 - accuracy: 0.4609 - val_loss: 1.7272 - val_accuracy: 0.4348\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6982 - accuracy: 0.4825\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.6981 - accuracy: 0.4821 - val_loss: 1.6647 - val_accuracy: 0.4962\n",
            "Epoch 7/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.6246 - accuracy: 0.5299\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 1.6249 - accuracy: 0.5308 - val_loss: 1.6028 - val_accuracy: 0.5243\n",
            "Epoch 8/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 1.5626 - accuracy: 0.5796\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.5618 - accuracy: 0.5788 - val_loss: 1.5405 - val_accuracy: 0.5499\n",
            "Epoch 9/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.4907 - accuracy: 0.6014\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.4921 - accuracy: 0.6000 - val_loss: 1.4811 - val_accuracy: 0.5652\n",
            "Epoch 10/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.4324 - accuracy: 0.6257\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 1.4300 - accuracy: 0.6263 - val_loss: 1.4213 - val_accuracy: 0.5882\n",
            "Epoch 11/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 1.3717 - accuracy: 0.6355\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 1.3733 - accuracy: 0.6346 - val_loss: 1.3583 - val_accuracy: 0.6419\n",
            "Epoch 12/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.3017 - accuracy: 0.6829\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.3017 - accuracy: 0.6821 - val_loss: 1.2945 - val_accuracy: 0.6675\n",
            "Epoch 13/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 1.2369 - accuracy: 0.7046\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.2346 - accuracy: 0.7058 - val_loss: 1.2276 - val_accuracy: 0.6957\n",
            "Epoch 14/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.1725 - accuracy: 0.7330\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 1.1724 - accuracy: 0.7321 - val_loss: 1.1662 - val_accuracy: 0.7187\n",
            "Epoch 15/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.1152 - accuracy: 0.7500\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.1149 - accuracy: 0.7506 - val_loss: 1.1057 - val_accuracy: 0.7468\n",
            "Epoch 16/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.0555 - accuracy: 0.7795\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.0555 - accuracy: 0.7795 - val_loss: 1.0550 - val_accuracy: 0.7596\n",
            "Epoch 17/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 1.0027 - accuracy: 0.7993\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 1.0019 - accuracy: 0.7987 - val_loss: 1.0037 - val_accuracy: 0.7775\n",
            "Epoch 18/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.9605 - accuracy: 0.8106\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.9609 - accuracy: 0.8096 - val_loss: 0.9596 - val_accuracy: 0.7903\n",
            "Epoch 19/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.9084 - accuracy: 0.8392\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.9087 - accuracy: 0.8397 - val_loss: 0.9167 - val_accuracy: 0.8133\n",
            "Epoch 20/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.8688 - accuracy: 0.8547\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.8663 - accuracy: 0.8558 - val_loss: 0.8767 - val_accuracy: 0.8286\n",
            "Epoch 21/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.8377 - accuracy: 0.8618\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.8346 - accuracy: 0.8628 - val_loss: 0.8426 - val_accuracy: 0.8465\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8000 - accuracy: 0.8841\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.8002 - accuracy: 0.8846 - val_loss: 0.8139 - val_accuracy: 0.8465\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7695 - accuracy: 0.8880\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.7696 - accuracy: 0.8872 - val_loss: 0.7811 - val_accuracy: 0.8849\n",
            "Epoch 24/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.7453 - accuracy: 0.9033\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.7447 - accuracy: 0.9038 - val_loss: 0.7526 - val_accuracy: 0.8977\n",
            "Epoch 25/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.7183 - accuracy: 0.9143\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.7174 - accuracy: 0.9135 - val_loss: 0.7282 - val_accuracy: 0.8951\n",
            "Epoch 26/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.6956 - accuracy: 0.9130\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.6958 - accuracy: 0.9122 - val_loss: 0.7039 - val_accuracy: 0.8951\n",
            "Epoch 27/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.6648 - accuracy: 0.9240\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.6641 - accuracy: 0.9244 - val_loss: 0.6800 - val_accuracy: 0.9156\n",
            "Epoch 28/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.6481 - accuracy: 0.9336\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.6496 - accuracy: 0.9327 - val_loss: 0.6590 - val_accuracy: 0.9207\n",
            "Epoch 29/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.6208 - accuracy: 0.9388\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.6241 - accuracy: 0.9372 - val_loss: 0.6390 - val_accuracy: 0.9258\n",
            "Epoch 30/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.6182 - accuracy: 0.9287\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.6167 - accuracy: 0.9295 - val_loss: 0.6240 - val_accuracy: 0.9335\n",
            "Epoch 31/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.5910 - accuracy: 0.9459\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.5914 - accuracy: 0.9455 - val_loss: 0.6075 - val_accuracy: 0.9361\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5688 - accuracy: 0.9527\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.5690 - accuracy: 0.9526 - val_loss: 0.5838 - val_accuracy: 0.9463\n",
            "Epoch 33/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.5450 - accuracy: 0.9505\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.5463 - accuracy: 0.9506 - val_loss: 0.5681 - val_accuracy: 0.9514\n",
            "Epoch 34/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.5343 - accuracy: 0.9564\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.5353 - accuracy: 0.9551 - val_loss: 0.5553 - val_accuracy: 0.9488\n",
            "Epoch 35/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5197 - accuracy: 0.9598\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.5196 - accuracy: 0.9596 - val_loss: 0.5408 - val_accuracy: 0.9540\n",
            "Epoch 36/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.5024 - accuracy: 0.9625\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.5037 - accuracy: 0.9622 - val_loss: 0.5251 - val_accuracy: 0.9565\n",
            "Epoch 37/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.4982 - accuracy: 0.9601\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.4980 - accuracy: 0.9596 - val_loss: 0.5119 - val_accuracy: 0.9540\n",
            "Epoch 38/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.4764 - accuracy: 0.9712\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.4769 - accuracy: 0.9712 - val_loss: 0.4969 - val_accuracy: 0.9565\n",
            "Epoch 39/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.4696 - accuracy: 0.9679\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.4690 - accuracy: 0.9686 - val_loss: 0.4845 - val_accuracy: 0.9591\n",
            "Epoch 40/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.4611 - accuracy: 0.9673\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.4610 - accuracy: 0.9679 - val_loss: 0.4735 - val_accuracy: 0.9642\n",
            "Epoch 41/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.4445 - accuracy: 0.9733\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.4448 - accuracy: 0.9731 - val_loss: 0.4608 - val_accuracy: 0.9565\n",
            "Epoch 42/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4369 - accuracy: 0.9755\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.4369 - accuracy: 0.9756 - val_loss: 0.4526 - val_accuracy: 0.9642\n",
            "Epoch 43/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4229 - accuracy: 0.9788\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.4229 - accuracy: 0.9788 - val_loss: 0.4503 - val_accuracy: 0.9591\n",
            "Epoch 44/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.4105 - accuracy: 0.9810\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.4103 - accuracy: 0.9814 - val_loss: 0.4340 - val_accuracy: 0.9642\n",
            "Epoch 45/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4037 - accuracy: 0.9808\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.4037 - accuracy: 0.9808 - val_loss: 0.4217 - val_accuracy: 0.9668\n",
            "Epoch 46/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3932 - accuracy: 0.9833\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.3932 - accuracy: 0.9833 - val_loss: 0.4159 - val_accuracy: 0.9719\n",
            "Epoch 47/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.3836 - accuracy: 0.9862\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.3835 - accuracy: 0.9865 - val_loss: 0.4098 - val_accuracy: 0.9668\n",
            "Epoch 48/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3712 - accuracy: 0.9885\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.3712 - accuracy: 0.9885 - val_loss: 0.3974 - val_accuracy: 0.9770\n",
            "Epoch 49/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3631 - accuracy: 0.9870\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.3636 - accuracy: 0.9872 - val_loss: 0.3886 - val_accuracy: 0.9795\n",
            "Epoch 50/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3580 - accuracy: 0.9858\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.3577 - accuracy: 0.9859 - val_loss: 0.3786 - val_accuracy: 0.9795\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/83/assets\n",
            "\n",
            "\n",
            " 42%|████▏     | 84/200 [3:22:37<4:13:29, 131.12s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.2881 - accuracy: 0.6199\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 13ms/step - loss: 1.2881 - accuracy: 0.6199 - val_loss: 1.9128 - val_accuracy: 0.2711\n",
            "Epoch 2/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.8596 - accuracy: 0.8099\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.8585 - accuracy: 0.8096 - val_loss: 1.2865 - val_accuracy: 0.5524\n",
            "Epoch 3/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.4801 - accuracy: 0.9033\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.4769 - accuracy: 0.9051 - val_loss: 0.3814 - val_accuracy: 0.9565\n",
            "Epoch 4/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3750 - accuracy: 0.9342\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.3750 - accuracy: 0.9333 - val_loss: 0.3756 - val_accuracy: 0.9335\n",
            "Epoch 5/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2645 - accuracy: 0.9641\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.2645 - accuracy: 0.9641 - val_loss: 0.6972 - val_accuracy: 0.7647\n",
            "Epoch 6/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5114 - accuracy: 0.9019\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.5114 - accuracy: 0.9019 - val_loss: 0.3745 - val_accuracy: 0.9437\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3411 - accuracy: 0.9475\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.3396 - accuracy: 0.9481 - val_loss: 0.2299 - val_accuracy: 0.9693\n",
            "Epoch 8/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3607 - accuracy: 0.9388\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.3598 - accuracy: 0.9391 - val_loss: 0.2673 - val_accuracy: 0.9693\n",
            "Epoch 9/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3603 - accuracy: 0.9468\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.3603 - accuracy: 0.9468 - val_loss: 1.7991 - val_accuracy: 0.8491\n",
            "Epoch 10/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.2954 - accuracy: 0.9594\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.2938 - accuracy: 0.9596 - val_loss: 0.4315 - val_accuracy: 0.8875\n",
            "Epoch 11/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.3488 - accuracy: 0.9457\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.3477 - accuracy: 0.9462 - val_loss: 0.2900 - val_accuracy: 0.9744\n",
            "Epoch 12/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3762 - accuracy: 0.9460\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.3740 - accuracy: 0.9468 - val_loss: 0.3877 - val_accuracy: 0.9258\n",
            "Epoch 12: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/84/assets\n",
            "\n",
            "\n",
            " 42%|████▎     | 85/200 [3:23:07<3:12:50, 100.61s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 2.3517 - accuracy: 0.2441\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 13ms/step - loss: 2.3459 - accuracy: 0.2462 - val_loss: 1.7583 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 2.0412 - accuracy: 0.2921\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 2.0387 - accuracy: 0.2929 - val_loss: 1.7639 - val_accuracy: 0.2864\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.9245 - accuracy: 0.3329\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.9243 - accuracy: 0.3333 - val_loss: 1.7330 - val_accuracy: 0.3069\n",
            "Epoch 4/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.8441 - accuracy: 0.3567\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.8439 - accuracy: 0.3577 - val_loss: 1.7236 - val_accuracy: 0.3734\n",
            "Epoch 5/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.7700 - accuracy: 0.4012\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.7736 - accuracy: 0.3981 - val_loss: 1.6918 - val_accuracy: 0.4271\n",
            "Epoch 6/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.7070 - accuracy: 0.4319\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.7036 - accuracy: 0.4327 - val_loss: 1.6393 - val_accuracy: 0.4706\n",
            "Epoch 7/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.6268 - accuracy: 0.4935\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.6296 - accuracy: 0.4917 - val_loss: 1.5836 - val_accuracy: 0.5090\n",
            "Epoch 8/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.5837 - accuracy: 0.5026\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.5826 - accuracy: 0.5032 - val_loss: 1.5299 - val_accuracy: 0.5371\n",
            "Epoch 9/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 1.5298 - accuracy: 0.5316\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.5299 - accuracy: 0.5327 - val_loss: 1.4750 - val_accuracy: 0.5524\n",
            "Epoch 10/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.4682 - accuracy: 0.5632\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 1.4715 - accuracy: 0.5609 - val_loss: 1.4216 - val_accuracy: 0.5806\n",
            "Epoch 11/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.4251 - accuracy: 0.5749\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.4243 - accuracy: 0.5744 - val_loss: 1.3713 - val_accuracy: 0.6087\n",
            "Epoch 12/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.3731 - accuracy: 0.6083\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.3731 - accuracy: 0.6083 - val_loss: 1.3218 - val_accuracy: 0.6292\n",
            "Epoch 13/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.3181 - accuracy: 0.6374\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 1.3121 - accuracy: 0.6410 - val_loss: 1.2754 - val_accuracy: 0.6547\n",
            "Epoch 14/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 1.2662 - accuracy: 0.6441\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.2656 - accuracy: 0.6449 - val_loss: 1.2276 - val_accuracy: 0.6726\n",
            "Epoch 15/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.2240 - accuracy: 0.6772\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.2243 - accuracy: 0.6769 - val_loss: 1.1859 - val_accuracy: 0.6905\n",
            "Epoch 16/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.1847 - accuracy: 0.6821\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.1847 - accuracy: 0.6821 - val_loss: 1.1464 - val_accuracy: 0.7059\n",
            "Epoch 17/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.1484 - accuracy: 0.7000\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 1.1484 - accuracy: 0.7000 - val_loss: 1.1059 - val_accuracy: 0.7136\n",
            "Epoch 18/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.1033 - accuracy: 0.7179\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.1025 - accuracy: 0.7186 - val_loss: 1.0686 - val_accuracy: 0.7263\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.0688 - accuracy: 0.7306\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.0684 - accuracy: 0.7308 - val_loss: 1.0378 - val_accuracy: 0.7212\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.0360 - accuracy: 0.7481\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.0331 - accuracy: 0.7494 - val_loss: 1.0040 - val_accuracy: 0.7391\n",
            "Epoch 21/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.9993 - accuracy: 0.7728\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.9987 - accuracy: 0.7724 - val_loss: 0.9706 - val_accuracy: 0.7494\n",
            "Epoch 22/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.9645 - accuracy: 0.7786\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.9630 - accuracy: 0.7788 - val_loss: 0.9337 - val_accuracy: 0.7698\n",
            "Epoch 23/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.9242 - accuracy: 0.8013\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.9242 - accuracy: 0.8013 - val_loss: 0.8977 - val_accuracy: 0.8031\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.9195 - accuracy: 0.7986\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.9170 - accuracy: 0.7987 - val_loss: 0.8722 - val_accuracy: 0.8082\n",
            "Epoch 25/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.8778 - accuracy: 0.8224\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.8778 - accuracy: 0.8224 - val_loss: 0.8417 - val_accuracy: 0.8210\n",
            "Epoch 26/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.8568 - accuracy: 0.8229\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.8554 - accuracy: 0.8244 - val_loss: 0.8196 - val_accuracy: 0.8338\n",
            "Epoch 27/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.8215 - accuracy: 0.8372\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.8215 - accuracy: 0.8372 - val_loss: 0.7892 - val_accuracy: 0.8440\n",
            "Epoch 28/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.7921 - accuracy: 0.8645\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.7892 - accuracy: 0.8647 - val_loss: 0.7635 - val_accuracy: 0.8568\n",
            "Epoch 29/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.7576 - accuracy: 0.8750\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.7571 - accuracy: 0.8737 - val_loss: 0.7401 - val_accuracy: 0.8696\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7393 - accuracy: 0.8795\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.7395 - accuracy: 0.8801 - val_loss: 0.7176 - val_accuracy: 0.8721\n",
            "Epoch 31/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7426 - accuracy: 0.8692\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.7419 - accuracy: 0.8699 - val_loss: 0.7000 - val_accuracy: 0.9028\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6945 - accuracy: 0.8996\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.6961 - accuracy: 0.8987 - val_loss: 0.6848 - val_accuracy: 0.8951\n",
            "Epoch 33/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.6870 - accuracy: 0.9001\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.6884 - accuracy: 0.9000 - val_loss: 0.6546 - val_accuracy: 0.9130\n",
            "Epoch 34/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6570 - accuracy: 0.9135\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.6570 - accuracy: 0.9135 - val_loss: 0.6381 - val_accuracy: 0.9309\n",
            "Epoch 35/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6444 - accuracy: 0.9074\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.6448 - accuracy: 0.9071 - val_loss: 0.6180 - val_accuracy: 0.9233\n",
            "Epoch 36/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6225 - accuracy: 0.9301\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.6225 - accuracy: 0.9301 - val_loss: 0.6009 - val_accuracy: 0.9335\n",
            "Epoch 37/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.6083 - accuracy: 0.9290\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.6078 - accuracy: 0.9295 - val_loss: 0.5864 - val_accuracy: 0.9437\n",
            "Epoch 38/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5887 - accuracy: 0.9365\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.5887 - accuracy: 0.9365 - val_loss: 0.5716 - val_accuracy: 0.9514\n",
            "Epoch 39/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5777 - accuracy: 0.9410\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.5777 - accuracy: 0.9410 - val_loss: 0.5618 - val_accuracy: 0.9463\n",
            "Epoch 40/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5581 - accuracy: 0.9468\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.5581 - accuracy: 0.9468 - val_loss: 0.5525 - val_accuracy: 0.9437\n",
            "Epoch 41/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.5498 - accuracy: 0.9466\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.5508 - accuracy: 0.9462 - val_loss: 0.5333 - val_accuracy: 0.9642\n",
            "Epoch 42/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.5472 - accuracy: 0.9440\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.5450 - accuracy: 0.9449 - val_loss: 0.5216 - val_accuracy: 0.9591\n",
            "Epoch 43/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.5163 - accuracy: 0.9536\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.5167 - accuracy: 0.9532 - val_loss: 0.5119 - val_accuracy: 0.9642\n",
            "Epoch 44/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.5143 - accuracy: 0.9525\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.5140 - accuracy: 0.9526 - val_loss: 0.4995 - val_accuracy: 0.9668\n",
            "Epoch 45/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5071 - accuracy: 0.9514\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.5071 - accuracy: 0.9519 - val_loss: 0.4873 - val_accuracy: 0.9668\n",
            "Epoch 46/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4939 - accuracy: 0.9592\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.4929 - accuracy: 0.9596 - val_loss: 0.4817 - val_accuracy: 0.9642\n",
            "Epoch 47/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.4798 - accuracy: 0.9609\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.4785 - accuracy: 0.9615 - val_loss: 0.4710 - val_accuracy: 0.9693\n",
            "Epoch 48/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4799 - accuracy: 0.9575\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.4793 - accuracy: 0.9577 - val_loss: 0.4678 - val_accuracy: 0.9540\n",
            "Epoch 49/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.4650 - accuracy: 0.9691\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.4619 - accuracy: 0.9699 - val_loss: 0.4533 - val_accuracy: 0.9668\n",
            "Epoch 50/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4503 - accuracy: 0.9718\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.4503 - accuracy: 0.9718 - val_loss: 0.4424 - val_accuracy: 0.9719\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/85/assets\n",
            "\n",
            "\n",
            " 43%|████▎     | 86/200 [3:25:02<3:19:39, 105.09s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 2.5975 - accuracy: 0.1571\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 11ms/step - loss: 2.5975 - accuracy: 0.1571 - val_loss: 1.8254 - val_accuracy: 0.1228\n",
            "Epoch 2/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 2.1835 - accuracy: 0.2103\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 2.1812 - accuracy: 0.2115 - val_loss: 1.8220 - val_accuracy: 0.1841\n",
            "Epoch 3/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 2.0367 - accuracy: 0.2631\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 2.0352 - accuracy: 0.2641 - val_loss: 1.7852 - val_accuracy: 0.2839\n",
            "Epoch 4/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.9206 - accuracy: 0.3338\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.9196 - accuracy: 0.3353 - val_loss: 1.7627 - val_accuracy: 0.3913\n",
            "Epoch 5/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.8318 - accuracy: 0.3885\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 1.8308 - accuracy: 0.3891 - val_loss: 1.7267 - val_accuracy: 0.4348\n",
            "Epoch 6/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 1.7654 - accuracy: 0.4178\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 1.7643 - accuracy: 0.4186 - val_loss: 1.6723 - val_accuracy: 0.4808\n",
            "Epoch 7/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.6995 - accuracy: 0.4857\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.6984 - accuracy: 0.4853 - val_loss: 1.6181 - val_accuracy: 0.5269\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6407 - accuracy: 0.5259\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.6398 - accuracy: 0.5256 - val_loss: 1.5671 - val_accuracy: 0.5448\n",
            "Epoch 9/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.5832 - accuracy: 0.5503\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 1.5826 - accuracy: 0.5506 - val_loss: 1.5197 - val_accuracy: 0.5499\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.5330 - accuracy: 0.5745\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 1.5317 - accuracy: 0.5756 - val_loss: 1.4758 - val_accuracy: 0.5857\n",
            "Epoch 11/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.4883 - accuracy: 0.5975\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.4901 - accuracy: 0.5968 - val_loss: 1.4305 - val_accuracy: 0.6215\n",
            "Epoch 12/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.4381 - accuracy: 0.6296\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 1.4448 - accuracy: 0.6250 - val_loss: 1.3913 - val_accuracy: 0.6522\n",
            "Epoch 13/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 1.3976 - accuracy: 0.6428\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.3976 - accuracy: 0.6404 - val_loss: 1.3537 - val_accuracy: 0.6675\n",
            "Epoch 14/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.3638 - accuracy: 0.6562\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 1.3646 - accuracy: 0.6564 - val_loss: 1.3157 - val_accuracy: 0.6701\n",
            "Epoch 15/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 1.3213 - accuracy: 0.6711\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 1.3191 - accuracy: 0.6731 - val_loss: 1.2769 - val_accuracy: 0.6905\n",
            "Epoch 16/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.2814 - accuracy: 0.6898\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.2838 - accuracy: 0.6891 - val_loss: 1.2411 - val_accuracy: 0.6931\n",
            "Epoch 17/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 1.2395 - accuracy: 0.6980\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 1.2441 - accuracy: 0.6955 - val_loss: 1.2046 - val_accuracy: 0.7187\n",
            "Epoch 18/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 1.2066 - accuracy: 0.7086\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 1.2078 - accuracy: 0.7071 - val_loss: 1.1727 - val_accuracy: 0.7315\n",
            "Epoch 19/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.1700 - accuracy: 0.7326\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.1709 - accuracy: 0.7327 - val_loss: 1.1431 - val_accuracy: 0.7315\n",
            "Epoch 20/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.1336 - accuracy: 0.7332\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.1359 - accuracy: 0.7321 - val_loss: 1.1079 - val_accuracy: 0.7494\n",
            "Epoch 21/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.0974 - accuracy: 0.7429\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 1.0974 - accuracy: 0.7429 - val_loss: 1.0760 - val_accuracy: 0.7545\n",
            "Epoch 22/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.0843 - accuracy: 0.7533\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.0835 - accuracy: 0.7532 - val_loss: 1.0443 - val_accuracy: 0.7596\n",
            "Epoch 23/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.0357 - accuracy: 0.7723\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 1.0363 - accuracy: 0.7737 - val_loss: 1.0106 - val_accuracy: 0.7698\n",
            "Epoch 24/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.9946 - accuracy: 0.7842\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.0004 - accuracy: 0.7801 - val_loss: 0.9803 - val_accuracy: 0.7749\n",
            "Epoch 25/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.9712 - accuracy: 0.7936\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.9712 - accuracy: 0.7936 - val_loss: 0.9477 - val_accuracy: 0.8005\n",
            "Epoch 26/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.9387 - accuracy: 0.8035\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.9390 - accuracy: 0.8032 - val_loss: 0.9183 - val_accuracy: 0.8159\n",
            "Epoch 27/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.9287 - accuracy: 0.7991\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.9274 - accuracy: 0.8006 - val_loss: 0.8899 - val_accuracy: 0.8235\n",
            "Epoch 28/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.8921 - accuracy: 0.8237\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.8921 - accuracy: 0.8237 - val_loss: 0.8634 - val_accuracy: 0.8338\n",
            "Epoch 29/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.8578 - accuracy: 0.8408\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.8607 - accuracy: 0.8404 - val_loss: 0.8403 - val_accuracy: 0.8414\n",
            "Epoch 30/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.8463 - accuracy: 0.8391\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.8463 - accuracy: 0.8391 - val_loss: 0.8144 - val_accuracy: 0.8542\n",
            "Epoch 31/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.8163 - accuracy: 0.8454\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.8150 - accuracy: 0.8462 - val_loss: 0.7936 - val_accuracy: 0.8645\n",
            "Epoch 32/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.8015 - accuracy: 0.8481\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.8015 - accuracy: 0.8481 - val_loss: 0.7754 - val_accuracy: 0.8824\n",
            "Epoch 33/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7673 - accuracy: 0.8679\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.7663 - accuracy: 0.8679 - val_loss: 0.7544 - val_accuracy: 0.8849\n",
            "Epoch 34/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.7574 - accuracy: 0.8731\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.7574 - accuracy: 0.8731 - val_loss: 0.7360 - val_accuracy: 0.8798\n",
            "Epoch 35/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.7403 - accuracy: 0.8814\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.7392 - accuracy: 0.8814 - val_loss: 0.7164 - val_accuracy: 0.8900\n",
            "Epoch 36/50\n",
            "188/195 [===========================>..] - ETA: 0s - loss: 0.7148 - accuracy: 0.8797\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.7182 - accuracy: 0.8782 - val_loss: 0.6989 - val_accuracy: 0.8951\n",
            "Epoch 37/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.7051 - accuracy: 0.8835\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.7038 - accuracy: 0.8840 - val_loss: 0.6827 - val_accuracy: 0.8926\n",
            "Epoch 38/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.6800 - accuracy: 0.9053\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.6799 - accuracy: 0.9064 - val_loss: 0.6689 - val_accuracy: 0.8951\n",
            "Epoch 39/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.6693 - accuracy: 0.8914\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.6676 - accuracy: 0.8942 - val_loss: 0.6558 - val_accuracy: 0.9054\n",
            "Epoch 40/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 0.6773 - accuracy: 0.8955\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.6772 - accuracy: 0.8949 - val_loss: 0.6443 - val_accuracy: 0.9028\n",
            "Epoch 41/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.6561 - accuracy: 0.8982\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.6548 - accuracy: 0.8987 - val_loss: 0.6301 - val_accuracy: 0.9105\n",
            "Epoch 42/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.6313 - accuracy: 0.9171\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.6308 - accuracy: 0.9179 - val_loss: 0.6164 - val_accuracy: 0.9182\n",
            "Epoch 43/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 0.6300 - accuracy: 0.9127\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.6304 - accuracy: 0.9115 - val_loss: 0.6070 - val_accuracy: 0.9284\n",
            "Epoch 44/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.6222 - accuracy: 0.9123\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.6220 - accuracy: 0.9115 - val_loss: 0.5958 - val_accuracy: 0.9309\n",
            "Epoch 45/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.5990 - accuracy: 0.9284\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.5986 - accuracy: 0.9282 - val_loss: 0.5868 - val_accuracy: 0.9233\n",
            "Epoch 46/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5985 - accuracy: 0.9224\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.5985 - accuracy: 0.9224 - val_loss: 0.5743 - val_accuracy: 0.9412\n",
            "Epoch 47/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5827 - accuracy: 0.9308\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.5827 - accuracy: 0.9308 - val_loss: 0.5659 - val_accuracy: 0.9309\n",
            "Epoch 48/50\n",
            "188/195 [===========================>..] - ETA: 0s - loss: 0.5798 - accuracy: 0.9215\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.5775 - accuracy: 0.9231 - val_loss: 0.5565 - val_accuracy: 0.9412\n",
            "Epoch 49/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5652 - accuracy: 0.9365\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.5652 - accuracy: 0.9365 - val_loss: 0.5480 - val_accuracy: 0.9463\n",
            "Epoch 50/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.5509 - accuracy: 0.9362\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.5470 - accuracy: 0.9372 - val_loss: 0.5384 - val_accuracy: 0.9463\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/86/assets\n",
            "\n",
            "\n",
            " 44%|████▎     | 87/200 [3:27:30<3:41:48, 117.77s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 2.7106 - accuracy: 0.3981\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 9s 36ms/step - loss: 2.7106 - accuracy: 0.3981 - val_loss: 1.9734 - val_accuracy: 0.3683\n",
            "Epoch 2/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.9953 - accuracy: 0.6564\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 34ms/step - loss: 1.9953 - accuracy: 0.6564 - val_loss: 1.9112 - val_accuracy: 0.4041\n",
            "Epoch 3/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6708 - accuracy: 0.7628\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 34ms/step - loss: 1.6708 - accuracy: 0.7628 - val_loss: 1.6558 - val_accuracy: 0.5575\n",
            "Epoch 4/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.4584 - accuracy: 0.8231\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 34ms/step - loss: 1.4584 - accuracy: 0.8231 - val_loss: 1.3545 - val_accuracy: 0.8542\n",
            "Epoch 5/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.3141 - accuracy: 0.8603\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 35ms/step - loss: 1.3141 - accuracy: 0.8603 - val_loss: 1.2520 - val_accuracy: 0.8875\n",
            "Epoch 6/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.1916 - accuracy: 0.9071\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 34ms/step - loss: 1.1916 - accuracy: 0.9071 - val_loss: 1.1594 - val_accuracy: 0.9003\n",
            "Epoch 7/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.0828 - accuracy: 0.9410\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 34ms/step - loss: 1.0828 - accuracy: 0.9410 - val_loss: 1.0707 - val_accuracy: 0.9284\n",
            "Epoch 8/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.0059 - accuracy: 0.9564\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 34ms/step - loss: 1.0059 - accuracy: 0.9564 - val_loss: 1.0078 - val_accuracy: 0.9719\n",
            "Epoch 9/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.9487 - accuracy: 0.9609\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 34ms/step - loss: 0.9487 - accuracy: 0.9609 - val_loss: 0.9484 - val_accuracy: 0.9693\n",
            "Epoch 10/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.8903 - accuracy: 0.9744\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 33ms/step - loss: 0.8903 - accuracy: 0.9744 - val_loss: 0.8910 - val_accuracy: 0.9693\n",
            "Epoch 11/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.8419 - accuracy: 0.9840\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 34ms/step - loss: 0.8419 - accuracy: 0.9840 - val_loss: 0.8578 - val_accuracy: 0.9642\n",
            "Epoch 12/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.8047 - accuracy: 0.9878\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 34ms/step - loss: 0.8047 - accuracy: 0.9878 - val_loss: 0.8216 - val_accuracy: 0.9795\n",
            "Epoch 13/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.7730 - accuracy: 0.9872\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 33ms/step - loss: 0.7730 - accuracy: 0.9872 - val_loss: 0.7844 - val_accuracy: 0.9770\n",
            "Epoch 14/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.7364 - accuracy: 0.9929\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 34ms/step - loss: 0.7364 - accuracy: 0.9929 - val_loss: 0.7548 - val_accuracy: 0.9795\n",
            "Epoch 15/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.7125 - accuracy: 0.9936\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 34ms/step - loss: 0.7125 - accuracy: 0.9936 - val_loss: 0.7271 - val_accuracy: 0.9795\n",
            "Epoch 16/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6850 - accuracy: 0.9936\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 34ms/step - loss: 0.6850 - accuracy: 0.9936 - val_loss: 0.7049 - val_accuracy: 0.9795\n",
            "Epoch 17/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6632 - accuracy: 0.9974\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 34ms/step - loss: 0.6632 - accuracy: 0.9974 - val_loss: 0.6830 - val_accuracy: 0.9872\n",
            "Epoch 18/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6402 - accuracy: 0.9974\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 34ms/step - loss: 0.6402 - accuracy: 0.9974 - val_loss: 0.6622 - val_accuracy: 0.9872\n",
            "Epoch 19/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6252 - accuracy: 0.9962\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 34ms/step - loss: 0.6252 - accuracy: 0.9962 - val_loss: 0.6439 - val_accuracy: 0.9872\n",
            "Epoch 20/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6040 - accuracy: 0.9974\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 34ms/step - loss: 0.6040 - accuracy: 0.9974 - val_loss: 0.6256 - val_accuracy: 0.9847\n",
            "Epoch 21/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5865 - accuracy: 0.9962\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 34ms/step - loss: 0.5865 - accuracy: 0.9962 - val_loss: 0.6139 - val_accuracy: 0.9847\n",
            "Epoch 22/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5739 - accuracy: 0.9962\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 34ms/step - loss: 0.5739 - accuracy: 0.9962 - val_loss: 0.5979 - val_accuracy: 0.9872\n",
            "Epoch 23/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5617 - accuracy: 0.9968\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 34ms/step - loss: 0.5617 - accuracy: 0.9968 - val_loss: 0.5820 - val_accuracy: 0.9923\n",
            "Epoch 24/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5450 - accuracy: 0.9981\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 34ms/step - loss: 0.5450 - accuracy: 0.9981 - val_loss: 0.5721 - val_accuracy: 0.9847\n",
            "Epoch 25/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5295 - accuracy: 0.9981\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 33ms/step - loss: 0.5295 - accuracy: 0.9981 - val_loss: 0.5571 - val_accuracy: 0.9923\n",
            "Epoch 26/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5226 - accuracy: 0.9981\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 0.5226 - accuracy: 0.9981 - val_loss: 0.5432 - val_accuracy: 0.9898\n",
            "Epoch 27/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5103 - accuracy: 0.9987\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 34ms/step - loss: 0.5103 - accuracy: 0.9987 - val_loss: 0.5312 - val_accuracy: 0.9923\n",
            "Epoch 28/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4996 - accuracy: 0.9994\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 33ms/step - loss: 0.4996 - accuracy: 0.9994 - val_loss: 0.5242 - val_accuracy: 0.9923\n",
            "Epoch 29/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4893 - accuracy: 0.9994\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 33ms/step - loss: 0.4893 - accuracy: 0.9994 - val_loss: 0.5148 - val_accuracy: 0.9923\n",
            "Epoch 30/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4795 - accuracy: 0.9987\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 33ms/step - loss: 0.4795 - accuracy: 0.9987 - val_loss: 0.5027 - val_accuracy: 0.9898\n",
            "Epoch 31/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4707 - accuracy: 0.9987\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 34ms/step - loss: 0.4707 - accuracy: 0.9987 - val_loss: 0.4938 - val_accuracy: 0.9898\n",
            "Epoch 32/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4603 - accuracy: 0.9994\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 34ms/step - loss: 0.4603 - accuracy: 0.9994 - val_loss: 0.4905 - val_accuracy: 0.9898\n",
            "Epoch 33/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4533 - accuracy: 0.9994\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 33ms/step - loss: 0.4533 - accuracy: 0.9994 - val_loss: 0.4737 - val_accuracy: 0.9949\n",
            "Epoch 34/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4474 - accuracy: 0.9981\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 0.4474 - accuracy: 0.9981 - val_loss: 0.4690 - val_accuracy: 0.9923\n",
            "Epoch 35/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4367 - accuracy: 0.9994\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 34ms/step - loss: 0.4367 - accuracy: 0.9994 - val_loss: 0.4589 - val_accuracy: 0.9949\n",
            "Epoch 36/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4290 - accuracy: 0.9987\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 34ms/step - loss: 0.4290 - accuracy: 0.9987 - val_loss: 0.4541 - val_accuracy: 0.9898\n",
            "Epoch 37/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4232 - accuracy: 0.9994\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 34ms/step - loss: 0.4232 - accuracy: 0.9994 - val_loss: 0.4488 - val_accuracy: 0.9923\n",
            "Epoch 38/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4162 - accuracy: 0.9994\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 34ms/step - loss: 0.4162 - accuracy: 0.9994 - val_loss: 0.4448 - val_accuracy: 0.9847\n",
            "Epoch 39/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4092 - accuracy: 0.9994\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 34ms/step - loss: 0.4092 - accuracy: 0.9994 - val_loss: 0.4348 - val_accuracy: 0.9949\n",
            "Epoch 40/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4028 - accuracy: 0.9987\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 33ms/step - loss: 0.4028 - accuracy: 0.9987 - val_loss: 0.4248 - val_accuracy: 0.9949\n",
            "Epoch 41/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3965 - accuracy: 1.0000\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 33ms/step - loss: 0.3965 - accuracy: 1.0000 - val_loss: 0.4217 - val_accuracy: 0.9949\n",
            "Epoch 42/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3940 - accuracy: 0.9994\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 34ms/step - loss: 0.3940 - accuracy: 0.9994 - val_loss: 0.4169 - val_accuracy: 0.9923\n",
            "Epoch 43/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3871 - accuracy: 0.9974\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 33ms/step - loss: 0.3871 - accuracy: 0.9974 - val_loss: 0.4098 - val_accuracy: 0.9949\n",
            "Epoch 44/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3801 - accuracy: 0.9994\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 33ms/step - loss: 0.3801 - accuracy: 0.9994 - val_loss: 0.4064 - val_accuracy: 0.9898\n",
            "Epoch 45/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3747 - accuracy: 0.9987\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 0.3747 - accuracy: 0.9987 - val_loss: 0.3999 - val_accuracy: 0.9949\n",
            "Epoch 46/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3710 - accuracy: 0.9994\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 33ms/step - loss: 0.3710 - accuracy: 0.9994 - val_loss: 0.3938 - val_accuracy: 0.9923\n",
            "Epoch 47/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3653 - accuracy: 0.9994\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 33ms/step - loss: 0.3653 - accuracy: 0.9994 - val_loss: 0.3883 - val_accuracy: 0.9949\n",
            "Epoch 48/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3594 - accuracy: 0.9994\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 33ms/step - loss: 0.3594 - accuracy: 0.9994 - val_loss: 0.3888 - val_accuracy: 0.9949\n",
            "Epoch 49/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3549 - accuracy: 1.0000\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 33ms/step - loss: 0.3549 - accuracy: 1.0000 - val_loss: 0.3799 - val_accuracy: 0.9949\n",
            "Epoch 50/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3506 - accuracy: 1.0000\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 33ms/step - loss: 0.3506 - accuracy: 1.0000 - val_loss: 0.3737 - val_accuracy: 0.9949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/87/assets\n",
            "\n",
            "\n",
            " 44%|████▍     | 88/200 [3:33:04<5:41:04, 182.72s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.8915 - accuracy: 0.4551\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 18ms/step - loss: 1.8915 - accuracy: 0.4551 - val_loss: 1.7355 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.0762 - accuracy: 0.8063\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 1.0748 - accuracy: 0.8058 - val_loss: 1.7119 - val_accuracy: 0.2890\n",
            "Epoch 3/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.7301 - accuracy: 0.9130\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.7303 - accuracy: 0.9128 - val_loss: 1.2099 - val_accuracy: 0.5678\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5680 - accuracy: 0.9495\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.5664 - accuracy: 0.9500 - val_loss: 0.6015 - val_accuracy: 0.9130\n",
            "Epoch 5/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.4719 - accuracy: 0.9701\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.4701 - accuracy: 0.9705 - val_loss: 0.4397 - val_accuracy: 0.9668\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4113 - accuracy: 0.9773\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.4103 - accuracy: 0.9776 - val_loss: 0.4264 - val_accuracy: 0.9744\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3557 - accuracy: 0.9890\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.3554 - accuracy: 0.9891 - val_loss: 0.3255 - val_accuracy: 0.9872\n",
            "Epoch 8/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3186 - accuracy: 0.9922\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.3187 - accuracy: 0.9923 - val_loss: 0.2944 - val_accuracy: 0.9949\n",
            "Epoch 9/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2873 - accuracy: 0.9961\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.2866 - accuracy: 0.9962 - val_loss: 0.2827 - val_accuracy: 0.9872\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2627 - accuracy: 0.9955\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.2622 - accuracy: 0.9955 - val_loss: 0.2438 - val_accuracy: 0.9949\n",
            "Epoch 11/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2402 - accuracy: 0.9961\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.2399 - accuracy: 0.9962 - val_loss: 0.2389 - val_accuracy: 0.9898\n",
            "Epoch 12/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2187 - accuracy: 0.9980\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.2186 - accuracy: 0.9981 - val_loss: 0.2544 - val_accuracy: 0.9770\n",
            "Epoch 13/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2097 - accuracy: 0.9974\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.2097 - accuracy: 0.9974 - val_loss: 0.2017 - val_accuracy: 0.9923\n",
            "Epoch 14/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1894 - accuracy: 0.9974\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1892 - accuracy: 0.9974 - val_loss: 0.1967 - val_accuracy: 0.9898\n",
            "Epoch 15/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1835 - accuracy: 0.9968\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1836 - accuracy: 0.9968 - val_loss: 0.1971 - val_accuracy: 0.9872\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1707 - accuracy: 0.9981\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1706 - accuracy: 0.9981 - val_loss: 0.1675 - val_accuracy: 0.9974\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1687 - accuracy: 0.9974\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1684 - accuracy: 0.9974 - val_loss: 0.1894 - val_accuracy: 0.9898\n",
            "Epoch 18/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1548 - accuracy: 0.9987\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1547 - accuracy: 0.9987 - val_loss: 0.1919 - val_accuracy: 0.9847\n",
            "Epoch 19/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1450 - accuracy: 1.0000\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1455 - accuracy: 0.9994 - val_loss: 0.1517 - val_accuracy: 0.9974\n",
            "Epoch 20/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1536 - accuracy: 0.9961\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1540 - accuracy: 0.9962 - val_loss: 0.1511 - val_accuracy: 0.9949\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1336 - accuracy: 1.0000\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1336 - accuracy: 1.0000 - val_loss: 0.1417 - val_accuracy: 0.9974\n",
            "Epoch 22/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1282 - accuracy: 0.9994\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1282 - accuracy: 0.9994 - val_loss: 0.1337 - val_accuracy: 0.9949\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1257 - accuracy: 0.9987\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1255 - accuracy: 0.9987 - val_loss: 0.1375 - val_accuracy: 0.9923\n",
            "Epoch 24/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1189 - accuracy: 0.9993\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1188 - accuracy: 0.9994 - val_loss: 0.1299 - val_accuracy: 0.9974\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1176 - accuracy: 0.9994\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1175 - accuracy: 0.9994 - val_loss: 0.1255 - val_accuracy: 0.9974\n",
            "Epoch 26/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1131 - accuracy: 1.0000\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1130 - accuracy: 1.0000 - val_loss: 0.1185 - val_accuracy: 0.9974\n",
            "Epoch 27/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1104 - accuracy: 1.0000\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1104 - accuracy: 1.0000 - val_loss: 0.1223 - val_accuracy: 0.9949\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1044 - accuracy: 1.0000\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1044 - accuracy: 1.0000 - val_loss: 0.1198 - val_accuracy: 0.9949\n",
            "Epoch 29/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1011 - accuracy: 0.9994\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1011 - accuracy: 0.9994 - val_loss: 0.1179 - val_accuracy: 0.9949\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0993 - accuracy: 0.9994\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0992 - accuracy: 0.9994 - val_loss: 0.1100 - val_accuracy: 0.9949\n",
            "Epoch 31/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0958 - accuracy: 1.0000\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0958 - accuracy: 1.0000 - val_loss: 0.1068 - val_accuracy: 0.9974\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0936 - accuracy: 1.0000\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0937 - accuracy: 1.0000 - val_loss: 0.1059 - val_accuracy: 0.9974\n",
            "Epoch 33/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0935 - accuracy: 1.0000\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0934 - accuracy: 1.0000 - val_loss: 0.1185 - val_accuracy: 0.9949\n",
            "Epoch 34/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0909 - accuracy: 1.0000\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0909 - accuracy: 1.0000 - val_loss: 0.1114 - val_accuracy: 0.9949\n",
            "Epoch 35/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0856 - accuracy: 1.0000\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0857 - accuracy: 1.0000 - val_loss: 0.1045 - val_accuracy: 0.9949\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0843 - accuracy: 1.0000\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0844 - accuracy: 1.0000 - val_loss: 0.0991 - val_accuracy: 0.9949\n",
            "Epoch 37/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0830 - accuracy: 1.0000\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0829 - accuracy: 1.0000 - val_loss: 0.0998 - val_accuracy: 0.9949\n",
            "Epoch 38/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0817 - accuracy: 0.9994\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0818 - accuracy: 0.9994 - val_loss: 0.0982 - val_accuracy: 0.9974\n",
            "Epoch 39/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0841 - accuracy: 1.0000\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0842 - accuracy: 1.0000 - val_loss: 0.0994 - val_accuracy: 0.9949\n",
            "Epoch 40/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0811 - accuracy: 1.0000\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0811 - accuracy: 1.0000 - val_loss: 0.0951 - val_accuracy: 0.9949\n",
            "Epoch 41/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0764 - accuracy: 1.0000\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0764 - accuracy: 1.0000 - val_loss: 0.1171 - val_accuracy: 0.9821\n",
            "Epoch 42/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0959 - accuracy: 0.9968\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0959 - accuracy: 0.9968 - val_loss: 0.1020 - val_accuracy: 0.9923\n",
            "Epoch 43/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0773 - accuracy: 1.0000\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0773 - accuracy: 1.0000 - val_loss: 0.0901 - val_accuracy: 0.9949\n",
            "Epoch 44/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0723 - accuracy: 1.0000\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0723 - accuracy: 1.0000 - val_loss: 0.0921 - val_accuracy: 0.9949\n",
            "Epoch 45/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0711 - accuracy: 1.0000\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0711 - accuracy: 1.0000 - val_loss: 0.0898 - val_accuracy: 0.9949\n",
            "Epoch 46/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0712 - accuracy: 0.9993\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0712 - accuracy: 0.9994 - val_loss: 0.0837 - val_accuracy: 0.9949\n",
            "Epoch 47/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0686 - accuracy: 1.0000\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0686 - accuracy: 1.0000 - val_loss: 0.0896 - val_accuracy: 0.9949\n",
            "Epoch 48/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0675 - accuracy: 1.0000\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0675 - accuracy: 1.0000 - val_loss: 0.1106 - val_accuracy: 0.9795\n",
            "Epoch 49/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0666 - accuracy: 1.0000\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0666 - accuracy: 1.0000 - val_loss: 0.0921 - val_accuracy: 0.9923\n",
            "Epoch 50/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0644 - accuracy: 1.0000\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0644 - accuracy: 1.0000 - val_loss: 0.0869 - val_accuracy: 0.9949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/88/assets\n",
            "\n",
            "\n",
            " 44%|████▍     | 89/200 [3:35:48<5:27:34, 177.07s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 2.2140 - accuracy: 0.4624\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 29ms/step - loss: 2.2127 - accuracy: 0.4654 - val_loss: 1.8969 - val_accuracy: 0.4015\n",
            "Epoch 2/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.7915 - accuracy: 0.6628\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 1.7915 - accuracy: 0.6628 - val_loss: 1.8871 - val_accuracy: 0.2890\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.5151 - accuracy: 0.7481\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 1.5174 - accuracy: 0.7468 - val_loss: 1.6259 - val_accuracy: 0.5090\n",
            "Epoch 4/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.3046 - accuracy: 0.8177\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 1.3028 - accuracy: 0.8186 - val_loss: 1.2056 - val_accuracy: 0.8312\n",
            "Epoch 5/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.1253 - accuracy: 0.8737\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 1.1253 - accuracy: 0.8737 - val_loss: 1.0494 - val_accuracy: 0.9054\n",
            "Epoch 6/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.9804 - accuracy: 0.9333\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.9804 - accuracy: 0.9333 - val_loss: 0.9386 - val_accuracy: 0.9182\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8869 - accuracy: 0.9449\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.8862 - accuracy: 0.9449 - val_loss: 0.8579 - val_accuracy: 0.9437\n",
            "Epoch 8/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.8083 - accuracy: 0.9628\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.8083 - accuracy: 0.9628 - val_loss: 0.7910 - val_accuracy: 0.9770\n",
            "Epoch 9/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.7470 - accuracy: 0.9807\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.7461 - accuracy: 0.9808 - val_loss: 0.7337 - val_accuracy: 0.9795\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7008 - accuracy: 0.9793\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.7003 - accuracy: 0.9795 - val_loss: 0.6880 - val_accuracy: 0.9770\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6579 - accuracy: 0.9851\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.6578 - accuracy: 0.9853 - val_loss: 0.6534 - val_accuracy: 0.9795\n",
            "Epoch 12/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.6228 - accuracy: 0.9884\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.6228 - accuracy: 0.9885 - val_loss: 0.6201 - val_accuracy: 0.9821\n",
            "Epoch 13/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.5947 - accuracy: 0.9884\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.5945 - accuracy: 0.9885 - val_loss: 0.5915 - val_accuracy: 0.9847\n",
            "Epoch 14/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.5672 - accuracy: 0.9910\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.5674 - accuracy: 0.9910 - val_loss: 0.5702 - val_accuracy: 0.9872\n",
            "Epoch 15/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.5432 - accuracy: 0.9923\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.5437 - accuracy: 0.9923 - val_loss: 0.5429 - val_accuracy: 0.9898\n",
            "Epoch 16/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5238 - accuracy: 0.9929\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.5238 - accuracy: 0.9929 - val_loss: 0.5234 - val_accuracy: 0.9898\n",
            "Epoch 17/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4997 - accuracy: 0.9955\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.4999 - accuracy: 0.9955 - val_loss: 0.5068 - val_accuracy: 0.9923\n",
            "Epoch 18/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4885 - accuracy: 0.9955\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.4885 - accuracy: 0.9955 - val_loss: 0.4869 - val_accuracy: 0.9898\n",
            "Epoch 19/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4665 - accuracy: 0.9955\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.4665 - accuracy: 0.9955 - val_loss: 0.4700 - val_accuracy: 0.9949\n",
            "Epoch 20/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4547 - accuracy: 0.9955\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.4547 - accuracy: 0.9955 - val_loss: 0.4645 - val_accuracy: 0.9872\n",
            "Epoch 21/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4414 - accuracy: 0.9974\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.4412 - accuracy: 0.9974 - val_loss: 0.4456 - val_accuracy: 0.9898\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4268 - accuracy: 0.9961\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.4268 - accuracy: 0.9962 - val_loss: 0.4333 - val_accuracy: 0.9898\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4135 - accuracy: 0.9968\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.4139 - accuracy: 0.9968 - val_loss: 0.4239 - val_accuracy: 0.9949\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4039 - accuracy: 0.9942\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.4041 - accuracy: 0.9942 - val_loss: 0.4081 - val_accuracy: 0.9923\n",
            "Epoch 25/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3905 - accuracy: 0.9974\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.3905 - accuracy: 0.9974 - val_loss: 0.3977 - val_accuracy: 0.9949\n",
            "Epoch 26/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3811 - accuracy: 0.9981\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.3810 - accuracy: 0.9981 - val_loss: 0.3929 - val_accuracy: 0.9923\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3712 - accuracy: 0.9974\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.3714 - accuracy: 0.9974 - val_loss: 0.3803 - val_accuracy: 0.9949\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3624 - accuracy: 0.9987\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.3623 - accuracy: 0.9987 - val_loss: 0.3695 - val_accuracy: 0.9949\n",
            "Epoch 29/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3530 - accuracy: 0.9994\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.3532 - accuracy: 0.9994 - val_loss: 0.3631 - val_accuracy: 0.9923\n",
            "Epoch 30/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3485 - accuracy: 0.9981\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.3485 - accuracy: 0.9981 - val_loss: 0.3532 - val_accuracy: 0.9949\n",
            "Epoch 31/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3397 - accuracy: 0.9987\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.3394 - accuracy: 0.9987 - val_loss: 0.3449 - val_accuracy: 0.9949\n",
            "Epoch 32/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3287 - accuracy: 0.9987\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.3287 - accuracy: 0.9987 - val_loss: 0.3397 - val_accuracy: 0.9949\n",
            "Epoch 33/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3218 - accuracy: 0.9987\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.3216 - accuracy: 0.9987 - val_loss: 0.3355 - val_accuracy: 0.9949\n",
            "Epoch 34/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3179 - accuracy: 0.9994\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.3177 - accuracy: 0.9994 - val_loss: 0.3261 - val_accuracy: 0.9949\n",
            "Epoch 35/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3101 - accuracy: 0.9994\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.3099 - accuracy: 0.9994 - val_loss: 0.3245 - val_accuracy: 0.9949\n",
            "Epoch 36/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3046 - accuracy: 0.9994\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.3046 - accuracy: 0.9994 - val_loss: 0.3162 - val_accuracy: 0.9949\n",
            "Epoch 37/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2991 - accuracy: 0.9994\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.2990 - accuracy: 0.9994 - val_loss: 0.3074 - val_accuracy: 0.9949\n",
            "Epoch 38/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2932 - accuracy: 0.9994\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.2935 - accuracy: 0.9994 - val_loss: 0.3053 - val_accuracy: 0.9949\n",
            "Epoch 39/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2895 - accuracy: 0.9987\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.2895 - accuracy: 0.9987 - val_loss: 0.2967 - val_accuracy: 0.9949\n",
            "Epoch 40/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2815 - accuracy: 0.9987\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.2815 - accuracy: 0.9987 - val_loss: 0.2926 - val_accuracy: 0.9949\n",
            "Epoch 41/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2770 - accuracy: 0.9987\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.2769 - accuracy: 0.9987 - val_loss: 0.2928 - val_accuracy: 0.9923\n",
            "Epoch 42/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2726 - accuracy: 0.9987\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.2726 - accuracy: 0.9987 - val_loss: 0.2844 - val_accuracy: 0.9949\n",
            "Epoch 43/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2697 - accuracy: 0.9994\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.2696 - accuracy: 0.9994 - val_loss: 0.2801 - val_accuracy: 0.9949\n",
            "Epoch 44/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2631 - accuracy: 0.9994\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.2630 - accuracy: 0.9994 - val_loss: 0.2756 - val_accuracy: 0.9949\n",
            "Epoch 45/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2586 - accuracy: 0.9987\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.2587 - accuracy: 0.9987 - val_loss: 0.2723 - val_accuracy: 0.9949\n",
            "Epoch 46/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2557 - accuracy: 0.9994\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.2554 - accuracy: 0.9994 - val_loss: 0.2673 - val_accuracy: 0.9949\n",
            "Epoch 47/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2511 - accuracy: 0.9987\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.2511 - accuracy: 0.9987 - val_loss: 0.2691 - val_accuracy: 0.9949\n",
            "Epoch 48/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2475 - accuracy: 0.9994\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.2475 - accuracy: 0.9994 - val_loss: 0.2598 - val_accuracy: 0.9923\n",
            "Epoch 49/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2442 - accuracy: 0.9994\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.2442 - accuracy: 0.9994 - val_loss: 0.2576 - val_accuracy: 0.9949\n",
            "Epoch 50/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2374 - accuracy: 0.9994\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.2374 - accuracy: 0.9994 - val_loss: 0.2562 - val_accuracy: 0.9949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/89/assets\n",
            "\n",
            "\n",
            " 45%|████▌     | 90/200 [3:40:12<6:12:42, 203.30s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 2.0195 - accuracy: 0.3297\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 18ms/step - loss: 2.0190 - accuracy: 0.3301 - val_loss: 1.7688 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.7710 - accuracy: 0.5150\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 1.7690 - accuracy: 0.5147 - val_loss: 1.7013 - val_accuracy: 0.2890\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.5244 - accuracy: 0.6898\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 1.5213 - accuracy: 0.6910 - val_loss: 1.4681 - val_accuracy: 0.5422\n",
            "Epoch 4/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.2767 - accuracy: 0.7506\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 1.2767 - accuracy: 0.7506 - val_loss: 1.1741 - val_accuracy: 0.7340\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.0786 - accuracy: 0.8102\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 1.0797 - accuracy: 0.8090 - val_loss: 0.9757 - val_accuracy: 0.8414\n",
            "Epoch 6/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.9379 - accuracy: 0.8647\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.9379 - accuracy: 0.8647 - val_loss: 0.8583 - val_accuracy: 0.8798\n",
            "Epoch 7/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.8197 - accuracy: 0.9058\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.8197 - accuracy: 0.9058 - val_loss: 0.7666 - val_accuracy: 0.9156\n",
            "Epoch 8/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.7333 - accuracy: 0.9278\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.7327 - accuracy: 0.9282 - val_loss: 0.6918 - val_accuracy: 0.9335\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6663 - accuracy: 0.9475\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.6643 - accuracy: 0.9481 - val_loss: 0.6330 - val_accuracy: 0.9565\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5943 - accuracy: 0.9650\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.5941 - accuracy: 0.9654 - val_loss: 0.5854 - val_accuracy: 0.9668\n",
            "Epoch 11/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.5587 - accuracy: 0.9733\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.5579 - accuracy: 0.9737 - val_loss: 0.5351 - val_accuracy: 0.9770\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5137 - accuracy: 0.9806\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.5133 - accuracy: 0.9808 - val_loss: 0.4987 - val_accuracy: 0.9847\n",
            "Epoch 13/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.4739 - accuracy: 0.9857\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.4747 - accuracy: 0.9846 - val_loss: 0.4721 - val_accuracy: 0.9847\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4414 - accuracy: 0.9896\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.4419 - accuracy: 0.9897 - val_loss: 0.4427 - val_accuracy: 0.9847\n",
            "Epoch 15/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.4214 - accuracy: 0.9902\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.4208 - accuracy: 0.9904 - val_loss: 0.4179 - val_accuracy: 0.9898\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3987 - accuracy: 0.9896\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.3994 - accuracy: 0.9897 - val_loss: 0.4024 - val_accuracy: 0.9923\n",
            "Epoch 17/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3796 - accuracy: 0.9936\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.3796 - accuracy: 0.9936 - val_loss: 0.3761 - val_accuracy: 0.9949\n",
            "Epoch 18/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3609 - accuracy: 0.9922\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.3613 - accuracy: 0.9923 - val_loss: 0.3675 - val_accuracy: 0.9847\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3445 - accuracy: 0.9955\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.3442 - accuracy: 0.9955 - val_loss: 0.3476 - val_accuracy: 0.9923\n",
            "Epoch 20/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3297 - accuracy: 0.9948\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.3295 - accuracy: 0.9949 - val_loss: 0.3339 - val_accuracy: 0.9949\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3173 - accuracy: 0.9974\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.3169 - accuracy: 0.9974 - val_loss: 0.3243 - val_accuracy: 0.9923\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3097 - accuracy: 0.9942\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.3093 - accuracy: 0.9942 - val_loss: 0.3099 - val_accuracy: 0.9949\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2972 - accuracy: 0.9968\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.2970 - accuracy: 0.9968 - val_loss: 0.3014 - val_accuracy: 0.9949\n",
            "Epoch 24/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2858 - accuracy: 0.9968\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.2858 - accuracy: 0.9968 - val_loss: 0.2931 - val_accuracy: 0.9949\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2766 - accuracy: 0.9987\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.2765 - accuracy: 0.9987 - val_loss: 0.2867 - val_accuracy: 0.9923\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2719 - accuracy: 0.9968\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.2714 - accuracy: 0.9968 - val_loss: 0.2747 - val_accuracy: 0.9949\n",
            "Epoch 27/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2568 - accuracy: 0.9980\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.2568 - accuracy: 0.9981 - val_loss: 0.2653 - val_accuracy: 0.9949\n",
            "Epoch 28/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2544 - accuracy: 0.9967\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.2540 - accuracy: 0.9968 - val_loss: 0.2566 - val_accuracy: 0.9923\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2457 - accuracy: 0.9981\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.2456 - accuracy: 0.9981 - val_loss: 0.2540 - val_accuracy: 0.9949\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2401 - accuracy: 0.9968\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.2400 - accuracy: 0.9968 - val_loss: 0.2446 - val_accuracy: 0.9949\n",
            "Epoch 31/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2282 - accuracy: 0.9994\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.2281 - accuracy: 0.9994 - val_loss: 0.2389 - val_accuracy: 0.9949\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2288 - accuracy: 0.9981\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.2286 - accuracy: 0.9981 - val_loss: 0.2319 - val_accuracy: 0.9949\n",
            "Epoch 33/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2214 - accuracy: 0.9974\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.2214 - accuracy: 0.9974 - val_loss: 0.2235 - val_accuracy: 0.9949\n",
            "Epoch 34/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2142 - accuracy: 0.9974\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.2141 - accuracy: 0.9974 - val_loss: 0.2212 - val_accuracy: 0.9949\n",
            "Epoch 35/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2067 - accuracy: 0.9994\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.2069 - accuracy: 0.9994 - val_loss: 0.2180 - val_accuracy: 0.9949\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2016 - accuracy: 0.9994\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.2020 - accuracy: 0.9994 - val_loss: 0.2102 - val_accuracy: 0.9949\n",
            "Epoch 37/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2005 - accuracy: 0.9980\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.2003 - accuracy: 0.9981 - val_loss: 0.2074 - val_accuracy: 0.9949\n",
            "Epoch 38/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1929 - accuracy: 1.0000\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1928 - accuracy: 1.0000 - val_loss: 0.2024 - val_accuracy: 0.9923\n",
            "Epoch 39/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1906 - accuracy: 0.9981\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1904 - accuracy: 0.9981 - val_loss: 0.2022 - val_accuracy: 0.9949\n",
            "Epoch 40/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1841 - accuracy: 0.9994\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1841 - accuracy: 0.9994 - val_loss: 0.1950 - val_accuracy: 0.9923\n",
            "Epoch 41/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1823 - accuracy: 0.9987\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1821 - accuracy: 0.9987 - val_loss: 0.1879 - val_accuracy: 0.9949\n",
            "Epoch 42/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1762 - accuracy: 0.9994\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1762 - accuracy: 0.9994 - val_loss: 0.1904 - val_accuracy: 0.9923\n",
            "Epoch 43/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1763 - accuracy: 0.9981\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1762 - accuracy: 0.9981 - val_loss: 0.1823 - val_accuracy: 0.9949\n",
            "Epoch 44/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1683 - accuracy: 0.9994\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1689 - accuracy: 0.9987 - val_loss: 0.1809 - val_accuracy: 0.9923\n",
            "Epoch 45/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1665 - accuracy: 0.9994\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1664 - accuracy: 0.9994 - val_loss: 0.1758 - val_accuracy: 0.9949\n",
            "Epoch 46/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1626 - accuracy: 1.0000\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1626 - accuracy: 1.0000 - val_loss: 0.1739 - val_accuracy: 0.9949\n",
            "Epoch 47/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1591 - accuracy: 0.9994\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1591 - accuracy: 0.9994 - val_loss: 0.1714 - val_accuracy: 0.9923\n",
            "Epoch 48/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1561 - accuracy: 1.0000\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1560 - accuracy: 1.0000 - val_loss: 0.1670 - val_accuracy: 0.9923\n",
            "Epoch 49/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1529 - accuracy: 1.0000\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1529 - accuracy: 1.0000 - val_loss: 0.1655 - val_accuracy: 0.9923\n",
            "Epoch 50/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1519 - accuracy: 0.9994\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1518 - accuracy: 0.9994 - val_loss: 0.1630 - val_accuracy: 0.9923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/90/assets\n",
            "\n",
            "\n",
            " 46%|████▌     | 91/200 [3:42:56<5:47:45, 191.43s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 2.4704 - accuracy: 0.2865\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 18ms/step - loss: 2.4597 - accuracy: 0.2885 - val_loss: 1.7805 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.7506 - accuracy: 0.2979\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.7502 - accuracy: 0.2974 - val_loss: 1.7635 - val_accuracy: 0.2864\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.7032 - accuracy: 0.3251\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.7048 - accuracy: 0.3250 - val_loss: 1.8607 - val_accuracy: 0.2864\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6769 - accuracy: 0.3225\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.6777 - accuracy: 0.3231 - val_loss: 1.5112 - val_accuracy: 0.3862\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.5943 - accuracy: 0.4139\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.5943 - accuracy: 0.4135 - val_loss: 1.6275 - val_accuracy: 0.4731\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6417 - accuracy: 0.3510\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.6396 - accuracy: 0.3526 - val_loss: 1.5483 - val_accuracy: 0.3939\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.5874 - accuracy: 0.3938\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.5848 - accuracy: 0.3936 - val_loss: 2.6605 - val_accuracy: 0.3095\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6234 - accuracy: 0.4197\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.6206 - accuracy: 0.4205 - val_loss: 1.4042 - val_accuracy: 0.4578\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.4635 - accuracy: 0.4598\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.4638 - accuracy: 0.4596 - val_loss: 1.4345 - val_accuracy: 0.4425\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.4531 - accuracy: 0.4715\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.4521 - accuracy: 0.4699 - val_loss: 1.5288 - val_accuracy: 0.4118\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.4212 - accuracy: 0.4864\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.4207 - accuracy: 0.4872 - val_loss: 1.4584 - val_accuracy: 0.3811\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.4011 - accuracy: 0.4942\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.4006 - accuracy: 0.4936 - val_loss: 1.3515 - val_accuracy: 0.4757\n",
            "Epoch 13/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.4529 - accuracy: 0.4837\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.4515 - accuracy: 0.4827 - val_loss: 1.4968 - val_accuracy: 0.4194\n",
            "Epoch 14/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.4721 - accuracy: 0.4798\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.4686 - accuracy: 0.4769 - val_loss: 1.3217 - val_accuracy: 0.4859\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.3038 - accuracy: 0.5427\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.3030 - accuracy: 0.5449 - val_loss: 1.3853 - val_accuracy: 0.4425\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.7835 - accuracy: 0.4352\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 1.7876 - accuracy: 0.4327 - val_loss: 2.4515 - val_accuracy: 0.3376\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.5994 - accuracy: 0.4456\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.5973 - accuracy: 0.4462 - val_loss: 1.6169 - val_accuracy: 0.4297\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.5311 - accuracy: 0.5019\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.5303 - accuracy: 0.5019 - val_loss: 1.3007 - val_accuracy: 0.5754\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.5237 - accuracy: 0.5622\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.5245 - accuracy: 0.5622 - val_loss: 2.2255 - val_accuracy: 0.3069\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6589 - accuracy: 0.4585\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.6589 - accuracy: 0.4603 - val_loss: 1.6897 - val_accuracy: 0.4271\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.4657 - accuracy: 0.5622\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.4625 - accuracy: 0.5628 - val_loss: 1.2957 - val_accuracy: 0.5780\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6368 - accuracy: 0.5181\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.6406 - accuracy: 0.5154 - val_loss: 1.8277 - val_accuracy: 0.4143\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.7323 - accuracy: 0.4598\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.7322 - accuracy: 0.4609 - val_loss: 1.5778 - val_accuracy: 0.6317\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.4920 - accuracy: 0.5810\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.4857 - accuracy: 0.5833 - val_loss: 1.5932 - val_accuracy: 0.5448\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.1509 - accuracy: 0.6995\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.1493 - accuracy: 0.6981 - val_loss: 1.7516 - val_accuracy: 0.3785\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8790 - accuracy: 0.7947\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.8767 - accuracy: 0.7955 - val_loss: 0.6853 - val_accuracy: 0.9156\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.4608 - accuracy: 0.6548\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.4638 - accuracy: 0.6513 - val_loss: 2.5511 - val_accuracy: 0.2583\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 2.0548 - accuracy: 0.3038\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 2.0528 - accuracy: 0.3051 - val_loss: 1.9764 - val_accuracy: 0.2634\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.9395 - accuracy: 0.2759\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.9396 - accuracy: 0.2737 - val_loss: 1.9070 - val_accuracy: 0.2634\n",
            "Epoch 30/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.8863 - accuracy: 0.2689\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.8847 - accuracy: 0.2692 - val_loss: 1.8580 - val_accuracy: 0.2864\n",
            "Epoch 31/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.8444 - accuracy: 0.2798\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.8436 - accuracy: 0.2808 - val_loss: 1.8237 - val_accuracy: 0.2864\n",
            "Epoch 31: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/91/assets\n",
            "\n",
            "\n",
            " 46%|████▌     | 92/200 [3:45:23<5:20:41, 178.16s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 2.0286 - accuracy: 0.1898\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 15ms/step - loss: 2.0257 - accuracy: 0.1929 - val_loss: 1.8268 - val_accuracy: 0.2634\n",
            "Epoch 2/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.8152 - accuracy: 0.3551\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 1.8152 - accuracy: 0.3551 - val_loss: 1.8022 - val_accuracy: 0.2634\n",
            "Epoch 3/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.7270 - accuracy: 0.4215\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 1.7243 - accuracy: 0.4231 - val_loss: 1.7067 - val_accuracy: 0.3299\n",
            "Epoch 4/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6338 - accuracy: 0.5205\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 1.6338 - accuracy: 0.5205 - val_loss: 1.5863 - val_accuracy: 0.5038\n",
            "Epoch 5/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.5301 - accuracy: 0.6003\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 1.5313 - accuracy: 0.6000 - val_loss: 1.4842 - val_accuracy: 0.6113\n",
            "Epoch 6/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.4172 - accuracy: 0.6596\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 1.4172 - accuracy: 0.6596 - val_loss: 1.3651 - val_accuracy: 0.6931\n",
            "Epoch 7/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.2860 - accuracy: 0.7295\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 1.2860 - accuracy: 0.7295 - val_loss: 1.2392 - val_accuracy: 0.7110\n",
            "Epoch 8/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.1662 - accuracy: 0.7622\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 1.1670 - accuracy: 0.7622 - val_loss: 1.1210 - val_accuracy: 0.7391\n",
            "Epoch 9/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.0602 - accuracy: 0.7751\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 1.0603 - accuracy: 0.7750 - val_loss: 1.0173 - val_accuracy: 0.7724\n",
            "Epoch 10/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.9656 - accuracy: 0.8106\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.9645 - accuracy: 0.8115 - val_loss: 0.9272 - val_accuracy: 0.8082\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8861 - accuracy: 0.8368\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.8856 - accuracy: 0.8365 - val_loss: 0.8681 - val_accuracy: 0.8363\n",
            "Epoch 12/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.8229 - accuracy: 0.8564\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.8229 - accuracy: 0.8564 - val_loss: 0.8002 - val_accuracy: 0.8696\n",
            "Epoch 13/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.7666 - accuracy: 0.8821\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.7658 - accuracy: 0.8821 - val_loss: 0.7539 - val_accuracy: 0.8875\n",
            "Epoch 14/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.7293 - accuracy: 0.8942\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.7293 - accuracy: 0.8942 - val_loss: 0.7078 - val_accuracy: 0.9028\n",
            "Epoch 15/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.6911 - accuracy: 0.9008\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.6906 - accuracy: 0.9013 - val_loss: 0.6731 - val_accuracy: 0.9079\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6452 - accuracy: 0.9158\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.6462 - accuracy: 0.9154 - val_loss: 0.6453 - val_accuracy: 0.9156\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6132 - accuracy: 0.9333\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.6124 - accuracy: 0.9340 - val_loss: 0.6162 - val_accuracy: 0.9309\n",
            "Epoch 18/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.5959 - accuracy: 0.9378\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.5961 - accuracy: 0.9365 - val_loss: 0.5940 - val_accuracy: 0.9412\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5711 - accuracy: 0.9378\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.5713 - accuracy: 0.9378 - val_loss: 0.5690 - val_accuracy: 0.9412\n",
            "Epoch 20/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.5442 - accuracy: 0.9512\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.5458 - accuracy: 0.9500 - val_loss: 0.5477 - val_accuracy: 0.9412\n",
            "Epoch 21/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5280 - accuracy: 0.9590\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.5280 - accuracy: 0.9590 - val_loss: 0.5281 - val_accuracy: 0.9412\n",
            "Epoch 22/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5073 - accuracy: 0.9564\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.5073 - accuracy: 0.9564 - val_loss: 0.5109 - val_accuracy: 0.9463\n",
            "Epoch 23/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4901 - accuracy: 0.9660\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.4901 - accuracy: 0.9660 - val_loss: 0.4983 - val_accuracy: 0.9488\n",
            "Epoch 24/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4803 - accuracy: 0.9596\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.4803 - accuracy: 0.9596 - val_loss: 0.4948 - val_accuracy: 0.9437\n",
            "Epoch 25/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.4540 - accuracy: 0.9779\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.4544 - accuracy: 0.9782 - val_loss: 0.4683 - val_accuracy: 0.9565\n",
            "Epoch 26/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4452 - accuracy: 0.9737\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.4452 - accuracy: 0.9737 - val_loss: 0.4556 - val_accuracy: 0.9565\n",
            "Epoch 27/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4295 - accuracy: 0.9801\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.4295 - accuracy: 0.9801 - val_loss: 0.4435 - val_accuracy: 0.9642\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4211 - accuracy: 0.9741\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.4220 - accuracy: 0.9731 - val_loss: 0.4343 - val_accuracy: 0.9668\n",
            "Epoch 29/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4029 - accuracy: 0.9788\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.4029 - accuracy: 0.9788 - val_loss: 0.4245 - val_accuracy: 0.9668\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3927 - accuracy: 0.9806\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.3920 - accuracy: 0.9808 - val_loss: 0.4125 - val_accuracy: 0.9693\n",
            "Epoch 31/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3874 - accuracy: 0.9844\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.3883 - accuracy: 0.9840 - val_loss: 0.3987 - val_accuracy: 0.9744\n",
            "Epoch 32/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.3734 - accuracy: 0.9889\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.3736 - accuracy: 0.9885 - val_loss: 0.3904 - val_accuracy: 0.9744\n",
            "Epoch 33/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3657 - accuracy: 0.9838\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.3651 - accuracy: 0.9840 - val_loss: 0.3817 - val_accuracy: 0.9821\n",
            "Epoch 34/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3527 - accuracy: 0.9897\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.3526 - accuracy: 0.9897 - val_loss: 0.3737 - val_accuracy: 0.9821\n",
            "Epoch 35/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3463 - accuracy: 0.9922\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.3471 - accuracy: 0.9917 - val_loss: 0.3638 - val_accuracy: 0.9821\n",
            "Epoch 36/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.3403 - accuracy: 0.9908\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.3401 - accuracy: 0.9910 - val_loss: 0.3551 - val_accuracy: 0.9872\n",
            "Epoch 37/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3287 - accuracy: 0.9917\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.3287 - accuracy: 0.9917 - val_loss: 0.3493 - val_accuracy: 0.9821\n",
            "Epoch 38/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3245 - accuracy: 0.9916\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.3240 - accuracy: 0.9917 - val_loss: 0.3381 - val_accuracy: 0.9872\n",
            "Epoch 39/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.3112 - accuracy: 0.9935\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.3114 - accuracy: 0.9936 - val_loss: 0.3334 - val_accuracy: 0.9872\n",
            "Epoch 40/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.3063 - accuracy: 0.9941\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.3060 - accuracy: 0.9942 - val_loss: 0.3247 - val_accuracy: 0.9898\n",
            "Epoch 41/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3031 - accuracy: 0.9955\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.3030 - accuracy: 0.9955 - val_loss: 0.3217 - val_accuracy: 0.9872\n",
            "Epoch 42/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2956 - accuracy: 0.9902\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.2960 - accuracy: 0.9904 - val_loss: 0.3151 - val_accuracy: 0.9898\n",
            "Epoch 43/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2888 - accuracy: 0.9910\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.2885 - accuracy: 0.9910 - val_loss: 0.3078 - val_accuracy: 0.9898\n",
            "Epoch 44/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2808 - accuracy: 0.9941\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.2822 - accuracy: 0.9936 - val_loss: 0.3012 - val_accuracy: 0.9898\n",
            "Epoch 45/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2800 - accuracy: 0.9941\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.2799 - accuracy: 0.9942 - val_loss: 0.2952 - val_accuracy: 0.9923\n",
            "Epoch 46/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2728 - accuracy: 0.9962\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.2728 - accuracy: 0.9962 - val_loss: 0.2878 - val_accuracy: 0.9923\n",
            "Epoch 47/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2658 - accuracy: 0.9929\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.2652 - accuracy: 0.9929 - val_loss: 0.2841 - val_accuracy: 0.9923\n",
            "Epoch 48/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.2597 - accuracy: 0.9961\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.2596 - accuracy: 0.9962 - val_loss: 0.2784 - val_accuracy: 0.9949\n",
            "Epoch 49/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2530 - accuracy: 0.9974\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.2530 - accuracy: 0.9974 - val_loss: 0.2727 - val_accuracy: 0.9949\n",
            "Epoch 50/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2517 - accuracy: 0.9961\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.2525 - accuracy: 0.9962 - val_loss: 0.2694 - val_accuracy: 0.9949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/92/assets\n",
            "\n",
            "\n",
            " 46%|████▋     | 93/200 [3:47:37<4:53:49, 164.76s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.6391 - accuracy: 0.4058\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 12ms/step - loss: 1.6414 - accuracy: 0.4058 - val_loss: 2.0769 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.4024 - accuracy: 0.5432\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.3996 - accuracy: 0.5436 - val_loss: 2.3178 - val_accuracy: 0.3120\n",
            "Epoch 3/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.2994 - accuracy: 0.5788\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.2994 - accuracy: 0.5788 - val_loss: 1.8206 - val_accuracy: 0.3734\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8404 - accuracy: 0.7733\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.8346 - accuracy: 0.7744 - val_loss: 0.9903 - val_accuracy: 0.6803\n",
            "Epoch 5/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.7516 - accuracy: 0.7954\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.7550 - accuracy: 0.7949 - val_loss: 1.7731 - val_accuracy: 0.6240\n",
            "Epoch 6/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.5499 - accuracy: 0.8652\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.5470 - accuracy: 0.8667 - val_loss: 0.5581 - val_accuracy: 0.8798\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4218 - accuracy: 0.8990\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.4216 - accuracy: 0.8987 - val_loss: 0.4847 - val_accuracy: 0.8849\n",
            "Epoch 8/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 0.3806 - accuracy: 0.9120\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.3831 - accuracy: 0.9103 - val_loss: 1.0958 - val_accuracy: 0.7161\n",
            "Epoch 9/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 0.5601 - accuracy: 0.8823\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.5566 - accuracy: 0.8808 - val_loss: 0.6152 - val_accuracy: 0.8440\n",
            "Epoch 10/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.3863 - accuracy: 0.9132\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.3828 - accuracy: 0.9135 - val_loss: 0.5254 - val_accuracy: 0.8721\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3620 - accuracy: 0.9190\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.3653 - accuracy: 0.9186 - val_loss: 0.4204 - val_accuracy: 0.9207\n",
            "Epoch 12/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2878 - accuracy: 0.9414\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.2888 - accuracy: 0.9404 - val_loss: 0.6085 - val_accuracy: 0.8440\n",
            "Epoch 13/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 0.2809 - accuracy: 0.9325\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.2796 - accuracy: 0.9327 - val_loss: 0.3348 - val_accuracy: 0.9156\n",
            "Epoch 14/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2053 - accuracy: 0.9538\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.2045 - accuracy: 0.9545 - val_loss: 0.6245 - val_accuracy: 0.8900\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3367 - accuracy: 0.9223\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.3409 - accuracy: 0.9212 - val_loss: 0.6422 - val_accuracy: 0.8491\n",
            "Epoch 16/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.3683 - accuracy: 0.6453\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.3581 - accuracy: 0.6481 - val_loss: 1.0507 - val_accuracy: 0.7110\n",
            "Epoch 17/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.6078 - accuracy: 0.8658\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.6037 - accuracy: 0.8673 - val_loss: 0.5022 - val_accuracy: 0.9079\n",
            "Epoch 18/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3477 - accuracy: 0.9349\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.3451 - accuracy: 0.9359 - val_loss: 0.4169 - val_accuracy: 0.9054\n",
            "Epoch 18: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/93/assets\n",
            "\n",
            "\n",
            " 47%|████▋     | 94/200 [3:48:14<3:43:38, 126.59s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.7537 - accuracy: 0.4375\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 12ms/step - loss: 1.7513 - accuracy: 0.4391 - val_loss: 1.7670 - val_accuracy: 0.1714\n",
            "Epoch 2/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.2170 - accuracy: 0.6198\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.2071 - accuracy: 0.6244 - val_loss: 2.7572 - val_accuracy: 0.3760\n",
            "Epoch 3/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.9108 - accuracy: 0.7358\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.9087 - accuracy: 0.7372 - val_loss: 1.0311 - val_accuracy: 0.6931\n",
            "Epoch 4/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.8099 - accuracy: 0.7728\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.8135 - accuracy: 0.7699 - val_loss: 1.3267 - val_accuracy: 0.5473\n",
            "Epoch 5/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.7807 - accuracy: 0.7866\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.7806 - accuracy: 0.7891 - val_loss: 1.2852 - val_accuracy: 0.6880\n",
            "Epoch 6/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.5609 - accuracy: 0.5290\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.5573 - accuracy: 0.5295 - val_loss: 1.2519 - val_accuracy: 0.5550\n",
            "Epoch 7/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.9586 - accuracy: 0.6868\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.9590 - accuracy: 0.6872 - val_loss: 1.1349 - val_accuracy: 0.6803\n",
            "Epoch 8/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.7737 - accuracy: 0.7651\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.7734 - accuracy: 0.7660 - val_loss: 0.7300 - val_accuracy: 0.7928\n",
            "Epoch 9/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.6081 - accuracy: 0.8389\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.6063 - accuracy: 0.8391 - val_loss: 0.6162 - val_accuracy: 0.8005\n",
            "Epoch 10/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.5758 - accuracy: 0.8526\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.5681 - accuracy: 0.8551 - val_loss: 0.7041 - val_accuracy: 0.7928\n",
            "Epoch 11/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.3366 - accuracy: 0.9184\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.3339 - accuracy: 0.9199 - val_loss: 0.7121 - val_accuracy: 0.8645\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3204 - accuracy: 0.9262\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.3201 - accuracy: 0.9263 - val_loss: 0.6145 - val_accuracy: 0.8235\n",
            "Epoch 13/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.2571 - accuracy: 0.9395\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.2594 - accuracy: 0.9385 - val_loss: 0.6456 - val_accuracy: 0.8005\n",
            "Epoch 14/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3014 - accuracy: 0.9355\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.3004 - accuracy: 0.9353 - val_loss: 0.3724 - val_accuracy: 0.9054\n",
            "Epoch 15/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.2324 - accuracy: 0.9470\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.2353 - accuracy: 0.9468 - val_loss: 0.5371 - val_accuracy: 0.8465\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2080 - accuracy: 0.9560\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.2076 - accuracy: 0.9558 - val_loss: 1.3599 - val_accuracy: 0.8900\n",
            "Epoch 17/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.1772 - accuracy: 0.9697\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.1799 - accuracy: 0.9686 - val_loss: 0.4098 - val_accuracy: 0.9054\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2505 - accuracy: 0.9475\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.2514 - accuracy: 0.9474 - val_loss: 0.3700 - val_accuracy: 0.9028\n",
            "Epoch 19/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2299 - accuracy: 0.9492\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.2295 - accuracy: 0.9494 - val_loss: 2.7892 - val_accuracy: 0.7391\n",
            "Epoch 20/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2746 - accuracy: 0.9460\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.2730 - accuracy: 0.9462 - val_loss: 1.0793 - val_accuracy: 0.6394\n",
            "Epoch 21/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1753 - accuracy: 0.9661\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.1740 - accuracy: 0.9667 - val_loss: 0.5578 - val_accuracy: 0.8875\n",
            "Epoch 22/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.2891 - accuracy: 0.9388\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.2872 - accuracy: 0.9397 - val_loss: 0.4006 - val_accuracy: 0.9284\n",
            "Epoch 23/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.9307 - accuracy: 0.7827\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.9307 - accuracy: 0.7827 - val_loss: 1.9736 - val_accuracy: 0.3223\n",
            "Epoch 23: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/94/assets\n",
            "\n",
            "\n",
            " 48%|████▊     | 95/200 [3:49:01<2:59:37, 102.64s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.4850 - accuracy: 0.6179\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 20ms/step - loss: 1.4829 - accuracy: 0.6179 - val_loss: 1.7454 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.8244 - accuracy: 0.8724\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.8244 - accuracy: 0.8724 - val_loss: 1.9241 - val_accuracy: 0.2890\n",
            "Epoch 3/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.5646 - accuracy: 0.9491\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.5644 - accuracy: 0.9487 - val_loss: 1.2574 - val_accuracy: 0.5729\n",
            "Epoch 4/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4409 - accuracy: 0.9774\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.4405 - accuracy: 0.9776 - val_loss: 0.5145 - val_accuracy: 0.9488\n",
            "Epoch 5/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3697 - accuracy: 0.9859\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.3697 - accuracy: 0.9859 - val_loss: 0.3337 - val_accuracy: 0.9898\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3069 - accuracy: 0.9961\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.3078 - accuracy: 0.9955 - val_loss: 0.3101 - val_accuracy: 0.9872\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2713 - accuracy: 0.9974\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.2711 - accuracy: 0.9974 - val_loss: 0.2737 - val_accuracy: 0.9847\n",
            "Epoch 8/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2477 - accuracy: 0.9961\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.2473 - accuracy: 0.9962 - val_loss: 0.2523 - val_accuracy: 0.9898\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2268 - accuracy: 0.9974\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.2266 - accuracy: 0.9974 - val_loss: 0.2324 - val_accuracy: 0.9898\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2091 - accuracy: 0.9968\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.2089 - accuracy: 0.9968 - val_loss: 0.2170 - val_accuracy: 0.9872\n",
            "Epoch 11/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1891 - accuracy: 0.9994\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.1893 - accuracy: 0.9994 - val_loss: 0.2023 - val_accuracy: 0.9898\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1781 - accuracy: 1.0000\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.1779 - accuracy: 1.0000 - val_loss: 0.1935 - val_accuracy: 0.9898\n",
            "Epoch 13/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1663 - accuracy: 0.9987\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.1663 - accuracy: 0.9987 - val_loss: 0.1826 - val_accuracy: 0.9923\n",
            "Epoch 14/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1547 - accuracy: 0.9987\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.1547 - accuracy: 0.9987 - val_loss: 0.1741 - val_accuracy: 0.9898\n",
            "Epoch 15/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1496 - accuracy: 0.9987\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.1496 - accuracy: 0.9987 - val_loss: 0.1676 - val_accuracy: 0.9898\n",
            "Epoch 16/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1407 - accuracy: 0.9993\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.1405 - accuracy: 0.9994 - val_loss: 0.1681 - val_accuracy: 0.9872\n",
            "Epoch 17/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1367 - accuracy: 0.9993\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.1364 - accuracy: 0.9994 - val_loss: 0.1710 - val_accuracy: 0.9872\n",
            "Epoch 18/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1288 - accuracy: 0.9987\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.1288 - accuracy: 0.9987 - val_loss: 0.1590 - val_accuracy: 0.9898\n",
            "Epoch 19/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1230 - accuracy: 1.0000\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.1230 - accuracy: 1.0000 - val_loss: 0.1479 - val_accuracy: 0.9898\n",
            "Epoch 20/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1211 - accuracy: 0.9994\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.1211 - accuracy: 0.9994 - val_loss: 0.1441 - val_accuracy: 0.9923\n",
            "Epoch 21/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1190 - accuracy: 1.0000\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.1190 - accuracy: 1.0000 - val_loss: 0.1507 - val_accuracy: 0.9898\n",
            "Epoch 22/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1138 - accuracy: 0.9994\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.1138 - accuracy: 0.9994 - val_loss: 0.1389 - val_accuracy: 0.9923\n",
            "Epoch 23/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1087 - accuracy: 1.0000\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.1087 - accuracy: 1.0000 - val_loss: 0.1330 - val_accuracy: 0.9923\n",
            "Epoch 24/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1058 - accuracy: 1.0000\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.1058 - accuracy: 1.0000 - val_loss: 0.1300 - val_accuracy: 0.9898\n",
            "Epoch 25/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1013 - accuracy: 1.0000\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.1012 - accuracy: 1.0000 - val_loss: 0.1320 - val_accuracy: 0.9923\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0970 - accuracy: 1.0000\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0970 - accuracy: 1.0000 - val_loss: 0.1286 - val_accuracy: 0.9898\n",
            "Epoch 27/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0951 - accuracy: 1.0000\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.0951 - accuracy: 1.0000 - val_loss: 0.1215 - val_accuracy: 0.9923\n",
            "Epoch 28/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0932 - accuracy: 1.0000\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0932 - accuracy: 1.0000 - val_loss: 0.1224 - val_accuracy: 0.9898\n",
            "Epoch 29/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0917 - accuracy: 1.0000\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.0917 - accuracy: 1.0000 - val_loss: 0.1273 - val_accuracy: 0.9898\n",
            "Epoch 30/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0906 - accuracy: 1.0000\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0906 - accuracy: 1.0000 - val_loss: 0.1166 - val_accuracy: 0.9923\n",
            "Epoch 31/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0874 - accuracy: 1.0000\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.0874 - accuracy: 1.0000 - val_loss: 0.1175 - val_accuracy: 0.9923\n",
            "Epoch 32/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0899 - accuracy: 1.0000\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0898 - accuracy: 1.0000 - val_loss: 0.1348 - val_accuracy: 0.9847\n",
            "Epoch 33/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0860 - accuracy: 1.0000\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.0860 - accuracy: 1.0000 - val_loss: 0.1168 - val_accuracy: 0.9898\n",
            "Epoch 34/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0845 - accuracy: 1.0000\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0844 - accuracy: 1.0000 - val_loss: 0.1185 - val_accuracy: 0.9898\n",
            "Epoch 35/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0899 - accuracy: 0.9994\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0899 - accuracy: 0.9994 - val_loss: 0.1173 - val_accuracy: 0.9872\n",
            "Epoch 35: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/95/assets\n",
            "\n",
            "\n",
            " 48%|████▊     | 96/200 [3:51:28<3:21:02, 115.98s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 3.4178 - accuracy: 0.3526\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 8s 33ms/step - loss: 3.4178 - accuracy: 0.3526 - val_loss: 1.9079 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 2.4949 - accuracy: 0.5833\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 2.4949 - accuracy: 0.5833 - val_loss: 2.2105 - val_accuracy: 0.2864\n",
            "Epoch 3/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 2.0916 - accuracy: 0.7115\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 2.0916 - accuracy: 0.7115 - val_loss: 2.1580 - val_accuracy: 0.3223\n",
            "Epoch 4/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.8352 - accuracy: 0.7788\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 1.8352 - accuracy: 0.7788 - val_loss: 1.5918 - val_accuracy: 0.7852\n",
            "Epoch 5/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6371 - accuracy: 0.8321\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 1.6371 - accuracy: 0.8321 - val_loss: 1.4620 - val_accuracy: 0.8900\n",
            "Epoch 6/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.4820 - accuracy: 0.8731\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 1.4820 - accuracy: 0.8731 - val_loss: 1.3365 - val_accuracy: 0.9182\n",
            "Epoch 7/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.3659 - accuracy: 0.9135\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 1.3659 - accuracy: 0.9135 - val_loss: 1.2251 - val_accuracy: 0.9463\n",
            "Epoch 8/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.2570 - accuracy: 0.9244\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 1.2570 - accuracy: 0.9244 - val_loss: 1.1442 - val_accuracy: 0.9540\n",
            "Epoch 9/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.1843 - accuracy: 0.9429\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 1.1843 - accuracy: 0.9429 - val_loss: 1.0760 - val_accuracy: 0.9463\n",
            "Epoch 10/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.1032 - accuracy: 0.9487\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 1.1032 - accuracy: 0.9487 - val_loss: 1.0168 - val_accuracy: 0.9591\n",
            "Epoch 11/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.0458 - accuracy: 0.9622\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 32ms/step - loss: 1.0458 - accuracy: 0.9622 - val_loss: 0.9626 - val_accuracy: 0.9642\n",
            "Epoch 12/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.9868 - accuracy: 0.9724\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 30ms/step - loss: 0.9868 - accuracy: 0.9724 - val_loss: 0.9154 - val_accuracy: 0.9744\n",
            "Epoch 13/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.9388 - accuracy: 0.9744\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 30ms/step - loss: 0.9388 - accuracy: 0.9744 - val_loss: 0.8701 - val_accuracy: 0.9821\n",
            "Epoch 14/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.8961 - accuracy: 0.9788\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.8961 - accuracy: 0.9788 - val_loss: 0.8329 - val_accuracy: 0.9847\n",
            "Epoch 15/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.8564 - accuracy: 0.9840\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 30ms/step - loss: 0.8564 - accuracy: 0.9840 - val_loss: 0.8073 - val_accuracy: 0.9795\n",
            "Epoch 16/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.8246 - accuracy: 0.9859\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.8246 - accuracy: 0.9859 - val_loss: 0.7728 - val_accuracy: 0.9821\n",
            "Epoch 17/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.7883 - accuracy: 0.9878\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.7883 - accuracy: 0.9878 - val_loss: 0.7459 - val_accuracy: 0.9847\n",
            "Epoch 18/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.7653 - accuracy: 0.9891\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.7653 - accuracy: 0.9891 - val_loss: 0.7209 - val_accuracy: 0.9923\n",
            "Epoch 19/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.7331 - accuracy: 0.9929\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.7331 - accuracy: 0.9929 - val_loss: 0.6908 - val_accuracy: 0.9923\n",
            "Epoch 20/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.7098 - accuracy: 0.9917\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.7098 - accuracy: 0.9917 - val_loss: 0.6690 - val_accuracy: 0.9898\n",
            "Epoch 21/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6896 - accuracy: 0.9936\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.6896 - accuracy: 0.9936 - val_loss: 0.6456 - val_accuracy: 0.9923\n",
            "Epoch 22/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6640 - accuracy: 0.9962\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.6640 - accuracy: 0.9962 - val_loss: 0.6251 - val_accuracy: 0.9923\n",
            "Epoch 23/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6440 - accuracy: 0.9962\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.6440 - accuracy: 0.9962 - val_loss: 0.6112 - val_accuracy: 0.9923\n",
            "Epoch 24/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6219 - accuracy: 0.9962\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.6219 - accuracy: 0.9962 - val_loss: 0.5887 - val_accuracy: 0.9974\n",
            "Epoch 25/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6073 - accuracy: 0.9955\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 30ms/step - loss: 0.6073 - accuracy: 0.9955 - val_loss: 0.5759 - val_accuracy: 0.9949\n",
            "Epoch 26/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5842 - accuracy: 0.9974\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.5842 - accuracy: 0.9974 - val_loss: 0.5559 - val_accuracy: 0.9949\n",
            "Epoch 27/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5718 - accuracy: 0.9968\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.5718 - accuracy: 0.9968 - val_loss: 0.5392 - val_accuracy: 0.9974\n",
            "Epoch 28/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5550 - accuracy: 0.9962\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 30ms/step - loss: 0.5550 - accuracy: 0.9962 - val_loss: 0.5335 - val_accuracy: 0.9923\n",
            "Epoch 29/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5387 - accuracy: 0.9968\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.5387 - accuracy: 0.9968 - val_loss: 0.5125 - val_accuracy: 0.9974\n",
            "Epoch 30/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5235 - accuracy: 0.9987\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.5235 - accuracy: 0.9987 - val_loss: 0.5008 - val_accuracy: 0.9974\n",
            "Epoch 31/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5119 - accuracy: 0.9981\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.5119 - accuracy: 0.9981 - val_loss: 0.4868 - val_accuracy: 0.9949\n",
            "Epoch 32/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4964 - accuracy: 0.9981\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.4964 - accuracy: 0.9981 - val_loss: 0.4754 - val_accuracy: 0.9974\n",
            "Epoch 33/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4854 - accuracy: 0.9968\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.4854 - accuracy: 0.9968 - val_loss: 0.4616 - val_accuracy: 0.9974\n",
            "Epoch 34/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4718 - accuracy: 0.9994\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.4718 - accuracy: 0.9994 - val_loss: 0.4501 - val_accuracy: 0.9949\n",
            "Epoch 35/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4603 - accuracy: 0.9987\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.4603 - accuracy: 0.9987 - val_loss: 0.4415 - val_accuracy: 0.9974\n",
            "Epoch 36/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4474 - accuracy: 0.9987\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.4474 - accuracy: 0.9987 - val_loss: 0.4341 - val_accuracy: 0.9949\n",
            "Epoch 37/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4394 - accuracy: 0.9974\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.4394 - accuracy: 0.9974 - val_loss: 0.4191 - val_accuracy: 0.9949\n",
            "Epoch 38/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4278 - accuracy: 0.9968\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.4278 - accuracy: 0.9968 - val_loss: 0.4102 - val_accuracy: 0.9949\n",
            "Epoch 39/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4156 - accuracy: 0.9994\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.4156 - accuracy: 0.9994 - val_loss: 0.4023 - val_accuracy: 0.9949\n",
            "Epoch 40/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4080 - accuracy: 0.9987\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.4080 - accuracy: 0.9987 - val_loss: 0.3890 - val_accuracy: 0.9974\n",
            "Epoch 41/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3948 - accuracy: 0.9994\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.3948 - accuracy: 0.9994 - val_loss: 0.3838 - val_accuracy: 0.9974\n",
            "Epoch 42/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3871 - accuracy: 0.9994\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.3871 - accuracy: 0.9994 - val_loss: 0.3743 - val_accuracy: 0.9949\n",
            "Epoch 43/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3767 - accuracy: 0.9994\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.3767 - accuracy: 0.9994 - val_loss: 0.3636 - val_accuracy: 0.9974\n",
            "Epoch 44/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3693 - accuracy: 0.9994\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.3693 - accuracy: 0.9994 - val_loss: 0.3565 - val_accuracy: 0.9974\n",
            "Epoch 45/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3619 - accuracy: 0.9981\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.3619 - accuracy: 0.9981 - val_loss: 0.3497 - val_accuracy: 0.9974\n",
            "Epoch 46/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3551 - accuracy: 0.9968\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.3551 - accuracy: 0.9968 - val_loss: 0.3412 - val_accuracy: 0.9974\n",
            "Epoch 47/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3437 - accuracy: 0.9994\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.3437 - accuracy: 0.9994 - val_loss: 0.3351 - val_accuracy: 0.9974\n",
            "Epoch 48/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3357 - accuracy: 0.9981\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.3357 - accuracy: 0.9981 - val_loss: 0.3264 - val_accuracy: 0.9949\n",
            "Epoch 49/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3303 - accuracy: 0.9994\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.3303 - accuracy: 0.9994 - val_loss: 0.3200 - val_accuracy: 0.9974\n",
            "Epoch 50/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3224 - accuracy: 0.9994\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.3224 - accuracy: 0.9994 - val_loss: 0.3140 - val_accuracy: 0.9974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/96/assets\n",
            "\n",
            "\n",
            " 48%|████▊     | 97/200 [3:56:34<4:56:42, 172.84s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 2.0209 - accuracy: 0.2660\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 25ms/step - loss: 2.0209 - accuracy: 0.2660 - val_loss: 1.8170 - val_accuracy: 0.2813\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.8232 - accuracy: 0.3685\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.8232 - accuracy: 0.3679 - val_loss: 1.7555 - val_accuracy: 0.3683\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6941 - accuracy: 0.5000\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6942 - accuracy: 0.5006 - val_loss: 1.6307 - val_accuracy: 0.4450\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.5435 - accuracy: 0.6146\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.5433 - accuracy: 0.6147 - val_loss: 1.4461 - val_accuracy: 0.6368\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.3626 - accuracy: 0.6937\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.3656 - accuracy: 0.6910 - val_loss: 1.2621 - val_accuracy: 0.7391\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.1868 - accuracy: 0.7370\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.1868 - accuracy: 0.7365 - val_loss: 1.0936 - val_accuracy: 0.7647\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.0452 - accuracy: 0.7843\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.0443 - accuracy: 0.7846 - val_loss: 0.9522 - val_accuracy: 0.8133\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.9125 - accuracy: 0.8251\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.9118 - accuracy: 0.8263 - val_loss: 0.8519 - val_accuracy: 0.8389\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8172 - accuracy: 0.8698\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.8162 - accuracy: 0.8705 - val_loss: 0.7646 - val_accuracy: 0.8824\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7403 - accuracy: 0.8977\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.7394 - accuracy: 0.8974 - val_loss: 0.7028 - val_accuracy: 0.8926\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6832 - accuracy: 0.9165\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.6820 - accuracy: 0.9173 - val_loss: 0.6505 - val_accuracy: 0.9130\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6479 - accuracy: 0.9210\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.6462 - accuracy: 0.9218 - val_loss: 0.6035 - val_accuracy: 0.9309\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5948 - accuracy: 0.9313\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.5939 - accuracy: 0.9314 - val_loss: 0.5655 - val_accuracy: 0.9386\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5543 - accuracy: 0.9521\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.5546 - accuracy: 0.9519 - val_loss: 0.5529 - val_accuracy: 0.9540\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5265 - accuracy: 0.9579\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.5273 - accuracy: 0.9577 - val_loss: 0.5068 - val_accuracy: 0.9540\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4998 - accuracy: 0.9553\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.4992 - accuracy: 0.9551 - val_loss: 0.4739 - val_accuracy: 0.9642\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4842 - accuracy: 0.9631\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.4842 - accuracy: 0.9635 - val_loss: 0.4599 - val_accuracy: 0.9668\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4589 - accuracy: 0.9670\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.4586 - accuracy: 0.9667 - val_loss: 0.4436 - val_accuracy: 0.9693\n",
            "Epoch 19/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4416 - accuracy: 0.9647\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.4416 - accuracy: 0.9647 - val_loss: 0.4141 - val_accuracy: 0.9770\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4245 - accuracy: 0.9702\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.4234 - accuracy: 0.9705 - val_loss: 0.4078 - val_accuracy: 0.9795\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4042 - accuracy: 0.9773\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.4033 - accuracy: 0.9776 - val_loss: 0.3869 - val_accuracy: 0.9770\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3917 - accuracy: 0.9760\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.3912 - accuracy: 0.9763 - val_loss: 0.3688 - val_accuracy: 0.9821\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3767 - accuracy: 0.9806\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.3766 - accuracy: 0.9808 - val_loss: 0.3584 - val_accuracy: 0.9795\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3584 - accuracy: 0.9832\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.3601 - accuracy: 0.9827 - val_loss: 0.3444 - val_accuracy: 0.9847\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3556 - accuracy: 0.9806\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.3553 - accuracy: 0.9808 - val_loss: 0.3315 - val_accuracy: 0.9872\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3343 - accuracy: 0.9864\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.3341 - accuracy: 0.9865 - val_loss: 0.3261 - val_accuracy: 0.9847\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3315 - accuracy: 0.9851\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.3313 - accuracy: 0.9853 - val_loss: 0.3160 - val_accuracy: 0.9898\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3215 - accuracy: 0.9877\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.3218 - accuracy: 0.9878 - val_loss: 0.3052 - val_accuracy: 0.9872\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3090 - accuracy: 0.9890\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.3086 - accuracy: 0.9891 - val_loss: 0.3002 - val_accuracy: 0.9898\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3036 - accuracy: 0.9877\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.3034 - accuracy: 0.9878 - val_loss: 0.2953 - val_accuracy: 0.9949\n",
            "Epoch 31/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2959 - accuracy: 0.9904\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2959 - accuracy: 0.9904 - val_loss: 0.2885 - val_accuracy: 0.9898\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2924 - accuracy: 0.9877\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2919 - accuracy: 0.9878 - val_loss: 0.2789 - val_accuracy: 0.9949\n",
            "Epoch 33/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2797 - accuracy: 0.9909\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2798 - accuracy: 0.9910 - val_loss: 0.2647 - val_accuracy: 0.9949\n",
            "Epoch 34/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2673 - accuracy: 0.9916\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2672 - accuracy: 0.9917 - val_loss: 0.2644 - val_accuracy: 0.9923\n",
            "Epoch 35/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2672 - accuracy: 0.9890\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2667 - accuracy: 0.9891 - val_loss: 0.2546 - val_accuracy: 0.9974\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2596 - accuracy: 0.9929\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2598 - accuracy: 0.9929 - val_loss: 0.2516 - val_accuracy: 0.9949\n",
            "Epoch 37/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2575 - accuracy: 0.9929\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2570 - accuracy: 0.9929 - val_loss: 0.2452 - val_accuracy: 0.9949\n",
            "Epoch 38/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2464 - accuracy: 0.9929\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2471 - accuracy: 0.9923 - val_loss: 0.2375 - val_accuracy: 0.9974\n",
            "Epoch 39/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2429 - accuracy: 0.9942\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2430 - accuracy: 0.9942 - val_loss: 0.2313 - val_accuracy: 0.9974\n",
            "Epoch 40/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2397 - accuracy: 0.9922\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2394 - accuracy: 0.9923 - val_loss: 0.2298 - val_accuracy: 0.9974\n",
            "Epoch 41/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2306 - accuracy: 0.9955\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.2305 - accuracy: 0.9955 - val_loss: 0.2255 - val_accuracy: 0.9974\n",
            "Epoch 42/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2245 - accuracy: 0.9942\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2244 - accuracy: 0.9942 - val_loss: 0.2202 - val_accuracy: 0.9974\n",
            "Epoch 43/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2195 - accuracy: 0.9942\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2196 - accuracy: 0.9942 - val_loss: 0.2153 - val_accuracy: 0.9974\n",
            "Epoch 44/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2188 - accuracy: 0.9948\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2185 - accuracy: 0.9949 - val_loss: 0.2231 - val_accuracy: 0.9898\n",
            "Epoch 45/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2122 - accuracy: 0.9961\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2121 - accuracy: 0.9962 - val_loss: 0.2108 - val_accuracy: 0.9974\n",
            "Epoch 46/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2103 - accuracy: 0.9955\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2110 - accuracy: 0.9949 - val_loss: 0.2083 - val_accuracy: 0.9974\n",
            "Epoch 47/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2037 - accuracy: 0.9974\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2035 - accuracy: 0.9974 - val_loss: 0.2034 - val_accuracy: 0.9974\n",
            "Epoch 48/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2015 - accuracy: 0.9961\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2012 - accuracy: 0.9962 - val_loss: 0.1974 - val_accuracy: 0.9974\n",
            "Epoch 49/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2002 - accuracy: 0.9948\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2004 - accuracy: 0.9949 - val_loss: 0.1953 - val_accuracy: 0.9974\n",
            "Epoch 50/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1947 - accuracy: 0.9987\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1947 - accuracy: 0.9987 - val_loss: 0.1957 - val_accuracy: 0.9974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/97/assets\n",
            "\n",
            "\n",
            " 49%|████▉     | 98/200 [4:00:16<5:18:59, 187.65s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.7077 - accuracy: 0.5690\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 18ms/step - loss: 1.6969 - accuracy: 0.5731 - val_loss: 1.7940 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7656 - accuracy: 0.9223\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.7639 - accuracy: 0.9218 - val_loss: 2.1757 - val_accuracy: 0.2890\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5246 - accuracy: 0.9754\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.5246 - accuracy: 0.9756 - val_loss: 0.9315 - val_accuracy: 0.8414\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4241 - accuracy: 0.9870\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.4237 - accuracy: 0.9872 - val_loss: 0.3935 - val_accuracy: 0.9795\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3498 - accuracy: 0.9961\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.3497 - accuracy: 0.9962 - val_loss: 0.3258 - val_accuracy: 0.9923\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2994 - accuracy: 0.9948\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.3001 - accuracy: 0.9949 - val_loss: 0.2831 - val_accuracy: 0.9923\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2700 - accuracy: 0.9961\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.2698 - accuracy: 0.9962 - val_loss: 0.2576 - val_accuracy: 0.9923\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2271 - accuracy: 0.9994\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.2270 - accuracy: 0.9994 - val_loss: 0.2294 - val_accuracy: 0.9923\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2034 - accuracy: 0.9994\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.2031 - accuracy: 0.9994 - val_loss: 0.2009 - val_accuracy: 0.9923\n",
            "Epoch 10/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1864 - accuracy: 0.9987\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1862 - accuracy: 0.9987 - val_loss: 0.1910 - val_accuracy: 0.9949\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1687 - accuracy: 0.9981\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1684 - accuracy: 0.9981 - val_loss: 0.1697 - val_accuracy: 0.9923\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1530 - accuracy: 0.9981\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1527 - accuracy: 0.9981 - val_loss: 0.1574 - val_accuracy: 0.9923\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1395 - accuracy: 0.9981\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1396 - accuracy: 0.9981 - val_loss: 0.1523 - val_accuracy: 0.9923\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1330 - accuracy: 0.9981\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1329 - accuracy: 0.9981 - val_loss: 0.1499 - val_accuracy: 0.9898\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1202 - accuracy: 0.9994\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1201 - accuracy: 0.9994 - val_loss: 0.1422 - val_accuracy: 0.9923\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1133 - accuracy: 1.0000\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1133 - accuracy: 1.0000 - val_loss: 0.1283 - val_accuracy: 0.9923\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1073 - accuracy: 1.0000\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1073 - accuracy: 1.0000 - val_loss: 0.1223 - val_accuracy: 0.9923\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1028 - accuracy: 1.0000\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1028 - accuracy: 1.0000 - val_loss: 0.1203 - val_accuracy: 0.9923\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1025 - accuracy: 1.0000\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1025 - accuracy: 1.0000 - val_loss: 0.1188 - val_accuracy: 0.9923\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0946 - accuracy: 1.0000\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0945 - accuracy: 1.0000 - val_loss: 0.1144 - val_accuracy: 0.9923\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0917 - accuracy: 1.0000\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0917 - accuracy: 1.0000 - val_loss: 0.1130 - val_accuracy: 0.9923\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0874 - accuracy: 1.0000\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0874 - accuracy: 1.0000 - val_loss: 0.1084 - val_accuracy: 0.9949\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0855 - accuracy: 0.9994\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0859 - accuracy: 0.9994 - val_loss: 0.1657 - val_accuracy: 0.9795\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0834 - accuracy: 1.0000\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0833 - accuracy: 1.0000 - val_loss: 0.1001 - val_accuracy: 0.9949\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0789 - accuracy: 1.0000\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0790 - accuracy: 1.0000 - val_loss: 0.0941 - val_accuracy: 0.9949\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0783 - accuracy: 1.0000\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0782 - accuracy: 1.0000 - val_loss: 0.0977 - val_accuracy: 0.9949\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0763 - accuracy: 1.0000\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0764 - accuracy: 1.0000 - val_loss: 0.1097 - val_accuracy: 0.9949\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0835 - accuracy: 0.9994\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0834 - accuracy: 0.9994 - val_loss: 0.0991 - val_accuracy: 0.9949\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0732 - accuracy: 1.0000\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0731 - accuracy: 1.0000 - val_loss: 0.0935 - val_accuracy: 0.9923\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0706 - accuracy: 1.0000\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0705 - accuracy: 1.0000 - val_loss: 0.0904 - val_accuracy: 0.9949\n",
            "Epoch 31/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0689 - accuracy: 1.0000\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0689 - accuracy: 1.0000 - val_loss: 0.0919 - val_accuracy: 0.9923\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0664 - accuracy: 1.0000\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0664 - accuracy: 1.0000 - val_loss: 0.0857 - val_accuracy: 0.9923\n",
            "Epoch 33/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0672 - accuracy: 1.0000\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0671 - accuracy: 1.0000 - val_loss: 0.0832 - val_accuracy: 0.9949\n",
            "Epoch 34/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0646 - accuracy: 1.0000\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0645 - accuracy: 1.0000 - val_loss: 0.0862 - val_accuracy: 0.9949\n",
            "Epoch 35/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0635 - accuracy: 1.0000\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0634 - accuracy: 1.0000 - val_loss: 0.0861 - val_accuracy: 0.9949\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0616 - accuracy: 1.0000\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0618 - accuracy: 1.0000 - val_loss: 0.0946 - val_accuracy: 0.9923\n",
            "Epoch 37/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0733 - accuracy: 0.9974\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0732 - accuracy: 0.9974 - val_loss: 0.0856 - val_accuracy: 0.9923\n",
            "Epoch 38/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0653 - accuracy: 0.9994\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0652 - accuracy: 0.9994 - val_loss: 0.0804 - val_accuracy: 0.9949\n",
            "Epoch 39/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0597 - accuracy: 1.0000\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0596 - accuracy: 1.0000 - val_loss: 0.0813 - val_accuracy: 0.9949\n",
            "Epoch 40/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0585 - accuracy: 1.0000\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0585 - accuracy: 1.0000 - val_loss: 0.0820 - val_accuracy: 0.9949\n",
            "Epoch 41/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0566 - accuracy: 1.0000\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0566 - accuracy: 1.0000 - val_loss: 0.0798 - val_accuracy: 0.9949\n",
            "Epoch 42/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0557 - accuracy: 1.0000\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0558 - accuracy: 1.0000 - val_loss: 0.0854 - val_accuracy: 0.9949\n",
            "Epoch 43/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0544 - accuracy: 1.0000\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0544 - accuracy: 1.0000 - val_loss: 0.0831 - val_accuracy: 0.9949\n",
            "Epoch 44/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0552 - accuracy: 1.0000\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0552 - accuracy: 1.0000 - val_loss: 0.1175 - val_accuracy: 0.9898\n",
            "Epoch 45/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0540 - accuracy: 1.0000\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0540 - accuracy: 1.0000 - val_loss: 0.0762 - val_accuracy: 0.9949\n",
            "Epoch 46/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0513 - accuracy: 1.0000\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0513 - accuracy: 1.0000 - val_loss: 0.0735 - val_accuracy: 0.9949\n",
            "Epoch 47/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0506 - accuracy: 1.0000\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0506 - accuracy: 1.0000 - val_loss: 0.0738 - val_accuracy: 0.9949\n",
            "Epoch 48/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0490 - accuracy: 1.0000\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0490 - accuracy: 1.0000 - val_loss: 0.0794 - val_accuracy: 0.9923\n",
            "Epoch 49/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0480 - accuracy: 1.0000\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0480 - accuracy: 1.0000 - val_loss: 0.0675 - val_accuracy: 0.9949\n",
            "Epoch 50/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0474 - accuracy: 1.0000\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0474 - accuracy: 1.0000 - val_loss: 0.0905 - val_accuracy: 0.9898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/98/assets\n",
            "\n",
            "\n",
            " 50%|████▉     | 99/200 [4:02:47<4:57:19, 176.63s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 2.7366 - accuracy: 0.2533\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 16ms/step - loss: 2.7292 - accuracy: 0.2526 - val_loss: 1.8989 - val_accuracy: 0.1560\n",
            "Epoch 2/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 2.2286 - accuracy: 0.3424\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 2.2255 - accuracy: 0.3449 - val_loss: 1.9460 - val_accuracy: 0.2097\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 2.0061 - accuracy: 0.4469\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 2.0069 - accuracy: 0.4455 - val_loss: 1.8384 - val_accuracy: 0.4425\n",
            "Epoch 4/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.8677 - accuracy: 0.5231\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 1.8677 - accuracy: 0.5231 - val_loss: 1.7272 - val_accuracy: 0.5422\n",
            "Epoch 5/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.7506 - accuracy: 0.5699\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 1.7506 - accuracy: 0.5699 - val_loss: 1.6536 - val_accuracy: 0.5959\n",
            "Epoch 6/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.6616 - accuracy: 0.6001\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6619 - accuracy: 0.5994 - val_loss: 1.5734 - val_accuracy: 0.6240\n",
            "Epoch 7/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.5627 - accuracy: 0.6667\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 1.5627 - accuracy: 0.6667 - val_loss: 1.4861 - val_accuracy: 0.6624\n",
            "Epoch 8/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.4760 - accuracy: 0.6885\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.4760 - accuracy: 0.6885 - val_loss: 1.4076 - val_accuracy: 0.7110\n",
            "Epoch 9/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.3918 - accuracy: 0.7249\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.3934 - accuracy: 0.7244 - val_loss: 1.3273 - val_accuracy: 0.7238\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.3167 - accuracy: 0.7519\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.3165 - accuracy: 0.7519 - val_loss: 1.2527 - val_accuracy: 0.7647\n",
            "Epoch 11/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.2399 - accuracy: 0.7713\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.2407 - accuracy: 0.7705 - val_loss: 1.1819 - val_accuracy: 0.7775\n",
            "Epoch 12/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.1848 - accuracy: 0.7912\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.1851 - accuracy: 0.7904 - val_loss: 1.1150 - val_accuracy: 0.8005\n",
            "Epoch 13/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.1176 - accuracy: 0.8173\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 1.1176 - accuracy: 0.8173 - val_loss: 1.0464 - val_accuracy: 0.8440\n",
            "Epoch 14/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.0518 - accuracy: 0.8301\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.0518 - accuracy: 0.8301 - val_loss: 1.0086 - val_accuracy: 0.8286\n",
            "Epoch 15/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.0012 - accuracy: 0.8628\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.0008 - accuracy: 0.8628 - val_loss: 0.9542 - val_accuracy: 0.8491\n",
            "Epoch 16/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.9526 - accuracy: 0.8724\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.9511 - accuracy: 0.8731 - val_loss: 0.9168 - val_accuracy: 0.8645\n",
            "Epoch 17/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.9113 - accuracy: 0.8814\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.9112 - accuracy: 0.8814 - val_loss: 0.8672 - val_accuracy: 0.8824\n",
            "Epoch 18/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.8659 - accuracy: 0.8926\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.8660 - accuracy: 0.8923 - val_loss: 0.8334 - val_accuracy: 0.9003\n",
            "Epoch 19/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.8342 - accuracy: 0.9069\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.8320 - accuracy: 0.9077 - val_loss: 0.8073 - val_accuracy: 0.8977\n",
            "Epoch 20/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.8034 - accuracy: 0.9059\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.8034 - accuracy: 0.9064 - val_loss: 0.7761 - val_accuracy: 0.9130\n",
            "Epoch 21/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.7689 - accuracy: 0.9311\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.7690 - accuracy: 0.9314 - val_loss: 0.7425 - val_accuracy: 0.9182\n",
            "Epoch 22/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.7455 - accuracy: 0.9306\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.7458 - accuracy: 0.9308 - val_loss: 0.7400 - val_accuracy: 0.9182\n",
            "Epoch 23/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.7259 - accuracy: 0.9388\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.7252 - accuracy: 0.9391 - val_loss: 0.6953 - val_accuracy: 0.9309\n",
            "Epoch 24/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.6937 - accuracy: 0.9496\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.6923 - accuracy: 0.9494 - val_loss: 0.6783 - val_accuracy: 0.9361\n",
            "Epoch 25/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6787 - accuracy: 0.9481\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.6787 - accuracy: 0.9481 - val_loss: 0.6848 - val_accuracy: 0.9361\n",
            "Epoch 26/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6511 - accuracy: 0.9583\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.6511 - accuracy: 0.9583 - val_loss: 0.6838 - val_accuracy: 0.9284\n",
            "Epoch 27/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.6437 - accuracy: 0.9555\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.6435 - accuracy: 0.9558 - val_loss: 0.6282 - val_accuracy: 0.9488\n",
            "Epoch 28/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.6152 - accuracy: 0.9671\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.6149 - accuracy: 0.9673 - val_loss: 0.6090 - val_accuracy: 0.9463\n",
            "Epoch 29/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.6086 - accuracy: 0.9601\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.6080 - accuracy: 0.9603 - val_loss: 0.5929 - val_accuracy: 0.9540\n",
            "Epoch 30/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5850 - accuracy: 0.9654\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.5850 - accuracy: 0.9654 - val_loss: 0.5748 - val_accuracy: 0.9565\n",
            "Epoch 31/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5730 - accuracy: 0.9692\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.5730 - accuracy: 0.9692 - val_loss: 0.5729 - val_accuracy: 0.9540\n",
            "Epoch 32/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5635 - accuracy: 0.9724\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.5635 - accuracy: 0.9724 - val_loss: 0.5550 - val_accuracy: 0.9591\n",
            "Epoch 33/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.5375 - accuracy: 0.9774\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.5369 - accuracy: 0.9776 - val_loss: 0.5368 - val_accuracy: 0.9565\n",
            "Epoch 34/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5287 - accuracy: 0.9788\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.5287 - accuracy: 0.9788 - val_loss: 0.5478 - val_accuracy: 0.9488\n",
            "Epoch 35/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.5187 - accuracy: 0.9753\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.5177 - accuracy: 0.9756 - val_loss: 0.5127 - val_accuracy: 0.9668\n",
            "Epoch 36/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.5032 - accuracy: 0.9832\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.5028 - accuracy: 0.9833 - val_loss: 0.5236 - val_accuracy: 0.9514\n",
            "Epoch 37/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.4944 - accuracy: 0.9798\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.4939 - accuracy: 0.9801 - val_loss: 0.5081 - val_accuracy: 0.9565\n",
            "Epoch 38/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.4859 - accuracy: 0.9810\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.4853 - accuracy: 0.9814 - val_loss: 0.4786 - val_accuracy: 0.9719\n",
            "Epoch 39/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4686 - accuracy: 0.9853\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.4686 - accuracy: 0.9853 - val_loss: 0.4852 - val_accuracy: 0.9591\n",
            "Epoch 40/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.4632 - accuracy: 0.9836\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.4631 - accuracy: 0.9833 - val_loss: 0.4805 - val_accuracy: 0.9642\n",
            "Epoch 41/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4531 - accuracy: 0.9839\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.4529 - accuracy: 0.9840 - val_loss: 0.4486 - val_accuracy: 0.9719\n",
            "Epoch 42/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.4465 - accuracy: 0.9863\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.4457 - accuracy: 0.9865 - val_loss: 0.4525 - val_accuracy: 0.9719\n",
            "Epoch 43/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.4319 - accuracy: 0.9883\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.4312 - accuracy: 0.9885 - val_loss: 0.4304 - val_accuracy: 0.9770\n",
            "Epoch 44/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4265 - accuracy: 0.9865\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.4262 - accuracy: 0.9865 - val_loss: 0.4191 - val_accuracy: 0.9821\n",
            "Epoch 45/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.4178 - accuracy: 0.9870\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.4180 - accuracy: 0.9865 - val_loss: 0.4284 - val_accuracy: 0.9744\n",
            "Epoch 46/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4108 - accuracy: 0.9890\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.4117 - accuracy: 0.9885 - val_loss: 0.4078 - val_accuracy: 0.9795\n",
            "Epoch 47/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.4006 - accuracy: 0.9915\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.4006 - accuracy: 0.9917 - val_loss: 0.4042 - val_accuracy: 0.9795\n",
            "Epoch 48/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3904 - accuracy: 0.9922\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.3902 - accuracy: 0.9923 - val_loss: 0.3965 - val_accuracy: 0.9744\n",
            "Epoch 49/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3851 - accuracy: 0.9922\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.3846 - accuracy: 0.9923 - val_loss: 0.3898 - val_accuracy: 0.9795\n",
            "Epoch 50/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3813 - accuracy: 0.9922\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.3805 - accuracy: 0.9923 - val_loss: 0.4105 - val_accuracy: 0.9642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/99/assets\n",
            "\n",
            "\n",
            " 50%|█████     | 100/200 [4:05:14<4:39:44, 167.85s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 2.2632 - accuracy: 0.3076\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 19ms/step - loss: 2.2608 - accuracy: 0.3090 - val_loss: 1.8744 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.8916 - accuracy: 0.5154\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 1.8916 - accuracy: 0.5154 - val_loss: 1.8655 - val_accuracy: 0.3427\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6674 - accuracy: 0.6405\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 1.6662 - accuracy: 0.6410 - val_loss: 1.6699 - val_accuracy: 0.4220\n",
            "Epoch 4/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.5010 - accuracy: 0.7018\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 1.4995 - accuracy: 0.7032 - val_loss: 1.4162 - val_accuracy: 0.6931\n",
            "Epoch 5/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.3441 - accuracy: 0.7584\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 1.3445 - accuracy: 0.7583 - val_loss: 1.2950 - val_accuracy: 0.7647\n",
            "Epoch 6/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.2020 - accuracy: 0.8242\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 1.2009 - accuracy: 0.8256 - val_loss: 1.1694 - val_accuracy: 0.8082\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.0932 - accuracy: 0.8582\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 1.0925 - accuracy: 0.8590 - val_loss: 1.0667 - val_accuracy: 0.8593\n",
            "Epoch 8/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.9987 - accuracy: 0.8981\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.9987 - accuracy: 0.8981 - val_loss: 0.9912 - val_accuracy: 0.8900\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.9217 - accuracy: 0.9171\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.9210 - accuracy: 0.9179 - val_loss: 0.9204 - val_accuracy: 0.9233\n",
            "Epoch 10/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.8695 - accuracy: 0.9330\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.8699 - accuracy: 0.9321 - val_loss: 0.8715 - val_accuracy: 0.9182\n",
            "Epoch 11/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.8117 - accuracy: 0.9472\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.8118 - accuracy: 0.9474 - val_loss: 0.8195 - val_accuracy: 0.9463\n",
            "Epoch 12/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.7583 - accuracy: 0.9699\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.7583 - accuracy: 0.9699 - val_loss: 0.7795 - val_accuracy: 0.9463\n",
            "Epoch 13/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.7262 - accuracy: 0.9736\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.7257 - accuracy: 0.9737 - val_loss: 0.7435 - val_accuracy: 0.9540\n",
            "Epoch 14/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.6945 - accuracy: 0.9746\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.6941 - accuracy: 0.9750 - val_loss: 0.7122 - val_accuracy: 0.9642\n",
            "Epoch 15/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.6622 - accuracy: 0.9787\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.6635 - accuracy: 0.9782 - val_loss: 0.6924 - val_accuracy: 0.9668\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6354 - accuracy: 0.9877\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.6365 - accuracy: 0.9865 - val_loss: 0.6572 - val_accuracy: 0.9642\n",
            "Epoch 17/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.6158 - accuracy: 0.9876\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.6158 - accuracy: 0.9872 - val_loss: 0.6371 - val_accuracy: 0.9719\n",
            "Epoch 18/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5992 - accuracy: 0.9821\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.5992 - accuracy: 0.9821 - val_loss: 0.6181 - val_accuracy: 0.9770\n",
            "Epoch 19/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5749 - accuracy: 0.9917\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.5749 - accuracy: 0.9917 - val_loss: 0.6011 - val_accuracy: 0.9744\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5481 - accuracy: 0.9916\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.5487 - accuracy: 0.9917 - val_loss: 0.5808 - val_accuracy: 0.9668\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5388 - accuracy: 0.9935\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.5381 - accuracy: 0.9936 - val_loss: 0.5625 - val_accuracy: 0.9770\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5203 - accuracy: 0.9955\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.5200 - accuracy: 0.9949 - val_loss: 0.5459 - val_accuracy: 0.9795\n",
            "Epoch 23/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.5032 - accuracy: 0.9941\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.5027 - accuracy: 0.9942 - val_loss: 0.5311 - val_accuracy: 0.9795\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4868 - accuracy: 0.9922\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.4868 - accuracy: 0.9923 - val_loss: 0.5251 - val_accuracy: 0.9770\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4788 - accuracy: 0.9942\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.4781 - accuracy: 0.9942 - val_loss: 0.5058 - val_accuracy: 0.9795\n",
            "Epoch 26/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4640 - accuracy: 0.9942\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.4640 - accuracy: 0.9942 - val_loss: 0.4972 - val_accuracy: 0.9795\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4511 - accuracy: 0.9955\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.4509 - accuracy: 0.9955 - val_loss: 0.4852 - val_accuracy: 0.9821\n",
            "Epoch 28/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4412 - accuracy: 0.9968\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.4412 - accuracy: 0.9968 - val_loss: 0.4739 - val_accuracy: 0.9821\n",
            "Epoch 29/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.4341 - accuracy: 0.9948\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.4334 - accuracy: 0.9949 - val_loss: 0.4593 - val_accuracy: 0.9821\n",
            "Epoch 30/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4187 - accuracy: 0.9961\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.4188 - accuracy: 0.9962 - val_loss: 0.4496 - val_accuracy: 0.9795\n",
            "Epoch 31/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4091 - accuracy: 0.9968\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.4091 - accuracy: 0.9968 - val_loss: 0.4402 - val_accuracy: 0.9795\n",
            "Epoch 32/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.4002 - accuracy: 0.9980\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.4002 - accuracy: 0.9981 - val_loss: 0.4316 - val_accuracy: 0.9821\n",
            "Epoch 33/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3892 - accuracy: 0.9981\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.3892 - accuracy: 0.9981 - val_loss: 0.4213 - val_accuracy: 0.9821\n",
            "Epoch 34/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3865 - accuracy: 0.9955\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.3865 - accuracy: 0.9955 - val_loss: 0.4157 - val_accuracy: 0.9821\n",
            "Epoch 35/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3749 - accuracy: 0.9974\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.3749 - accuracy: 0.9974 - val_loss: 0.4083 - val_accuracy: 0.9821\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3674 - accuracy: 0.9974\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.3668 - accuracy: 0.9974 - val_loss: 0.3956 - val_accuracy: 0.9898\n",
            "Epoch 37/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3604 - accuracy: 0.9962\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.3604 - accuracy: 0.9962 - val_loss: 0.3977 - val_accuracy: 0.9872\n",
            "Epoch 38/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3527 - accuracy: 0.9968\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.3527 - accuracy: 0.9968 - val_loss: 0.3847 - val_accuracy: 0.9795\n",
            "Epoch 39/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3445 - accuracy: 0.9961\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.3445 - accuracy: 0.9962 - val_loss: 0.3772 - val_accuracy: 0.9821\n",
            "Epoch 40/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3358 - accuracy: 0.9987\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.3364 - accuracy: 0.9987 - val_loss: 0.3720 - val_accuracy: 0.9795\n",
            "Epoch 41/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3304 - accuracy: 0.9987\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.3304 - accuracy: 0.9987 - val_loss: 0.3597 - val_accuracy: 0.9898\n",
            "Epoch 42/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3272 - accuracy: 0.9974\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.3272 - accuracy: 0.9974 - val_loss: 0.3562 - val_accuracy: 0.9898\n",
            "Epoch 43/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3195 - accuracy: 0.9981\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.3196 - accuracy: 0.9981 - val_loss: 0.3578 - val_accuracy: 0.9872\n",
            "Epoch 44/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3139 - accuracy: 0.9981\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.3138 - accuracy: 0.9981 - val_loss: 0.3426 - val_accuracy: 0.9923\n",
            "Epoch 45/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3113 - accuracy: 0.9974\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.3113 - accuracy: 0.9974 - val_loss: 0.3394 - val_accuracy: 0.9898\n",
            "Epoch 46/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3009 - accuracy: 0.9987\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.3009 - accuracy: 0.9987 - val_loss: 0.3339 - val_accuracy: 0.9898\n",
            "Epoch 47/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2981 - accuracy: 0.9987\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.2980 - accuracy: 0.9987 - val_loss: 0.3276 - val_accuracy: 0.9898\n",
            "Epoch 48/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2939 - accuracy: 0.9987\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.2936 - accuracy: 0.9987 - val_loss: 0.3231 - val_accuracy: 0.9872\n",
            "Epoch 49/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2891 - accuracy: 0.9968\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.2890 - accuracy: 0.9968 - val_loss: 0.3175 - val_accuracy: 0.9898\n",
            "Epoch 50/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2828 - accuracy: 0.9994\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.2828 - accuracy: 0.9994 - val_loss: 0.3132 - val_accuracy: 0.9898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/100/assets\n",
            "\n",
            "\n",
            " 50%|█████     | 101/200 [4:08:41<4:56:24, 179.64s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.1586 - accuracy: 0.7122\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 8s 30ms/step - loss: 1.1586 - accuracy: 0.7122 - val_loss: 1.8398 - val_accuracy: 0.2634\n",
            "Epoch 2/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4319 - accuracy: 0.9423\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 0.4319 - accuracy: 0.9423 - val_loss: 1.7640 - val_accuracy: 0.3606\n",
            "Epoch 3/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2142 - accuracy: 0.9845\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.2143 - accuracy: 0.9846 - val_loss: 0.5807 - val_accuracy: 0.8542\n",
            "Epoch 4/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1806 - accuracy: 0.9904\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.1806 - accuracy: 0.9904 - val_loss: 0.4921 - val_accuracy: 0.8568\n",
            "Epoch 5/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2991 - accuracy: 0.9615\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.2991 - accuracy: 0.9615 - val_loss: 0.6280 - val_accuracy: 0.8184\n",
            "Epoch 6/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2047 - accuracy: 0.9878\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.2047 - accuracy: 0.9878 - val_loss: 0.4587 - val_accuracy: 0.8645\n",
            "Epoch 7/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1435 - accuracy: 0.9942\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.1435 - accuracy: 0.9942 - val_loss: 0.1600 - val_accuracy: 0.9923\n",
            "Epoch 8/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1205 - accuracy: 0.9994\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.1205 - accuracy: 0.9994 - val_loss: 0.1545 - val_accuracy: 0.9872\n",
            "Epoch 9/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1713 - accuracy: 0.9820\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 0.1714 - accuracy: 0.9821 - val_loss: 0.2828 - val_accuracy: 0.9668\n",
            "Epoch 10/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1553 - accuracy: 0.9897\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 0.1551 - accuracy: 0.9897 - val_loss: 0.1969 - val_accuracy: 0.9642\n",
            "Epoch 11/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1162 - accuracy: 0.9981\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 0.1163 - accuracy: 0.9981 - val_loss: 0.1779 - val_accuracy: 0.9872\n",
            "Epoch 12/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1696 - accuracy: 0.9795\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.1696 - accuracy: 0.9795 - val_loss: 0.3343 - val_accuracy: 0.9744\n",
            "Epoch 13/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1262 - accuracy: 0.9929\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.1261 - accuracy: 0.9929 - val_loss: 0.2245 - val_accuracy: 0.9847\n",
            "Epoch 13: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/101/assets\n",
            "\n",
            "\n",
            " 51%|█████     | 102/200 [4:09:59<4:03:39, 149.18s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 3.2192 - accuracy: 0.3038\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 8s 33ms/step - loss: 3.2192 - accuracy: 0.3038 - val_loss: 2.1481 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.9932 - accuracy: 0.3128\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 1.9932 - accuracy: 0.3128 - val_loss: 1.9855 - val_accuracy: 0.2685\n",
            "Epoch 3/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.7632 - accuracy: 0.4083\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 1.7632 - accuracy: 0.4083 - val_loss: 1.6175 - val_accuracy: 0.4118\n",
            "Epoch 4/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 2.1568 - accuracy: 0.3667\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 2.1568 - accuracy: 0.3667 - val_loss: 2.1894 - val_accuracy: 0.2558\n",
            "Epoch 5/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 2.1339 - accuracy: 0.2635\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 32ms/step - loss: 2.1339 - accuracy: 0.2635 - val_loss: 1.9912 - val_accuracy: 0.3095\n",
            "Epoch 6/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.9875 - accuracy: 0.2782\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 32ms/step - loss: 1.9875 - accuracy: 0.2782 - val_loss: 1.9580 - val_accuracy: 0.2864\n",
            "Epoch 7/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.9225 - accuracy: 0.2846\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 1.9225 - accuracy: 0.2846 - val_loss: 1.8874 - val_accuracy: 0.2634\n",
            "Epoch 8/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.8625 - accuracy: 0.2840\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 1.8625 - accuracy: 0.2840 - val_loss: 1.8349 - val_accuracy: 0.2864\n",
            "Epoch 8: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/102/assets\n",
            "\n",
            "\n",
            " 52%|█████▏    | 103/200 [4:11:27<3:31:06, 130.58s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.2584 - accuracy: 0.6839\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 23ms/step - loss: 1.2517 - accuracy: 0.6872 - val_loss: 1.6322 - val_accuracy: 0.2941\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4441 - accuracy: 0.9767\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.4435 - accuracy: 0.9763 - val_loss: 1.2322 - val_accuracy: 0.5320\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2962 - accuracy: 0.9942\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.2971 - accuracy: 0.9936 - val_loss: 0.4992 - val_accuracy: 0.9616\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2473 - accuracy: 0.9955\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.2471 - accuracy: 0.9955 - val_loss: 0.2379 - val_accuracy: 0.9898\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2069 - accuracy: 0.9994\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.2066 - accuracy: 0.9994 - val_loss: 0.2065 - val_accuracy: 0.9923\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1830 - accuracy: 0.9987\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1827 - accuracy: 0.9987 - val_loss: 0.1952 - val_accuracy: 0.9898\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1649 - accuracy: 0.9981\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1651 - accuracy: 0.9981 - val_loss: 0.2258 - val_accuracy: 0.9898\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1514 - accuracy: 0.9987\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1514 - accuracy: 0.9987 - val_loss: 0.1654 - val_accuracy: 0.9923\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1369 - accuracy: 0.9994\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1368 - accuracy: 0.9994 - val_loss: 0.1555 - val_accuracy: 0.9923\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1287 - accuracy: 0.9994\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1285 - accuracy: 0.9994 - val_loss: 0.1437 - val_accuracy: 0.9923\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1180 - accuracy: 1.0000\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1180 - accuracy: 1.0000 - val_loss: 0.1650 - val_accuracy: 0.9923\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1139 - accuracy: 0.9987\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1139 - accuracy: 0.9987 - val_loss: 0.1505 - val_accuracy: 0.9923\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1064 - accuracy: 1.0000\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1064 - accuracy: 1.0000 - val_loss: 0.1198 - val_accuracy: 0.9923\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1020 - accuracy: 0.9994\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1019 - accuracy: 0.9994 - val_loss: 0.1155 - val_accuracy: 0.9923\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0967 - accuracy: 0.9994\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0967 - accuracy: 0.9994 - val_loss: 0.1162 - val_accuracy: 0.9923\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0921 - accuracy: 0.9994\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0921 - accuracy: 0.9994 - val_loss: 0.1170 - val_accuracy: 0.9923\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0853 - accuracy: 1.0000\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0852 - accuracy: 1.0000 - val_loss: 0.1062 - val_accuracy: 0.9923\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0815 - accuracy: 1.0000\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0814 - accuracy: 1.0000 - val_loss: 0.1061 - val_accuracy: 0.9923\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1107 - accuracy: 0.9922\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1108 - accuracy: 0.9923 - val_loss: 0.3478 - val_accuracy: 0.9156\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1104 - accuracy: 0.9968\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1102 - accuracy: 0.9968 - val_loss: 0.1225 - val_accuracy: 0.9923\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0856 - accuracy: 1.0000\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0855 - accuracy: 1.0000 - val_loss: 0.0999 - val_accuracy: 0.9923\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0797 - accuracy: 1.0000\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0798 - accuracy: 1.0000 - val_loss: 0.0995 - val_accuracy: 0.9949\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0764 - accuracy: 1.0000\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0764 - accuracy: 1.0000 - val_loss: 0.0901 - val_accuracy: 0.9923\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0727 - accuracy: 1.0000\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0728 - accuracy: 1.0000 - val_loss: 0.0893 - val_accuracy: 0.9923\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0705 - accuracy: 1.0000\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0705 - accuracy: 1.0000 - val_loss: 0.0851 - val_accuracy: 0.9923\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0683 - accuracy: 1.0000\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0683 - accuracy: 1.0000 - val_loss: 0.0822 - val_accuracy: 0.9949\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0683 - accuracy: 1.0000\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0683 - accuracy: 1.0000 - val_loss: 0.0848 - val_accuracy: 0.9923\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0658 - accuracy: 1.0000\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0658 - accuracy: 1.0000 - val_loss: 0.0791 - val_accuracy: 0.9949\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0639 - accuracy: 1.0000\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0638 - accuracy: 1.0000 - val_loss: 0.0792 - val_accuracy: 0.9949\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0628 - accuracy: 1.0000\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0628 - accuracy: 1.0000 - val_loss: 0.0756 - val_accuracy: 0.9974\n",
            "Epoch 31/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0618 - accuracy: 1.0000\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0619 - accuracy: 1.0000 - val_loss: 0.0815 - val_accuracy: 0.9949\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0601 - accuracy: 1.0000\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0602 - accuracy: 1.0000 - val_loss: 0.0865 - val_accuracy: 0.9923\n",
            "Epoch 33/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0589 - accuracy: 1.0000\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0589 - accuracy: 1.0000 - val_loss: 0.0779 - val_accuracy: 0.9949\n",
            "Epoch 34/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0574 - accuracy: 1.0000\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0574 - accuracy: 1.0000 - val_loss: 0.0726 - val_accuracy: 0.9949\n",
            "Epoch 35/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0564 - accuracy: 1.0000\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0563 - accuracy: 1.0000 - val_loss: 0.0734 - val_accuracy: 0.9974\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0543 - accuracy: 1.0000\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0543 - accuracy: 1.0000 - val_loss: 0.0735 - val_accuracy: 0.9949\n",
            "Epoch 37/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0536 - accuracy: 1.0000\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0536 - accuracy: 1.0000 - val_loss: 0.0727 - val_accuracy: 0.9923\n",
            "Epoch 38/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0523 - accuracy: 1.0000\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0523 - accuracy: 1.0000 - val_loss: 0.0720 - val_accuracy: 0.9949\n",
            "Epoch 39/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0510 - accuracy: 1.0000\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0510 - accuracy: 1.0000 - val_loss: 0.0657 - val_accuracy: 0.9974\n",
            "Epoch 40/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0496 - accuracy: 1.0000\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0496 - accuracy: 1.0000 - val_loss: 0.0753 - val_accuracy: 0.9923\n",
            "Epoch 41/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0484 - accuracy: 1.0000\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0484 - accuracy: 1.0000 - val_loss: 0.0646 - val_accuracy: 0.9974\n",
            "Epoch 42/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0484 - accuracy: 1.0000\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0484 - accuracy: 1.0000 - val_loss: 0.0780 - val_accuracy: 0.9923\n",
            "Epoch 43/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0467 - accuracy: 1.0000\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0467 - accuracy: 1.0000 - val_loss: 0.0885 - val_accuracy: 0.9872\n",
            "Epoch 44/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0460 - accuracy: 1.0000\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0459 - accuracy: 1.0000 - val_loss: 0.0695 - val_accuracy: 0.9949\n",
            "Epoch 45/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0945 - accuracy: 0.9903\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0943 - accuracy: 0.9904 - val_loss: 0.1248 - val_accuracy: 0.9821\n",
            "Epoch 46/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0566 - accuracy: 0.9994\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0566 - accuracy: 0.9994 - val_loss: 0.0703 - val_accuracy: 0.9949\n",
            "Epoch 46: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/103/assets\n",
            "\n",
            "\n",
            " 52%|█████▏    | 104/200 [4:14:54<4:05:44, 153.59s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 4.6121 - accuracy: 0.4710\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 9s 35ms/step - loss: 4.5956 - accuracy: 0.4724 - val_loss: 2.2188 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.2885 - accuracy: 0.7237\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 1.2885 - accuracy: 0.7237 - val_loss: 2.7051 - val_accuracy: 0.2992\n",
            "Epoch 3/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.0324 - accuracy: 0.8051\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 34ms/step - loss: 1.0324 - accuracy: 0.8051 - val_loss: 2.8471 - val_accuracy: 0.6113\n",
            "Epoch 4/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.0600 - accuracy: 0.7981\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 34ms/step - loss: 1.0600 - accuracy: 0.7981 - val_loss: 0.9360 - val_accuracy: 0.8286\n",
            "Epoch 5/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.8202 - accuracy: 0.8641\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 34ms/step - loss: 0.8202 - accuracy: 0.8641 - val_loss: 0.7199 - val_accuracy: 0.8772\n",
            "Epoch 6/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6725 - accuracy: 0.8891\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 34ms/step - loss: 0.6725 - accuracy: 0.8891 - val_loss: 2.7892 - val_accuracy: 0.6215\n",
            "Epoch 7/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.7014 - accuracy: 0.8910\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 34ms/step - loss: 0.7014 - accuracy: 0.8910 - val_loss: 0.5187 - val_accuracy: 0.9309\n",
            "Epoch 8/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5665 - accuracy: 0.9167\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 34ms/step - loss: 0.5665 - accuracy: 0.9167 - val_loss: 10.9025 - val_accuracy: 0.5166\n",
            "Epoch 9/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 2.3468 - accuracy: 0.3744\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 2.3468 - accuracy: 0.3744 - val_loss: 2.1143 - val_accuracy: 0.2864\n",
            "Epoch 10/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 2.0722 - accuracy: 0.2795\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 2.0722 - accuracy: 0.2795 - val_loss: 2.0309 - val_accuracy: 0.2864\n",
            "Epoch 11/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 2.0101 - accuracy: 0.2808\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 2.0101 - accuracy: 0.2808 - val_loss: 1.9747 - val_accuracy: 0.2864\n",
            "Epoch 12/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.9532 - accuracy: 0.2776\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 1.9532 - accuracy: 0.2776 - val_loss: 1.9256 - val_accuracy: 0.2864\n",
            "Epoch 12: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/104/assets\n",
            "\n",
            "\n",
            " 52%|█████▎    | 105/200 [4:16:18<3:30:23, 132.88s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 2.4354 - accuracy: 0.2759\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 15ms/step - loss: 2.4360 - accuracy: 0.2750 - val_loss: 1.8207 - val_accuracy: 0.2634\n",
            "Epoch 2/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 2.1568 - accuracy: 0.3840\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 2.1568 - accuracy: 0.3840 - val_loss: 1.8435 - val_accuracy: 0.3248\n",
            "Epoch 3/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.9263 - accuracy: 0.5013\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 1.9248 - accuracy: 0.5013 - val_loss: 1.7509 - val_accuracy: 0.3913\n",
            "Epoch 4/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.7144 - accuracy: 0.6106\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 1.7131 - accuracy: 0.6128 - val_loss: 1.5072 - val_accuracy: 0.6445\n",
            "Epoch 5/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.5212 - accuracy: 0.6875\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 1.5190 - accuracy: 0.6878 - val_loss: 1.3381 - val_accuracy: 0.7366\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.3448 - accuracy: 0.7571\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 1.3434 - accuracy: 0.7590 - val_loss: 1.1902 - val_accuracy: 0.7980\n",
            "Epoch 7/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.2014 - accuracy: 0.8135\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 1.2004 - accuracy: 0.8147 - val_loss: 1.0643 - val_accuracy: 0.8338\n",
            "Epoch 8/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.0947 - accuracy: 0.8529\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 1.0942 - accuracy: 0.8526 - val_loss: 0.9664 - val_accuracy: 0.8849\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.0018 - accuracy: 0.8867\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 1.0015 - accuracy: 0.8859 - val_loss: 0.8937 - val_accuracy: 0.8977\n",
            "Epoch 10/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.9328 - accuracy: 0.9071\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.9328 - accuracy: 0.9071 - val_loss: 0.8272 - val_accuracy: 0.9361\n",
            "Epoch 11/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.8657 - accuracy: 0.9241\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.8667 - accuracy: 0.9244 - val_loss: 0.7839 - val_accuracy: 0.9514\n",
            "Epoch 12/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.8139 - accuracy: 0.9397\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.8139 - accuracy: 0.9397 - val_loss: 0.7386 - val_accuracy: 0.9514\n",
            "Epoch 13/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.7731 - accuracy: 0.9468\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.7731 - accuracy: 0.9468 - val_loss: 0.6968 - val_accuracy: 0.9642\n",
            "Epoch 14/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.7341 - accuracy: 0.9499\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.7330 - accuracy: 0.9506 - val_loss: 0.6642 - val_accuracy: 0.9719\n",
            "Epoch 15/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.6934 - accuracy: 0.9601\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.6933 - accuracy: 0.9603 - val_loss: 0.6355 - val_accuracy: 0.9770\n",
            "Epoch 16/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.6647 - accuracy: 0.9601\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.6645 - accuracy: 0.9603 - val_loss: 0.6081 - val_accuracy: 0.9872\n",
            "Epoch 17/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.6397 - accuracy: 0.9660\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.6390 - accuracy: 0.9647 - val_loss: 0.5885 - val_accuracy: 0.9898\n",
            "Epoch 18/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.6170 - accuracy: 0.9688\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.6166 - accuracy: 0.9692 - val_loss: 0.5603 - val_accuracy: 0.9872\n",
            "Epoch 19/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5918 - accuracy: 0.9737\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.5918 - accuracy: 0.9737 - val_loss: 0.5449 - val_accuracy: 0.9898\n",
            "Epoch 20/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.5678 - accuracy: 0.9787\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.5678 - accuracy: 0.9788 - val_loss: 0.5253 - val_accuracy: 0.9898\n",
            "Epoch 21/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5523 - accuracy: 0.9756\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.5523 - accuracy: 0.9756 - val_loss: 0.5091 - val_accuracy: 0.9847\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5323 - accuracy: 0.9806\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.5318 - accuracy: 0.9808 - val_loss: 0.4914 - val_accuracy: 0.9872\n",
            "Epoch 23/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5064 - accuracy: 0.9872\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.5064 - accuracy: 0.9872 - val_loss: 0.4768 - val_accuracy: 0.9898\n",
            "Epoch 24/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4953 - accuracy: 0.9878\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.4951 - accuracy: 0.9878 - val_loss: 0.4622 - val_accuracy: 0.9923\n",
            "Epoch 25/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4834 - accuracy: 0.9878\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.4834 - accuracy: 0.9878 - val_loss: 0.4499 - val_accuracy: 0.9898\n",
            "Epoch 26/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.4662 - accuracy: 0.9876\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.4659 - accuracy: 0.9878 - val_loss: 0.4388 - val_accuracy: 0.9923\n",
            "Epoch 27/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4570 - accuracy: 0.9897\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.4567 - accuracy: 0.9897 - val_loss: 0.4267 - val_accuracy: 0.9923\n",
            "Epoch 28/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.4438 - accuracy: 0.9902\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.4429 - accuracy: 0.9904 - val_loss: 0.4186 - val_accuracy: 0.9872\n",
            "Epoch 29/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.4307 - accuracy: 0.9895\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.4304 - accuracy: 0.9897 - val_loss: 0.4075 - val_accuracy: 0.9872\n",
            "Epoch 30/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4179 - accuracy: 0.9923\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.4179 - accuracy: 0.9923 - val_loss: 0.3969 - val_accuracy: 0.9898\n",
            "Epoch 31/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.4067 - accuracy: 0.9928\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.4073 - accuracy: 0.9923 - val_loss: 0.3891 - val_accuracy: 0.9923\n",
            "Epoch 32/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.3921 - accuracy: 0.9941\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.3918 - accuracy: 0.9942 - val_loss: 0.3761 - val_accuracy: 0.9949\n",
            "Epoch 33/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3847 - accuracy: 0.9961\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.3843 - accuracy: 0.9962 - val_loss: 0.3686 - val_accuracy: 0.9949\n",
            "Epoch 34/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.3787 - accuracy: 0.9948\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.3779 - accuracy: 0.9949 - val_loss: 0.3589 - val_accuracy: 0.9949\n",
            "Epoch 35/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3659 - accuracy: 0.9936\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.3659 - accuracy: 0.9936 - val_loss: 0.3511 - val_accuracy: 0.9923\n",
            "Epoch 36/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3593 - accuracy: 0.9955\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.3593 - accuracy: 0.9955 - val_loss: 0.3445 - val_accuracy: 0.9923\n",
            "Epoch 37/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.3471 - accuracy: 0.9954\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.3474 - accuracy: 0.9955 - val_loss: 0.3368 - val_accuracy: 0.9898\n",
            "Epoch 38/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3430 - accuracy: 0.9974\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.3430 - accuracy: 0.9974 - val_loss: 0.3353 - val_accuracy: 0.9872\n",
            "Epoch 39/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3369 - accuracy: 0.9955\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.3369 - accuracy: 0.9955 - val_loss: 0.3226 - val_accuracy: 0.9949\n",
            "Epoch 40/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3249 - accuracy: 0.9968\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.3249 - accuracy: 0.9968 - val_loss: 0.3148 - val_accuracy: 0.9949\n",
            "Epoch 41/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3173 - accuracy: 0.9955\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.3174 - accuracy: 0.9955 - val_loss: 0.3098 - val_accuracy: 0.9949\n",
            "Epoch 42/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3115 - accuracy: 0.9961\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.3117 - accuracy: 0.9962 - val_loss: 0.3052 - val_accuracy: 0.9923\n",
            "Epoch 43/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3045 - accuracy: 0.9974\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.3045 - accuracy: 0.9974 - val_loss: 0.2973 - val_accuracy: 0.9923\n",
            "Epoch 44/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2999 - accuracy: 0.9961\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.3000 - accuracy: 0.9962 - val_loss: 0.2947 - val_accuracy: 0.9923\n",
            "Epoch 45/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2939 - accuracy: 0.9967\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.2940 - accuracy: 0.9968 - val_loss: 0.2869 - val_accuracy: 0.9949\n",
            "Epoch 46/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2848 - accuracy: 0.9987\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.2843 - accuracy: 0.9987 - val_loss: 0.2838 - val_accuracy: 0.9872\n",
            "Epoch 47/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2820 - accuracy: 0.9968\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.2820 - accuracy: 0.9968 - val_loss: 0.2731 - val_accuracy: 0.9949\n",
            "Epoch 48/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2764 - accuracy: 0.9955\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.2764 - accuracy: 0.9955 - val_loss: 0.2686 - val_accuracy: 0.9949\n",
            "Epoch 49/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2687 - accuracy: 0.9987\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.2686 - accuracy: 0.9987 - val_loss: 0.2639 - val_accuracy: 0.9949\n",
            "Epoch 50/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2641 - accuracy: 0.9974\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.2641 - accuracy: 0.9974 - val_loss: 0.2605 - val_accuracy: 0.9898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/105/assets\n",
            "\n",
            "\n",
            " 53%|█████▎    | 106/200 [4:18:29<3:27:07, 132.21s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 2.4730 - accuracy: 0.2744\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 18ms/step - loss: 2.4730 - accuracy: 0.2744 - val_loss: 1.7358 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.7304 - accuracy: 0.3517\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 1.7312 - accuracy: 0.3506 - val_loss: 1.7946 - val_accuracy: 0.2864\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.5621 - accuracy: 0.4391\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 1.5617 - accuracy: 0.4391 - val_loss: 1.5695 - val_accuracy: 0.4757\n",
            "Epoch 4/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.5650 - accuracy: 0.4436\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 1.5650 - accuracy: 0.4436 - val_loss: 1.3579 - val_accuracy: 0.4834\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.3106 - accuracy: 0.5667\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 1.3099 - accuracy: 0.5660 - val_loss: 1.6275 - val_accuracy: 0.3862\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.1887 - accuracy: 0.6321\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 1.1890 - accuracy: 0.6340 - val_loss: 1.0650 - val_accuracy: 0.6266\n",
            "Epoch 7/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.9457 - accuracy: 0.7116\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.9436 - accuracy: 0.7141 - val_loss: 0.8663 - val_accuracy: 0.7136\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7791 - accuracy: 0.7811\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.7822 - accuracy: 0.7795 - val_loss: 1.0246 - val_accuracy: 0.7187\n",
            "Epoch 9/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.7969 - accuracy: 0.7777\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.8008 - accuracy: 0.7763 - val_loss: 2.7371 - val_accuracy: 0.6010\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7562 - accuracy: 0.8018\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.7544 - accuracy: 0.8032 - val_loss: 0.8140 - val_accuracy: 0.7954\n",
            "Epoch 11/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.1039 - accuracy: 0.7372\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 1.1039 - accuracy: 0.7372 - val_loss: 1.0439 - val_accuracy: 0.6982\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7594 - accuracy: 0.8497\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.7567 - accuracy: 0.8500 - val_loss: 0.7267 - val_accuracy: 0.8389\n",
            "Epoch 13/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.5635 - accuracy: 0.8880\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.5641 - accuracy: 0.8872 - val_loss: 0.9985 - val_accuracy: 0.7136\n",
            "Epoch 14/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.5014 - accuracy: 0.8956\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.5001 - accuracy: 0.8962 - val_loss: 0.7314 - val_accuracy: 0.8261\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4877 - accuracy: 0.8970\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.4864 - accuracy: 0.8974 - val_loss: 0.7920 - val_accuracy: 0.7826\n",
            "Epoch 16/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.6783 - accuracy: 0.8479\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.6771 - accuracy: 0.8481 - val_loss: 0.8312 - val_accuracy: 0.7954\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7640 - accuracy: 0.8225\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.7608 - accuracy: 0.8237 - val_loss: 0.9152 - val_accuracy: 0.7877\n",
            "Epoch 17: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/106/assets\n",
            "\n",
            "\n",
            " 54%|█████▎    | 107/200 [4:19:56<3:03:59, 118.71s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.8762 - accuracy: 0.8061\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 16ms/step - loss: 0.8761 - accuracy: 0.8064 - val_loss: 1.7363 - val_accuracy: 0.2916\n",
            "Epoch 2/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.2472 - accuracy: 0.9777\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.2463 - accuracy: 0.9776 - val_loss: 1.2794 - val_accuracy: 0.6189\n",
            "Epoch 3/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1786 - accuracy: 0.9844\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.1777 - accuracy: 0.9846 - val_loss: 0.3712 - val_accuracy: 0.9309\n",
            "Epoch 4/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1305 - accuracy: 0.9949\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.1305 - accuracy: 0.9949 - val_loss: 0.2423 - val_accuracy: 0.9693\n",
            "Epoch 5/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1293 - accuracy: 0.9923\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.1293 - accuracy: 0.9923 - val_loss: 0.9891 - val_accuracy: 0.8798\n",
            "Epoch 6/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2237 - accuracy: 0.9707\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.2229 - accuracy: 0.9712 - val_loss: 0.2146 - val_accuracy: 0.9642\n",
            "Epoch 7/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1232 - accuracy: 0.9935\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.1225 - accuracy: 0.9936 - val_loss: 0.2208 - val_accuracy: 0.9744\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0969 - accuracy: 0.9981\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0968 - accuracy: 0.9981 - val_loss: 0.3899 - val_accuracy: 0.9488\n",
            "Epoch 9/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1037 - accuracy: 0.9968\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.1037 - accuracy: 0.9968 - val_loss: 0.1320 - val_accuracy: 0.9923\n",
            "Epoch 10/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0899 - accuracy: 0.9961\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0900 - accuracy: 0.9962 - val_loss: 0.2422 - val_accuracy: 0.9386\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0806 - accuracy: 1.0000\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0819 - accuracy: 0.9994 - val_loss: 0.2319 - val_accuracy: 0.9514\n",
            "Epoch 12/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0827 - accuracy: 0.9994\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0827 - accuracy: 0.9994 - val_loss: 0.1519 - val_accuracy: 0.9847\n",
            "Epoch 13/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0722 - accuracy: 1.0000\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0723 - accuracy: 1.0000 - val_loss: 0.0932 - val_accuracy: 0.9923\n",
            "Epoch 14/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0602 - accuracy: 1.0000\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0602 - accuracy: 1.0000 - val_loss: 0.0858 - val_accuracy: 0.9923\n",
            "Epoch 15/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0560 - accuracy: 1.0000\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0560 - accuracy: 1.0000 - val_loss: 0.0752 - val_accuracy: 0.9923\n",
            "Epoch 16/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0522 - accuracy: 1.0000\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0524 - accuracy: 1.0000 - val_loss: 0.0737 - val_accuracy: 0.9949\n",
            "Epoch 17/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0492 - accuracy: 1.0000\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0492 - accuracy: 1.0000 - val_loss: 0.1210 - val_accuracy: 0.9770\n",
            "Epoch 18/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0485 - accuracy: 1.0000\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0485 - accuracy: 1.0000 - val_loss: 0.0669 - val_accuracy: 0.9923\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0442 - accuracy: 1.0000\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0442 - accuracy: 1.0000 - val_loss: 0.0982 - val_accuracy: 0.9898\n",
            "Epoch 20/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0447 - accuracy: 1.0000\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0447 - accuracy: 1.0000 - val_loss: 0.0752 - val_accuracy: 0.9923\n",
            "Epoch 21/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0401 - accuracy: 1.0000\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0400 - accuracy: 1.0000 - val_loss: 0.0600 - val_accuracy: 0.9923\n",
            "Epoch 22/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0379 - accuracy: 1.0000\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0379 - accuracy: 1.0000 - val_loss: 0.0961 - val_accuracy: 0.9872\n",
            "Epoch 23/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0369 - accuracy: 1.0000\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0369 - accuracy: 1.0000 - val_loss: 0.0681 - val_accuracy: 0.9898\n",
            "Epoch 24/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3100 - accuracy: 0.9525\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.3069 - accuracy: 0.9532 - val_loss: 0.2596 - val_accuracy: 0.9514\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1518 - accuracy: 0.9799\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.1512 - accuracy: 0.9801 - val_loss: 0.1457 - val_accuracy: 0.9872\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0775 - accuracy: 0.9994\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0774 - accuracy: 0.9994 - val_loss: 0.1067 - val_accuracy: 0.9898\n",
            "Epoch 26: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/107/assets\n",
            "\n",
            "\n",
            " 54%|█████▍    | 108/200 [4:21:24<2:47:35, 109.30s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.0474 - accuracy: 0.7128\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 11ms/step - loss: 1.0474 - accuracy: 0.7128 - val_loss: 2.4543 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3745 - accuracy: 0.9365\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.3745 - accuracy: 0.9365 - val_loss: 3.4042 - val_accuracy: 0.2864\n",
            "Epoch 3/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2221 - accuracy: 0.9762\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.2222 - accuracy: 0.9756 - val_loss: 1.4351 - val_accuracy: 0.5499\n",
            "Epoch 4/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.1610 - accuracy: 0.9888\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.1599 - accuracy: 0.9891 - val_loss: 0.1732 - val_accuracy: 0.9795\n",
            "Epoch 5/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 0.1165 - accuracy: 0.9940\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.1170 - accuracy: 0.9942 - val_loss: 0.1751 - val_accuracy: 0.9770\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1209 - accuracy: 0.9896\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.1205 - accuracy: 0.9897 - val_loss: 0.1265 - val_accuracy: 0.9923\n",
            "Epoch 7/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0894 - accuracy: 0.9955\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0894 - accuracy: 0.9955 - val_loss: 0.1870 - val_accuracy: 0.9693\n",
            "Epoch 8/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1034 - accuracy: 0.9891\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.1034 - accuracy: 0.9891 - val_loss: 0.2578 - val_accuracy: 0.9565\n",
            "Epoch 9/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.0905 - accuracy: 0.9961\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.0907 - accuracy: 0.9962 - val_loss: 0.1048 - val_accuracy: 0.9923\n",
            "Epoch 10/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 0.0759 - accuracy: 0.9960\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0768 - accuracy: 0.9955 - val_loss: 0.1509 - val_accuracy: 0.9693\n",
            "Epoch 11/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0738 - accuracy: 0.9974\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0737 - accuracy: 0.9974 - val_loss: 0.1140 - val_accuracy: 0.9898\n",
            "Epoch 12/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0565 - accuracy: 1.0000\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0566 - accuracy: 1.0000 - val_loss: 0.0806 - val_accuracy: 0.9923\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0514 - accuracy: 1.0000\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.0514 - accuracy: 1.0000 - val_loss: 0.0781 - val_accuracy: 0.9923\n",
            "Epoch 14/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0514 - accuracy: 1.0000\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.0514 - accuracy: 1.0000 - val_loss: 0.0756 - val_accuracy: 0.9923\n",
            "Epoch 15/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0501 - accuracy: 1.0000\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0500 - accuracy: 1.0000 - val_loss: 0.0725 - val_accuracy: 0.9923\n",
            "Epoch 16/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0517 - accuracy: 0.9961\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0529 - accuracy: 0.9955 - val_loss: 0.5488 - val_accuracy: 0.8798\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1262 - accuracy: 0.9858\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.1255 - accuracy: 0.9859 - val_loss: 0.1150 - val_accuracy: 0.9949\n",
            "Epoch 18/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0735 - accuracy: 0.9936\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.0735 - accuracy: 0.9936 - val_loss: 0.0981 - val_accuracy: 0.9923\n",
            "Epoch 19/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0528 - accuracy: 0.9974\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0528 - accuracy: 0.9974 - val_loss: 0.2022 - val_accuracy: 0.9565\n",
            "Epoch 20/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0547 - accuracy: 0.9993\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0548 - accuracy: 0.9994 - val_loss: 0.0665 - val_accuracy: 0.9949\n",
            "Epoch 21/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0444 - accuracy: 1.0000\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0448 - accuracy: 1.0000 - val_loss: 0.0572 - val_accuracy: 0.9949\n",
            "Epoch 22/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0407 - accuracy: 1.0000\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.0406 - accuracy: 1.0000 - val_loss: 0.0712 - val_accuracy: 0.9949\n",
            "Epoch 23/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.0366 - accuracy: 1.0000\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.0366 - accuracy: 1.0000 - val_loss: 0.1013 - val_accuracy: 0.9898\n",
            "Epoch 24/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0361 - accuracy: 1.0000\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0361 - accuracy: 1.0000 - val_loss: 0.0521 - val_accuracy: 0.9949\n",
            "Epoch 25/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0335 - accuracy: 1.0000\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0335 - accuracy: 1.0000 - val_loss: 0.0618 - val_accuracy: 0.9923\n",
            "Epoch 26/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 0.0333 - accuracy: 0.9993\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.0336 - accuracy: 0.9994 - val_loss: 0.3953 - val_accuracy: 0.8824\n",
            "Epoch 27/50\n",
            "188/195 [===========================>..] - ETA: 0s - loss: 0.2671 - accuracy: 0.9402\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.2613 - accuracy: 0.9417 - val_loss: 0.1803 - val_accuracy: 0.9616\n",
            "Epoch 28/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0796 - accuracy: 0.9948\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0791 - accuracy: 0.9949 - val_loss: 0.1072 - val_accuracy: 0.9898\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0557 - accuracy: 0.9994\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0557 - accuracy: 0.9994 - val_loss: 0.0846 - val_accuracy: 0.9923\n",
            "Epoch 29: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/108/assets\n",
            "\n",
            "\n",
            " 55%|█████▍    | 109/200 [4:22:19<2:21:16, 93.15s/it] \u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 2.8686 - accuracy: 0.4679\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 10s 41ms/step - loss: 2.8686 - accuracy: 0.4679 - val_loss: 1.9788 - val_accuracy: 0.2251\n",
            "Epoch 2/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.5326 - accuracy: 0.5917\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 38ms/step - loss: 1.5326 - accuracy: 0.5917 - val_loss: 1.4785 - val_accuracy: 0.5703\n",
            "Epoch 3/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6737 - accuracy: 0.6378\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 38ms/step - loss: 1.6737 - accuracy: 0.6378 - val_loss: 7.4625 - val_accuracy: 0.5985\n",
            "Epoch 4/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 2.0794 - accuracy: 0.3147\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 38ms/step - loss: 2.0794 - accuracy: 0.3147 - val_loss: 1.9404 - val_accuracy: 0.2864\n",
            "Epoch 5/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.9066 - accuracy: 0.2827\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 38ms/step - loss: 1.9066 - accuracy: 0.2827 - val_loss: 1.8721 - val_accuracy: 0.2864\n",
            "Epoch 6/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.8509 - accuracy: 0.2776\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 38ms/step - loss: 1.8509 - accuracy: 0.2776 - val_loss: 1.8261 - val_accuracy: 0.2864\n",
            "Epoch 7/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.8122 - accuracy: 0.2660\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 8s 39ms/step - loss: 1.8122 - accuracy: 0.2660 - val_loss: 1.7917 - val_accuracy: 0.2864\n",
            "Epoch 7: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/109/assets\n",
            "\n",
            "\n",
            " 55%|█████▌    | 110/200 [4:23:17<2:04:00, 82.68s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.8307 - accuracy: 0.4090\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 12ms/step - loss: 1.8307 - accuracy: 0.4090 - val_loss: 1.7513 - val_accuracy: 0.3274\n",
            "Epoch 2/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.2540 - accuracy: 0.6853\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 1.2540 - accuracy: 0.6853 - val_loss: 1.6365 - val_accuracy: 0.3018\n",
            "Epoch 3/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.8773 - accuracy: 0.8385\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.8773 - accuracy: 0.8385 - val_loss: 0.9759 - val_accuracy: 0.7494\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6781 - accuracy: 0.9009\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.6766 - accuracy: 0.9019 - val_loss: 0.6191 - val_accuracy: 0.9156\n",
            "Epoch 5/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5578 - accuracy: 0.9442\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.5578 - accuracy: 0.9442 - val_loss: 0.5277 - val_accuracy: 0.9437\n",
            "Epoch 6/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4834 - accuracy: 0.9609\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.4834 - accuracy: 0.9609 - val_loss: 0.4747 - val_accuracy: 0.9565\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4293 - accuracy: 0.9709\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.4282 - accuracy: 0.9712 - val_loss: 0.4575 - val_accuracy: 0.9616\n",
            "Epoch 8/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3869 - accuracy: 0.9813\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.3866 - accuracy: 0.9814 - val_loss: 0.3880 - val_accuracy: 0.9719\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3562 - accuracy: 0.9851\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.3562 - accuracy: 0.9853 - val_loss: 0.3659 - val_accuracy: 0.9744\n",
            "Epoch 10/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3255 - accuracy: 0.9863\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.3252 - accuracy: 0.9865 - val_loss: 0.3392 - val_accuracy: 0.9744\n",
            "Epoch 11/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3016 - accuracy: 0.9929\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.3014 - accuracy: 0.9929 - val_loss: 0.3182 - val_accuracy: 0.9847\n",
            "Epoch 12/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2806 - accuracy: 0.9955\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.2806 - accuracy: 0.9955 - val_loss: 0.3225 - val_accuracy: 0.9770\n",
            "Epoch 13/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2675 - accuracy: 0.9968\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.2680 - accuracy: 0.9968 - val_loss: 0.2821 - val_accuracy: 0.9795\n",
            "Epoch 14/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2516 - accuracy: 0.9949\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.2516 - accuracy: 0.9949 - val_loss: 0.2648 - val_accuracy: 0.9847\n",
            "Epoch 15/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.2318 - accuracy: 0.9974\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.2322 - accuracy: 0.9968 - val_loss: 0.2640 - val_accuracy: 0.9847\n",
            "Epoch 16/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 0.2226 - accuracy: 0.9974\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.2224 - accuracy: 0.9974 - val_loss: 0.2404 - val_accuracy: 0.9847\n",
            "Epoch 17/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2109 - accuracy: 0.9974\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.2108 - accuracy: 0.9974 - val_loss: 0.2329 - val_accuracy: 0.9872\n",
            "Epoch 18/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1997 - accuracy: 0.9980\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.1993 - accuracy: 0.9981 - val_loss: 0.2179 - val_accuracy: 0.9923\n",
            "Epoch 19/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1916 - accuracy: 0.9981\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1915 - accuracy: 0.9981 - val_loss: 0.2168 - val_accuracy: 0.9872\n",
            "Epoch 20/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1848 - accuracy: 0.9987\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.1849 - accuracy: 0.9987 - val_loss: 0.2042 - val_accuracy: 0.9923\n",
            "Epoch 21/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1731 - accuracy: 0.9994\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.1730 - accuracy: 0.9994 - val_loss: 0.2012 - val_accuracy: 0.9821\n",
            "Epoch 22/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1652 - accuracy: 0.9987\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.1652 - accuracy: 0.9987 - val_loss: 0.1924 - val_accuracy: 0.9923\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1579 - accuracy: 0.9981\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1578 - accuracy: 0.9981 - val_loss: 0.1946 - val_accuracy: 0.9847\n",
            "Epoch 24/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1517 - accuracy: 0.9980\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.1515 - accuracy: 0.9981 - val_loss: 0.1773 - val_accuracy: 0.9872\n",
            "Epoch 25/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 0.1460 - accuracy: 0.9980\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.1458 - accuracy: 0.9981 - val_loss: 0.1672 - val_accuracy: 0.9847\n",
            "Epoch 26/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1391 - accuracy: 0.9993\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.1388 - accuracy: 0.9994 - val_loss: 0.1722 - val_accuracy: 0.9847\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1350 - accuracy: 0.9974\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1348 - accuracy: 0.9974 - val_loss: 0.1544 - val_accuracy: 0.9923\n",
            "Epoch 28/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 0.1262 - accuracy: 0.9993\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.1267 - accuracy: 0.9994 - val_loss: 0.1461 - val_accuracy: 0.9923\n",
            "Epoch 29/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1237 - accuracy: 0.9981\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.1236 - accuracy: 0.9981 - val_loss: 0.1464 - val_accuracy: 0.9923\n",
            "Epoch 30/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.1179 - accuracy: 1.0000\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.1176 - accuracy: 1.0000 - val_loss: 0.1379 - val_accuracy: 0.9949\n",
            "Epoch 31/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1129 - accuracy: 0.9994\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1129 - accuracy: 0.9994 - val_loss: 0.1353 - val_accuracy: 0.9898\n",
            "Epoch 32/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 0.1077 - accuracy: 0.9993\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1076 - accuracy: 0.9994 - val_loss: 0.1278 - val_accuracy: 0.9923\n",
            "Epoch 33/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1062 - accuracy: 0.9987\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.1062 - accuracy: 0.9987 - val_loss: 0.1338 - val_accuracy: 0.9898\n",
            "Epoch 34/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1047 - accuracy: 1.0000\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.1047 - accuracy: 1.0000 - val_loss: 0.1227 - val_accuracy: 0.9923\n",
            "Epoch 35/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0988 - accuracy: 1.0000\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0988 - accuracy: 1.0000 - val_loss: 0.1176 - val_accuracy: 0.9949\n",
            "Epoch 36/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0956 - accuracy: 1.0000\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0954 - accuracy: 1.0000 - val_loss: 0.1194 - val_accuracy: 0.9872\n",
            "Epoch 37/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0925 - accuracy: 1.0000\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0923 - accuracy: 1.0000 - val_loss: 0.1089 - val_accuracy: 0.9974\n",
            "Epoch 38/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 0.0887 - accuracy: 0.9993\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0887 - accuracy: 0.9994 - val_loss: 0.1058 - val_accuracy: 0.9974\n",
            "Epoch 39/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0867 - accuracy: 1.0000\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0866 - accuracy: 1.0000 - val_loss: 0.1021 - val_accuracy: 0.9974\n",
            "Epoch 40/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0832 - accuracy: 1.0000\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0832 - accuracy: 1.0000 - val_loss: 0.1012 - val_accuracy: 0.9949\n",
            "Epoch 41/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.0818 - accuracy: 1.0000\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0817 - accuracy: 1.0000 - val_loss: 0.0993 - val_accuracy: 0.9949\n",
            "Epoch 42/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0803 - accuracy: 1.0000\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0803 - accuracy: 1.0000 - val_loss: 0.0961 - val_accuracy: 0.9974\n",
            "Epoch 43/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0785 - accuracy: 1.0000\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0784 - accuracy: 1.0000 - val_loss: 0.0993 - val_accuracy: 0.9949\n",
            "Epoch 44/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0753 - accuracy: 1.0000\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0753 - accuracy: 1.0000 - val_loss: 0.0927 - val_accuracy: 0.9949\n",
            "Epoch 45/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0734 - accuracy: 1.0000\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0734 - accuracy: 1.0000 - val_loss: 0.0886 - val_accuracy: 0.9974\n",
            "Epoch 46/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0717 - accuracy: 1.0000\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0717 - accuracy: 1.0000 - val_loss: 0.0875 - val_accuracy: 0.9974\n",
            "Epoch 47/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0720 - accuracy: 1.0000\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0720 - accuracy: 1.0000 - val_loss: 0.0904 - val_accuracy: 0.9923\n",
            "Epoch 48/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0706 - accuracy: 1.0000\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0705 - accuracy: 1.0000 - val_loss: 0.0885 - val_accuracy: 0.9974\n",
            "Epoch 49/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0680 - accuracy: 1.0000\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0679 - accuracy: 1.0000 - val_loss: 0.0849 - val_accuracy: 0.9949\n",
            "Epoch 50/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0675 - accuracy: 1.0000\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0675 - accuracy: 1.0000 - val_loss: 0.0861 - val_accuracy: 0.9949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/110/assets\n",
            "\n",
            "\n",
            " 56%|█████▌    | 111/200 [4:24:53<2:08:20, 86.52s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.0717 - accuracy: 0.7584\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 19ms/step - loss: 1.0651 - accuracy: 0.7609 - val_loss: 1.7913 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3746 - accuracy: 0.9555\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.3740 - accuracy: 0.9558 - val_loss: 1.6596 - val_accuracy: 0.3095\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2666 - accuracy: 0.9786\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.2657 - accuracy: 0.9788 - val_loss: 0.9909 - val_accuracy: 0.6726\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1924 - accuracy: 0.9922\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1932 - accuracy: 0.9917 - val_loss: 0.2101 - val_accuracy: 0.9923\n",
            "Epoch 5/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1664 - accuracy: 0.9949\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1664 - accuracy: 0.9949 - val_loss: 0.2560 - val_accuracy: 0.9668\n",
            "Epoch 6/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1651 - accuracy: 0.9942\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1651 - accuracy: 0.9942 - val_loss: 0.1697 - val_accuracy: 0.9923\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1258 - accuracy: 0.9994\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.1257 - accuracy: 0.9994 - val_loss: 0.1471 - val_accuracy: 0.9898\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1167 - accuracy: 1.0000\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1166 - accuracy: 1.0000 - val_loss: 0.1821 - val_accuracy: 0.9821\n",
            "Epoch 9/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1178 - accuracy: 0.9993\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.1179 - accuracy: 0.9994 - val_loss: 0.2324 - val_accuracy: 0.9719\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1073 - accuracy: 1.0000\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1073 - accuracy: 1.0000 - val_loss: 0.1411 - val_accuracy: 0.9923\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0997 - accuracy: 1.0000\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0996 - accuracy: 1.0000 - val_loss: 0.1428 - val_accuracy: 0.9847\n",
            "Epoch 12/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0950 - accuracy: 1.0000\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0950 - accuracy: 1.0000 - val_loss: 0.1211 - val_accuracy: 0.9923\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2974 - accuracy: 0.9579\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.2977 - accuracy: 0.9577 - val_loss: 0.9243 - val_accuracy: 0.8031\n",
            "Epoch 14/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2275 - accuracy: 0.9766\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.2265 - accuracy: 0.9769 - val_loss: 0.2541 - val_accuracy: 0.9744\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1704 - accuracy: 0.9896\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1701 - accuracy: 0.9897 - val_loss: 0.2115 - val_accuracy: 0.9795\n",
            "Epoch 16/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1418 - accuracy: 0.9955\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1424 - accuracy: 0.9949 - val_loss: 0.1545 - val_accuracy: 0.9872\n",
            "Epoch 17/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1699 - accuracy: 0.9897\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1695 - accuracy: 0.9897 - val_loss: 0.4348 - val_accuracy: 0.8849\n",
            "Epoch 17: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/111/assets\n",
            "\n",
            "\n",
            " 56%|█████▌    | 112/200 [4:25:53<1:55:30, 78.75s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.9558 - accuracy: 0.3848\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 12ms/step - loss: 1.9471 - accuracy: 0.3910 - val_loss: 1.7537 - val_accuracy: 0.2634\n",
            "Epoch 2/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.3313 - accuracy: 0.6882\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 1.3254 - accuracy: 0.6917 - val_loss: 1.9707 - val_accuracy: 0.3376\n",
            "Epoch 3/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.9134 - accuracy: 0.8516\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.9125 - accuracy: 0.8526 - val_loss: 1.4581 - val_accuracy: 0.5703\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6989 - accuracy: 0.9203\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.6986 - accuracy: 0.9212 - val_loss: 0.7245 - val_accuracy: 0.8977\n",
            "Epoch 5/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.5884 - accuracy: 0.9492\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.5873 - accuracy: 0.9500 - val_loss: 0.5581 - val_accuracy: 0.9514\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5149 - accuracy: 0.9683\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.5144 - accuracy: 0.9679 - val_loss: 0.4781 - val_accuracy: 0.9693\n",
            "Epoch 7/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.4420 - accuracy: 0.9798\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.4409 - accuracy: 0.9801 - val_loss: 0.4363 - val_accuracy: 0.9719\n",
            "Epoch 8/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.4053 - accuracy: 0.9804\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.4055 - accuracy: 0.9808 - val_loss: 0.3780 - val_accuracy: 0.9821\n",
            "Epoch 9/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3681 - accuracy: 0.9902\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.3673 - accuracy: 0.9897 - val_loss: 0.3338 - val_accuracy: 0.9898\n",
            "Epoch 10/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3344 - accuracy: 0.9922\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.3349 - accuracy: 0.9917 - val_loss: 0.3295 - val_accuracy: 0.9770\n",
            "Epoch 11/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.3143 - accuracy: 0.9901\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.3132 - accuracy: 0.9904 - val_loss: 0.3050 - val_accuracy: 0.9872\n",
            "Epoch 12/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2922 - accuracy: 0.9948\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.2915 - accuracy: 0.9949 - val_loss: 0.3053 - val_accuracy: 0.9821\n",
            "Epoch 13/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2756 - accuracy: 0.9929\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.2753 - accuracy: 0.9929 - val_loss: 0.2623 - val_accuracy: 0.9898\n",
            "Epoch 14/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2548 - accuracy: 0.9922\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.2547 - accuracy: 0.9923 - val_loss: 0.2544 - val_accuracy: 0.9898\n",
            "Epoch 15/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2411 - accuracy: 0.9968\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.2409 - accuracy: 0.9968 - val_loss: 0.2655 - val_accuracy: 0.9744\n",
            "Epoch 16/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2296 - accuracy: 0.9961\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.2293 - accuracy: 0.9962 - val_loss: 0.2211 - val_accuracy: 0.9923\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2185 - accuracy: 0.9948\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.2184 - accuracy: 0.9949 - val_loss: 0.2223 - val_accuracy: 0.9872\n",
            "Epoch 18/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.2053 - accuracy: 0.9967\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.2058 - accuracy: 0.9968 - val_loss: 0.2086 - val_accuracy: 0.9898\n",
            "Epoch 19/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1971 - accuracy: 0.9948\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1978 - accuracy: 0.9949 - val_loss: 0.1973 - val_accuracy: 0.9923\n",
            "Epoch 20/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1898 - accuracy: 0.9948\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1896 - accuracy: 0.9949 - val_loss: 0.1922 - val_accuracy: 0.9898\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1754 - accuracy: 0.9994\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1751 - accuracy: 0.9994 - val_loss: 0.1806 - val_accuracy: 0.9923\n",
            "Epoch 22/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1698 - accuracy: 0.9987\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1696 - accuracy: 0.9987 - val_loss: 0.1806 - val_accuracy: 0.9923\n",
            "Epoch 23/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1592 - accuracy: 0.9993\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1588 - accuracy: 0.9994 - val_loss: 0.1673 - val_accuracy: 0.9923\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1602 - accuracy: 0.9968\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1599 - accuracy: 0.9968 - val_loss: 0.1684 - val_accuracy: 0.9923\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1493 - accuracy: 0.9981\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1492 - accuracy: 0.9981 - val_loss: 0.1630 - val_accuracy: 0.9923\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1407 - accuracy: 0.9994\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1407 - accuracy: 0.9994 - val_loss: 0.1617 - val_accuracy: 0.9898\n",
            "Epoch 27/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.1371 - accuracy: 0.9987\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1367 - accuracy: 0.9987 - val_loss: 0.1458 - val_accuracy: 0.9898\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1339 - accuracy: 0.9987\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1342 - accuracy: 0.9987 - val_loss: 0.1555 - val_accuracy: 0.9898\n",
            "Epoch 29/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1290 - accuracy: 0.9980\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1290 - accuracy: 0.9981 - val_loss: 0.1400 - val_accuracy: 0.9923\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1234 - accuracy: 0.9994\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1234 - accuracy: 0.9994 - val_loss: 0.1372 - val_accuracy: 0.9923\n",
            "Epoch 31/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.1194 - accuracy: 1.0000\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1192 - accuracy: 1.0000 - val_loss: 0.1357 - val_accuracy: 0.9898\n",
            "Epoch 32/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1150 - accuracy: 1.0000\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1152 - accuracy: 1.0000 - val_loss: 0.1287 - val_accuracy: 0.9923\n",
            "Epoch 33/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1126 - accuracy: 1.0000\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1128 - accuracy: 1.0000 - val_loss: 0.1558 - val_accuracy: 0.9821\n",
            "Epoch 34/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1127 - accuracy: 0.9993\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1127 - accuracy: 0.9994 - val_loss: 0.1230 - val_accuracy: 0.9898\n",
            "Epoch 35/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1048 - accuracy: 1.0000\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1049 - accuracy: 1.0000 - val_loss: 0.1195 - val_accuracy: 0.9898\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1023 - accuracy: 1.0000\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1023 - accuracy: 1.0000 - val_loss: 0.1214 - val_accuracy: 0.9923\n",
            "Epoch 37/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1049 - accuracy: 0.9994\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1048 - accuracy: 0.9994 - val_loss: 0.1194 - val_accuracy: 0.9898\n",
            "Epoch 38/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.0976 - accuracy: 1.0000\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0981 - accuracy: 1.0000 - val_loss: 0.1118 - val_accuracy: 0.9898\n",
            "Epoch 39/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0956 - accuracy: 1.0000\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0959 - accuracy: 1.0000 - val_loss: 0.1113 - val_accuracy: 0.9923\n",
            "Epoch 40/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0935 - accuracy: 1.0000\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0934 - accuracy: 1.0000 - val_loss: 0.1126 - val_accuracy: 0.9923\n",
            "Epoch 41/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0921 - accuracy: 0.9994\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0921 - accuracy: 0.9994 - val_loss: 0.1166 - val_accuracy: 0.9898\n",
            "Epoch 42/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.0896 - accuracy: 1.0000\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0896 - accuracy: 1.0000 - val_loss: 0.1121 - val_accuracy: 0.9898\n",
            "Epoch 43/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0890 - accuracy: 0.9987\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0891 - accuracy: 0.9987 - val_loss: 0.1118 - val_accuracy: 0.9923\n",
            "Epoch 44/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0857 - accuracy: 1.0000\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0856 - accuracy: 1.0000 - val_loss: 0.1044 - val_accuracy: 0.9898\n",
            "Epoch 45/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0823 - accuracy: 1.0000\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0823 - accuracy: 1.0000 - val_loss: 0.0996 - val_accuracy: 0.9923\n",
            "Epoch 46/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0818 - accuracy: 1.0000\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0817 - accuracy: 1.0000 - val_loss: 0.1062 - val_accuracy: 0.9898\n",
            "Epoch 47/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0809 - accuracy: 1.0000\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0808 - accuracy: 1.0000 - val_loss: 0.1034 - val_accuracy: 0.9898\n",
            "Epoch 48/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0772 - accuracy: 1.0000\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0772 - accuracy: 1.0000 - val_loss: 0.0990 - val_accuracy: 0.9923\n",
            "Epoch 49/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0839 - accuracy: 0.9974\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0839 - accuracy: 0.9974 - val_loss: 0.0926 - val_accuracy: 0.9949\n",
            "Epoch 50/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0748 - accuracy: 1.0000\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0748 - accuracy: 1.0000 - val_loss: 0.0937 - val_accuracy: 0.9923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/112/assets\n",
            "\n",
            "\n",
            " 56%|█████▋    | 113/200 [4:27:38<2:05:28, 86.54s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 2.5443 - accuracy: 0.3692\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 8s 31ms/step - loss: 2.5443 - accuracy: 0.3692 - val_loss: 1.9160 - val_accuracy: 0.2941\n",
            "Epoch 2/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 2.0765 - accuracy: 0.5365\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 2.0765 - accuracy: 0.5365 - val_loss: 1.9154 - val_accuracy: 0.3657\n",
            "Epoch 3/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.8313 - accuracy: 0.6508\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 1.8306 - accuracy: 0.6513 - val_loss: 1.7505 - val_accuracy: 0.4910\n",
            "Epoch 4/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6540 - accuracy: 0.7179\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 1.6540 - accuracy: 0.7179 - val_loss: 1.5049 - val_accuracy: 0.7494\n",
            "Epoch 5/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.5093 - accuracy: 0.7590\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 1.5093 - accuracy: 0.7590 - val_loss: 1.3742 - val_accuracy: 0.7980\n",
            "Epoch 6/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.3856 - accuracy: 0.7968\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 1.3856 - accuracy: 0.7968 - val_loss: 1.2566 - val_accuracy: 0.8465\n",
            "Epoch 7/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.2667 - accuracy: 0.8428\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 1.2669 - accuracy: 0.8417 - val_loss: 1.1588 - val_accuracy: 0.8747\n",
            "Epoch 8/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.1725 - accuracy: 0.8737\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 1.1725 - accuracy: 0.8737 - val_loss: 1.0744 - val_accuracy: 0.9079\n",
            "Epoch 9/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.0921 - accuracy: 0.9013\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 1.0921 - accuracy: 0.9013 - val_loss: 1.0030 - val_accuracy: 0.9182\n",
            "Epoch 10/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.0249 - accuracy: 0.9154\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 1.0249 - accuracy: 0.9154 - val_loss: 0.9462 - val_accuracy: 0.9386\n",
            "Epoch 11/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.9755 - accuracy: 0.9256\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.9755 - accuracy: 0.9256 - val_loss: 0.9007 - val_accuracy: 0.9514\n",
            "Epoch 12/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.9170 - accuracy: 0.9462\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.9170 - accuracy: 0.9462 - val_loss: 0.8562 - val_accuracy: 0.9616\n",
            "Epoch 13/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.8732 - accuracy: 0.9519\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.8732 - accuracy: 0.9519 - val_loss: 0.8187 - val_accuracy: 0.9642\n",
            "Epoch 14/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.8386 - accuracy: 0.9615\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.8386 - accuracy: 0.9615 - val_loss: 0.7874 - val_accuracy: 0.9770\n",
            "Epoch 15/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.7999 - accuracy: 0.9692\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.7999 - accuracy: 0.9692 - val_loss: 0.7569 - val_accuracy: 0.9744\n",
            "Epoch 16/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.7719 - accuracy: 0.9705\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.7719 - accuracy: 0.9705 - val_loss: 0.7307 - val_accuracy: 0.9821\n",
            "Epoch 17/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.7429 - accuracy: 0.9769\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.7429 - accuracy: 0.9769 - val_loss: 0.7023 - val_accuracy: 0.9821\n",
            "Epoch 18/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.7214 - accuracy: 0.9756\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.7214 - accuracy: 0.9756 - val_loss: 0.6776 - val_accuracy: 0.9847\n",
            "Epoch 19/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6970 - accuracy: 0.9795\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.6970 - accuracy: 0.9795 - val_loss: 0.6659 - val_accuracy: 0.9872\n",
            "Epoch 20/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.6721 - accuracy: 0.9813\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.6722 - accuracy: 0.9814 - val_loss: 0.6420 - val_accuracy: 0.9847\n",
            "Epoch 21/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6544 - accuracy: 0.9885\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.6544 - accuracy: 0.9885 - val_loss: 0.6210 - val_accuracy: 0.9847\n",
            "Epoch 22/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6373 - accuracy: 0.9827\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.6373 - accuracy: 0.9827 - val_loss: 0.6049 - val_accuracy: 0.9872\n",
            "Epoch 23/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.6238 - accuracy: 0.9871\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.6230 - accuracy: 0.9872 - val_loss: 0.5913 - val_accuracy: 0.9872\n",
            "Epoch 24/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5999 - accuracy: 0.9923\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.5999 - accuracy: 0.9923 - val_loss: 0.5868 - val_accuracy: 0.9872\n",
            "Epoch 25/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.5905 - accuracy: 0.9871\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.5904 - accuracy: 0.9872 - val_loss: 0.5625 - val_accuracy: 0.9872\n",
            "Epoch 26/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5727 - accuracy: 0.9878\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.5727 - accuracy: 0.9878 - val_loss: 0.5552 - val_accuracy: 0.9923\n",
            "Epoch 27/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5659 - accuracy: 0.9853\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.5659 - accuracy: 0.9853 - val_loss: 0.5428 - val_accuracy: 0.9847\n",
            "Epoch 28/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5500 - accuracy: 0.9910\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.5500 - accuracy: 0.9910 - val_loss: 0.5307 - val_accuracy: 0.9872\n",
            "Epoch 29/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5341 - accuracy: 0.9936\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.5341 - accuracy: 0.9936 - val_loss: 0.5239 - val_accuracy: 0.9872\n",
            "Epoch 30/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5243 - accuracy: 0.9910\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.5243 - accuracy: 0.9910 - val_loss: 0.5114 - val_accuracy: 0.9898\n",
            "Epoch 31/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.5158 - accuracy: 0.9916\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.5165 - accuracy: 0.9910 - val_loss: 0.5014 - val_accuracy: 0.9949\n",
            "Epoch 32/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5054 - accuracy: 0.9942\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.5054 - accuracy: 0.9942 - val_loss: 0.4937 - val_accuracy: 0.9898\n",
            "Epoch 33/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4947 - accuracy: 0.9936\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.4947 - accuracy: 0.9936 - val_loss: 0.4863 - val_accuracy: 0.9923\n",
            "Epoch 34/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4884 - accuracy: 0.9942\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.4884 - accuracy: 0.9942 - val_loss: 0.4776 - val_accuracy: 0.9898\n",
            "Epoch 35/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4730 - accuracy: 0.9961\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.4727 - accuracy: 0.9962 - val_loss: 0.4661 - val_accuracy: 0.9923\n",
            "Epoch 36/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4701 - accuracy: 0.9916\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.4700 - accuracy: 0.9917 - val_loss: 0.4586 - val_accuracy: 0.9898\n",
            "Epoch 37/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4598 - accuracy: 0.9917\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.4598 - accuracy: 0.9917 - val_loss: 0.4498 - val_accuracy: 0.9949\n",
            "Epoch 38/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4491 - accuracy: 0.9949\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.4491 - accuracy: 0.9949 - val_loss: 0.4478 - val_accuracy: 0.9923\n",
            "Epoch 39/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4450 - accuracy: 0.9917\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.4450 - accuracy: 0.9917 - val_loss: 0.4370 - val_accuracy: 0.9949\n",
            "Epoch 40/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4348 - accuracy: 0.9974\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.4348 - accuracy: 0.9974 - val_loss: 0.4305 - val_accuracy: 0.9923\n",
            "Epoch 41/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4266 - accuracy: 0.9942\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.4266 - accuracy: 0.9942 - val_loss: 0.4219 - val_accuracy: 0.9949\n",
            "Epoch 42/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4231 - accuracy: 0.9942\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.4229 - accuracy: 0.9942 - val_loss: 0.4159 - val_accuracy: 0.9949\n",
            "Epoch 43/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4150 - accuracy: 0.9968\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.4155 - accuracy: 0.9962 - val_loss: 0.4175 - val_accuracy: 0.9898\n",
            "Epoch 44/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4096 - accuracy: 0.9948\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.4093 - accuracy: 0.9949 - val_loss: 0.4087 - val_accuracy: 0.9923\n",
            "Epoch 45/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4021 - accuracy: 0.9968\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.4021 - accuracy: 0.9968 - val_loss: 0.4023 - val_accuracy: 0.9923\n",
            "Epoch 46/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3950 - accuracy: 0.9981\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.3950 - accuracy: 0.9981 - val_loss: 0.4049 - val_accuracy: 0.9872\n",
            "Epoch 47/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3918 - accuracy: 0.9962\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.3918 - accuracy: 0.9962 - val_loss: 0.3896 - val_accuracy: 0.9923\n",
            "Epoch 48/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3850 - accuracy: 0.9987\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.3850 - accuracy: 0.9987 - val_loss: 0.3851 - val_accuracy: 0.9923\n",
            "Epoch 49/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3767 - accuracy: 0.9961\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.3767 - accuracy: 0.9962 - val_loss: 0.3814 - val_accuracy: 0.9923\n",
            "Epoch 50/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3763 - accuracy: 0.9968\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.3763 - accuracy: 0.9968 - val_loss: 0.3758 - val_accuracy: 0.9923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/113/assets\n",
            "\n",
            "\n",
            " 57%|█████▋    | 114/200 [4:33:05<3:47:31, 158.74s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.7047 - accuracy: 0.3691\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 13ms/step - loss: 1.7030 - accuracy: 0.3679 - val_loss: 1.7145 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.4517 - accuracy: 0.4462\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.4516 - accuracy: 0.4474 - val_loss: 1.6072 - val_accuracy: 0.2992\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.1219 - accuracy: 0.6088\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 1.1164 - accuracy: 0.6090 - val_loss: 0.6956 - val_accuracy: 0.7775\n",
            "Epoch 4/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.8687 - accuracy: 0.7168\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.8686 - accuracy: 0.7160 - val_loss: 0.9026 - val_accuracy: 0.7187\n",
            "Epoch 5/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6051 - accuracy: 0.8147\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.6051 - accuracy: 0.8147 - val_loss: 0.6009 - val_accuracy: 0.8286\n",
            "Epoch 6/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.4155 - accuracy: 0.8867\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.4196 - accuracy: 0.8859 - val_loss: 0.5319 - val_accuracy: 0.8414\n",
            "Epoch 7/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.4173 - accuracy: 0.8848\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.4180 - accuracy: 0.8846 - val_loss: 0.5294 - val_accuracy: 0.8363\n",
            "Epoch 8/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3470 - accuracy: 0.9019\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.3470 - accuracy: 0.9019 - val_loss: 0.8098 - val_accuracy: 0.7621\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3706 - accuracy: 0.9080\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.3732 - accuracy: 0.9071 - val_loss: 0.8413 - val_accuracy: 0.7673\n",
            "Epoch 10/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2748 - accuracy: 0.9250\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.2748 - accuracy: 0.9250 - val_loss: 0.5920 - val_accuracy: 0.8210\n",
            "Epoch 11/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2505 - accuracy: 0.9282\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.2505 - accuracy: 0.9282 - val_loss: 0.5100 - val_accuracy: 0.8619\n",
            "Epoch 12/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2347 - accuracy: 0.9365\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.2347 - accuracy: 0.9365 - val_loss: 0.3934 - val_accuracy: 0.8951\n",
            "Epoch 13/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2199 - accuracy: 0.9442\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.2199 - accuracy: 0.9442 - val_loss: 0.6643 - val_accuracy: 0.8363\n",
            "Epoch 14/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2759 - accuracy: 0.9276\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.2759 - accuracy: 0.9276 - val_loss: 0.5489 - val_accuracy: 0.8082\n",
            "Epoch 15/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 0.2335 - accuracy: 0.9438\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.2418 - accuracy: 0.9404 - val_loss: 0.6250 - val_accuracy: 0.7928\n",
            "Epoch 16/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2192 - accuracy: 0.9500\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.2192 - accuracy: 0.9500 - val_loss: 0.7326 - val_accuracy: 0.8696\n",
            "Epoch 17/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 0.2296 - accuracy: 0.9431\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.2299 - accuracy: 0.9436 - val_loss: 0.7248 - val_accuracy: 0.7724\n",
            "Epoch 17: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/114/assets\n",
            "\n",
            "\n",
            " 57%|█████▊    | 115/200 [4:33:40<2:52:20, 121.65s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.8455 - accuracy: 0.4051\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 13ms/step - loss: 1.8455 - accuracy: 0.4051 - val_loss: 1.7203 - val_accuracy: 0.3427\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.2444 - accuracy: 0.6859\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 1.2423 - accuracy: 0.6872 - val_loss: 1.9507 - val_accuracy: 0.5038\n",
            "Epoch 3/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.8699 - accuracy: 0.8203\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.8683 - accuracy: 0.8212 - val_loss: 1.6682 - val_accuracy: 0.5217\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6674 - accuracy: 0.9087\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.6650 - accuracy: 0.9096 - val_loss: 0.6067 - val_accuracy: 0.8721\n",
            "Epoch 5/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.5379 - accuracy: 0.9362\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.5358 - accuracy: 0.9372 - val_loss: 0.5229 - val_accuracy: 0.9130\n",
            "Epoch 6/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.4707 - accuracy: 0.9548\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.4695 - accuracy: 0.9551 - val_loss: 0.4351 - val_accuracy: 0.9616\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3984 - accuracy: 0.9722\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.3971 - accuracy: 0.9724 - val_loss: 0.4014 - val_accuracy: 0.9668\n",
            "Epoch 8/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3492 - accuracy: 0.9807\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.3490 - accuracy: 0.9808 - val_loss: 0.3415 - val_accuracy: 0.9821\n",
            "Epoch 9/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.3218 - accuracy: 0.9829\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.3215 - accuracy: 0.9827 - val_loss: 0.3138 - val_accuracy: 0.9795\n",
            "Epoch 10/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2791 - accuracy: 0.9897\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.2794 - accuracy: 0.9897 - val_loss: 0.2955 - val_accuracy: 0.9821\n",
            "Epoch 11/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2601 - accuracy: 0.9936\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.2601 - accuracy: 0.9936 - val_loss: 0.2729 - val_accuracy: 0.9847\n",
            "Epoch 12/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2366 - accuracy: 0.9935\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.2367 - accuracy: 0.9936 - val_loss: 0.2528 - val_accuracy: 0.9872\n",
            "Epoch 13/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.2223 - accuracy: 0.9961\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.2232 - accuracy: 0.9955 - val_loss: 0.2337 - val_accuracy: 0.9847\n",
            "Epoch 14/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.2051 - accuracy: 0.9967\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.2071 - accuracy: 0.9968 - val_loss: 0.2406 - val_accuracy: 0.9821\n",
            "Epoch 15/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1918 - accuracy: 0.9954\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.1916 - accuracy: 0.9955 - val_loss: 0.2021 - val_accuracy: 0.9898\n",
            "Epoch 16/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1775 - accuracy: 0.9980\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.1770 - accuracy: 0.9981 - val_loss: 0.1968 - val_accuracy: 0.9872\n",
            "Epoch 17/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1641 - accuracy: 0.9980\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.1642 - accuracy: 0.9981 - val_loss: 0.1854 - val_accuracy: 0.9898\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1594 - accuracy: 0.9961\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.1590 - accuracy: 0.9962 - val_loss: 0.1783 - val_accuracy: 0.9898\n",
            "Epoch 19/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1486 - accuracy: 0.9987\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.1488 - accuracy: 0.9987 - val_loss: 0.1607 - val_accuracy: 0.9949\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1377 - accuracy: 0.9987\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.1376 - accuracy: 0.9987 - val_loss: 0.1559 - val_accuracy: 0.9898\n",
            "Epoch 21/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1309 - accuracy: 0.9987\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.1308 - accuracy: 0.9987 - val_loss: 0.1581 - val_accuracy: 0.9872\n",
            "Epoch 22/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.1241 - accuracy: 0.9993\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.1241 - accuracy: 0.9994 - val_loss: 0.1499 - val_accuracy: 0.9898\n",
            "Epoch 23/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1182 - accuracy: 0.9987\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.1183 - accuracy: 0.9987 - val_loss: 0.1464 - val_accuracy: 0.9872\n",
            "Epoch 24/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1157 - accuracy: 0.9987\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.1154 - accuracy: 0.9987 - val_loss: 0.1363 - val_accuracy: 0.9898\n",
            "Epoch 25/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1092 - accuracy: 0.9980\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.1090 - accuracy: 0.9981 - val_loss: 0.1263 - val_accuracy: 0.9898\n",
            "Epoch 26/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1029 - accuracy: 0.9987\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.1029 - accuracy: 0.9987 - val_loss: 0.1411 - val_accuracy: 0.9821\n",
            "Epoch 27/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1006 - accuracy: 0.9987\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.1004 - accuracy: 0.9987 - val_loss: 0.1257 - val_accuracy: 0.9898\n",
            "Epoch 28/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0984 - accuracy: 0.9980\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0984 - accuracy: 0.9981 - val_loss: 0.1385 - val_accuracy: 0.9847\n",
            "Epoch 29/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0944 - accuracy: 0.9987\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0944 - accuracy: 0.9987 - val_loss: 0.1227 - val_accuracy: 0.9898\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0889 - accuracy: 0.9994\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0890 - accuracy: 0.9994 - val_loss: 0.1156 - val_accuracy: 0.9898\n",
            "Epoch 31/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0839 - accuracy: 1.0000\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0840 - accuracy: 1.0000 - val_loss: 0.1098 - val_accuracy: 0.9923\n",
            "Epoch 32/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0835 - accuracy: 1.0000\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0834 - accuracy: 1.0000 - val_loss: 0.1223 - val_accuracy: 0.9898\n",
            "Epoch 33/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0809 - accuracy: 1.0000\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0809 - accuracy: 1.0000 - val_loss: 0.1057 - val_accuracy: 0.9898\n",
            "Epoch 34/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0794 - accuracy: 0.9994\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0794 - accuracy: 0.9994 - val_loss: 0.1195 - val_accuracy: 0.9898\n",
            "Epoch 35/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0952 - accuracy: 0.9949\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0952 - accuracy: 0.9949 - val_loss: 0.1061 - val_accuracy: 0.9923\n",
            "Epoch 36/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0768 - accuracy: 1.0000\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0768 - accuracy: 1.0000 - val_loss: 0.1031 - val_accuracy: 0.9923\n",
            "Epoch 37/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0721 - accuracy: 0.9993\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0720 - accuracy: 0.9994 - val_loss: 0.1020 - val_accuracy: 0.9923\n",
            "Epoch 38/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0701 - accuracy: 0.9993\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0701 - accuracy: 0.9994 - val_loss: 0.0984 - val_accuracy: 0.9923\n",
            "Epoch 39/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0702 - accuracy: 0.9993\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0702 - accuracy: 0.9994 - val_loss: 0.1016 - val_accuracy: 0.9923\n",
            "Epoch 40/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0677 - accuracy: 1.0000\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0676 - accuracy: 1.0000 - val_loss: 0.0971 - val_accuracy: 0.9923\n",
            "Epoch 41/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0648 - accuracy: 1.0000\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0647 - accuracy: 1.0000 - val_loss: 0.0891 - val_accuracy: 0.9898\n",
            "Epoch 42/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0642 - accuracy: 1.0000\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0642 - accuracy: 1.0000 - val_loss: 0.0873 - val_accuracy: 0.9898\n",
            "Epoch 43/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0635 - accuracy: 1.0000\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0634 - accuracy: 1.0000 - val_loss: 0.0904 - val_accuracy: 0.9898\n",
            "Epoch 44/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0612 - accuracy: 1.0000\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0612 - accuracy: 1.0000 - val_loss: 0.0877 - val_accuracy: 0.9898\n",
            "Epoch 45/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0620 - accuracy: 1.0000\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0620 - accuracy: 1.0000 - val_loss: 0.0889 - val_accuracy: 0.9872\n",
            "Epoch 46/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0578 - accuracy: 1.0000\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0577 - accuracy: 1.0000 - val_loss: 0.0841 - val_accuracy: 0.9949\n",
            "Epoch 47/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0577 - accuracy: 1.0000\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0577 - accuracy: 1.0000 - val_loss: 0.0870 - val_accuracy: 0.9872\n",
            "Epoch 48/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0563 - accuracy: 1.0000\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0563 - accuracy: 1.0000 - val_loss: 0.0860 - val_accuracy: 0.9949\n",
            "Epoch 49/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0563 - accuracy: 1.0000\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0563 - accuracy: 1.0000 - val_loss: 0.0801 - val_accuracy: 0.9949\n",
            "Epoch 50/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0541 - accuracy: 1.0000\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0541 - accuracy: 1.0000 - val_loss: 0.0816 - val_accuracy: 0.9872\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/115/assets\n",
            "\n",
            "\n",
            " 58%|█████▊    | 116/200 [4:36:08<3:01:01, 129.30s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.0584 - accuracy: 0.7428\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 16ms/step - loss: 1.0459 - accuracy: 0.7462 - val_loss: 1.7966 - val_accuracy: 0.4450\n",
            "Epoch 2/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2966 - accuracy: 0.9603\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.2966 - accuracy: 0.9603 - val_loss: 1.5049 - val_accuracy: 0.3274\n",
            "Epoch 3/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1616 - accuracy: 0.9890\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1616 - accuracy: 0.9891 - val_loss: 0.5744 - val_accuracy: 0.9105\n",
            "Epoch 4/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1125 - accuracy: 0.9987\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.1120 - accuracy: 0.9987 - val_loss: 0.1362 - val_accuracy: 0.9898\n",
            "Epoch 5/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0938 - accuracy: 0.9981\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0938 - accuracy: 0.9981 - val_loss: 0.1255 - val_accuracy: 0.9872\n",
            "Epoch 6/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0806 - accuracy: 1.0000\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0804 - accuracy: 1.0000 - val_loss: 0.1269 - val_accuracy: 0.9923\n",
            "Epoch 7/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3537 - accuracy: 0.9551\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.3537 - accuracy: 0.9551 - val_loss: 0.1346 - val_accuracy: 0.9923\n",
            "Epoch 8/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0992 - accuracy: 0.9968\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0992 - accuracy: 0.9968 - val_loss: 0.1171 - val_accuracy: 0.9949\n",
            "Epoch 9/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0802 - accuracy: 1.0000\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0801 - accuracy: 1.0000 - val_loss: 0.1396 - val_accuracy: 0.9898\n",
            "Epoch 10/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0794 - accuracy: 0.9993\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0790 - accuracy: 0.9994 - val_loss: 0.0819 - val_accuracy: 0.9923\n",
            "Epoch 11/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0621 - accuracy: 1.0000\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0621 - accuracy: 1.0000 - val_loss: 0.0902 - val_accuracy: 0.9898\n",
            "Epoch 12/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0585 - accuracy: 0.9994\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0585 - accuracy: 0.9994 - val_loss: 0.0972 - val_accuracy: 0.9923\n",
            "Epoch 13/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0722 - accuracy: 0.9968\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0722 - accuracy: 0.9968 - val_loss: 0.6796 - val_accuracy: 0.8645\n",
            "Epoch 14/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1572 - accuracy: 0.9777\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1556 - accuracy: 0.9782 - val_loss: 0.1722 - val_accuracy: 0.9719\n",
            "Epoch 15/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1066 - accuracy: 0.9910\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1066 - accuracy: 0.9910 - val_loss: 0.0862 - val_accuracy: 0.9949\n",
            "Epoch 15: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/116/assets\n",
            "\n",
            "\n",
            " 58%|█████▊    | 117/200 [4:36:54<2:24:21, 104.35s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.5087 - accuracy: 0.5361\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 21ms/step - loss: 1.5056 - accuracy: 0.5372 - val_loss: 1.7647 - val_accuracy: 0.2660\n",
            "Epoch 2/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.6885 - accuracy: 0.8866\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.6870 - accuracy: 0.8872 - val_loss: 1.5433 - val_accuracy: 0.3427\n",
            "Epoch 3/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4139 - accuracy: 0.9564\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.4139 - accuracy: 0.9564 - val_loss: 0.6098 - val_accuracy: 0.9284\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3116 - accuracy: 0.9851\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.3103 - accuracy: 0.9853 - val_loss: 0.2822 - val_accuracy: 0.9923\n",
            "Epoch 5/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2538 - accuracy: 0.9916\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.2534 - accuracy: 0.9917 - val_loss: 0.2458 - val_accuracy: 0.9949\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2241 - accuracy: 0.9935\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.2236 - accuracy: 0.9936 - val_loss: 0.2284 - val_accuracy: 0.9872\n",
            "Epoch 7/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1953 - accuracy: 0.9974\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1953 - accuracy: 0.9974 - val_loss: 0.1900 - val_accuracy: 0.9974\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1756 - accuracy: 0.9961\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1753 - accuracy: 0.9962 - val_loss: 0.1836 - val_accuracy: 0.9949\n",
            "Epoch 9/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1629 - accuracy: 0.9949\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1629 - accuracy: 0.9949 - val_loss: 0.1784 - val_accuracy: 0.9898\n",
            "Epoch 10/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1443 - accuracy: 0.9974\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1443 - accuracy: 0.9974 - val_loss: 0.1636 - val_accuracy: 0.9898\n",
            "Epoch 11/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1386 - accuracy: 0.9974\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1385 - accuracy: 0.9974 - val_loss: 0.1499 - val_accuracy: 0.9923\n",
            "Epoch 12/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1238 - accuracy: 0.9993\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1236 - accuracy: 0.9994 - val_loss: 0.1509 - val_accuracy: 0.9949\n",
            "Epoch 13/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1171 - accuracy: 0.9981\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1180 - accuracy: 0.9974 - val_loss: 0.1224 - val_accuracy: 0.9949\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1157 - accuracy: 0.9974\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1156 - accuracy: 0.9974 - val_loss: 0.1205 - val_accuracy: 0.9949\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1054 - accuracy: 0.9994\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1054 - accuracy: 0.9994 - val_loss: 0.1159 - val_accuracy: 0.9949\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0972 - accuracy: 0.9994\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0971 - accuracy: 0.9994 - val_loss: 0.1200 - val_accuracy: 0.9949\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0916 - accuracy: 0.9994\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0917 - accuracy: 0.9994 - val_loss: 0.1173 - val_accuracy: 0.9949\n",
            "Epoch 18/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0967 - accuracy: 0.9981\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0967 - accuracy: 0.9981 - val_loss: 0.1266 - val_accuracy: 0.9872\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0852 - accuracy: 0.9994\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0851 - accuracy: 0.9994 - val_loss: 0.1010 - val_accuracy: 0.9949\n",
            "Epoch 20/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0812 - accuracy: 1.0000\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0811 - accuracy: 1.0000 - val_loss: 0.0907 - val_accuracy: 0.9949\n",
            "Epoch 21/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0793 - accuracy: 0.9987\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0792 - accuracy: 0.9987 - val_loss: 0.1353 - val_accuracy: 0.9898\n",
            "Epoch 22/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0779 - accuracy: 0.9987\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0779 - accuracy: 0.9987 - val_loss: 0.0973 - val_accuracy: 0.9923\n",
            "Epoch 23/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0721 - accuracy: 1.0000\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.0721 - accuracy: 1.0000 - val_loss: 0.0900 - val_accuracy: 0.9923\n",
            "Epoch 24/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0868 - accuracy: 0.9962\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0868 - accuracy: 0.9962 - val_loss: 0.0978 - val_accuracy: 0.9949\n",
            "Epoch 25/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0744 - accuracy: 0.9994\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0745 - accuracy: 0.9994 - val_loss: 0.0842 - val_accuracy: 0.9949\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0653 - accuracy: 1.0000\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0652 - accuracy: 1.0000 - val_loss: 0.0794 - val_accuracy: 0.9949\n",
            "Epoch 27/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0629 - accuracy: 1.0000\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0630 - accuracy: 1.0000 - val_loss: 0.0776 - val_accuracy: 0.9949\n",
            "Epoch 28/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0625 - accuracy: 1.0000\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0625 - accuracy: 1.0000 - val_loss: 0.0780 - val_accuracy: 0.9949\n",
            "Epoch 29/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0607 - accuracy: 0.9994\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0607 - accuracy: 0.9994 - val_loss: 0.1030 - val_accuracy: 0.9898\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0601 - accuracy: 0.9994\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0600 - accuracy: 0.9994 - val_loss: 0.0828 - val_accuracy: 0.9923\n",
            "Epoch 31/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0596 - accuracy: 1.0000\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0596 - accuracy: 1.0000 - val_loss: 0.1086 - val_accuracy: 0.9821\n",
            "Epoch 32/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0574 - accuracy: 1.0000\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0574 - accuracy: 1.0000 - val_loss: 0.0735 - val_accuracy: 0.9949\n",
            "Epoch 33/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0550 - accuracy: 1.0000\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0551 - accuracy: 1.0000 - val_loss: 0.0714 - val_accuracy: 0.9974\n",
            "Epoch 34/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0575 - accuracy: 0.9987\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0574 - accuracy: 0.9987 - val_loss: 0.0740 - val_accuracy: 0.9923\n",
            "Epoch 35/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0522 - accuracy: 1.0000\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0522 - accuracy: 1.0000 - val_loss: 0.0691 - val_accuracy: 0.9923\n",
            "Epoch 36/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0499 - accuracy: 1.0000\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0499 - accuracy: 1.0000 - val_loss: 0.0695 - val_accuracy: 0.9949\n",
            "Epoch 37/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0493 - accuracy: 1.0000\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0493 - accuracy: 1.0000 - val_loss: 0.0803 - val_accuracy: 0.9898\n",
            "Epoch 38/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0547 - accuracy: 1.0000\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0547 - accuracy: 1.0000 - val_loss: 0.1340 - val_accuracy: 0.9847\n",
            "Epoch 39/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0912 - accuracy: 0.9897\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0911 - accuracy: 0.9897 - val_loss: 0.0985 - val_accuracy: 0.9923\n",
            "Epoch 40/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0585 - accuracy: 1.0000\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0585 - accuracy: 1.0000 - val_loss: 0.0752 - val_accuracy: 0.9923\n",
            "Epoch 40: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/117/assets\n",
            "\n",
            "\n",
            " 59%|█████▉    | 118/200 [4:40:21<3:04:45, 135.19s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.9003 - accuracy: 0.2630\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 22ms/step - loss: 1.9009 - accuracy: 0.2622 - val_loss: 1.7735 - val_accuracy: 0.2634\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.7329 - accuracy: 0.3679\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.7312 - accuracy: 0.3705 - val_loss: 1.7458 - val_accuracy: 0.3504\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.5877 - accuracy: 0.5227\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.5857 - accuracy: 0.5244 - val_loss: 1.6109 - val_accuracy: 0.5013\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.4346 - accuracy: 0.5991\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.4336 - accuracy: 0.6000 - val_loss: 1.3633 - val_accuracy: 0.6547\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.2843 - accuracy: 0.6982\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.2823 - accuracy: 0.6987 - val_loss: 1.1987 - val_accuracy: 0.7340\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.1115 - accuracy: 0.7714\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 1.1092 - accuracy: 0.7718 - val_loss: 1.0388 - val_accuracy: 0.8133\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.9657 - accuracy: 0.8128\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.9641 - accuracy: 0.8141 - val_loss: 0.8930 - val_accuracy: 0.8542\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8364 - accuracy: 0.8633\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.8361 - accuracy: 0.8635 - val_loss: 0.7825 - val_accuracy: 0.8926\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7454 - accuracy: 0.8905\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.7435 - accuracy: 0.8910 - val_loss: 0.6840 - val_accuracy: 0.9309\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6675 - accuracy: 0.9177\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.6666 - accuracy: 0.9186 - val_loss: 0.6247 - val_accuracy: 0.9488\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5978 - accuracy: 0.9365\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.5983 - accuracy: 0.9365 - val_loss: 0.5633 - val_accuracy: 0.9591\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5478 - accuracy: 0.9475\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.5460 - accuracy: 0.9481 - val_loss: 0.5204 - val_accuracy: 0.9668\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4991 - accuracy: 0.9611\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.4996 - accuracy: 0.9603 - val_loss: 0.4802 - val_accuracy: 0.9744\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4751 - accuracy: 0.9644\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.4744 - accuracy: 0.9647 - val_loss: 0.4470 - val_accuracy: 0.9770\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4398 - accuracy: 0.9689\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.4405 - accuracy: 0.9686 - val_loss: 0.4277 - val_accuracy: 0.9821\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4176 - accuracy: 0.9832\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.4168 - accuracy: 0.9833 - val_loss: 0.3991 - val_accuracy: 0.9795\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3957 - accuracy: 0.9806\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.3951 - accuracy: 0.9808 - val_loss: 0.3799 - val_accuracy: 0.9872\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3724 - accuracy: 0.9851\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.3714 - accuracy: 0.9853 - val_loss: 0.3615 - val_accuracy: 0.9847\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3538 - accuracy: 0.9883\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.3530 - accuracy: 0.9885 - val_loss: 0.3470 - val_accuracy: 0.9898\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3422 - accuracy: 0.9851\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.3417 - accuracy: 0.9853 - val_loss: 0.3322 - val_accuracy: 0.9923\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3296 - accuracy: 0.9890\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.3303 - accuracy: 0.9891 - val_loss: 0.3214 - val_accuracy: 0.9923\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3165 - accuracy: 0.9903\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.3165 - accuracy: 0.9904 - val_loss: 0.3177 - val_accuracy: 0.9923\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3042 - accuracy: 0.9922\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.3040 - accuracy: 0.9923 - val_loss: 0.2962 - val_accuracy: 0.9923\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2941 - accuracy: 0.9916\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.2933 - accuracy: 0.9917 - val_loss: 0.2960 - val_accuracy: 0.9923\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2819 - accuracy: 0.9942\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.2822 - accuracy: 0.9942 - val_loss: 0.2801 - val_accuracy: 0.9923\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2664 - accuracy: 0.9948\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.2665 - accuracy: 0.9949 - val_loss: 0.2684 - val_accuracy: 0.9949\n",
            "Epoch 27/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2658 - accuracy: 0.9890\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.2660 - accuracy: 0.9891 - val_loss: 0.2629 - val_accuracy: 0.9949\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2543 - accuracy: 0.9942\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2546 - accuracy: 0.9942 - val_loss: 0.2544 - val_accuracy: 0.9949\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2469 - accuracy: 0.9968\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.2464 - accuracy: 0.9968 - val_loss: 0.2530 - val_accuracy: 0.9923\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2386 - accuracy: 0.9948\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2382 - accuracy: 0.9949 - val_loss: 0.2423 - val_accuracy: 0.9949\n",
            "Epoch 31/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2309 - accuracy: 0.9955\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.2306 - accuracy: 0.9955 - val_loss: 0.2359 - val_accuracy: 0.9949\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2251 - accuracy: 0.9968\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2249 - accuracy: 0.9968 - val_loss: 0.2283 - val_accuracy: 0.9949\n",
            "Epoch 33/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2189 - accuracy: 0.9961\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.2190 - accuracy: 0.9962 - val_loss: 0.2262 - val_accuracy: 0.9949\n",
            "Epoch 34/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2119 - accuracy: 0.9981\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2119 - accuracy: 0.9981 - val_loss: 0.2198 - val_accuracy: 0.9949\n",
            "Epoch 35/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2079 - accuracy: 0.9948\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.2078 - accuracy: 0.9949 - val_loss: 0.2133 - val_accuracy: 0.9949\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2022 - accuracy: 0.9968\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.2025 - accuracy: 0.9968 - val_loss: 0.2079 - val_accuracy: 0.9949\n",
            "Epoch 37/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1994 - accuracy: 0.9955\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1995 - accuracy: 0.9955 - val_loss: 0.2162 - val_accuracy: 0.9923\n",
            "Epoch 38/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1904 - accuracy: 0.9981\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1905 - accuracy: 0.9981 - val_loss: 0.2053 - val_accuracy: 0.9949\n",
            "Epoch 39/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1887 - accuracy: 0.9955\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1884 - accuracy: 0.9955 - val_loss: 0.1963 - val_accuracy: 0.9949\n",
            "Epoch 40/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1832 - accuracy: 0.9987\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1834 - accuracy: 0.9987 - val_loss: 0.1928 - val_accuracy: 0.9949\n",
            "Epoch 41/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1808 - accuracy: 0.9987\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1805 - accuracy: 0.9987 - val_loss: 0.1902 - val_accuracy: 0.9949\n",
            "Epoch 42/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1736 - accuracy: 1.0000\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1734 - accuracy: 1.0000 - val_loss: 0.1836 - val_accuracy: 0.9949\n",
            "Epoch 43/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1731 - accuracy: 0.9974\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1729 - accuracy: 0.9974 - val_loss: 0.1816 - val_accuracy: 0.9949\n",
            "Epoch 44/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1731 - accuracy: 0.9961\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1729 - accuracy: 0.9962 - val_loss: 0.1804 - val_accuracy: 0.9949\n",
            "Epoch 45/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1658 - accuracy: 0.9981\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1656 - accuracy: 0.9981 - val_loss: 0.1754 - val_accuracy: 0.9949\n",
            "Epoch 46/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1605 - accuracy: 0.9994\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1605 - accuracy: 0.9994 - val_loss: 0.1736 - val_accuracy: 0.9949\n",
            "Epoch 47/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1580 - accuracy: 0.9981\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1578 - accuracy: 0.9981 - val_loss: 0.1698 - val_accuracy: 0.9949\n",
            "Epoch 48/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1538 - accuracy: 1.0000\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1538 - accuracy: 1.0000 - val_loss: 0.1675 - val_accuracy: 0.9949\n",
            "Epoch 49/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1498 - accuracy: 1.0000\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1499 - accuracy: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9949\n",
            "Epoch 50/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1478 - accuracy: 0.9981\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1479 - accuracy: 0.9981 - val_loss: 0.1633 - val_accuracy: 0.9949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/118/assets\n",
            "\n",
            "\n",
            " 60%|█████▉    | 119/200 [4:43:36<3:26:38, 153.07s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.4323 - accuracy: 0.7159\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 21ms/step - loss: 1.4286 - accuracy: 0.7167 - val_loss: 1.8985 - val_accuracy: 0.3913\n",
            "Epoch 2/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.5664 - accuracy: 0.9839\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.5659 - accuracy: 0.9840 - val_loss: 1.9391 - val_accuracy: 0.4936\n",
            "Epoch 3/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4057 - accuracy: 0.9949\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.4057 - accuracy: 0.9949 - val_loss: 0.9600 - val_accuracy: 0.6829\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3362 - accuracy: 0.9955\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.3357 - accuracy: 0.9955 - val_loss: 0.3032 - val_accuracy: 0.9949\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2770 - accuracy: 0.9981\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.2767 - accuracy: 0.9981 - val_loss: 0.2934 - val_accuracy: 0.9923\n",
            "Epoch 6/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2467 - accuracy: 0.9974\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.2465 - accuracy: 0.9974 - val_loss: 0.2432 - val_accuracy: 0.9949\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2172 - accuracy: 0.9994\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.2168 - accuracy: 0.9994 - val_loss: 0.2208 - val_accuracy: 0.9949\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1942 - accuracy: 0.9994\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1940 - accuracy: 0.9994 - val_loss: 0.2027 - val_accuracy: 0.9923\n",
            "Epoch 9/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1750 - accuracy: 0.9994\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1749 - accuracy: 0.9994 - val_loss: 0.1763 - val_accuracy: 0.9949\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1588 - accuracy: 1.0000\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1586 - accuracy: 1.0000 - val_loss: 0.1678 - val_accuracy: 0.9949\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1478 - accuracy: 0.9994\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1478 - accuracy: 0.9994 - val_loss: 0.1721 - val_accuracy: 0.9949\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1411 - accuracy: 0.9994\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1409 - accuracy: 0.9994 - val_loss: 0.1525 - val_accuracy: 0.9923\n",
            "Epoch 13/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1582 - accuracy: 0.9961\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1582 - accuracy: 0.9962 - val_loss: 0.1715 - val_accuracy: 0.9923\n",
            "Epoch 14/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1341 - accuracy: 1.0000\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1341 - accuracy: 1.0000 - val_loss: 0.1510 - val_accuracy: 0.9923\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1226 - accuracy: 1.0000\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1225 - accuracy: 1.0000 - val_loss: 0.1378 - val_accuracy: 0.9949\n",
            "Epoch 16/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1208 - accuracy: 0.9994\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1208 - accuracy: 0.9994 - val_loss: 0.1417 - val_accuracy: 0.9949\n",
            "Epoch 17/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1104 - accuracy: 1.0000\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1103 - accuracy: 1.0000 - val_loss: 0.1281 - val_accuracy: 0.9923\n",
            "Epoch 18/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1061 - accuracy: 1.0000\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1061 - accuracy: 1.0000 - val_loss: 0.1259 - val_accuracy: 0.9923\n",
            "Epoch 19/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1026 - accuracy: 1.0000\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1026 - accuracy: 1.0000 - val_loss: 0.1206 - val_accuracy: 0.9923\n",
            "Epoch 20/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1007 - accuracy: 1.0000\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1007 - accuracy: 1.0000 - val_loss: 0.1297 - val_accuracy: 0.9949\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0963 - accuracy: 1.0000\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0963 - accuracy: 1.0000 - val_loss: 0.1220 - val_accuracy: 0.9923\n",
            "Epoch 22/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0935 - accuracy: 1.0000\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0935 - accuracy: 1.0000 - val_loss: 0.1307 - val_accuracy: 0.9923\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0972 - accuracy: 0.9987\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0974 - accuracy: 0.9987 - val_loss: 0.1714 - val_accuracy: 0.9898\n",
            "Epoch 24/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0937 - accuracy: 1.0000\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0937 - accuracy: 1.0000 - val_loss: 0.1148 - val_accuracy: 0.9923\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0876 - accuracy: 1.0000\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0878 - accuracy: 1.0000 - val_loss: 0.1446 - val_accuracy: 0.9898\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0861 - accuracy: 1.0000\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0861 - accuracy: 1.0000 - val_loss: 0.1150 - val_accuracy: 0.9923\n",
            "Epoch 27/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0837 - accuracy: 1.0000\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0837 - accuracy: 1.0000 - val_loss: 0.1448 - val_accuracy: 0.9923\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0827 - accuracy: 1.0000\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0826 - accuracy: 1.0000 - val_loss: 0.1212 - val_accuracy: 0.9923\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0805 - accuracy: 1.0000\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0805 - accuracy: 1.0000 - val_loss: 0.1127 - val_accuracy: 0.9923\n",
            "Epoch 30/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0781 - accuracy: 1.0000\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0781 - accuracy: 1.0000 - val_loss: 0.1132 - val_accuracy: 0.9923\n",
            "Epoch 31/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0767 - accuracy: 1.0000\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0767 - accuracy: 1.0000 - val_loss: 0.1114 - val_accuracy: 0.9923\n",
            "Epoch 32/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0738 - accuracy: 1.0000\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0738 - accuracy: 1.0000 - val_loss: 0.1029 - val_accuracy: 0.9898\n",
            "Epoch 33/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0730 - accuracy: 1.0000\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0730 - accuracy: 1.0000 - val_loss: 0.0997 - val_accuracy: 0.9923\n",
            "Epoch 34/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0720 - accuracy: 1.0000\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0723 - accuracy: 1.0000 - val_loss: 0.0981 - val_accuracy: 0.9949\n",
            "Epoch 35/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0722 - accuracy: 1.0000\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0722 - accuracy: 1.0000 - val_loss: 0.1214 - val_accuracy: 0.9872\n",
            "Epoch 36/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1016 - accuracy: 0.9929\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1016 - accuracy: 0.9929 - val_loss: 0.3316 - val_accuracy: 0.9207\n",
            "Epoch 37/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0922 - accuracy: 0.9955\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0920 - accuracy: 0.9955 - val_loss: 0.1019 - val_accuracy: 0.9923\n",
            "Epoch 38/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0730 - accuracy: 1.0000\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0730 - accuracy: 1.0000 - val_loss: 0.0884 - val_accuracy: 0.9923\n",
            "Epoch 39/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0691 - accuracy: 1.0000\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0691 - accuracy: 1.0000 - val_loss: 0.0924 - val_accuracy: 0.9923\n",
            "Epoch 40/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0674 - accuracy: 1.0000\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0674 - accuracy: 1.0000 - val_loss: 0.0952 - val_accuracy: 0.9923\n",
            "Epoch 41/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0666 - accuracy: 1.0000\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0665 - accuracy: 1.0000 - val_loss: 0.0925 - val_accuracy: 0.9923\n",
            "Epoch 42/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0650 - accuracy: 1.0000\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0650 - accuracy: 1.0000 - val_loss: 0.0884 - val_accuracy: 0.9923\n",
            "Epoch 43/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0641 - accuracy: 1.0000\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0641 - accuracy: 1.0000 - val_loss: 0.0859 - val_accuracy: 0.9923\n",
            "Epoch 44/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0627 - accuracy: 1.0000\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0627 - accuracy: 1.0000 - val_loss: 0.0848 - val_accuracy: 0.9949\n",
            "Epoch 45/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0614 - accuracy: 1.0000\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0614 - accuracy: 1.0000 - val_loss: 0.0834 - val_accuracy: 0.9949\n",
            "Epoch 46/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0605 - accuracy: 1.0000\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0605 - accuracy: 1.0000 - val_loss: 0.0874 - val_accuracy: 0.9923\n",
            "Epoch 47/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0591 - accuracy: 1.0000\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0591 - accuracy: 1.0000 - val_loss: 0.0836 - val_accuracy: 0.9949\n",
            "Epoch 48/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0580 - accuracy: 1.0000\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0580 - accuracy: 1.0000 - val_loss: 0.0807 - val_accuracy: 0.9949\n",
            "Epoch 49/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0568 - accuracy: 1.0000\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0568 - accuracy: 1.0000 - val_loss: 0.0825 - val_accuracy: 0.9923\n",
            "Epoch 50/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0558 - accuracy: 1.0000\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0558 - accuracy: 1.0000 - val_loss: 0.0852 - val_accuracy: 0.9949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/119/assets\n",
            "\n",
            "\n",
            " 60%|██████    | 120/200 [4:47:03<3:45:45, 169.32s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8751 - accuracy: 0.7889\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 26ms/step - loss: 0.8721 - accuracy: 0.7904 - val_loss: 1.7539 - val_accuracy: 0.3095\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3333 - accuracy: 0.9573\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.3325 - accuracy: 0.9577 - val_loss: 1.5095 - val_accuracy: 0.4629\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2040 - accuracy: 0.9864\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.2036 - accuracy: 0.9865 - val_loss: 0.7282 - val_accuracy: 0.7749\n",
            "Epoch 4/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2133 - accuracy: 0.9832\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.2131 - accuracy: 0.9833 - val_loss: 0.3125 - val_accuracy: 0.9437\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1876 - accuracy: 0.9890\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1877 - accuracy: 0.9885 - val_loss: 0.2074 - val_accuracy: 0.9821\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1642 - accuracy: 0.9909\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1640 - accuracy: 0.9910 - val_loss: 0.1591 - val_accuracy: 0.9898\n",
            "Epoch 7/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1518 - accuracy: 0.9910\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1516 - accuracy: 0.9910 - val_loss: 0.1995 - val_accuracy: 0.9847\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1791 - accuracy: 0.9851\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1791 - accuracy: 0.9853 - val_loss: 0.2402 - val_accuracy: 0.9540\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1423 - accuracy: 0.9942\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1420 - accuracy: 0.9942 - val_loss: 0.1561 - val_accuracy: 0.9923\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1169 - accuracy: 0.9981\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.1168 - accuracy: 0.9981 - val_loss: 0.1888 - val_accuracy: 0.9616\n",
            "Epoch 11/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1205 - accuracy: 0.9968\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1205 - accuracy: 0.9968 - val_loss: 0.2276 - val_accuracy: 0.9770\n",
            "Epoch 12/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1318 - accuracy: 0.9917\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.1318 - accuracy: 0.9917 - val_loss: 0.2687 - val_accuracy: 0.9744\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1204 - accuracy: 0.9955\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1202 - accuracy: 0.9955 - val_loss: 0.1521 - val_accuracy: 0.9872\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0962 - accuracy: 0.9987\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.0962 - accuracy: 0.9987 - val_loss: 0.2240 - val_accuracy: 0.9693\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0839 - accuracy: 1.0000\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0838 - accuracy: 1.0000 - val_loss: 0.0917 - val_accuracy: 0.9974\n",
            "Epoch 16/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0763 - accuracy: 1.0000\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.0763 - accuracy: 1.0000 - val_loss: 0.0942 - val_accuracy: 0.9974\n",
            "Epoch 17/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1103 - accuracy: 0.9936\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 25ms/step - loss: 0.1108 - accuracy: 0.9936 - val_loss: 2.7665 - val_accuracy: 0.5831\n",
            "Epoch 18/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3389 - accuracy: 0.9462\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.3389 - accuracy: 0.9462 - val_loss: 0.3316 - val_accuracy: 0.9514\n",
            "Epoch 19/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1694 - accuracy: 0.9917\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.1694 - accuracy: 0.9917 - val_loss: 0.2041 - val_accuracy: 0.9821\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1324 - accuracy: 0.9942\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1322 - accuracy: 0.9942 - val_loss: 0.1568 - val_accuracy: 0.9872\n",
            "Epoch 20: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/120/assets\n",
            "\n",
            "\n",
            " 60%|██████    | 121/200 [4:48:40<3:14:35, 147.79s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 2.4948 - accuracy: 0.2068\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 16ms/step - loss: 2.4902 - accuracy: 0.2090 - val_loss: 1.8418 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 2.0497 - accuracy: 0.3730\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 2.0498 - accuracy: 0.3750 - val_loss: 1.8307 - val_accuracy: 0.2890\n",
            "Epoch 3/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.8717 - accuracy: 0.5039\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 1.8727 - accuracy: 0.5032 - val_loss: 1.7329 - val_accuracy: 0.3760\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.7232 - accuracy: 0.6056\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.7258 - accuracy: 0.6045 - val_loss: 1.5876 - val_accuracy: 0.6292\n",
            "Epoch 5/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.5794 - accuracy: 0.6731\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.5794 - accuracy: 0.6731 - val_loss: 1.4712 - val_accuracy: 0.7033\n",
            "Epoch 6/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.4414 - accuracy: 0.7214\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.4429 - accuracy: 0.7205 - val_loss: 1.3487 - val_accuracy: 0.7366\n",
            "Epoch 7/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.3193 - accuracy: 0.7480\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.3178 - accuracy: 0.7500 - val_loss: 1.2355 - val_accuracy: 0.7621\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.2144 - accuracy: 0.7701\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.2131 - accuracy: 0.7712 - val_loss: 1.1348 - val_accuracy: 0.8184\n",
            "Epoch 9/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.1183 - accuracy: 0.8118\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.1218 - accuracy: 0.8096 - val_loss: 1.0482 - val_accuracy: 0.8338\n",
            "Epoch 10/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.0453 - accuracy: 0.8273\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.0455 - accuracy: 0.8269 - val_loss: 0.9767 - val_accuracy: 0.8619\n",
            "Epoch 11/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.9812 - accuracy: 0.8481\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.9812 - accuracy: 0.8481 - val_loss: 0.9156 - val_accuracy: 0.8593\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.9237 - accuracy: 0.8705\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.9233 - accuracy: 0.8692 - val_loss: 0.8575 - val_accuracy: 0.8977\n",
            "Epoch 13/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.8688 - accuracy: 0.8783\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.8684 - accuracy: 0.8782 - val_loss: 0.8099 - val_accuracy: 0.9079\n",
            "Epoch 14/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.8206 - accuracy: 0.9032\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.8206 - accuracy: 0.9032 - val_loss: 0.7697 - val_accuracy: 0.9156\n",
            "Epoch 15/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.7862 - accuracy: 0.9071\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.7864 - accuracy: 0.9071 - val_loss: 0.7268 - val_accuracy: 0.9207\n",
            "Epoch 16/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.7427 - accuracy: 0.9193\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.7428 - accuracy: 0.9192 - val_loss: 0.6919 - val_accuracy: 0.9488\n",
            "Epoch 17/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.7087 - accuracy: 0.9394\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.7084 - accuracy: 0.9397 - val_loss: 0.6600 - val_accuracy: 0.9463\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6793 - accuracy: 0.9430\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.6788 - accuracy: 0.9436 - val_loss: 0.6337 - val_accuracy: 0.9540\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6506 - accuracy: 0.9469\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.6498 - accuracy: 0.9468 - val_loss: 0.6051 - val_accuracy: 0.9591\n",
            "Epoch 20/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.6190 - accuracy: 0.9568\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.6199 - accuracy: 0.9564 - val_loss: 0.5809 - val_accuracy: 0.9616\n",
            "Epoch 21/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.6042 - accuracy: 0.9497\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.6039 - accuracy: 0.9500 - val_loss: 0.5608 - val_accuracy: 0.9668\n",
            "Epoch 22/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.5816 - accuracy: 0.9614\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.5826 - accuracy: 0.9615 - val_loss: 0.5425 - val_accuracy: 0.9693\n",
            "Epoch 23/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5635 - accuracy: 0.9667\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.5635 - accuracy: 0.9667 - val_loss: 0.5246 - val_accuracy: 0.9719\n",
            "Epoch 24/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5429 - accuracy: 0.9705\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.5429 - accuracy: 0.9705 - val_loss: 0.5105 - val_accuracy: 0.9744\n",
            "Epoch 25/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.5209 - accuracy: 0.9792\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.5213 - accuracy: 0.9795 - val_loss: 0.4968 - val_accuracy: 0.9770\n",
            "Epoch 26/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.5073 - accuracy: 0.9779\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.5080 - accuracy: 0.9782 - val_loss: 0.4781 - val_accuracy: 0.9795\n",
            "Epoch 27/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.5035 - accuracy: 0.9688\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.5018 - accuracy: 0.9692 - val_loss: 0.4685 - val_accuracy: 0.9795\n",
            "Epoch 28/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4777 - accuracy: 0.9807\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.4780 - accuracy: 0.9801 - val_loss: 0.4508 - val_accuracy: 0.9821\n",
            "Epoch 29/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4642 - accuracy: 0.9821\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.4642 - accuracy: 0.9821 - val_loss: 0.4417 - val_accuracy: 0.9821\n",
            "Epoch 30/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4496 - accuracy: 0.9820\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.4498 - accuracy: 0.9821 - val_loss: 0.4283 - val_accuracy: 0.9872\n",
            "Epoch 31/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4367 - accuracy: 0.9853\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.4367 - accuracy: 0.9853 - val_loss: 0.4158 - val_accuracy: 0.9898\n",
            "Epoch 32/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4244 - accuracy: 0.9885\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.4244 - accuracy: 0.9885 - val_loss: 0.4067 - val_accuracy: 0.9872\n",
            "Epoch 33/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4169 - accuracy: 0.9858\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.4175 - accuracy: 0.9859 - val_loss: 0.3959 - val_accuracy: 0.9923\n",
            "Epoch 34/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4080 - accuracy: 0.9890\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.4076 - accuracy: 0.9891 - val_loss: 0.3876 - val_accuracy: 0.9923\n",
            "Epoch 35/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.4004 - accuracy: 0.9889\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.3993 - accuracy: 0.9891 - val_loss: 0.3785 - val_accuracy: 0.9923\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3946 - accuracy: 0.9896\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.3939 - accuracy: 0.9897 - val_loss: 0.3760 - val_accuracy: 0.9898\n",
            "Epoch 37/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.3813 - accuracy: 0.9889\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.3814 - accuracy: 0.9885 - val_loss: 0.3632 - val_accuracy: 0.9923\n",
            "Epoch 38/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3725 - accuracy: 0.9890\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.3723 - accuracy: 0.9891 - val_loss: 0.3621 - val_accuracy: 0.9898\n",
            "Epoch 39/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3630 - accuracy: 0.9915\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.3625 - accuracy: 0.9917 - val_loss: 0.3492 - val_accuracy: 0.9898\n",
            "Epoch 40/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3594 - accuracy: 0.9922\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.3594 - accuracy: 0.9923 - val_loss: 0.3431 - val_accuracy: 0.9898\n",
            "Epoch 41/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3534 - accuracy: 0.9891\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.3534 - accuracy: 0.9891 - val_loss: 0.3358 - val_accuracy: 0.9949\n",
            "Epoch 42/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3424 - accuracy: 0.9948\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.3426 - accuracy: 0.9949 - val_loss: 0.3307 - val_accuracy: 0.9923\n",
            "Epoch 43/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3370 - accuracy: 0.9916\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.3363 - accuracy: 0.9917 - val_loss: 0.3286 - val_accuracy: 0.9898\n",
            "Epoch 44/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3272 - accuracy: 0.9954\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.3272 - accuracy: 0.9955 - val_loss: 0.3190 - val_accuracy: 0.9923\n",
            "Epoch 45/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3271 - accuracy: 0.9929\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.3267 - accuracy: 0.9929 - val_loss: 0.3160 - val_accuracy: 0.9898\n",
            "Epoch 46/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.3190 - accuracy: 0.9915\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.3194 - accuracy: 0.9917 - val_loss: 0.3061 - val_accuracy: 0.9923\n",
            "Epoch 47/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3128 - accuracy: 0.9955\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.3128 - accuracy: 0.9955 - val_loss: 0.3031 - val_accuracy: 0.9923\n",
            "Epoch 48/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.3045 - accuracy: 0.9941\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.3044 - accuracy: 0.9942 - val_loss: 0.2993 - val_accuracy: 0.9923\n",
            "Epoch 49/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.2963 - accuracy: 0.9954\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.2973 - accuracy: 0.9949 - val_loss: 0.2917 - val_accuracy: 0.9949\n",
            "Epoch 50/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2975 - accuracy: 0.9942\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.2971 - accuracy: 0.9942 - val_loss: 0.2870 - val_accuracy: 0.9949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/121/assets\n",
            "\n",
            "\n",
            " 61%|██████    | 122/200 [4:51:01<3:09:22, 145.67s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 2.1547 - accuracy: 0.3280\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 8s 30ms/step - loss: 2.1531 - accuracy: 0.3282 - val_loss: 1.9012 - val_accuracy: 0.2737\n",
            "Epoch 2/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.7725 - accuracy: 0.5609\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 1.7725 - accuracy: 0.5609 - val_loss: 1.8243 - val_accuracy: 0.3529\n",
            "Epoch 3/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.5522 - accuracy: 0.6946\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 1.5519 - accuracy: 0.6942 - val_loss: 1.5887 - val_accuracy: 0.5601\n",
            "Epoch 4/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.3550 - accuracy: 0.7790\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 1.3552 - accuracy: 0.7795 - val_loss: 1.2955 - val_accuracy: 0.7570\n",
            "Epoch 5/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.1845 - accuracy: 0.8244\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 1.1845 - accuracy: 0.8244 - val_loss: 1.1222 - val_accuracy: 0.8363\n",
            "Epoch 6/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.0417 - accuracy: 0.8653\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 1.0416 - accuracy: 0.8647 - val_loss: 1.0120 - val_accuracy: 0.8593\n",
            "Epoch 7/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.9237 - accuracy: 0.9000\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 0.9237 - accuracy: 0.9000 - val_loss: 0.8985 - val_accuracy: 0.9105\n",
            "Epoch 8/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.8310 - accuracy: 0.9321\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 0.8310 - accuracy: 0.9321 - val_loss: 0.8102 - val_accuracy: 0.9437\n",
            "Epoch 9/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.7491 - accuracy: 0.9568\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.7518 - accuracy: 0.9551 - val_loss: 0.7358 - val_accuracy: 0.9591\n",
            "Epoch 10/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6925 - accuracy: 0.9660\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 0.6925 - accuracy: 0.9660 - val_loss: 0.6854 - val_accuracy: 0.9744\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6405 - accuracy: 0.9780\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 0.6401 - accuracy: 0.9776 - val_loss: 0.6451 - val_accuracy: 0.9668\n",
            "Epoch 12/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.5975 - accuracy: 0.9807\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.5976 - accuracy: 0.9808 - val_loss: 0.6076 - val_accuracy: 0.9719\n",
            "Epoch 13/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5656 - accuracy: 0.9859\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 0.5656 - accuracy: 0.9859 - val_loss: 0.5741 - val_accuracy: 0.9847\n",
            "Epoch 14/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5408 - accuracy: 0.9885\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.5408 - accuracy: 0.9885 - val_loss: 0.5507 - val_accuracy: 0.9770\n",
            "Epoch 15/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.5125 - accuracy: 0.9878\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.5127 - accuracy: 0.9878 - val_loss: 0.5233 - val_accuracy: 0.9847\n",
            "Epoch 16/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4907 - accuracy: 0.9897\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.4907 - accuracy: 0.9897 - val_loss: 0.5149 - val_accuracy: 0.9719\n",
            "Epoch 17/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4653 - accuracy: 0.9948\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.4653 - accuracy: 0.9949 - val_loss: 0.4855 - val_accuracy: 0.9872\n",
            "Epoch 18/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4547 - accuracy: 0.9929\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.4547 - accuracy: 0.9929 - val_loss: 0.4717 - val_accuracy: 0.9821\n",
            "Epoch 19/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4390 - accuracy: 0.9936\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.4393 - accuracy: 0.9936 - val_loss: 0.4590 - val_accuracy: 0.9795\n",
            "Epoch 20/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4219 - accuracy: 0.9949\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 0.4219 - accuracy: 0.9949 - val_loss: 0.4402 - val_accuracy: 0.9770\n",
            "Epoch 21/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4121 - accuracy: 0.9968\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 0.4117 - accuracy: 0.9968 - val_loss: 0.4293 - val_accuracy: 0.9795\n",
            "Epoch 22/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3955 - accuracy: 0.9948\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.3961 - accuracy: 0.9949 - val_loss: 0.4146 - val_accuracy: 0.9847\n",
            "Epoch 23/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3865 - accuracy: 0.9974\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.3865 - accuracy: 0.9974 - val_loss: 0.4021 - val_accuracy: 0.9898\n",
            "Epoch 24/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3746 - accuracy: 0.9981\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 0.3746 - accuracy: 0.9981 - val_loss: 0.3949 - val_accuracy: 0.9847\n",
            "Epoch 25/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3638 - accuracy: 0.9981\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.3638 - accuracy: 0.9981 - val_loss: 0.3878 - val_accuracy: 0.9923\n",
            "Epoch 26/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3555 - accuracy: 0.9981\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 0.3555 - accuracy: 0.9981 - val_loss: 0.3720 - val_accuracy: 0.9923\n",
            "Epoch 27/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3434 - accuracy: 0.9987\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.3434 - accuracy: 0.9987 - val_loss: 0.3648 - val_accuracy: 0.9923\n",
            "Epoch 28/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3371 - accuracy: 0.9968\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.3371 - accuracy: 0.9968 - val_loss: 0.3598 - val_accuracy: 0.9949\n",
            "Epoch 29/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3294 - accuracy: 0.9968\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.3290 - accuracy: 0.9968 - val_loss: 0.3499 - val_accuracy: 0.9898\n",
            "Epoch 30/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3192 - accuracy: 0.9974\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.3192 - accuracy: 0.9974 - val_loss: 0.3429 - val_accuracy: 0.9898\n",
            "Epoch 31/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3135 - accuracy: 0.9994\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.3136 - accuracy: 0.9994 - val_loss: 0.3361 - val_accuracy: 0.9949\n",
            "Epoch 32/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3075 - accuracy: 0.9987\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.3076 - accuracy: 0.9987 - val_loss: 0.3291 - val_accuracy: 0.9898\n",
            "Epoch 33/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3010 - accuracy: 0.9981\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.3010 - accuracy: 0.9981 - val_loss: 0.3209 - val_accuracy: 0.9923\n",
            "Epoch 34/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2940 - accuracy: 0.9981\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.2939 - accuracy: 0.9981 - val_loss: 0.3145 - val_accuracy: 0.9923\n",
            "Epoch 35/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2884 - accuracy: 0.9987\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.2886 - accuracy: 0.9987 - val_loss: 0.3082 - val_accuracy: 0.9949\n",
            "Epoch 36/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2816 - accuracy: 0.9987\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.2816 - accuracy: 0.9987 - val_loss: 0.3031 - val_accuracy: 0.9923\n",
            "Epoch 37/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2765 - accuracy: 1.0000\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.2764 - accuracy: 1.0000 - val_loss: 0.2986 - val_accuracy: 0.9923\n",
            "Epoch 38/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2721 - accuracy: 0.9994\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.2720 - accuracy: 0.9994 - val_loss: 0.2918 - val_accuracy: 0.9923\n",
            "Epoch 39/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2671 - accuracy: 0.9987\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.2671 - accuracy: 0.9987 - val_loss: 0.2905 - val_accuracy: 0.9898\n",
            "Epoch 40/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2603 - accuracy: 1.0000\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.2603 - accuracy: 1.0000 - val_loss: 0.2944 - val_accuracy: 0.9923\n",
            "Epoch 41/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2575 - accuracy: 0.9994\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.2574 - accuracy: 0.9994 - val_loss: 0.2783 - val_accuracy: 0.9949\n",
            "Epoch 42/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2525 - accuracy: 1.0000\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.2525 - accuracy: 1.0000 - val_loss: 0.2758 - val_accuracy: 0.9898\n",
            "Epoch 43/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2479 - accuracy: 0.9994\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.2479 - accuracy: 0.9994 - val_loss: 0.2706 - val_accuracy: 0.9923\n",
            "Epoch 44/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2439 - accuracy: 1.0000\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.2439 - accuracy: 1.0000 - val_loss: 0.2684 - val_accuracy: 0.9923\n",
            "Epoch 45/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2389 - accuracy: 0.9994\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.2393 - accuracy: 0.9994 - val_loss: 0.2653 - val_accuracy: 0.9923\n",
            "Epoch 46/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2365 - accuracy: 0.9994\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.2365 - accuracy: 0.9994 - val_loss: 0.2591 - val_accuracy: 0.9923\n",
            "Epoch 47/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2324 - accuracy: 0.9994\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.2324 - accuracy: 0.9994 - val_loss: 0.2555 - val_accuracy: 0.9923\n",
            "Epoch 48/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2286 - accuracy: 0.9994\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.2286 - accuracy: 0.9994 - val_loss: 0.2507 - val_accuracy: 0.9923\n",
            "Epoch 49/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2275 - accuracy: 0.9994\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.2275 - accuracy: 0.9994 - val_loss: 0.2485 - val_accuracy: 0.9949\n",
            "Epoch 50/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2207 - accuracy: 1.0000\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.2207 - accuracy: 1.0000 - val_loss: 0.2442 - val_accuracy: 0.9923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/122/assets\n",
            "\n",
            "\n",
            " 62%|██████▏   | 123/200 [4:55:42<3:58:53, 186.16s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 3.6420 - accuracy: 0.2848\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 8s 30ms/step - loss: 3.6394 - accuracy: 0.2859 - val_loss: 1.8843 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 2.6869 - accuracy: 0.4794\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 2.6862 - accuracy: 0.4776 - val_loss: 2.0309 - val_accuracy: 0.2864\n",
            "Epoch 3/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 2.2629 - accuracy: 0.6256\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 2.2625 - accuracy: 0.6256 - val_loss: 1.9350 - val_accuracy: 0.4655\n",
            "Epoch 4/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.9899 - accuracy: 0.7071\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 1.9899 - accuracy: 0.7071 - val_loss: 1.7020 - val_accuracy: 0.7391\n",
            "Epoch 5/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.7736 - accuracy: 0.7776\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 1.7736 - accuracy: 0.7776 - val_loss: 1.5411 - val_accuracy: 0.8389\n",
            "Epoch 6/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.5957 - accuracy: 0.8351\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 1.5959 - accuracy: 0.8353 - val_loss: 1.4021 - val_accuracy: 0.8772\n",
            "Epoch 7/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.4640 - accuracy: 0.8769\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 1.4629 - accuracy: 0.8769 - val_loss: 1.2832 - val_accuracy: 0.9335\n",
            "Epoch 8/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.3447 - accuracy: 0.9064\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 1.3447 - accuracy: 0.9064 - val_loss: 1.2007 - val_accuracy: 0.9309\n",
            "Epoch 9/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.2535 - accuracy: 0.9381\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 1.2534 - accuracy: 0.9385 - val_loss: 1.1195 - val_accuracy: 0.9642\n",
            "Epoch 10/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.1776 - accuracy: 0.9494\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 1.1776 - accuracy: 0.9494 - val_loss: 1.0553 - val_accuracy: 0.9591\n",
            "Epoch 11/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.1119 - accuracy: 0.9626\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 1.1116 - accuracy: 0.9628 - val_loss: 1.0034 - val_accuracy: 0.9616\n",
            "Epoch 12/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.0526 - accuracy: 0.9724\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 1.0526 - accuracy: 0.9724 - val_loss: 0.9521 - val_accuracy: 0.9770\n",
            "Epoch 13/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.0063 - accuracy: 0.9731\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 1.0063 - accuracy: 0.9731 - val_loss: 0.9266 - val_accuracy: 0.9744\n",
            "Epoch 14/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.9546 - accuracy: 0.9814\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.9546 - accuracy: 0.9814 - val_loss: 0.8667 - val_accuracy: 0.9872\n",
            "Epoch 15/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.9132 - accuracy: 0.9878\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 0.9132 - accuracy: 0.9878 - val_loss: 0.8298 - val_accuracy: 0.9898\n",
            "Epoch 16/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.8782 - accuracy: 0.9845\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 0.8774 - accuracy: 0.9846 - val_loss: 0.8040 - val_accuracy: 0.9872\n",
            "Epoch 17/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.8457 - accuracy: 0.9910\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.8453 - accuracy: 0.9910 - val_loss: 0.7731 - val_accuracy: 0.9872\n",
            "Epoch 18/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.8116 - accuracy: 0.9865\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.8116 - accuracy: 0.9865 - val_loss: 0.7394 - val_accuracy: 0.9923\n",
            "Epoch 19/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.7820 - accuracy: 0.9903\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 0.7821 - accuracy: 0.9904 - val_loss: 0.7100 - val_accuracy: 0.9923\n",
            "Epoch 20/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.7568 - accuracy: 0.9936\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 0.7562 - accuracy: 0.9936 - val_loss: 0.6919 - val_accuracy: 0.9949\n",
            "Epoch 21/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.7300 - accuracy: 0.9936\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.7300 - accuracy: 0.9936 - val_loss: 0.6695 - val_accuracy: 0.9949\n",
            "Epoch 22/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.7016 - accuracy: 0.9949\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 0.7016 - accuracy: 0.9949 - val_loss: 0.6426 - val_accuracy: 0.9949\n",
            "Epoch 23/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.6771 - accuracy: 0.9942\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 0.6771 - accuracy: 0.9942 - val_loss: 0.6244 - val_accuracy: 0.9949\n",
            "Epoch 24/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6561 - accuracy: 0.9955\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.6561 - accuracy: 0.9955 - val_loss: 0.6074 - val_accuracy: 0.9923\n",
            "Epoch 25/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6367 - accuracy: 0.9981\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 0.6367 - accuracy: 0.9981 - val_loss: 0.5883 - val_accuracy: 0.9923\n",
            "Epoch 26/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.6161 - accuracy: 0.9955\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 0.6154 - accuracy: 0.9955 - val_loss: 0.5697 - val_accuracy: 0.9949\n",
            "Epoch 27/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5983 - accuracy: 0.9968\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.5983 - accuracy: 0.9968 - val_loss: 0.5527 - val_accuracy: 0.9949\n",
            "Epoch 28/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5814 - accuracy: 0.9974\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 0.5814 - accuracy: 0.9974 - val_loss: 0.5389 - val_accuracy: 0.9949\n",
            "Epoch 29/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5611 - accuracy: 0.9981\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 0.5611 - accuracy: 0.9981 - val_loss: 0.5222 - val_accuracy: 0.9949\n",
            "Epoch 30/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5425 - accuracy: 0.9987\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.5425 - accuracy: 0.9987 - val_loss: 0.5046 - val_accuracy: 0.9949\n",
            "Epoch 31/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.5269 - accuracy: 0.9968\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 0.5272 - accuracy: 0.9968 - val_loss: 0.4889 - val_accuracy: 0.9949\n",
            "Epoch 32/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.5145 - accuracy: 0.9961\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 0.5144 - accuracy: 0.9962 - val_loss: 0.4741 - val_accuracy: 0.9949\n",
            "Epoch 33/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4963 - accuracy: 0.9974\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 0.4963 - accuracy: 0.9974 - val_loss: 0.4641 - val_accuracy: 0.9949\n",
            "Epoch 34/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4840 - accuracy: 0.9981\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.4837 - accuracy: 0.9981 - val_loss: 0.4535 - val_accuracy: 0.9949\n",
            "Epoch 35/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4680 - accuracy: 0.9981\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 0.4675 - accuracy: 0.9981 - val_loss: 0.4411 - val_accuracy: 0.9949\n",
            "Epoch 36/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4564 - accuracy: 0.9987\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 0.4563 - accuracy: 0.9987 - val_loss: 0.4272 - val_accuracy: 0.9949\n",
            "Epoch 37/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4431 - accuracy: 0.9987\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.4431 - accuracy: 0.9987 - val_loss: 0.4255 - val_accuracy: 0.9923\n",
            "Epoch 38/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4278 - accuracy: 0.9987\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.4279 - accuracy: 0.9987 - val_loss: 0.4063 - val_accuracy: 0.9949\n",
            "Epoch 39/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4194 - accuracy: 0.9974\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 0.4194 - accuracy: 0.9974 - val_loss: 0.3955 - val_accuracy: 0.9949\n",
            "Epoch 40/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4059 - accuracy: 0.9974\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.4059 - accuracy: 0.9974 - val_loss: 0.3853 - val_accuracy: 0.9949\n",
            "Epoch 41/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3925 - accuracy: 0.9994\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.3922 - accuracy: 0.9994 - val_loss: 0.3710 - val_accuracy: 0.9949\n",
            "Epoch 42/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3800 - accuracy: 0.9994\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 0.3800 - accuracy: 0.9994 - val_loss: 0.3633 - val_accuracy: 0.9949\n",
            "Epoch 43/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3711 - accuracy: 0.9994\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.3711 - accuracy: 0.9994 - val_loss: 0.3525 - val_accuracy: 0.9949\n",
            "Epoch 44/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3606 - accuracy: 0.9994\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.3606 - accuracy: 0.9994 - val_loss: 0.3426 - val_accuracy: 0.9949\n",
            "Epoch 45/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3510 - accuracy: 0.9987\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 0.3510 - accuracy: 0.9987 - val_loss: 0.3392 - val_accuracy: 0.9949\n",
            "Epoch 46/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3414 - accuracy: 0.9987\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.3416 - accuracy: 0.9987 - val_loss: 0.3260 - val_accuracy: 0.9949\n",
            "Epoch 47/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3348 - accuracy: 0.9981\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.3346 - accuracy: 0.9981 - val_loss: 0.3211 - val_accuracy: 0.9949\n",
            "Epoch 48/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3226 - accuracy: 0.9994\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.3230 - accuracy: 0.9994 - val_loss: 0.3158 - val_accuracy: 0.9949\n",
            "Epoch 49/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3175 - accuracy: 0.9987\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 0.3175 - accuracy: 0.9987 - val_loss: 0.3032 - val_accuracy: 0.9949\n",
            "Epoch 50/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3084 - accuracy: 0.9994\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.3084 - accuracy: 0.9994 - val_loss: 0.2981 - val_accuracy: 0.9949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/123/assets\n",
            "\n",
            "\n",
            " 62%|██████▏   | 124/200 [5:01:09<4:49:26, 228.50s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 2.2395 - accuracy: 0.3776\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 8s 35ms/step - loss: 2.2395 - accuracy: 0.3776 - val_loss: 1.9222 - val_accuracy: 0.3095\n",
            "Epoch 2/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.8685 - accuracy: 0.5840\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 1.8685 - accuracy: 0.5840 - val_loss: 1.9235 - val_accuracy: 0.3299\n",
            "Epoch 3/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6079 - accuracy: 0.6962\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 34ms/step - loss: 1.6079 - accuracy: 0.6962 - val_loss: 1.7163 - val_accuracy: 0.5550\n",
            "Epoch 4/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.4071 - accuracy: 0.7737\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 34ms/step - loss: 1.4071 - accuracy: 0.7737 - val_loss: 1.3206 - val_accuracy: 0.7903\n",
            "Epoch 5/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.2333 - accuracy: 0.8218\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 34ms/step - loss: 1.2333 - accuracy: 0.8218 - val_loss: 1.1296 - val_accuracy: 0.8798\n",
            "Epoch 6/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.0910 - accuracy: 0.8603\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 34ms/step - loss: 1.0910 - accuracy: 0.8603 - val_loss: 0.9816 - val_accuracy: 0.9386\n",
            "Epoch 7/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.9735 - accuracy: 0.9058\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 33ms/step - loss: 0.9735 - accuracy: 0.9058 - val_loss: 0.8888 - val_accuracy: 0.9565\n",
            "Epoch 8/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.8940 - accuracy: 0.9340\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 0.8940 - accuracy: 0.9340 - val_loss: 0.8045 - val_accuracy: 0.9565\n",
            "Epoch 9/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.8219 - accuracy: 0.9500\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 0.8219 - accuracy: 0.9500 - val_loss: 0.7572 - val_accuracy: 0.9744\n",
            "Epoch 10/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.7871 - accuracy: 0.9494\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 0.7871 - accuracy: 0.9494 - val_loss: 0.7109 - val_accuracy: 0.9770\n",
            "Epoch 11/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.7397 - accuracy: 0.9603\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 0.7397 - accuracy: 0.9603 - val_loss: 0.6808 - val_accuracy: 0.9795\n",
            "Epoch 12/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.7061 - accuracy: 0.9615\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 0.7061 - accuracy: 0.9615 - val_loss: 0.6380 - val_accuracy: 0.9821\n",
            "Epoch 13/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6701 - accuracy: 0.9705\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 0.6701 - accuracy: 0.9705 - val_loss: 0.6100 - val_accuracy: 0.9795\n",
            "Epoch 14/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6377 - accuracy: 0.9776\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 0.6377 - accuracy: 0.9776 - val_loss: 0.5924 - val_accuracy: 0.9821\n",
            "Epoch 15/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6121 - accuracy: 0.9814\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 0.6121 - accuracy: 0.9814 - val_loss: 0.5647 - val_accuracy: 0.9847\n",
            "Epoch 16/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5900 - accuracy: 0.9821\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 33ms/step - loss: 0.5900 - accuracy: 0.9821 - val_loss: 0.5461 - val_accuracy: 0.9872\n",
            "Epoch 17/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5671 - accuracy: 0.9865\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 33ms/step - loss: 0.5671 - accuracy: 0.9865 - val_loss: 0.5264 - val_accuracy: 0.9872\n",
            "Epoch 18/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5508 - accuracy: 0.9814\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 0.5508 - accuracy: 0.9814 - val_loss: 0.5170 - val_accuracy: 0.9847\n",
            "Epoch 19/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5341 - accuracy: 0.9897\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 33ms/step - loss: 0.5341 - accuracy: 0.9897 - val_loss: 0.5071 - val_accuracy: 0.9847\n",
            "Epoch 20/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5130 - accuracy: 0.9910\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 0.5130 - accuracy: 0.9910 - val_loss: 0.5009 - val_accuracy: 0.9872\n",
            "Epoch 21/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5070 - accuracy: 0.9891\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 0.5070 - accuracy: 0.9891 - val_loss: 0.4783 - val_accuracy: 0.9898\n",
            "Epoch 22/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4874 - accuracy: 0.9910\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 0.4874 - accuracy: 0.9910 - val_loss: 0.4719 - val_accuracy: 0.9923\n",
            "Epoch 23/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4756 - accuracy: 0.9929\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 0.4756 - accuracy: 0.9929 - val_loss: 0.4486 - val_accuracy: 0.9923\n",
            "Epoch 24/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4658 - accuracy: 0.9891\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 0.4658 - accuracy: 0.9891 - val_loss: 0.4424 - val_accuracy: 0.9923\n",
            "Epoch 25/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4523 - accuracy: 0.9987\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 0.4523 - accuracy: 0.9987 - val_loss: 0.4353 - val_accuracy: 0.9923\n",
            "Epoch 26/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4430 - accuracy: 0.9929\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 0.4430 - accuracy: 0.9929 - val_loss: 0.4277 - val_accuracy: 0.9923\n",
            "Epoch 27/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4329 - accuracy: 0.9949\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 0.4329 - accuracy: 0.9949 - val_loss: 0.4093 - val_accuracy: 0.9949\n",
            "Epoch 28/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4251 - accuracy: 0.9962\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 0.4251 - accuracy: 0.9962 - val_loss: 0.4185 - val_accuracy: 0.9898\n",
            "Epoch 29/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4150 - accuracy: 0.9949\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 0.4150 - accuracy: 0.9949 - val_loss: 0.3959 - val_accuracy: 0.9949\n",
            "Epoch 30/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4069 - accuracy: 0.9942\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 0.4069 - accuracy: 0.9942 - val_loss: 0.3965 - val_accuracy: 0.9949\n",
            "Epoch 31/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3952 - accuracy: 0.9981\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 0.3952 - accuracy: 0.9981 - val_loss: 0.3867 - val_accuracy: 0.9949\n",
            "Epoch 32/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3944 - accuracy: 0.9917\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 34ms/step - loss: 0.3944 - accuracy: 0.9917 - val_loss: 0.3847 - val_accuracy: 0.9923\n",
            "Epoch 33/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3817 - accuracy: 0.9974\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 0.3817 - accuracy: 0.9974 - val_loss: 0.3671 - val_accuracy: 0.9949\n",
            "Epoch 34/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3737 - accuracy: 0.9974\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 0.3737 - accuracy: 0.9974 - val_loss: 0.3641 - val_accuracy: 0.9949\n",
            "Epoch 35/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3687 - accuracy: 0.9981\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 0.3687 - accuracy: 0.9981 - val_loss: 0.3643 - val_accuracy: 0.9949\n",
            "Epoch 36/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3602 - accuracy: 0.9987\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 0.3602 - accuracy: 0.9987 - val_loss: 0.3595 - val_accuracy: 0.9923\n",
            "Epoch 37/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3530 - accuracy: 0.9981\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 0.3530 - accuracy: 0.9981 - val_loss: 0.3527 - val_accuracy: 0.9898\n",
            "Epoch 38/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3477 - accuracy: 0.9987\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 0.3477 - accuracy: 0.9987 - val_loss: 0.3419 - val_accuracy: 0.9949\n",
            "Epoch 39/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3415 - accuracy: 0.9981\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 0.3415 - accuracy: 0.9981 - val_loss: 0.3423 - val_accuracy: 0.9923\n",
            "Epoch 40/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3400 - accuracy: 0.9968\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 0.3400 - accuracy: 0.9968 - val_loss: 0.3498 - val_accuracy: 0.9872\n",
            "Epoch 41/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3326 - accuracy: 0.9987\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 0.3326 - accuracy: 0.9987 - val_loss: 0.3266 - val_accuracy: 0.9949\n",
            "Epoch 42/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3239 - accuracy: 0.9987\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 0.3239 - accuracy: 0.9987 - val_loss: 0.3218 - val_accuracy: 0.9949\n",
            "Epoch 43/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3210 - accuracy: 0.9981\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 0.3210 - accuracy: 0.9981 - val_loss: 0.3328 - val_accuracy: 0.9923\n",
            "Epoch 44/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3176 - accuracy: 0.9987\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 0.3176 - accuracy: 0.9987 - val_loss: 0.3118 - val_accuracy: 0.9949\n",
            "Epoch 45/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3098 - accuracy: 0.9994\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 0.3098 - accuracy: 0.9994 - val_loss: 0.3087 - val_accuracy: 0.9949\n",
            "Epoch 46/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3053 - accuracy: 0.9987\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 0.3053 - accuracy: 0.9987 - val_loss: 0.3055 - val_accuracy: 0.9949\n",
            "Epoch 47/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3015 - accuracy: 0.9994\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 0.3015 - accuracy: 0.9994 - val_loss: 0.3010 - val_accuracy: 0.9949\n",
            "Epoch 48/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2948 - accuracy: 0.9994\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 0.2948 - accuracy: 0.9994 - val_loss: 0.2975 - val_accuracy: 0.9949\n",
            "Epoch 49/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2909 - accuracy: 0.9994\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 0.2909 - accuracy: 0.9994 - val_loss: 0.2927 - val_accuracy: 0.9949\n",
            "Epoch 50/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2887 - accuracy: 0.9981\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 33ms/step - loss: 0.2887 - accuracy: 0.9981 - val_loss: 0.2966 - val_accuracy: 0.9923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/124/assets\n",
            "\n",
            "\n",
            " 62%|██████▎   | 125/200 [5:07:36<5:45:11, 276.15s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.5426 - accuracy: 0.4858\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 24ms/step - loss: 1.5382 - accuracy: 0.4865 - val_loss: 1.7720 - val_accuracy: 0.2967\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7546 - accuracy: 0.8640\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.7509 - accuracy: 0.8654 - val_loss: 1.9987 - val_accuracy: 0.3120\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4730 - accuracy: 0.9566\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.4719 - accuracy: 0.9571 - val_loss: 1.2545 - val_accuracy: 0.6215\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3682 - accuracy: 0.9722\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.3674 - accuracy: 0.9724 - val_loss: 0.3590 - val_accuracy: 0.9693\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3020 - accuracy: 0.9851\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.3016 - accuracy: 0.9853 - val_loss: 0.4284 - val_accuracy: 0.9258\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2558 - accuracy: 0.9922\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2557 - accuracy: 0.9923 - val_loss: 0.2609 - val_accuracy: 0.9949\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2267 - accuracy: 0.9948\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2265 - accuracy: 0.9949 - val_loss: 0.2355 - val_accuracy: 0.9949\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1998 - accuracy: 0.9968\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1996 - accuracy: 0.9968 - val_loss: 0.2155 - val_accuracy: 0.9923\n",
            "Epoch 9/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1881 - accuracy: 0.9974\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1880 - accuracy: 0.9974 - val_loss: 0.1835 - val_accuracy: 0.9974\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1681 - accuracy: 0.9987\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1680 - accuracy: 0.9987 - val_loss: 0.1847 - val_accuracy: 0.9949\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1501 - accuracy: 0.9987\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1502 - accuracy: 0.9987 - val_loss: 0.1624 - val_accuracy: 0.9949\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1397 - accuracy: 0.9994\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1398 - accuracy: 0.9994 - val_loss: 0.1486 - val_accuracy: 0.9949\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1345 - accuracy: 0.9974\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1343 - accuracy: 0.9974 - val_loss: 0.1497 - val_accuracy: 0.9898\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1236 - accuracy: 0.9994\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1236 - accuracy: 0.9994 - val_loss: 0.1380 - val_accuracy: 0.9974\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1184 - accuracy: 0.9987\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1186 - accuracy: 0.9987 - val_loss: 0.1495 - val_accuracy: 0.9923\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1142 - accuracy: 0.9987\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1142 - accuracy: 0.9987 - val_loss: 0.1274 - val_accuracy: 0.9949\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1054 - accuracy: 0.9994\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1053 - accuracy: 0.9994 - val_loss: 0.1284 - val_accuracy: 0.9949\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1005 - accuracy: 0.9994\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1005 - accuracy: 0.9994 - val_loss: 0.1214 - val_accuracy: 0.9974\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0962 - accuracy: 0.9994\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0962 - accuracy: 0.9994 - val_loss: 0.1125 - val_accuracy: 0.9949\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0966 - accuracy: 1.0000\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0967 - accuracy: 1.0000 - val_loss: 0.1987 - val_accuracy: 0.9642\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0902 - accuracy: 1.0000\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0901 - accuracy: 1.0000 - val_loss: 0.1097 - val_accuracy: 0.9923\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0855 - accuracy: 0.9994\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0856 - accuracy: 0.9994 - val_loss: 0.1013 - val_accuracy: 0.9949\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0829 - accuracy: 1.0000\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0830 - accuracy: 1.0000 - val_loss: 0.0988 - val_accuracy: 0.9949\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0806 - accuracy: 0.9994\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0805 - accuracy: 0.9994 - val_loss: 0.1134 - val_accuracy: 0.9923\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0770 - accuracy: 1.0000\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0770 - accuracy: 1.0000 - val_loss: 0.0940 - val_accuracy: 0.9949\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0956 - accuracy: 0.9942\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0955 - accuracy: 0.9942 - val_loss: 0.1444 - val_accuracy: 0.9898\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0846 - accuracy: 0.9994\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0845 - accuracy: 0.9994 - val_loss: 0.1000 - val_accuracy: 0.9923\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0730 - accuracy: 1.0000\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0729 - accuracy: 1.0000 - val_loss: 0.0894 - val_accuracy: 0.9923\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0696 - accuracy: 1.0000\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0696 - accuracy: 1.0000 - val_loss: 0.0888 - val_accuracy: 0.9923\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0686 - accuracy: 1.0000\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0686 - accuracy: 1.0000 - val_loss: 0.0856 - val_accuracy: 0.9923\n",
            "Epoch 31/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0662 - accuracy: 1.0000\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0662 - accuracy: 1.0000 - val_loss: 0.0876 - val_accuracy: 0.9949\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0643 - accuracy: 1.0000\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0643 - accuracy: 1.0000 - val_loss: 0.0806 - val_accuracy: 0.9923\n",
            "Epoch 33/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0650 - accuracy: 1.0000\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0650 - accuracy: 1.0000 - val_loss: 0.0920 - val_accuracy: 0.9923\n",
            "Epoch 34/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0612 - accuracy: 1.0000\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0611 - accuracy: 1.0000 - val_loss: 0.0789 - val_accuracy: 0.9949\n",
            "Epoch 35/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0755 - accuracy: 0.9974\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0753 - accuracy: 0.9974 - val_loss: 0.1080 - val_accuracy: 0.9923\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0620 - accuracy: 1.0000\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0619 - accuracy: 1.0000 - val_loss: 0.0781 - val_accuracy: 0.9949\n",
            "Epoch 37/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0596 - accuracy: 1.0000\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0596 - accuracy: 1.0000 - val_loss: 0.0810 - val_accuracy: 0.9923\n",
            "Epoch 38/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0584 - accuracy: 1.0000\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0584 - accuracy: 1.0000 - val_loss: 0.0774 - val_accuracy: 0.9898\n",
            "Epoch 39/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0565 - accuracy: 1.0000\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0565 - accuracy: 1.0000 - val_loss: 0.0801 - val_accuracy: 0.9923\n",
            "Epoch 40/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0561 - accuracy: 1.0000\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0560 - accuracy: 1.0000 - val_loss: 0.0766 - val_accuracy: 0.9923\n",
            "Epoch 41/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0857 - accuracy: 0.9929\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0856 - accuracy: 0.9929 - val_loss: 0.2036 - val_accuracy: 0.9616\n",
            "Epoch 42/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0680 - accuracy: 0.9994\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0679 - accuracy: 0.9994 - val_loss: 0.0779 - val_accuracy: 0.9923\n",
            "Epoch 43/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0579 - accuracy: 1.0000\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0580 - accuracy: 1.0000 - val_loss: 0.0763 - val_accuracy: 0.9923\n",
            "Epoch 44/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0558 - accuracy: 1.0000\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0562 - accuracy: 1.0000 - val_loss: 0.0751 - val_accuracy: 0.9923\n",
            "Epoch 45/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0555 - accuracy: 1.0000\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0556 - accuracy: 1.0000 - val_loss: 0.0741 - val_accuracy: 0.9923\n",
            "Epoch 46/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0538 - accuracy: 1.0000\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0538 - accuracy: 1.0000 - val_loss: 0.0735 - val_accuracy: 0.9923\n",
            "Epoch 47/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0523 - accuracy: 1.0000\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0523 - accuracy: 1.0000 - val_loss: 0.0745 - val_accuracy: 0.9923\n",
            "Epoch 48/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0511 - accuracy: 1.0000\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0511 - accuracy: 1.0000 - val_loss: 0.0743 - val_accuracy: 0.9923\n",
            "Epoch 49/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0648 - accuracy: 0.9961\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0650 - accuracy: 0.9962 - val_loss: 0.2069 - val_accuracy: 0.9437\n",
            "Epoch 50/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0631 - accuracy: 0.9987\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0631 - accuracy: 0.9987 - val_loss: 0.0802 - val_accuracy: 0.9949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/125/assets\n",
            "\n",
            "\n",
            " 63%|██████▎   | 126/200 [5:11:13<5:18:39, 258.37s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.7948 - accuracy: 0.2856\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 24ms/step - loss: 1.7956 - accuracy: 0.2833 - val_loss: 1.7014 - val_accuracy: 0.2634\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6924 - accuracy: 0.2649\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6934 - accuracy: 0.2635 - val_loss: 1.6677 - val_accuracy: 0.2864\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6645 - accuracy: 0.2584\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6622 - accuracy: 0.2596 - val_loss: 1.6462 - val_accuracy: 0.2864\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6513 - accuracy: 0.2811\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6505 - accuracy: 0.2814 - val_loss: 1.6366 - val_accuracy: 0.2864\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6381 - accuracy: 0.2772\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6361 - accuracy: 0.2782 - val_loss: 1.6299 - val_accuracy: 0.2864\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6308 - accuracy: 0.2882\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6316 - accuracy: 0.2859 - val_loss: 1.6281 - val_accuracy: 0.2864\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6320 - accuracy: 0.2863\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6298 - accuracy: 0.2859 - val_loss: 1.6271 - val_accuracy: 0.2634\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6293 - accuracy: 0.2681\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6293 - accuracy: 0.2673 - val_loss: 1.6258 - val_accuracy: 0.2864\n",
            "Epoch 9/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6274 - accuracy: 0.2859\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6274 - accuracy: 0.2859 - val_loss: 1.6249 - val_accuracy: 0.2864\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6281 - accuracy: 0.2791\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6278 - accuracy: 0.2782 - val_loss: 1.6247 - val_accuracy: 0.2864\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6269 - accuracy: 0.2850\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6267 - accuracy: 0.2859 - val_loss: 1.6243 - val_accuracy: 0.2864\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6267 - accuracy: 0.2785\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6274 - accuracy: 0.2782 - val_loss: 1.6242 - val_accuracy: 0.2864\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6272 - accuracy: 0.2785\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6265 - accuracy: 0.2776 - val_loss: 1.6246 - val_accuracy: 0.2864\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6273 - accuracy: 0.2863\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6261 - accuracy: 0.2859 - val_loss: 1.6243 - val_accuracy: 0.2864\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6263 - accuracy: 0.2804\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6264 - accuracy: 0.2808 - val_loss: 1.6238 - val_accuracy: 0.2864\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6258 - accuracy: 0.2843\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6254 - accuracy: 0.2859 - val_loss: 1.6246 - val_accuracy: 0.2864\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6292 - accuracy: 0.2772\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6277 - accuracy: 0.2782 - val_loss: 1.6237 - val_accuracy: 0.2864\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6313 - accuracy: 0.2772\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6289 - accuracy: 0.2795 - val_loss: 1.6237 - val_accuracy: 0.2864\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6280 - accuracy: 0.2733\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6282 - accuracy: 0.2737 - val_loss: 1.6239 - val_accuracy: 0.2864\n",
            "Epoch 20/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6282 - accuracy: 0.2853\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6282 - accuracy: 0.2853 - val_loss: 1.6241 - val_accuracy: 0.2864\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6271 - accuracy: 0.2863\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6266 - accuracy: 0.2859 - val_loss: 1.6238 - val_accuracy: 0.2864\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6290 - accuracy: 0.2863\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6315 - accuracy: 0.2846 - val_loss: 1.6255 - val_accuracy: 0.2864\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6287 - accuracy: 0.2701\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6282 - accuracy: 0.2718 - val_loss: 1.6248 - val_accuracy: 0.2864\n",
            "Epoch 23: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/126/assets\n",
            "\n",
            "\n",
            " 64%|██████▎   | 127/200 [5:12:58<4:18:21, 212.35s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 2.1101 - accuracy: 0.3446\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 18ms/step - loss: 2.1086 - accuracy: 0.3436 - val_loss: 1.8613 - val_accuracy: 0.1535\n",
            "Epoch 2/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.5681 - accuracy: 0.4473\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 1.5680 - accuracy: 0.4468 - val_loss: 1.8073 - val_accuracy: 0.1841\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.3313 - accuracy: 0.5376\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.3321 - accuracy: 0.5372 - val_loss: 1.4862 - val_accuracy: 0.4527\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.1045 - accuracy: 0.6231\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.1063 - accuracy: 0.6218 - val_loss: 1.1075 - val_accuracy: 0.6292\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.0225 - accuracy: 0.6768\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 1.0242 - accuracy: 0.6750 - val_loss: 1.1114 - val_accuracy: 0.6419\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8507 - accuracy: 0.7325\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.8531 - accuracy: 0.7321 - val_loss: 1.0452 - val_accuracy: 0.6701\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7676 - accuracy: 0.7811\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.7666 - accuracy: 0.7814 - val_loss: 1.1462 - val_accuracy: 0.6471\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7325 - accuracy: 0.7804\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.7297 - accuracy: 0.7821 - val_loss: 0.9637 - val_accuracy: 0.6777\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6530 - accuracy: 0.8122\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.6566 - accuracy: 0.8109 - val_loss: 1.0860 - val_accuracy: 0.6368\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6817 - accuracy: 0.8128\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.6813 - accuracy: 0.8135 - val_loss: 0.9723 - val_accuracy: 0.7110\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5219 - accuracy: 0.8685\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.5241 - accuracy: 0.8673 - val_loss: 1.1652 - val_accuracy: 0.6726\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5928 - accuracy: 0.8549\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.5914 - accuracy: 0.8551 - val_loss: 0.8455 - val_accuracy: 0.7596\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5115 - accuracy: 0.8672\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.5149 - accuracy: 0.8660 - val_loss: 0.9237 - val_accuracy: 0.7698\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4969 - accuracy: 0.8808\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.4965 - accuracy: 0.8814 - val_loss: 0.7754 - val_accuracy: 0.8184\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3504 - accuracy: 0.9242\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.3543 - accuracy: 0.9231 - val_loss: 1.6245 - val_accuracy: 0.7775\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3855 - accuracy: 0.9067\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.3853 - accuracy: 0.9064 - val_loss: 0.7681 - val_accuracy: 0.7724\n",
            "Epoch 17/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3266 - accuracy: 0.9245\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.3267 - accuracy: 0.9250 - val_loss: 0.9832 - val_accuracy: 0.6829\n",
            "Epoch 18/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.4201 - accuracy: 0.6769\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 1.4201 - accuracy: 0.6769 - val_loss: 1.7999 - val_accuracy: 0.3478\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.9653 - accuracy: 0.2940\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 1.9670 - accuracy: 0.2910 - val_loss: 1.9398 - val_accuracy: 0.2660\n",
            "Epoch 20/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.7752 - accuracy: 0.2767\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.7773 - accuracy: 0.2756 - val_loss: 1.8965 - val_accuracy: 0.2839\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.7590 - accuracy: 0.2889\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 1.7588 - accuracy: 0.2885 - val_loss: 1.8138 - val_accuracy: 0.2660\n",
            "Epoch 21: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/127/assets\n",
            "\n",
            "\n",
            " 64%|██████▍   | 128/200 [5:14:08<3:23:30, 169.59s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.6620 - accuracy: 0.5746\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 16ms/step - loss: 1.6540 - accuracy: 0.5776 - val_loss: 1.8102 - val_accuracy: 0.4501\n",
            "Epoch 2/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.9699 - accuracy: 0.8613\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.9677 - accuracy: 0.8609 - val_loss: 1.6057 - val_accuracy: 0.4143\n",
            "Epoch 3/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.6908 - accuracy: 0.9522\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.6909 - accuracy: 0.9519 - val_loss: 1.0002 - val_accuracy: 0.8184\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5615 - accuracy: 0.9741\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.5615 - accuracy: 0.9737 - val_loss: 0.5286 - val_accuracy: 0.9693\n",
            "Epoch 5/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.4833 - accuracy: 0.9805\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.4834 - accuracy: 0.9808 - val_loss: 0.4649 - val_accuracy: 0.9719\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4221 - accuracy: 0.9890\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.4219 - accuracy: 0.9885 - val_loss: 0.4258 - val_accuracy: 0.9770\n",
            "Epoch 7/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3807 - accuracy: 0.9870\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.3808 - accuracy: 0.9872 - val_loss: 0.3982 - val_accuracy: 0.9770\n",
            "Epoch 8/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3434 - accuracy: 0.9948\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.3433 - accuracy: 0.9949 - val_loss: 0.3486 - val_accuracy: 0.9872\n",
            "Epoch 9/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3082 - accuracy: 0.9954\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.3078 - accuracy: 0.9955 - val_loss: 0.3087 - val_accuracy: 0.9847\n",
            "Epoch 10/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2844 - accuracy: 0.9948\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.2844 - accuracy: 0.9949 - val_loss: 0.3385 - val_accuracy: 0.9719\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2670 - accuracy: 0.9981\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.2669 - accuracy: 0.9981 - val_loss: 0.2864 - val_accuracy: 0.9872\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2468 - accuracy: 0.9961\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.2469 - accuracy: 0.9962 - val_loss: 0.2570 - val_accuracy: 0.9898\n",
            "Epoch 13/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2260 - accuracy: 0.9987\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.2260 - accuracy: 0.9987 - val_loss: 0.2530 - val_accuracy: 0.9872\n",
            "Epoch 14/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2134 - accuracy: 0.9968\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.2134 - accuracy: 0.9968 - val_loss: 0.2296 - val_accuracy: 0.9923\n",
            "Epoch 15/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2031 - accuracy: 0.9981\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.2032 - accuracy: 0.9981 - val_loss: 0.2150 - val_accuracy: 0.9923\n",
            "Epoch 16/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1886 - accuracy: 0.9987\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.1888 - accuracy: 0.9987 - val_loss: 0.2032 - val_accuracy: 0.9949\n",
            "Epoch 17/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1812 - accuracy: 0.9981\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1812 - accuracy: 0.9981 - val_loss: 0.1966 - val_accuracy: 0.9923\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1724 - accuracy: 0.9981\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1727 - accuracy: 0.9981 - val_loss: 0.1950 - val_accuracy: 0.9847\n",
            "Epoch 19/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1639 - accuracy: 0.9974\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1637 - accuracy: 0.9974 - val_loss: 0.1773 - val_accuracy: 0.9949\n",
            "Epoch 20/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1553 - accuracy: 0.9994\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1552 - accuracy: 0.9994 - val_loss: 0.1790 - val_accuracy: 0.9898\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1478 - accuracy: 0.9987\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1478 - accuracy: 0.9987 - val_loss: 0.1740 - val_accuracy: 0.9847\n",
            "Epoch 22/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1426 - accuracy: 0.9994\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.1427 - accuracy: 0.9994 - val_loss: 0.1623 - val_accuracy: 0.9923\n",
            "Epoch 23/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1380 - accuracy: 0.9994\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1380 - accuracy: 0.9994 - val_loss: 0.1568 - val_accuracy: 0.9898\n",
            "Epoch 24/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1373 - accuracy: 0.9974\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1373 - accuracy: 0.9974 - val_loss: 0.1606 - val_accuracy: 0.9898\n",
            "Epoch 25/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1295 - accuracy: 0.9994\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.1295 - accuracy: 0.9994 - val_loss: 0.1543 - val_accuracy: 0.9872\n",
            "Epoch 26/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1263 - accuracy: 1.0000\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.1262 - accuracy: 1.0000 - val_loss: 0.1459 - val_accuracy: 0.9923\n",
            "Epoch 27/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1412 - accuracy: 0.9942\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1415 - accuracy: 0.9942 - val_loss: 0.1798 - val_accuracy: 0.9872\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1282 - accuracy: 0.9987\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1281 - accuracy: 0.9987 - val_loss: 0.1450 - val_accuracy: 0.9898\n",
            "Epoch 29/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1163 - accuracy: 1.0000\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.1163 - accuracy: 1.0000 - val_loss: 0.1344 - val_accuracy: 0.9949\n",
            "Epoch 30/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1113 - accuracy: 1.0000\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1114 - accuracy: 1.0000 - val_loss: 0.1388 - val_accuracy: 0.9872\n",
            "Epoch 31/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1089 - accuracy: 1.0000\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.1089 - accuracy: 1.0000 - val_loss: 0.1350 - val_accuracy: 0.9923\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1088 - accuracy: 0.9994\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1087 - accuracy: 0.9994 - val_loss: 0.1313 - val_accuracy: 0.9898\n",
            "Epoch 33/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1041 - accuracy: 1.0000\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1041 - accuracy: 1.0000 - val_loss: 0.1275 - val_accuracy: 0.9872\n",
            "Epoch 34/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1032 - accuracy: 1.0000\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1031 - accuracy: 1.0000 - val_loss: 0.1249 - val_accuracy: 0.9898\n",
            "Epoch 35/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1018 - accuracy: 1.0000\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.1018 - accuracy: 1.0000 - val_loss: 0.1263 - val_accuracy: 0.9898\n",
            "Epoch 36/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0998 - accuracy: 1.0000\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0998 - accuracy: 1.0000 - val_loss: 0.1212 - val_accuracy: 0.9949\n",
            "Epoch 37/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1043 - accuracy: 0.9981\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1043 - accuracy: 0.9981 - val_loss: 0.1239 - val_accuracy: 0.9898\n",
            "Epoch 38/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0961 - accuracy: 1.0000\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0960 - accuracy: 1.0000 - val_loss: 0.1211 - val_accuracy: 0.9872\n",
            "Epoch 39/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0937 - accuracy: 1.0000\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0937 - accuracy: 1.0000 - val_loss: 0.1181 - val_accuracy: 0.9923\n",
            "Epoch 40/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0923 - accuracy: 1.0000\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0923 - accuracy: 1.0000 - val_loss: 0.1184 - val_accuracy: 0.9923\n",
            "Epoch 41/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0903 - accuracy: 1.0000\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0904 - accuracy: 1.0000 - val_loss: 0.1169 - val_accuracy: 0.9898\n",
            "Epoch 42/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0888 - accuracy: 1.0000\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0887 - accuracy: 1.0000 - val_loss: 0.1129 - val_accuracy: 0.9923\n",
            "Epoch 43/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0870 - accuracy: 1.0000\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0869 - accuracy: 1.0000 - val_loss: 0.1111 - val_accuracy: 0.9923\n",
            "Epoch 44/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0852 - accuracy: 1.0000\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0852 - accuracy: 1.0000 - val_loss: 0.1143 - val_accuracy: 0.9923\n",
            "Epoch 45/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0855 - accuracy: 1.0000\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0855 - accuracy: 1.0000 - val_loss: 0.1129 - val_accuracy: 0.9923\n",
            "Epoch 46/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0827 - accuracy: 1.0000\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0827 - accuracy: 1.0000 - val_loss: 0.1054 - val_accuracy: 0.9949\n",
            "Epoch 47/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0810 - accuracy: 1.0000\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0810 - accuracy: 1.0000 - val_loss: 0.1035 - val_accuracy: 0.9923\n",
            "Epoch 48/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0791 - accuracy: 1.0000\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0792 - accuracy: 1.0000 - val_loss: 0.1109 - val_accuracy: 0.9923\n",
            "Epoch 49/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0776 - accuracy: 1.0000\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0776 - accuracy: 1.0000 - val_loss: 0.1038 - val_accuracy: 0.9898\n",
            "Epoch 50/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0804 - accuracy: 0.9994\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0804 - accuracy: 0.9994 - val_loss: 0.1412 - val_accuracy: 0.9847\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/128/assets\n",
            "\n",
            "\n",
            " 64%|██████▍   | 129/200 [5:16:25<3:09:05, 159.80s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6873 - accuracy: 0.6153\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 24ms/step - loss: 1.6836 - accuracy: 0.6167 - val_loss: 1.8041 - val_accuracy: 0.5090\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7455 - accuracy: 0.9475\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.7432 - accuracy: 0.9481 - val_loss: 2.0985 - val_accuracy: 0.5090\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4981 - accuracy: 0.9851\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.4977 - accuracy: 0.9853 - val_loss: 0.9555 - val_accuracy: 0.7596\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3878 - accuracy: 0.9955\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.3870 - accuracy: 0.9955 - val_loss: 0.3511 - val_accuracy: 0.9898\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3178 - accuracy: 0.9987\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.3174 - accuracy: 0.9987 - val_loss: 0.3008 - val_accuracy: 0.9898\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2760 - accuracy: 0.9968\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2757 - accuracy: 0.9968 - val_loss: 0.2502 - val_accuracy: 0.9949\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2333 - accuracy: 0.9994\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2330 - accuracy: 0.9994 - val_loss: 0.2307 - val_accuracy: 0.9898\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2041 - accuracy: 0.9994\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.2039 - accuracy: 0.9994 - val_loss: 0.2020 - val_accuracy: 0.9949\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1853 - accuracy: 0.9981\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1853 - accuracy: 0.9981 - val_loss: 0.1915 - val_accuracy: 0.9923\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1667 - accuracy: 1.0000\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1666 - accuracy: 1.0000 - val_loss: 0.1949 - val_accuracy: 0.9898\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1539 - accuracy: 1.0000\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1541 - accuracy: 1.0000 - val_loss: 0.1675 - val_accuracy: 0.9923\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1496 - accuracy: 0.9994\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.1493 - accuracy: 0.9994 - val_loss: 0.1744 - val_accuracy: 0.9923\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1357 - accuracy: 1.0000\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1355 - accuracy: 1.0000 - val_loss: 0.1626 - val_accuracy: 0.9923\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1293 - accuracy: 1.0000\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1291 - accuracy: 1.0000 - val_loss: 0.1434 - val_accuracy: 0.9923\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1227 - accuracy: 1.0000\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1226 - accuracy: 1.0000 - val_loss: 0.1425 - val_accuracy: 0.9923\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1188 - accuracy: 0.9994\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1187 - accuracy: 0.9994 - val_loss: 0.1425 - val_accuracy: 0.9923\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1290 - accuracy: 0.9974\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1288 - accuracy: 0.9974 - val_loss: 0.1349 - val_accuracy: 0.9923\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1101 - accuracy: 1.0000\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1100 - accuracy: 1.0000 - val_loss: 0.1325 - val_accuracy: 0.9923\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1052 - accuracy: 1.0000\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1052 - accuracy: 1.0000 - val_loss: 0.1299 - val_accuracy: 0.9923\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1019 - accuracy: 0.9994\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1023 - accuracy: 0.9994 - val_loss: 0.1248 - val_accuracy: 0.9923\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0986 - accuracy: 1.0000\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0986 - accuracy: 1.0000 - val_loss: 0.1199 - val_accuracy: 0.9923\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0957 - accuracy: 1.0000\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0957 - accuracy: 1.0000 - val_loss: 0.1182 - val_accuracy: 0.9923\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0936 - accuracy: 1.0000\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0935 - accuracy: 1.0000 - val_loss: 0.1133 - val_accuracy: 0.9923\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0914 - accuracy: 1.0000\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0914 - accuracy: 1.0000 - val_loss: 0.1148 - val_accuracy: 0.9923\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0891 - accuracy: 1.0000\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0891 - accuracy: 1.0000 - val_loss: 0.1162 - val_accuracy: 0.9923\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0863 - accuracy: 1.0000\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0863 - accuracy: 1.0000 - val_loss: 0.1138 - val_accuracy: 0.9923\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0846 - accuracy: 1.0000\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0846 - accuracy: 1.0000 - val_loss: 0.1049 - val_accuracy: 0.9923\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0830 - accuracy: 1.0000\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0829 - accuracy: 1.0000 - val_loss: 0.1025 - val_accuracy: 0.9923\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0830 - accuracy: 1.0000\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0831 - accuracy: 1.0000 - val_loss: 0.1055 - val_accuracy: 0.9923\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0798 - accuracy: 1.0000\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0798 - accuracy: 1.0000 - val_loss: 0.1070 - val_accuracy: 0.9923\n",
            "Epoch 31/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0783 - accuracy: 1.0000\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0783 - accuracy: 1.0000 - val_loss: 0.0999 - val_accuracy: 0.9923\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0758 - accuracy: 1.0000\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0758 - accuracy: 1.0000 - val_loss: 0.1047 - val_accuracy: 0.9923\n",
            "Epoch 33/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0738 - accuracy: 1.0000\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0738 - accuracy: 1.0000 - val_loss: 0.1031 - val_accuracy: 0.9923\n",
            "Epoch 34/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0720 - accuracy: 1.0000\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0720 - accuracy: 1.0000 - val_loss: 0.0967 - val_accuracy: 0.9923\n",
            "Epoch 35/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0701 - accuracy: 1.0000\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0701 - accuracy: 1.0000 - val_loss: 0.0963 - val_accuracy: 0.9923\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0682 - accuracy: 1.0000\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0682 - accuracy: 1.0000 - val_loss: 0.1089 - val_accuracy: 0.9923\n",
            "Epoch 37/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0666 - accuracy: 1.0000\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0665 - accuracy: 1.0000 - val_loss: 0.1031 - val_accuracy: 0.9898\n",
            "Epoch 38/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0651 - accuracy: 1.0000\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0651 - accuracy: 1.0000 - val_loss: 0.0908 - val_accuracy: 0.9923\n",
            "Epoch 39/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0640 - accuracy: 1.0000\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0640 - accuracy: 1.0000 - val_loss: 0.0902 - val_accuracy: 0.9923\n",
            "Epoch 40/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0620 - accuracy: 1.0000\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0620 - accuracy: 1.0000 - val_loss: 0.0862 - val_accuracy: 0.9923\n",
            "Epoch 41/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0599 - accuracy: 1.0000\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0599 - accuracy: 1.0000 - val_loss: 0.0902 - val_accuracy: 0.9898\n",
            "Epoch 42/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0575 - accuracy: 1.0000\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0575 - accuracy: 1.0000 - val_loss: 0.0851 - val_accuracy: 0.9898\n",
            "Epoch 43/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0552 - accuracy: 1.0000\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0552 - accuracy: 1.0000 - val_loss: 0.0804 - val_accuracy: 0.9923\n",
            "Epoch 44/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1244 - accuracy: 0.9896\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1237 - accuracy: 0.9897 - val_loss: 0.1126 - val_accuracy: 0.9923\n",
            "Epoch 45/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0621 - accuracy: 1.0000\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0620 - accuracy: 1.0000 - val_loss: 0.0858 - val_accuracy: 0.9923\n",
            "Epoch 46/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0579 - accuracy: 1.0000\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0579 - accuracy: 1.0000 - val_loss: 0.0828 - val_accuracy: 0.9923\n",
            "Epoch 47/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0565 - accuracy: 1.0000\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0565 - accuracy: 1.0000 - val_loss: 0.0811 - val_accuracy: 0.9923\n",
            "Epoch 48/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0538 - accuracy: 1.0000\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0538 - accuracy: 1.0000 - val_loss: 0.0796 - val_accuracy: 0.9923\n",
            "Epoch 49/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0523 - accuracy: 1.0000\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0523 - accuracy: 1.0000 - val_loss: 0.0794 - val_accuracy: 0.9923\n",
            "Epoch 50/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0507 - accuracy: 1.0000\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0508 - accuracy: 1.0000 - val_loss: 0.0762 - val_accuracy: 0.9923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/129/assets\n",
            "\n",
            "\n",
            " 65%|██████▌   | 130/200 [5:20:01<3:26:02, 176.61s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 2.2764 - accuracy: 0.2455\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 24ms/step - loss: 2.2763 - accuracy: 0.2455 - val_loss: 1.8539 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.8789 - accuracy: 0.4255\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.8782 - accuracy: 0.4269 - val_loss: 1.7894 - val_accuracy: 0.2864\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6805 - accuracy: 0.5784\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6778 - accuracy: 0.5808 - val_loss: 1.6555 - val_accuracy: 0.3299\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.5065 - accuracy: 0.6658\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.5054 - accuracy: 0.6660 - val_loss: 1.3825 - val_accuracy: 0.7263\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.3486 - accuracy: 0.7377\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.3479 - accuracy: 0.7385 - val_loss: 1.2394 - val_accuracy: 0.7647\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.2178 - accuracy: 0.7649\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.2173 - accuracy: 0.7647 - val_loss: 1.1056 - val_accuracy: 0.8210\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.0978 - accuracy: 0.8005\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.0968 - accuracy: 0.8013 - val_loss: 1.0015 - val_accuracy: 0.8593\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.9893 - accuracy: 0.8472\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.9885 - accuracy: 0.8481 - val_loss: 0.9114 - val_accuracy: 0.8875\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.9078 - accuracy: 0.8692\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.9061 - accuracy: 0.8699 - val_loss: 0.8359 - val_accuracy: 0.9105\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8395 - accuracy: 0.9009\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.8378 - accuracy: 0.9019 - val_loss: 0.7687 - val_accuracy: 0.9309\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7696 - accuracy: 0.9229\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.7710 - accuracy: 0.9218 - val_loss: 0.7144 - val_accuracy: 0.9488\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7145 - accuracy: 0.9378\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.7128 - accuracy: 0.9385 - val_loss: 0.6673 - val_accuracy: 0.9591\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6642 - accuracy: 0.9521\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.6626 - accuracy: 0.9519 - val_loss: 0.6256 - val_accuracy: 0.9668\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6333 - accuracy: 0.9585\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.6330 - accuracy: 0.9590 - val_loss: 0.6038 - val_accuracy: 0.9744\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5938 - accuracy: 0.9650\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.5949 - accuracy: 0.9647 - val_loss: 0.5706 - val_accuracy: 0.9795\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5601 - accuracy: 0.9773\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.5598 - accuracy: 0.9776 - val_loss: 0.5407 - val_accuracy: 0.9795\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5438 - accuracy: 0.9754\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.5429 - accuracy: 0.9756 - val_loss: 0.5212 - val_accuracy: 0.9847\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5192 - accuracy: 0.9793\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.5184 - accuracy: 0.9795 - val_loss: 0.5020 - val_accuracy: 0.9847\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4934 - accuracy: 0.9812\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.4932 - accuracy: 0.9814 - val_loss: 0.4892 - val_accuracy: 0.9847\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4767 - accuracy: 0.9838\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.4762 - accuracy: 0.9840 - val_loss: 0.4640 - val_accuracy: 0.9898\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4559 - accuracy: 0.9877\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.4562 - accuracy: 0.9872 - val_loss: 0.4473 - val_accuracy: 0.9872\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4414 - accuracy: 0.9864\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.4408 - accuracy: 0.9865 - val_loss: 0.4322 - val_accuracy: 0.9872\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4237 - accuracy: 0.9916\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.4241 - accuracy: 0.9917 - val_loss: 0.4241 - val_accuracy: 0.9898\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4150 - accuracy: 0.9890\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.4150 - accuracy: 0.9891 - val_loss: 0.4084 - val_accuracy: 0.9898\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4021 - accuracy: 0.9922\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.4027 - accuracy: 0.9923 - val_loss: 0.3988 - val_accuracy: 0.9847\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3881 - accuracy: 0.9922\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.3878 - accuracy: 0.9923 - val_loss: 0.3850 - val_accuracy: 0.9898\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3725 - accuracy: 0.9948\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.3727 - accuracy: 0.9942 - val_loss: 0.3761 - val_accuracy: 0.9923\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3651 - accuracy: 0.9961\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.3644 - accuracy: 0.9962 - val_loss: 0.3682 - val_accuracy: 0.9923\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3563 - accuracy: 0.9948\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.3558 - accuracy: 0.9949 - val_loss: 0.3554 - val_accuracy: 0.9923\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3481 - accuracy: 0.9961\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.3478 - accuracy: 0.9962 - val_loss: 0.3474 - val_accuracy: 0.9949\n",
            "Epoch 31/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3369 - accuracy: 0.9961\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.3368 - accuracy: 0.9962 - val_loss: 0.3467 - val_accuracy: 0.9949\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3264 - accuracy: 0.9974\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.3263 - accuracy: 0.9974 - val_loss: 0.3327 - val_accuracy: 0.9949\n",
            "Epoch 33/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3208 - accuracy: 0.9968\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.3210 - accuracy: 0.9968 - val_loss: 0.3240 - val_accuracy: 0.9974\n",
            "Epoch 34/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3124 - accuracy: 0.9974\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.3126 - accuracy: 0.9974 - val_loss: 0.3186 - val_accuracy: 0.9949\n",
            "Epoch 35/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3061 - accuracy: 0.9974\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.3061 - accuracy: 0.9974 - val_loss: 0.3155 - val_accuracy: 0.9949\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2968 - accuracy: 0.9994\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2964 - accuracy: 0.9994 - val_loss: 0.2999 - val_accuracy: 0.9974\n",
            "Epoch 37/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2879 - accuracy: 0.9968\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2874 - accuracy: 0.9968 - val_loss: 0.2962 - val_accuracy: 0.9949\n",
            "Epoch 38/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2849 - accuracy: 0.9987\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2847 - accuracy: 0.9987 - val_loss: 0.2908 - val_accuracy: 0.9949\n",
            "Epoch 39/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2767 - accuracy: 0.9981\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2767 - accuracy: 0.9981 - val_loss: 0.2844 - val_accuracy: 0.9974\n",
            "Epoch 40/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2716 - accuracy: 0.9994\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2717 - accuracy: 0.9994 - val_loss: 0.2778 - val_accuracy: 0.9974\n",
            "Epoch 41/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2679 - accuracy: 0.9987\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2679 - accuracy: 0.9987 - val_loss: 0.2792 - val_accuracy: 0.9923\n",
            "Epoch 42/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2603 - accuracy: 0.9994\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2602 - accuracy: 0.9994 - val_loss: 0.2763 - val_accuracy: 0.9949\n",
            "Epoch 43/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2556 - accuracy: 0.9987\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2553 - accuracy: 0.9987 - val_loss: 0.2651 - val_accuracy: 0.9974\n",
            "Epoch 44/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2490 - accuracy: 1.0000\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2492 - accuracy: 1.0000 - val_loss: 0.2597 - val_accuracy: 0.9974\n",
            "Epoch 45/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2480 - accuracy: 0.9994\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2480 - accuracy: 0.9994 - val_loss: 0.2661 - val_accuracy: 0.9949\n",
            "Epoch 46/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2434 - accuracy: 0.9981\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2433 - accuracy: 0.9981 - val_loss: 0.2520 - val_accuracy: 0.9949\n",
            "Epoch 47/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2379 - accuracy: 0.9981\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2379 - accuracy: 0.9981 - val_loss: 0.2490 - val_accuracy: 0.9949\n",
            "Epoch 48/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2349 - accuracy: 0.9994\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2345 - accuracy: 0.9994 - val_loss: 0.2417 - val_accuracy: 0.9974\n",
            "Epoch 49/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2268 - accuracy: 0.9987\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2276 - accuracy: 0.9981 - val_loss: 0.2376 - val_accuracy: 0.9974\n",
            "Epoch 50/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2277 - accuracy: 0.9994\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2277 - accuracy: 0.9994 - val_loss: 0.2386 - val_accuracy: 0.9949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/130/assets\n",
            "\n",
            "\n",
            " 66%|██████▌   | 131/200 [5:23:41<3:38:15, 189.79s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.9525 - accuracy: 0.7336\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 10ms/step - loss: 0.9393 - accuracy: 0.7391 - val_loss: 2.1208 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3411 - accuracy: 0.9394\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.3403 - accuracy: 0.9397 - val_loss: 2.5711 - val_accuracy: 0.2941\n",
            "Epoch 3/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.2141 - accuracy: 0.9699\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.2133 - accuracy: 0.9699 - val_loss: 0.6736 - val_accuracy: 0.7621\n",
            "Epoch 4/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.1466 - accuracy: 0.9908\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.1457 - accuracy: 0.9910 - val_loss: 0.1805 - val_accuracy: 0.9770\n",
            "Epoch 5/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1178 - accuracy: 0.9949\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.1178 - accuracy: 0.9949 - val_loss: 0.2412 - val_accuracy: 0.9591\n",
            "Epoch 6/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1367 - accuracy: 0.9882\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.1359 - accuracy: 0.9885 - val_loss: 0.3118 - val_accuracy: 0.9079\n",
            "Epoch 7/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0919 - accuracy: 0.9954\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.0914 - accuracy: 0.9955 - val_loss: 0.1453 - val_accuracy: 0.9872\n",
            "Epoch 8/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0750 - accuracy: 0.9987\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0749 - accuracy: 0.9987 - val_loss: 0.0943 - val_accuracy: 0.9923\n",
            "Epoch 9/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0754 - accuracy: 0.9949\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0754 - accuracy: 0.9949 - val_loss: 0.2482 - val_accuracy: 0.9463\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0932 - accuracy: 0.9935\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.0929 - accuracy: 0.9936 - val_loss: 0.1028 - val_accuracy: 0.9898\n",
            "Epoch 11/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0611 - accuracy: 0.9993\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.0616 - accuracy: 0.9987 - val_loss: 0.1059 - val_accuracy: 0.9923\n",
            "Epoch 12/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0821 - accuracy: 0.9902\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.0817 - accuracy: 0.9904 - val_loss: 0.2062 - val_accuracy: 0.9565\n",
            "Epoch 13/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0632 - accuracy: 0.9981\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0632 - accuracy: 0.9981 - val_loss: 0.0728 - val_accuracy: 0.9949\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0544 - accuracy: 0.9987\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.0544 - accuracy: 0.9987 - val_loss: 0.0838 - val_accuracy: 0.9949\n",
            "Epoch 15/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0556 - accuracy: 0.9974\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.0561 - accuracy: 0.9974 - val_loss: 0.9510 - val_accuracy: 0.7187\n",
            "Epoch 16/50\n",
            "188/195 [===========================>..] - ETA: 0s - loss: 0.0722 - accuracy: 0.9934\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.0802 - accuracy: 0.9917 - val_loss: 0.2716 - val_accuracy: 0.9437\n",
            "Epoch 17/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1055 - accuracy: 0.9844\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.1046 - accuracy: 0.9846 - val_loss: 0.1068 - val_accuracy: 0.9872\n",
            "Epoch 18/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0518 - accuracy: 0.9993\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0516 - accuracy: 0.9994 - val_loss: 0.0731 - val_accuracy: 0.9898\n",
            "Epoch 18: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/131/assets\n",
            "\n",
            "\n",
            " 66%|██████▌   | 132/200 [5:24:17<2:42:37, 143.49s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.9714 - accuracy: 0.6082\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 25ms/step - loss: 1.9640 - accuracy: 0.6109 - val_loss: 1.8919 - val_accuracy: 0.3248\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.1363 - accuracy: 0.8951\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 1.1369 - accuracy: 0.8942 - val_loss: 1.9902 - val_accuracy: 0.3171\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8189 - accuracy: 0.9741\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.8172 - accuracy: 0.9744 - val_loss: 1.1453 - val_accuracy: 0.8465\n",
            "Epoch 4/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.6690 - accuracy: 0.9852\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.6684 - accuracy: 0.9853 - val_loss: 0.6242 - val_accuracy: 0.9847\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5654 - accuracy: 0.9942\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.5648 - accuracy: 0.9942 - val_loss: 0.5307 - val_accuracy: 0.9898\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4877 - accuracy: 0.9974\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.4872 - accuracy: 0.9974 - val_loss: 0.4690 - val_accuracy: 0.9923\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4417 - accuracy: 0.9961\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.4410 - accuracy: 0.9962 - val_loss: 0.4321 - val_accuracy: 0.9949\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3863 - accuracy: 0.9981\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.3863 - accuracy: 0.9981 - val_loss: 0.3683 - val_accuracy: 0.9949\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3539 - accuracy: 0.9987\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.3541 - accuracy: 0.9987 - val_loss: 0.3828 - val_accuracy: 0.9821\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3240 - accuracy: 0.9987\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.3240 - accuracy: 0.9987 - val_loss: 0.3209 - val_accuracy: 0.9898\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2943 - accuracy: 0.9994\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2940 - accuracy: 0.9994 - val_loss: 0.2987 - val_accuracy: 0.9898\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2769 - accuracy: 0.9987\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.2770 - accuracy: 0.9987 - val_loss: 0.2916 - val_accuracy: 0.9898\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2587 - accuracy: 0.9987\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2587 - accuracy: 0.9987 - val_loss: 0.2692 - val_accuracy: 0.9898\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2409 - accuracy: 0.9994\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2410 - accuracy: 0.9994 - val_loss: 0.2502 - val_accuracy: 0.9923\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2386 - accuracy: 0.9994\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.2385 - accuracy: 0.9994 - val_loss: 0.2577 - val_accuracy: 0.9923\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2223 - accuracy: 1.0000\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2221 - accuracy: 1.0000 - val_loss: 0.2325 - val_accuracy: 0.9923\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2157 - accuracy: 0.9994\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2155 - accuracy: 0.9994 - val_loss: 0.2280 - val_accuracy: 0.9923\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2046 - accuracy: 1.0000\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2045 - accuracy: 1.0000 - val_loss: 0.2173 - val_accuracy: 0.9923\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2043 - accuracy: 0.9987\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.2042 - accuracy: 0.9987 - val_loss: 0.2147 - val_accuracy: 0.9923\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1949 - accuracy: 1.0000\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1949 - accuracy: 1.0000 - val_loss: 0.2144 - val_accuracy: 0.9923\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1902 - accuracy: 0.9994\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1901 - accuracy: 0.9994 - val_loss: 0.2071 - val_accuracy: 0.9898\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1838 - accuracy: 1.0000\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1837 - accuracy: 1.0000 - val_loss: 0.2036 - val_accuracy: 0.9898\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1844 - accuracy: 0.9994\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1843 - accuracy: 0.9994 - val_loss: 0.1999 - val_accuracy: 0.9923\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1749 - accuracy: 1.0000\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1749 - accuracy: 1.0000 - val_loss: 0.1933 - val_accuracy: 0.9898\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1756 - accuracy: 1.0000\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1756 - accuracy: 1.0000 - val_loss: 0.2048 - val_accuracy: 0.9898\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1686 - accuracy: 0.9994\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1686 - accuracy: 0.9994 - val_loss: 0.1948 - val_accuracy: 0.9898\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1626 - accuracy: 1.0000\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1626 - accuracy: 1.0000 - val_loss: 0.1846 - val_accuracy: 0.9898\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1594 - accuracy: 1.0000\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1594 - accuracy: 1.0000 - val_loss: 0.1838 - val_accuracy: 0.9898\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1563 - accuracy: 1.0000\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1564 - accuracy: 1.0000 - val_loss: 0.1893 - val_accuracy: 0.9898\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1534 - accuracy: 1.0000\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1534 - accuracy: 1.0000 - val_loss: 0.1744 - val_accuracy: 0.9898\n",
            "Epoch 31/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1495 - accuracy: 1.0000\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1495 - accuracy: 1.0000 - val_loss: 0.1730 - val_accuracy: 0.9898\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1457 - accuracy: 1.0000\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1457 - accuracy: 1.0000 - val_loss: 0.1689 - val_accuracy: 0.9898\n",
            "Epoch 33/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1426 - accuracy: 1.0000\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1426 - accuracy: 1.0000 - val_loss: 0.1699 - val_accuracy: 0.9898\n",
            "Epoch 34/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1396 - accuracy: 1.0000\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1396 - accuracy: 1.0000 - val_loss: 0.1637 - val_accuracy: 0.9898\n",
            "Epoch 35/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1354 - accuracy: 1.0000\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1354 - accuracy: 1.0000 - val_loss: 0.1622 - val_accuracy: 0.9898\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1317 - accuracy: 1.0000\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1317 - accuracy: 1.0000 - val_loss: 0.1622 - val_accuracy: 0.9898\n",
            "Epoch 37/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1292 - accuracy: 1.0000\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1292 - accuracy: 1.0000 - val_loss: 0.1608 - val_accuracy: 0.9872\n",
            "Epoch 38/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1284 - accuracy: 0.9994\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1284 - accuracy: 0.9994 - val_loss: 0.1533 - val_accuracy: 0.9872\n",
            "Epoch 39/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1226 - accuracy: 1.0000\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1227 - accuracy: 1.0000 - val_loss: 0.1414 - val_accuracy: 0.9923\n",
            "Epoch 40/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1182 - accuracy: 1.0000\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1182 - accuracy: 1.0000 - val_loss: 0.1396 - val_accuracy: 0.9923\n",
            "Epoch 41/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1137 - accuracy: 1.0000\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1137 - accuracy: 1.0000 - val_loss: 0.1371 - val_accuracy: 0.9898\n",
            "Epoch 42/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1094 - accuracy: 1.0000\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1094 - accuracy: 1.0000 - val_loss: 0.1358 - val_accuracy: 0.9872\n",
            "Epoch 43/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1069 - accuracy: 1.0000\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1069 - accuracy: 1.0000 - val_loss: 0.1277 - val_accuracy: 0.9898\n",
            "Epoch 44/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1015 - accuracy: 1.0000\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1015 - accuracy: 1.0000 - val_loss: 0.1257 - val_accuracy: 0.9898\n",
            "Epoch 45/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0974 - accuracy: 1.0000\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0974 - accuracy: 1.0000 - val_loss: 0.1189 - val_accuracy: 0.9898\n",
            "Epoch 46/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0927 - accuracy: 1.0000\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0926 - accuracy: 1.0000 - val_loss: 0.1193 - val_accuracy: 0.9898\n",
            "Epoch 47/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0888 - accuracy: 1.0000\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0887 - accuracy: 1.0000 - val_loss: 0.1068 - val_accuracy: 0.9923\n",
            "Epoch 48/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1282 - accuracy: 0.9922\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1284 - accuracy: 0.9923 - val_loss: 0.2283 - val_accuracy: 0.9540\n",
            "Epoch 49/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1024 - accuracy: 0.9981\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1022 - accuracy: 0.9981 - val_loss: 0.1121 - val_accuracy: 0.9923\n",
            "Epoch 50/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0875 - accuracy: 1.0000\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0875 - accuracy: 1.0000 - val_loss: 0.1024 - val_accuracy: 0.9949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/132/assets\n",
            "\n",
            "\n",
            " 66%|██████▋   | 133/200 [5:28:02<3:07:36, 168.00s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 2.0160 - accuracy: 0.2744\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 20ms/step - loss: 2.0160 - accuracy: 0.2744 - val_loss: 1.6989 - val_accuracy: 0.2634\n",
            "Epoch 2/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6882 - accuracy: 0.2699\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 1.6882 - accuracy: 0.2699 - val_loss: 1.6763 - val_accuracy: 0.2864\n",
            "Epoch 3/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.6741 - accuracy: 0.2852\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 1.6726 - accuracy: 0.2859 - val_loss: 1.6654 - val_accuracy: 0.2864\n",
            "Epoch 4/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.6649 - accuracy: 0.2852\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 1.6641 - accuracy: 0.2859 - val_loss: 1.6572 - val_accuracy: 0.2864\n",
            "Epoch 5/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6556 - accuracy: 0.2859\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 1.6556 - accuracy: 0.2859 - val_loss: 1.6499 - val_accuracy: 0.2864\n",
            "Epoch 6/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6491 - accuracy: 0.2758\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 1.6505 - accuracy: 0.2750 - val_loss: 1.6450 - val_accuracy: 0.2864\n",
            "Epoch 7/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6453 - accuracy: 0.2859\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 1.6453 - accuracy: 0.2859 - val_loss: 1.6407 - val_accuracy: 0.2864\n",
            "Epoch 8/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6414 - accuracy: 0.2854\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 1.6420 - accuracy: 0.2859 - val_loss: 1.6374 - val_accuracy: 0.2864\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6407 - accuracy: 0.2837\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 1.6386 - accuracy: 0.2859 - val_loss: 1.6345 - val_accuracy: 0.2864\n",
            "Epoch 10/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.6348 - accuracy: 0.2826\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 1.6357 - accuracy: 0.2859 - val_loss: 1.6328 - val_accuracy: 0.2864\n",
            "Epoch 11/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6346 - accuracy: 0.2758\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 1.6341 - accuracy: 0.2763 - val_loss: 1.6308 - val_accuracy: 0.2864\n",
            "Epoch 12/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6330 - accuracy: 0.2859\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 1.6330 - accuracy: 0.2859 - val_loss: 1.6296 - val_accuracy: 0.2864\n",
            "Epoch 13/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6320 - accuracy: 0.2803\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 1.6319 - accuracy: 0.2808 - val_loss: 1.6281 - val_accuracy: 0.2864\n",
            "Epoch 14/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6310 - accuracy: 0.2726\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 1.6303 - accuracy: 0.2731 - val_loss: 1.6274 - val_accuracy: 0.2864\n",
            "Epoch 15/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6293 - accuracy: 0.2854\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 1.6294 - accuracy: 0.2859 - val_loss: 1.6267 - val_accuracy: 0.2864\n",
            "Epoch 16/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.6301 - accuracy: 0.2793\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 1.6294 - accuracy: 0.2795 - val_loss: 1.6274 - val_accuracy: 0.2864\n",
            "Epoch 17/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6306 - accuracy: 0.2854\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 1.6293 - accuracy: 0.2859 - val_loss: 1.6262 - val_accuracy: 0.2864\n",
            "Epoch 18/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.6269 - accuracy: 0.2799\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 1.6279 - accuracy: 0.2801 - val_loss: 1.6262 - val_accuracy: 0.2864\n",
            "Epoch 19/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6286 - accuracy: 0.2854\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 1.6282 - accuracy: 0.2859 - val_loss: 1.6248 - val_accuracy: 0.2864\n",
            "Epoch 20/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6258 - accuracy: 0.2796\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 1.6276 - accuracy: 0.2788 - val_loss: 1.6244 - val_accuracy: 0.2864\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6265 - accuracy: 0.2863\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 1.6270 - accuracy: 0.2859 - val_loss: 1.6241 - val_accuracy: 0.2864\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6275 - accuracy: 0.2843\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 1.6269 - accuracy: 0.2859 - val_loss: 1.6241 - val_accuracy: 0.2864\n",
            "Epoch 23/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.6261 - accuracy: 0.2780\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 1.6268 - accuracy: 0.2763 - val_loss: 1.6238 - val_accuracy: 0.2864\n",
            "Epoch 24/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6263 - accuracy: 0.2859\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 1.6263 - accuracy: 0.2859 - val_loss: 1.6243 - val_accuracy: 0.2864\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6275 - accuracy: 0.2804\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 1.6268 - accuracy: 0.2801 - val_loss: 1.6237 - val_accuracy: 0.2864\n",
            "Epoch 26/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.6281 - accuracy: 0.2793\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 1.6268 - accuracy: 0.2814 - val_loss: 1.6236 - val_accuracy: 0.2864\n",
            "Epoch 27/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6273 - accuracy: 0.2829\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 1.6263 - accuracy: 0.2827 - val_loss: 1.6235 - val_accuracy: 0.2864\n",
            "Epoch 28/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.6269 - accuracy: 0.2812\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 1.6263 - accuracy: 0.2808 - val_loss: 1.6240 - val_accuracy: 0.2864\n",
            "Epoch 29/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.6257 - accuracy: 0.2858\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 1.6265 - accuracy: 0.2859 - val_loss: 1.6235 - val_accuracy: 0.2864\n",
            "Epoch 30/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.6250 - accuracy: 0.2871\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 1.6256 - accuracy: 0.2872 - val_loss: 1.6245 - val_accuracy: 0.2634\n",
            "Epoch 31/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6263 - accuracy: 0.2801\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 1.6263 - accuracy: 0.2801 - val_loss: 1.6235 - val_accuracy: 0.2864\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6264 - accuracy: 0.2694\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 1.6265 - accuracy: 0.2692 - val_loss: 1.6254 - val_accuracy: 0.2864\n",
            "Epoch 33/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.6265 - accuracy: 0.2786\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 1.6274 - accuracy: 0.2782 - val_loss: 1.6256 - val_accuracy: 0.2864\n",
            "Epoch 34/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.6268 - accuracy: 0.2878\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 1.6267 - accuracy: 0.2859 - val_loss: 1.6246 - val_accuracy: 0.2634\n",
            "Epoch 35/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6267 - accuracy: 0.2808\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 1.6267 - accuracy: 0.2808 - val_loss: 1.6242 - val_accuracy: 0.2864\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6285 - accuracy: 0.2798\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 1.6267 - accuracy: 0.2801 - val_loss: 1.6242 - val_accuracy: 0.2864\n",
            "Epoch 36: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/133/assets\n",
            "\n",
            "\n",
            " 67%|██████▋   | 134/200 [5:30:12<2:52:07, 156.48s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 2.6663 - accuracy: 0.2571\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 18ms/step - loss: 2.6646 - accuracy: 0.2583 - val_loss: 1.8078 - val_accuracy: 0.2737\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 2.1596 - accuracy: 0.4268\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 2.1582 - accuracy: 0.4276 - val_loss: 1.7821 - val_accuracy: 0.3146\n",
            "Epoch 3/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.9104 - accuracy: 0.5169\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 1.9092 - accuracy: 0.5186 - val_loss: 1.6677 - val_accuracy: 0.5217\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.7054 - accuracy: 0.6120\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 1.7082 - accuracy: 0.6115 - val_loss: 1.4982 - val_accuracy: 0.6368\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.5547 - accuracy: 0.6788\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.5504 - accuracy: 0.6801 - val_loss: 1.3891 - val_accuracy: 0.6880\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.3980 - accuracy: 0.7448\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 1.3974 - accuracy: 0.7455 - val_loss: 1.2632 - val_accuracy: 0.7519\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.2677 - accuracy: 0.7811\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.2666 - accuracy: 0.7814 - val_loss: 1.1431 - val_accuracy: 0.8005\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.1684 - accuracy: 0.8148\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.1691 - accuracy: 0.8141 - val_loss: 1.0352 - val_accuracy: 0.8747\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.0606 - accuracy: 0.8614\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 1.0593 - accuracy: 0.8615 - val_loss: 0.9495 - val_accuracy: 0.8900\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.9757 - accuracy: 0.8880\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.9740 - accuracy: 0.8891 - val_loss: 0.8694 - val_accuracy: 0.9105\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.9002 - accuracy: 0.9087\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.8985 - accuracy: 0.9096 - val_loss: 0.8047 - val_accuracy: 0.9335\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8427 - accuracy: 0.9236\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.8418 - accuracy: 0.9237 - val_loss: 0.7490 - val_accuracy: 0.9386\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7839 - accuracy: 0.9462\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.7818 - accuracy: 0.9468 - val_loss: 0.7047 - val_accuracy: 0.9540\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7374 - accuracy: 0.9540\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.7374 - accuracy: 0.9538 - val_loss: 0.6716 - val_accuracy: 0.9591\n",
            "Epoch 15/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.6974 - accuracy: 0.9557\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.6967 - accuracy: 0.9558 - val_loss: 0.6348 - val_accuracy: 0.9642\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6668 - accuracy: 0.9650\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.6670 - accuracy: 0.9654 - val_loss: 0.6107 - val_accuracy: 0.9668\n",
            "Epoch 17/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.6383 - accuracy: 0.9674\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.6373 - accuracy: 0.9679 - val_loss: 0.5801 - val_accuracy: 0.9770\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6125 - accuracy: 0.9722\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.6120 - accuracy: 0.9724 - val_loss: 0.5650 - val_accuracy: 0.9693\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5803 - accuracy: 0.9786\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.5818 - accuracy: 0.9776 - val_loss: 0.5400 - val_accuracy: 0.9821\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5585 - accuracy: 0.9819\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.5580 - accuracy: 0.9821 - val_loss: 0.5249 - val_accuracy: 0.9795\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5441 - accuracy: 0.9786\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.5439 - accuracy: 0.9788 - val_loss: 0.5163 - val_accuracy: 0.9744\n",
            "Epoch 22/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.5252 - accuracy: 0.9837\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.5245 - accuracy: 0.9840 - val_loss: 0.4908 - val_accuracy: 0.9821\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5040 - accuracy: 0.9851\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.5044 - accuracy: 0.9853 - val_loss: 0.4922 - val_accuracy: 0.9795\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4884 - accuracy: 0.9935\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.4884 - accuracy: 0.9936 - val_loss: 0.4603 - val_accuracy: 0.9872\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4757 - accuracy: 0.9864\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.4760 - accuracy: 0.9865 - val_loss: 0.4552 - val_accuracy: 0.9872\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4620 - accuracy: 0.9909\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.4623 - accuracy: 0.9904 - val_loss: 0.4449 - val_accuracy: 0.9847\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4481 - accuracy: 0.9903\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.4480 - accuracy: 0.9904 - val_loss: 0.4361 - val_accuracy: 0.9847\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4350 - accuracy: 0.9935\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.4345 - accuracy: 0.9936 - val_loss: 0.4121 - val_accuracy: 0.9898\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4228 - accuracy: 0.9942\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.4222 - accuracy: 0.9942 - val_loss: 0.4038 - val_accuracy: 0.9872\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4148 - accuracy: 0.9916\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.4149 - accuracy: 0.9917 - val_loss: 0.3916 - val_accuracy: 0.9898\n",
            "Epoch 31/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3989 - accuracy: 0.9948\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.3984 - accuracy: 0.9949 - val_loss: 0.3858 - val_accuracy: 0.9923\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3903 - accuracy: 0.9968\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.3899 - accuracy: 0.9968 - val_loss: 0.3744 - val_accuracy: 0.9923\n",
            "Epoch 33/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3809 - accuracy: 0.9974\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.3806 - accuracy: 0.9974 - val_loss: 0.3635 - val_accuracy: 0.9923\n",
            "Epoch 34/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3704 - accuracy: 0.9948\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.3707 - accuracy: 0.9949 - val_loss: 0.3595 - val_accuracy: 0.9923\n",
            "Epoch 35/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3627 - accuracy: 0.9968\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.3625 - accuracy: 0.9968 - val_loss: 0.3488 - val_accuracy: 0.9923\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3513 - accuracy: 0.9968\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.3509 - accuracy: 0.9968 - val_loss: 0.3461 - val_accuracy: 0.9898\n",
            "Epoch 37/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3434 - accuracy: 0.9968\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.3428 - accuracy: 0.9968 - val_loss: 0.3421 - val_accuracy: 0.9898\n",
            "Epoch 38/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3352 - accuracy: 0.9981\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.3370 - accuracy: 0.9974 - val_loss: 0.3288 - val_accuracy: 0.9923\n",
            "Epoch 39/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3253 - accuracy: 0.9974\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.3254 - accuracy: 0.9974 - val_loss: 0.3250 - val_accuracy: 0.9898\n",
            "Epoch 40/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3182 - accuracy: 0.9987\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.3180 - accuracy: 0.9987 - val_loss: 0.3115 - val_accuracy: 0.9923\n",
            "Epoch 41/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3109 - accuracy: 0.9967\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.3107 - accuracy: 0.9968 - val_loss: 0.3106 - val_accuracy: 0.9898\n",
            "Epoch 42/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3045 - accuracy: 0.9974\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.3040 - accuracy: 0.9974 - val_loss: 0.2994 - val_accuracy: 0.9923\n",
            "Epoch 43/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2987 - accuracy: 0.9981\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.2984 - accuracy: 0.9981 - val_loss: 0.3084 - val_accuracy: 0.9872\n",
            "Epoch 44/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2929 - accuracy: 0.9961\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.2927 - accuracy: 0.9962 - val_loss: 0.2872 - val_accuracy: 0.9923\n",
            "Epoch 45/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2870 - accuracy: 0.9974\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.2870 - accuracy: 0.9974 - val_loss: 0.2867 - val_accuracy: 0.9923\n",
            "Epoch 46/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2792 - accuracy: 0.9981\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.2791 - accuracy: 0.9981 - val_loss: 0.2770 - val_accuracy: 0.9923\n",
            "Epoch 47/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2756 - accuracy: 0.9967\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.2756 - accuracy: 0.9968 - val_loss: 0.2781 - val_accuracy: 0.9923\n",
            "Epoch 48/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2697 - accuracy: 0.9987\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.2696 - accuracy: 0.9987 - val_loss: 0.2691 - val_accuracy: 0.9923\n",
            "Epoch 49/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2645 - accuracy: 0.9974\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.2642 - accuracy: 0.9974 - val_loss: 0.2650 - val_accuracy: 0.9923\n",
            "Epoch 50/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2577 - accuracy: 0.9994\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.2576 - accuracy: 0.9994 - val_loss: 0.2617 - val_accuracy: 0.9923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/134/assets\n",
            "\n",
            "\n",
            " 68%|██████▊   | 135/200 [5:32:49<2:49:40, 156.62s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.1272 - accuracy: 0.7526\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 20ms/step - loss: 1.1207 - accuracy: 0.7545 - val_loss: 1.7932 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3454 - accuracy: 0.9652\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.3453 - accuracy: 0.9654 - val_loss: 2.1232 - val_accuracy: 0.3632\n",
            "Epoch 3/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2941 - accuracy: 0.9707\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.2925 - accuracy: 0.9712 - val_loss: 1.5181 - val_accuracy: 0.4399\n",
            "Epoch 4/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2303 - accuracy: 0.9865\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.2303 - accuracy: 0.9865 - val_loss: 0.2067 - val_accuracy: 0.9898\n",
            "Epoch 5/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1900 - accuracy: 0.9935\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.1898 - accuracy: 0.9936 - val_loss: 0.3806 - val_accuracy: 0.9616\n",
            "Epoch 6/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1638 - accuracy: 0.9994\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.1638 - accuracy: 0.9994 - val_loss: 0.2083 - val_accuracy: 0.9847\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1516 - accuracy: 0.9981\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.1516 - accuracy: 0.9981 - val_loss: 0.2036 - val_accuracy: 0.9821\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3096 - accuracy: 0.9644\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.3089 - accuracy: 0.9647 - val_loss: 0.4477 - val_accuracy: 0.9463\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2076 - accuracy: 0.9896\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.2080 - accuracy: 0.9897 - val_loss: 0.2225 - val_accuracy: 0.9898\n",
            "Epoch 10/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1515 - accuracy: 0.9974\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.1515 - accuracy: 0.9974 - val_loss: 0.2396 - val_accuracy: 0.9795\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1338 - accuracy: 0.9994\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.1336 - accuracy: 0.9994 - val_loss: 0.1581 - val_accuracy: 0.9949\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1205 - accuracy: 1.0000\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.1204 - accuracy: 1.0000 - val_loss: 0.1285 - val_accuracy: 0.9949\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1146 - accuracy: 0.9994\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.1150 - accuracy: 0.9994 - val_loss: 0.1460 - val_accuracy: 0.9898\n",
            "Epoch 14/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2496 - accuracy: 0.9731\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.2496 - accuracy: 0.9731 - val_loss: 1.7504 - val_accuracy: 0.6496\n",
            "Epoch 15/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2914 - accuracy: 0.9681\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.2893 - accuracy: 0.9686 - val_loss: 0.1970 - val_accuracy: 0.9923\n",
            "Epoch 16/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1528 - accuracy: 0.9981\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.1528 - accuracy: 0.9981 - val_loss: 0.1604 - val_accuracy: 0.9923\n",
            "Epoch 17/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1410 - accuracy: 0.9961\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.1409 - accuracy: 0.9962 - val_loss: 0.3136 - val_accuracy: 0.9591\n",
            "Epoch 17: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/135/assets\n",
            "\n",
            "\n",
            " 68%|██████▊   | 136/200 [5:33:54<2:17:49, 129.22s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 2.7568 - accuracy: 0.2273\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 17ms/step - loss: 2.7532 - accuracy: 0.2282 - val_loss: 1.8358 - val_accuracy: 0.2532\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 2.3193 - accuracy: 0.3614\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 2.3180 - accuracy: 0.3635 - val_loss: 1.8249 - val_accuracy: 0.3095\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 2.1059 - accuracy: 0.4696\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 2.1055 - accuracy: 0.4718 - val_loss: 1.7886 - val_accuracy: 0.4322\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.9468 - accuracy: 0.5628\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.9433 - accuracy: 0.5635 - val_loss: 1.7194 - val_accuracy: 0.5601\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.7730 - accuracy: 0.6315\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.7718 - accuracy: 0.6340 - val_loss: 1.6210 - val_accuracy: 0.6650\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6427 - accuracy: 0.6671\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.6420 - accuracy: 0.6673 - val_loss: 1.4995 - val_accuracy: 0.7161\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.5088 - accuracy: 0.7403\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.5071 - accuracy: 0.7417 - val_loss: 1.3907 - val_accuracy: 0.7698\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.4133 - accuracy: 0.7655\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.4135 - accuracy: 0.7667 - val_loss: 1.3060 - val_accuracy: 0.7775\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.3177 - accuracy: 0.7856\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.3200 - accuracy: 0.7840 - val_loss: 1.2216 - val_accuracy: 0.8031\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.2523 - accuracy: 0.8089\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.2519 - accuracy: 0.8090 - val_loss: 1.1575 - val_accuracy: 0.8286\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.1865 - accuracy: 0.8355\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.1874 - accuracy: 0.8353 - val_loss: 1.1014 - val_accuracy: 0.8312\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.1351 - accuracy: 0.8420\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.1340 - accuracy: 0.8417 - val_loss: 1.0488 - val_accuracy: 0.8645\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.0864 - accuracy: 0.8666\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.0859 - accuracy: 0.8660 - val_loss: 1.0074 - val_accuracy: 0.8772\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.0406 - accuracy: 0.8808\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.0401 - accuracy: 0.8814 - val_loss: 0.9691 - val_accuracy: 0.8824\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.9992 - accuracy: 0.8886\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.9992 - accuracy: 0.8885 - val_loss: 0.9306 - val_accuracy: 0.9156\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.9668 - accuracy: 0.9022\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.9650 - accuracy: 0.9032 - val_loss: 0.9066 - val_accuracy: 0.9182\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.9393 - accuracy: 0.9087\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.9398 - accuracy: 0.9090 - val_loss: 0.8748 - val_accuracy: 0.9130\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.9084 - accuracy: 0.9152\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.9101 - accuracy: 0.9141 - val_loss: 0.8463 - val_accuracy: 0.9207\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8725 - accuracy: 0.9255\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.8731 - accuracy: 0.9244 - val_loss: 0.8275 - val_accuracy: 0.9233\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8594 - accuracy: 0.9313\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.8588 - accuracy: 0.9314 - val_loss: 0.8024 - val_accuracy: 0.9182\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8284 - accuracy: 0.9404\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.8268 - accuracy: 0.9410 - val_loss: 0.7770 - val_accuracy: 0.9540\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8034 - accuracy: 0.9495\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.8028 - accuracy: 0.9494 - val_loss: 0.7587 - val_accuracy: 0.9540\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7866 - accuracy: 0.9462\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.7877 - accuracy: 0.9449 - val_loss: 0.7394 - val_accuracy: 0.9488\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7664 - accuracy: 0.9508\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.7674 - accuracy: 0.9506 - val_loss: 0.7198 - val_accuracy: 0.9540\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7416 - accuracy: 0.9547\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.7405 - accuracy: 0.9551 - val_loss: 0.7017 - val_accuracy: 0.9668\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7257 - accuracy: 0.9611\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.7246 - accuracy: 0.9615 - val_loss: 0.6860 - val_accuracy: 0.9642\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7129 - accuracy: 0.9585\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.7123 - accuracy: 0.9583 - val_loss: 0.6708 - val_accuracy: 0.9616\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6901 - accuracy: 0.9722\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.6905 - accuracy: 0.9718 - val_loss: 0.6640 - val_accuracy: 0.9616\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6842 - accuracy: 0.9670\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.6828 - accuracy: 0.9673 - val_loss: 0.6418 - val_accuracy: 0.9693\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6597 - accuracy: 0.9709\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.6599 - accuracy: 0.9712 - val_loss: 0.6306 - val_accuracy: 0.9693\n",
            "Epoch 31/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6496 - accuracy: 0.9722\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.6498 - accuracy: 0.9724 - val_loss: 0.6191 - val_accuracy: 0.9744\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6371 - accuracy: 0.9734\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.6358 - accuracy: 0.9737 - val_loss: 0.6153 - val_accuracy: 0.9642\n",
            "Epoch 33/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6171 - accuracy: 0.9754\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.6182 - accuracy: 0.9744 - val_loss: 0.5934 - val_accuracy: 0.9693\n",
            "Epoch 34/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6094 - accuracy: 0.9754\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.6090 - accuracy: 0.9756 - val_loss: 0.5837 - val_accuracy: 0.9693\n",
            "Epoch 35/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6024 - accuracy: 0.9734\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.6026 - accuracy: 0.9731 - val_loss: 0.5790 - val_accuracy: 0.9693\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5887 - accuracy: 0.9780\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.5891 - accuracy: 0.9782 - val_loss: 0.5646 - val_accuracy: 0.9719\n",
            "Epoch 37/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.5780 - accuracy: 0.9824\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.5778 - accuracy: 0.9827 - val_loss: 0.5583 - val_accuracy: 0.9719\n",
            "Epoch 38/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5650 - accuracy: 0.9838\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.5653 - accuracy: 0.9840 - val_loss: 0.5444 - val_accuracy: 0.9770\n",
            "Epoch 39/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5525 - accuracy: 0.9870\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.5537 - accuracy: 0.9865 - val_loss: 0.5541 - val_accuracy: 0.9693\n",
            "Epoch 40/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5433 - accuracy: 0.9851\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.5433 - accuracy: 0.9853 - val_loss: 0.5318 - val_accuracy: 0.9693\n",
            "Epoch 41/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5357 - accuracy: 0.9890\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.5361 - accuracy: 0.9891 - val_loss: 0.5220 - val_accuracy: 0.9795\n",
            "Epoch 42/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5259 - accuracy: 0.9877\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.5260 - accuracy: 0.9878 - val_loss: 0.5205 - val_accuracy: 0.9693\n",
            "Epoch 43/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.5193 - accuracy: 0.9857\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.5211 - accuracy: 0.9859 - val_loss: 0.5056 - val_accuracy: 0.9795\n",
            "Epoch 44/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5091 - accuracy: 0.9903\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.5089 - accuracy: 0.9904 - val_loss: 0.4949 - val_accuracy: 0.9795\n",
            "Epoch 45/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4990 - accuracy: 0.9916\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.4991 - accuracy: 0.9917 - val_loss: 0.4969 - val_accuracy: 0.9770\n",
            "Epoch 46/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4898 - accuracy: 0.9903\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.4904 - accuracy: 0.9904 - val_loss: 0.4908 - val_accuracy: 0.9795\n",
            "Epoch 47/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4854 - accuracy: 0.9877\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.4851 - accuracy: 0.9878 - val_loss: 0.4716 - val_accuracy: 0.9795\n",
            "Epoch 48/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4762 - accuracy: 0.9896\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.4760 - accuracy: 0.9897 - val_loss: 0.4716 - val_accuracy: 0.9821\n",
            "Epoch 49/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4730 - accuracy: 0.9922\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.4724 - accuracy: 0.9923 - val_loss: 0.4623 - val_accuracy: 0.9795\n",
            "Epoch 50/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4603 - accuracy: 0.9935\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.4594 - accuracy: 0.9936 - val_loss: 0.4576 - val_accuracy: 0.9795\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/136/assets\n",
            "\n",
            "\n",
            " 68%|██████▊   | 137/200 [5:37:21<2:40:14, 152.61s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6858 - accuracy: 0.5167\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 15ms/step - loss: 1.6858 - accuracy: 0.5167 - val_loss: 1.7331 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.0101 - accuracy: 0.8043\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 1.0063 - accuracy: 0.8064 - val_loss: 2.1188 - val_accuracy: 0.4910\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7130 - accuracy: 0.8983\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.7115 - accuracy: 0.8994 - val_loss: 2.0778 - val_accuracy: 0.5217\n",
            "Epoch 4/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.5511 - accuracy: 0.9549\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.5505 - accuracy: 0.9551 - val_loss: 0.6930 - val_accuracy: 0.8338\n",
            "Epoch 5/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.4638 - accuracy: 0.9699\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.4652 - accuracy: 0.9692 - val_loss: 0.4196 - val_accuracy: 0.9821\n",
            "Epoch 6/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.4029 - accuracy: 0.9784\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.4014 - accuracy: 0.9788 - val_loss: 0.3783 - val_accuracy: 0.9872\n",
            "Epoch 7/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3596 - accuracy: 0.9858\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.3593 - accuracy: 0.9859 - val_loss: 0.3382 - val_accuracy: 0.9949\n",
            "Epoch 8/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3240 - accuracy: 0.9897\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.3240 - accuracy: 0.9897 - val_loss: 0.3324 - val_accuracy: 0.9872\n",
            "Epoch 9/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3044 - accuracy: 0.9897\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.3039 - accuracy: 0.9897 - val_loss: 0.3316 - val_accuracy: 0.9719\n",
            "Epoch 10/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2713 - accuracy: 0.9949\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.2713 - accuracy: 0.9949 - val_loss: 0.2581 - val_accuracy: 0.9949\n",
            "Epoch 11/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.2503 - accuracy: 0.9948\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.2498 - accuracy: 0.9949 - val_loss: 0.2337 - val_accuracy: 0.9949\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2362 - accuracy: 0.9922\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.2360 - accuracy: 0.9923 - val_loss: 0.2383 - val_accuracy: 0.9898\n",
            "Epoch 13/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2178 - accuracy: 0.9955\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.2178 - accuracy: 0.9955 - val_loss: 0.2198 - val_accuracy: 0.9923\n",
            "Epoch 14/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2031 - accuracy: 0.9967\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.2028 - accuracy: 0.9968 - val_loss: 0.3112 - val_accuracy: 0.9463\n",
            "Epoch 15/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1900 - accuracy: 0.9981\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1900 - accuracy: 0.9981 - val_loss: 0.2121 - val_accuracy: 0.9898\n",
            "Epoch 16/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1804 - accuracy: 0.9981\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1804 - accuracy: 0.9981 - val_loss: 0.1810 - val_accuracy: 0.9923\n",
            "Epoch 17/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1679 - accuracy: 0.9987\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1679 - accuracy: 0.9987 - val_loss: 0.1723 - val_accuracy: 0.9923\n",
            "Epoch 18/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1583 - accuracy: 1.0000\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1583 - accuracy: 1.0000 - val_loss: 0.1683 - val_accuracy: 0.9949\n",
            "Epoch 19/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1514 - accuracy: 0.9974\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.1517 - accuracy: 0.9974 - val_loss: 0.1502 - val_accuracy: 0.9974\n",
            "Epoch 20/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1432 - accuracy: 0.9981\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1432 - accuracy: 0.9981 - val_loss: 0.1421 - val_accuracy: 0.9974\n",
            "Epoch 21/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1340 - accuracy: 1.0000\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1340 - accuracy: 1.0000 - val_loss: 0.1422 - val_accuracy: 0.9949\n",
            "Epoch 22/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1294 - accuracy: 1.0000\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1296 - accuracy: 1.0000 - val_loss: 0.1677 - val_accuracy: 0.9795\n",
            "Epoch 23/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1237 - accuracy: 1.0000\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1237 - accuracy: 1.0000 - val_loss: 0.1358 - val_accuracy: 0.9949\n",
            "Epoch 24/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1243 - accuracy: 0.9987\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1242 - accuracy: 0.9987 - val_loss: 0.1243 - val_accuracy: 0.9949\n",
            "Epoch 25/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1156 - accuracy: 0.9987\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1156 - accuracy: 0.9987 - val_loss: 0.1192 - val_accuracy: 0.9974\n",
            "Epoch 26/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1112 - accuracy: 0.9987\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1111 - accuracy: 0.9987 - val_loss: 0.1185 - val_accuracy: 0.9949\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1059 - accuracy: 1.0000\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1060 - accuracy: 1.0000 - val_loss: 0.1168 - val_accuracy: 0.9949\n",
            "Epoch 28/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1090 - accuracy: 0.9981\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1090 - accuracy: 0.9981 - val_loss: 0.1143 - val_accuracy: 0.9949\n",
            "Epoch 29/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1020 - accuracy: 1.0000\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1020 - accuracy: 1.0000 - val_loss: 0.1090 - val_accuracy: 0.9974\n",
            "Epoch 30/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0978 - accuracy: 0.9993\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0977 - accuracy: 0.9994 - val_loss: 0.1114 - val_accuracy: 0.9923\n",
            "Epoch 31/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0939 - accuracy: 1.0000\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0938 - accuracy: 1.0000 - val_loss: 0.1131 - val_accuracy: 0.9949\n",
            "Epoch 32/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0929 - accuracy: 1.0000\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.0929 - accuracy: 1.0000 - val_loss: 0.1005 - val_accuracy: 0.9974\n",
            "Epoch 33/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0892 - accuracy: 1.0000\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0893 - accuracy: 1.0000 - val_loss: 0.0992 - val_accuracy: 0.9974\n",
            "Epoch 34/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0898 - accuracy: 0.9994\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.0899 - accuracy: 0.9994 - val_loss: 0.1018 - val_accuracy: 0.9974\n",
            "Epoch 35/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0914 - accuracy: 0.9987\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0913 - accuracy: 0.9987 - val_loss: 0.0999 - val_accuracy: 0.9949\n",
            "Epoch 36/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0850 - accuracy: 0.9994\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0850 - accuracy: 0.9994 - val_loss: 0.0973 - val_accuracy: 0.9949\n",
            "Epoch 37/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0822 - accuracy: 1.0000\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0822 - accuracy: 1.0000 - val_loss: 0.0928 - val_accuracy: 0.9923\n",
            "Epoch 38/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0818 - accuracy: 0.9993\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.0817 - accuracy: 0.9994 - val_loss: 0.0909 - val_accuracy: 0.9974\n",
            "Epoch 39/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0800 - accuracy: 1.0000\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0799 - accuracy: 1.0000 - val_loss: 0.0886 - val_accuracy: 0.9923\n",
            "Epoch 40/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0788 - accuracy: 1.0000\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0787 - accuracy: 1.0000 - val_loss: 0.0953 - val_accuracy: 0.9923\n",
            "Epoch 41/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0764 - accuracy: 1.0000\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.0764 - accuracy: 1.0000 - val_loss: 0.0962 - val_accuracy: 0.9898\n",
            "Epoch 42/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0744 - accuracy: 1.0000\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0743 - accuracy: 1.0000 - val_loss: 0.0882 - val_accuracy: 0.9949\n",
            "Epoch 43/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0749 - accuracy: 1.0000\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0749 - accuracy: 1.0000 - val_loss: 0.1175 - val_accuracy: 0.9923\n",
            "Epoch 44/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0754 - accuracy: 1.0000\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0758 - accuracy: 0.9994 - val_loss: 0.0871 - val_accuracy: 0.9923\n",
            "Epoch 45/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0734 - accuracy: 1.0000\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0735 - accuracy: 1.0000 - val_loss: 0.0902 - val_accuracy: 0.9923\n",
            "Epoch 46/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0692 - accuracy: 1.0000\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0692 - accuracy: 1.0000 - val_loss: 0.0881 - val_accuracy: 0.9923\n",
            "Epoch 47/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0705 - accuracy: 0.9994\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0705 - accuracy: 0.9994 - val_loss: 0.0847 - val_accuracy: 0.9923\n",
            "Epoch 48/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0676 - accuracy: 1.0000\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0676 - accuracy: 1.0000 - val_loss: 0.0825 - val_accuracy: 0.9949\n",
            "Epoch 49/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0690 - accuracy: 0.9994\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0690 - accuracy: 0.9994 - val_loss: 0.0835 - val_accuracy: 0.9923\n",
            "Epoch 50/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0667 - accuracy: 1.0000\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0666 - accuracy: 1.0000 - val_loss: 0.0806 - val_accuracy: 0.9923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/137/assets\n",
            "\n",
            "\n",
            " 69%|██████▉   | 138/200 [5:39:34<2:31:41, 146.80s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 3.1882 - accuracy: 0.2049\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 21ms/step - loss: 3.1863 - accuracy: 0.2058 - val_loss: 1.9576 - val_accuracy: 0.2634\n",
            "Epoch 2/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 2.3907 - accuracy: 0.4272\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 2.3900 - accuracy: 0.4276 - val_loss: 1.9803 - val_accuracy: 0.2660\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 2.0908 - accuracy: 0.5771\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 2.0892 - accuracy: 0.5776 - val_loss: 1.8713 - val_accuracy: 0.4373\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.9120 - accuracy: 0.6412\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 1.9112 - accuracy: 0.6417 - val_loss: 1.7032 - val_accuracy: 0.6803\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.7608 - accuracy: 0.7040\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.7632 - accuracy: 0.7013 - val_loss: 1.6170 - val_accuracy: 0.7494\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6477 - accuracy: 0.7468\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 1.6471 - accuracy: 0.7462 - val_loss: 1.5279 - val_accuracy: 0.7698\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.5469 - accuracy: 0.7753\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.5478 - accuracy: 0.7750 - val_loss: 1.4232 - val_accuracy: 0.8261\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.4555 - accuracy: 0.8083\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 1.4549 - accuracy: 0.8083 - val_loss: 1.3416 - val_accuracy: 0.8593\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.3786 - accuracy: 0.8232\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.3783 - accuracy: 0.8231 - val_loss: 1.2758 - val_accuracy: 0.8619\n",
            "Epoch 10/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.3216 - accuracy: 0.8282\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 1.3216 - accuracy: 0.8282 - val_loss: 1.2110 - val_accuracy: 0.9079\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.2428 - accuracy: 0.8633\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.2442 - accuracy: 0.8628 - val_loss: 1.1471 - val_accuracy: 0.9258\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.1967 - accuracy: 0.8731\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.1963 - accuracy: 0.8737 - val_loss: 1.0959 - val_accuracy: 0.9309\n",
            "Epoch 13/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.1446 - accuracy: 0.8821\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 1.1448 - accuracy: 0.8821 - val_loss: 1.0458 - val_accuracy: 0.9386\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.0937 - accuracy: 0.9048\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.0929 - accuracy: 0.9058 - val_loss: 1.0055 - val_accuracy: 0.9386\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.0416 - accuracy: 0.9223\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.0410 - accuracy: 0.9224 - val_loss: 0.9765 - val_accuracy: 0.9514\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.0109 - accuracy: 0.9229\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.0118 - accuracy: 0.9218 - val_loss: 0.9342 - val_accuracy: 0.9591\n",
            "Epoch 17/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.9719 - accuracy: 0.9349\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.9726 - accuracy: 0.9346 - val_loss: 0.9051 - val_accuracy: 0.9693\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.9394 - accuracy: 0.9398\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.9403 - accuracy: 0.9391 - val_loss: 0.8697 - val_accuracy: 0.9668\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.9032 - accuracy: 0.9462\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.9027 - accuracy: 0.9462 - val_loss: 0.8397 - val_accuracy: 0.9668\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8918 - accuracy: 0.9456\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.8908 - accuracy: 0.9462 - val_loss: 0.8162 - val_accuracy: 0.9668\n",
            "Epoch 21/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.8471 - accuracy: 0.9613\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.8488 - accuracy: 0.9609 - val_loss: 0.7931 - val_accuracy: 0.9795\n",
            "Epoch 22/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.8348 - accuracy: 0.9607\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.8346 - accuracy: 0.9609 - val_loss: 0.7699 - val_accuracy: 0.9744\n",
            "Epoch 23/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.8059 - accuracy: 0.9652\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.8061 - accuracy: 0.9654 - val_loss: 0.7527 - val_accuracy: 0.9770\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7759 - accuracy: 0.9767\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.7761 - accuracy: 0.9763 - val_loss: 0.7318 - val_accuracy: 0.9770\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7711 - accuracy: 0.9715\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.7713 - accuracy: 0.9712 - val_loss: 0.7139 - val_accuracy: 0.9770\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7444 - accuracy: 0.9741\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.7449 - accuracy: 0.9744 - val_loss: 0.7001 - val_accuracy: 0.9847\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7247 - accuracy: 0.9845\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.7257 - accuracy: 0.9833 - val_loss: 0.6844 - val_accuracy: 0.9872\n",
            "Epoch 28/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.7153 - accuracy: 0.9768\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.7162 - accuracy: 0.9763 - val_loss: 0.6696 - val_accuracy: 0.9872\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6943 - accuracy: 0.9819\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.6940 - accuracy: 0.9814 - val_loss: 0.6520 - val_accuracy: 0.9847\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6807 - accuracy: 0.9838\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.6812 - accuracy: 0.9840 - val_loss: 0.6456 - val_accuracy: 0.9923\n",
            "Epoch 31/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.6665 - accuracy: 0.9845\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.6658 - accuracy: 0.9846 - val_loss: 0.6335 - val_accuracy: 0.9898\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6502 - accuracy: 0.9806\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.6511 - accuracy: 0.9801 - val_loss: 0.6172 - val_accuracy: 0.9923\n",
            "Epoch 33/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6421 - accuracy: 0.9838\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.6417 - accuracy: 0.9840 - val_loss: 0.6117 - val_accuracy: 0.9898\n",
            "Epoch 34/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6250 - accuracy: 0.9883\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.6253 - accuracy: 0.9885 - val_loss: 0.5964 - val_accuracy: 0.9898\n",
            "Epoch 35/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6205 - accuracy: 0.9819\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.6207 - accuracy: 0.9821 - val_loss: 0.5878 - val_accuracy: 0.9898\n",
            "Epoch 36/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.6039 - accuracy: 0.9890\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.6042 - accuracy: 0.9891 - val_loss: 0.5734 - val_accuracy: 0.9949\n",
            "Epoch 37/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5890 - accuracy: 0.9890\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.5897 - accuracy: 0.9891 - val_loss: 0.5645 - val_accuracy: 0.9898\n",
            "Epoch 38/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5774 - accuracy: 0.9903\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.5772 - accuracy: 0.9904 - val_loss: 0.5555 - val_accuracy: 0.9923\n",
            "Epoch 39/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5702 - accuracy: 0.9890\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.5697 - accuracy: 0.9891 - val_loss: 0.5485 - val_accuracy: 0.9923\n",
            "Epoch 40/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5581 - accuracy: 0.9935\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.5582 - accuracy: 0.9936 - val_loss: 0.5429 - val_accuracy: 0.9898\n",
            "Epoch 41/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5534 - accuracy: 0.9942\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.5528 - accuracy: 0.9942 - val_loss: 0.5257 - val_accuracy: 0.9949\n",
            "Epoch 42/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.5448 - accuracy: 0.9890\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.5445 - accuracy: 0.9891 - val_loss: 0.5263 - val_accuracy: 0.9923\n",
            "Epoch 43/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5331 - accuracy: 0.9935\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.5330 - accuracy: 0.9929 - val_loss: 0.5111 - val_accuracy: 0.9949\n",
            "Epoch 44/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5255 - accuracy: 0.9909\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.5254 - accuracy: 0.9910 - val_loss: 0.5080 - val_accuracy: 0.9949\n",
            "Epoch 45/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.5169 - accuracy: 0.9936\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.5168 - accuracy: 0.9936 - val_loss: 0.5004 - val_accuracy: 0.9898\n",
            "Epoch 46/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5078 - accuracy: 0.9909\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.5081 - accuracy: 0.9910 - val_loss: 0.4911 - val_accuracy: 0.9923\n",
            "Epoch 47/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.5007 - accuracy: 0.9916\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.5005 - accuracy: 0.9917 - val_loss: 0.4828 - val_accuracy: 0.9949\n",
            "Epoch 48/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4923 - accuracy: 0.9955\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.4922 - accuracy: 0.9955 - val_loss: 0.4795 - val_accuracy: 0.9923\n",
            "Epoch 49/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4840 - accuracy: 0.9948\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.4842 - accuracy: 0.9949 - val_loss: 0.4710 - val_accuracy: 0.9923\n",
            "Epoch 50/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4750 - accuracy: 0.9955\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.4746 - accuracy: 0.9955 - val_loss: 0.4656 - val_accuracy: 0.9923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/138/assets\n",
            "\n",
            "\n",
            " 70%|██████▉   | 139/200 [5:43:02<2:47:41, 164.94s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 2.1174 - accuracy: 0.2494\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 25ms/step - loss: 2.1174 - accuracy: 0.2494 - val_loss: 1.7028 - val_accuracy: 0.2634\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.7046 - accuracy: 0.2908\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.7029 - accuracy: 0.2917 - val_loss: 1.6886 - val_accuracy: 0.2864\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6803 - accuracy: 0.2714\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6795 - accuracy: 0.2699 - val_loss: 1.6665 - val_accuracy: 0.2634\n",
            "Epoch 4/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6630 - accuracy: 0.2833\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6630 - accuracy: 0.2833 - val_loss: 1.6556 - val_accuracy: 0.2864\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6560 - accuracy: 0.2753\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6556 - accuracy: 0.2750 - val_loss: 1.6499 - val_accuracy: 0.2864\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6497 - accuracy: 0.2798\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 1.6497 - accuracy: 0.2788 - val_loss: 1.6458 - val_accuracy: 0.2864\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6476 - accuracy: 0.2740\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6469 - accuracy: 0.2756 - val_loss: 1.6419 - val_accuracy: 0.2864\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6422 - accuracy: 0.2856\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 1.6432 - accuracy: 0.2859 - val_loss: 1.6396 - val_accuracy: 0.2864\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6413 - accuracy: 0.2766\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6408 - accuracy: 0.2763 - val_loss: 1.6369 - val_accuracy: 0.2864\n",
            "Epoch 10/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6377 - accuracy: 0.2859\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 1.6377 - accuracy: 0.2859 - val_loss: 1.6342 - val_accuracy: 0.2864\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6379 - accuracy: 0.2759\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6365 - accuracy: 0.2776 - val_loss: 1.6325 - val_accuracy: 0.2864\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6344 - accuracy: 0.2785\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6349 - accuracy: 0.2788 - val_loss: 1.6317 - val_accuracy: 0.2864\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6368 - accuracy: 0.2707\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6347 - accuracy: 0.2718 - val_loss: 1.6311 - val_accuracy: 0.2864\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6331 - accuracy: 0.2869\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6329 - accuracy: 0.2859 - val_loss: 1.6297 - val_accuracy: 0.2864\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6319 - accuracy: 0.2785\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6316 - accuracy: 0.2795 - val_loss: 1.6292 - val_accuracy: 0.2864\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6323 - accuracy: 0.2778\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6312 - accuracy: 0.2776 - val_loss: 1.6285 - val_accuracy: 0.2634\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6321 - accuracy: 0.2759\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6338 - accuracy: 0.2750 - val_loss: 1.6280 - val_accuracy: 0.2634\n",
            "Epoch 18/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6298 - accuracy: 0.2827\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6298 - accuracy: 0.2827 - val_loss: 1.6275 - val_accuracy: 0.2864\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6280 - accuracy: 0.2798\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 1.6290 - accuracy: 0.2795 - val_loss: 1.6263 - val_accuracy: 0.2864\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6287 - accuracy: 0.2863\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6283 - accuracy: 0.2859 - val_loss: 1.6264 - val_accuracy: 0.2864\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6330 - accuracy: 0.2882\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6346 - accuracy: 0.2865 - val_loss: 1.6257 - val_accuracy: 0.2864\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6354 - accuracy: 0.2740\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6344 - accuracy: 0.2750 - val_loss: 1.6258 - val_accuracy: 0.2864\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6275 - accuracy: 0.2876\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6283 - accuracy: 0.2859 - val_loss: 1.6256 - val_accuracy: 0.2864\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6278 - accuracy: 0.2759\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6278 - accuracy: 0.2750 - val_loss: 1.6255 - val_accuracy: 0.2864\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6278 - accuracy: 0.2856\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6272 - accuracy: 0.2859 - val_loss: 1.6253 - val_accuracy: 0.2864\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6290 - accuracy: 0.2804\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6273 - accuracy: 0.2827 - val_loss: 1.6249 - val_accuracy: 0.2864\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6283 - accuracy: 0.2785\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6273 - accuracy: 0.2788 - val_loss: 1.6257 - val_accuracy: 0.2864\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6317 - accuracy: 0.2837\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6299 - accuracy: 0.2859 - val_loss: 1.6246 - val_accuracy: 0.2864\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6262 - accuracy: 0.2753\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6272 - accuracy: 0.2776 - val_loss: 1.6250 - val_accuracy: 0.2864\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6260 - accuracy: 0.2785\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6275 - accuracy: 0.2776 - val_loss: 1.6242 - val_accuracy: 0.2864\n",
            "Epoch 31/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6269 - accuracy: 0.2785\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6273 - accuracy: 0.2795 - val_loss: 1.6242 - val_accuracy: 0.2864\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6274 - accuracy: 0.2733\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6274 - accuracy: 0.2737 - val_loss: 1.6245 - val_accuracy: 0.2864\n",
            "Epoch 33/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6273 - accuracy: 0.2876\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6275 - accuracy: 0.2859 - val_loss: 1.6241 - val_accuracy: 0.2864\n",
            "Epoch 34/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6245 - accuracy: 0.2791\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6271 - accuracy: 0.2801 - val_loss: 1.6242 - val_accuracy: 0.2864\n",
            "Epoch 35/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6272 - accuracy: 0.2746\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6286 - accuracy: 0.2744 - val_loss: 1.6247 - val_accuracy: 0.2864\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6240 - accuracy: 0.2876\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6267 - accuracy: 0.2859 - val_loss: 1.6242 - val_accuracy: 0.2864\n",
            "Epoch 37/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6296 - accuracy: 0.2824\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6274 - accuracy: 0.2859 - val_loss: 1.6244 - val_accuracy: 0.2864\n",
            "Epoch 38/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6261 - accuracy: 0.2859\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6261 - accuracy: 0.2859 - val_loss: 1.6241 - val_accuracy: 0.2864\n",
            "Epoch 38: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/139/assets\n",
            "\n",
            "\n",
            " 70%|███████   | 140/200 [5:45:52<2:46:38, 166.64s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.3178 - accuracy: 0.5699\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 12ms/step - loss: 1.3184 - accuracy: 0.5712 - val_loss: 1.9061 - val_accuracy: 0.1714\n",
            "Epoch 2/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 0.6339 - accuracy: 0.8439\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.6264 - accuracy: 0.8468 - val_loss: 1.5340 - val_accuracy: 0.3990\n",
            "Epoch 3/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4029 - accuracy: 0.8982\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.4019 - accuracy: 0.8987 - val_loss: 0.5677 - val_accuracy: 0.8107\n",
            "Epoch 4/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.5370 - accuracy: 0.8782\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.5362 - accuracy: 0.8788 - val_loss: 1.1462 - val_accuracy: 0.8159\n",
            "Epoch 5/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3236 - accuracy: 0.9271\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.3230 - accuracy: 0.9276 - val_loss: 0.3328 - val_accuracy: 0.9488\n",
            "Epoch 6/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2630 - accuracy: 0.9504\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.2629 - accuracy: 0.9506 - val_loss: 0.5285 - val_accuracy: 0.8159\n",
            "Epoch 7/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2930 - accuracy: 0.9434\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.2911 - accuracy: 0.9442 - val_loss: 0.5970 - val_accuracy: 0.9028\n",
            "Epoch 8/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2339 - accuracy: 0.9588\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.2343 - accuracy: 0.9583 - val_loss: 0.3451 - val_accuracy: 0.9335\n",
            "Epoch 9/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1971 - accuracy: 0.9620\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.1964 - accuracy: 0.9622 - val_loss: 0.2319 - val_accuracy: 0.9693\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2131 - accuracy: 0.9598\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.2140 - accuracy: 0.9596 - val_loss: 0.5936 - val_accuracy: 0.8798\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3499 - accuracy: 0.9255\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.3497 - accuracy: 0.9256 - val_loss: 0.7339 - val_accuracy: 0.7749\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2465 - accuracy: 0.9611\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.2456 - accuracy: 0.9615 - val_loss: 0.2744 - val_accuracy: 0.9591\n",
            "Epoch 13/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5811 - accuracy: 0.8840\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.5811 - accuracy: 0.8840 - val_loss: 0.8266 - val_accuracy: 0.8056\n",
            "Epoch 14/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.3714 - accuracy: 0.9260\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.3682 - accuracy: 0.9276 - val_loss: 0.3044 - val_accuracy: 0.9284\n",
            "Epoch 14: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/140/assets\n",
            "\n",
            "\n",
            " 70%|███████   | 141/200 [5:46:38<2:08:20, 130.52s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 2.1960 - accuracy: 0.3711\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 26ms/step - loss: 2.1923 - accuracy: 0.3731 - val_loss: 1.7995 - val_accuracy: 0.2634\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.7125 - accuracy: 0.6276\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 1.7094 - accuracy: 0.6282 - val_loss: 1.7228 - val_accuracy: 0.4476\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.3552 - accuracy: 0.7720\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 1.3560 - accuracy: 0.7712 - val_loss: 1.5209 - val_accuracy: 0.4399\n",
            "Epoch 4/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.0591 - accuracy: 0.8686\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 1.0591 - accuracy: 0.8686 - val_loss: 0.9826 - val_accuracy: 0.8926\n",
            "Epoch 5/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.8686 - accuracy: 0.9244\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.8686 - accuracy: 0.9244 - val_loss: 0.7818 - val_accuracy: 0.9540\n",
            "Epoch 6/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.7338 - accuracy: 0.9558\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.7338 - accuracy: 0.9558 - val_loss: 0.6847 - val_accuracy: 0.9693\n",
            "Epoch 7/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6474 - accuracy: 0.9699\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.6474 - accuracy: 0.9699 - val_loss: 0.6066 - val_accuracy: 0.9821\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5803 - accuracy: 0.9793\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.5795 - accuracy: 0.9795 - val_loss: 0.5492 - val_accuracy: 0.9847\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5240 - accuracy: 0.9838\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.5237 - accuracy: 0.9840 - val_loss: 0.5088 - val_accuracy: 0.9923\n",
            "Epoch 10/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4896 - accuracy: 0.9865\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.4896 - accuracy: 0.9865 - val_loss: 0.4745 - val_accuracy: 0.9898\n",
            "Epoch 11/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4497 - accuracy: 0.9936\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.4497 - accuracy: 0.9936 - val_loss: 0.4498 - val_accuracy: 0.9898\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4226 - accuracy: 0.9935\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.4229 - accuracy: 0.9936 - val_loss: 0.4140 - val_accuracy: 0.9974\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4004 - accuracy: 0.9929\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.4002 - accuracy: 0.9929 - val_loss: 0.3954 - val_accuracy: 0.9974\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3776 - accuracy: 0.9955\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.3775 - accuracy: 0.9955 - val_loss: 0.3726 - val_accuracy: 0.9974\n",
            "Epoch 15/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3579 - accuracy: 0.9974\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.3579 - accuracy: 0.9974 - val_loss: 0.3591 - val_accuracy: 0.9974\n",
            "Epoch 16/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3416 - accuracy: 0.9981\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.3416 - accuracy: 0.9981 - val_loss: 0.3388 - val_accuracy: 0.9974\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3294 - accuracy: 0.9961\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.3292 - accuracy: 0.9962 - val_loss: 0.3258 - val_accuracy: 0.9949\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3153 - accuracy: 0.9987\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.3152 - accuracy: 0.9987 - val_loss: 0.3118 - val_accuracy: 0.9974\n",
            "Epoch 19/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3035 - accuracy: 0.9987\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.3035 - accuracy: 0.9987 - val_loss: 0.3047 - val_accuracy: 0.9974\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2950 - accuracy: 0.9968\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.2946 - accuracy: 0.9968 - val_loss: 0.2927 - val_accuracy: 0.9974\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2842 - accuracy: 0.9994\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.2844 - accuracy: 0.9994 - val_loss: 0.2854 - val_accuracy: 0.9974\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2723 - accuracy: 0.9987\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.2724 - accuracy: 0.9987 - val_loss: 0.2765 - val_accuracy: 0.9974\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2666 - accuracy: 1.0000\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.2665 - accuracy: 1.0000 - val_loss: 0.2671 - val_accuracy: 0.9974\n",
            "Epoch 24/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2540 - accuracy: 1.0000\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.2540 - accuracy: 1.0000 - val_loss: 0.2622 - val_accuracy: 0.9949\n",
            "Epoch 25/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2470 - accuracy: 0.9994\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.2470 - accuracy: 0.9994 - val_loss: 0.2529 - val_accuracy: 0.9974\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2413 - accuracy: 0.9994\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.2414 - accuracy: 0.9994 - val_loss: 0.2471 - val_accuracy: 0.9949\n",
            "Epoch 27/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2319 - accuracy: 0.9994\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.2319 - accuracy: 0.9994 - val_loss: 0.2384 - val_accuracy: 0.9949\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2282 - accuracy: 0.9994\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.2285 - accuracy: 0.9994 - val_loss: 0.2350 - val_accuracy: 0.9949\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2211 - accuracy: 1.0000\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.2209 - accuracy: 1.0000 - val_loss: 0.2288 - val_accuracy: 0.9974\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2181 - accuracy: 0.9968\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.2179 - accuracy: 0.9968 - val_loss: 0.2211 - val_accuracy: 0.9949\n",
            "Epoch 31/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2100 - accuracy: 0.9994\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.2100 - accuracy: 0.9994 - val_loss: 0.2160 - val_accuracy: 0.9974\n",
            "Epoch 32/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2063 - accuracy: 0.9987\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.2063 - accuracy: 0.9987 - val_loss: 0.2094 - val_accuracy: 0.9974\n",
            "Epoch 33/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1990 - accuracy: 0.9994\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1989 - accuracy: 0.9994 - val_loss: 0.2059 - val_accuracy: 0.9974\n",
            "Epoch 34/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1966 - accuracy: 0.9987\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1966 - accuracy: 0.9987 - val_loss: 0.2028 - val_accuracy: 0.9974\n",
            "Epoch 35/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1899 - accuracy: 1.0000\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.1899 - accuracy: 1.0000 - val_loss: 0.1991 - val_accuracy: 0.9949\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1876 - accuracy: 0.9987\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1877 - accuracy: 0.9987 - val_loss: 0.2018 - val_accuracy: 0.9949\n",
            "Epoch 37/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1823 - accuracy: 0.9994\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1823 - accuracy: 0.9994 - val_loss: 0.1903 - val_accuracy: 0.9974\n",
            "Epoch 38/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1783 - accuracy: 0.9994\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1783 - accuracy: 0.9994 - val_loss: 0.1870 - val_accuracy: 0.9974\n",
            "Epoch 39/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1750 - accuracy: 0.9994\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1750 - accuracy: 0.9994 - val_loss: 0.1825 - val_accuracy: 0.9949\n",
            "Epoch 40/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1694 - accuracy: 1.0000\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1694 - accuracy: 1.0000 - val_loss: 0.1783 - val_accuracy: 0.9974\n",
            "Epoch 41/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1694 - accuracy: 0.9987\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1694 - accuracy: 0.9987 - val_loss: 0.1803 - val_accuracy: 0.9949\n",
            "Epoch 42/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1639 - accuracy: 0.9987\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1639 - accuracy: 0.9987 - val_loss: 0.1742 - val_accuracy: 0.9949\n",
            "Epoch 43/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1617 - accuracy: 0.9994\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1616 - accuracy: 0.9994 - val_loss: 0.1700 - val_accuracy: 0.9949\n",
            "Epoch 44/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1570 - accuracy: 1.0000\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1572 - accuracy: 1.0000 - val_loss: 0.1679 - val_accuracy: 0.9949\n",
            "Epoch 45/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1552 - accuracy: 0.9987\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1551 - accuracy: 0.9987 - val_loss: 0.1646 - val_accuracy: 0.9949\n",
            "Epoch 46/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1518 - accuracy: 1.0000\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1518 - accuracy: 1.0000 - val_loss: 0.1623 - val_accuracy: 0.9974\n",
            "Epoch 47/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1477 - accuracy: 1.0000\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1476 - accuracy: 1.0000 - val_loss: 0.1599 - val_accuracy: 0.9949\n",
            "Epoch 48/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1465 - accuracy: 0.9994\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1464 - accuracy: 0.9994 - val_loss: 0.1645 - val_accuracy: 0.9949\n",
            "Epoch 49/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1428 - accuracy: 1.0000\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1428 - accuracy: 1.0000 - val_loss: 0.1537 - val_accuracy: 0.9949\n",
            "Epoch 50/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1411 - accuracy: 1.0000\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1411 - accuracy: 1.0000 - val_loss: 0.1512 - val_accuracy: 0.9949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/141/assets\n",
            "\n",
            "\n",
            " 71%|███████   | 142/200 [5:50:36<2:37:18, 162.74s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.3923 - accuracy: 0.6250\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 19ms/step - loss: 1.3908 - accuracy: 0.6256 - val_loss: 1.6501 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.5535 - accuracy: 0.9473\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.5517 - accuracy: 0.9481 - val_loss: 1.4613 - val_accuracy: 0.5524\n",
            "Epoch 3/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3699 - accuracy: 0.9859\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.3699 - accuracy: 0.9859 - val_loss: 0.9084 - val_accuracy: 0.7417\n",
            "Epoch 4/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2901 - accuracy: 0.9922\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.2903 - accuracy: 0.9923 - val_loss: 0.2888 - val_accuracy: 0.9847\n",
            "Epoch 5/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2466 - accuracy: 0.9948\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.2461 - accuracy: 0.9949 - val_loss: 0.2299 - val_accuracy: 0.9847\n",
            "Epoch 6/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2096 - accuracy: 0.9967\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.2093 - accuracy: 0.9968 - val_loss: 0.2078 - val_accuracy: 0.9872\n",
            "Epoch 7/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1948 - accuracy: 0.9967\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1946 - accuracy: 0.9968 - val_loss: 0.1735 - val_accuracy: 0.9974\n",
            "Epoch 8/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1632 - accuracy: 0.9987\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.1630 - accuracy: 0.9987 - val_loss: 0.1667 - val_accuracy: 0.9923\n",
            "Epoch 9/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1488 - accuracy: 0.9980\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1487 - accuracy: 0.9981 - val_loss: 0.1425 - val_accuracy: 0.9949\n",
            "Epoch 10/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1398 - accuracy: 0.9974\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.1397 - accuracy: 0.9974 - val_loss: 0.1384 - val_accuracy: 0.9949\n",
            "Epoch 11/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1230 - accuracy: 1.0000\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1230 - accuracy: 1.0000 - val_loss: 0.1249 - val_accuracy: 0.9949\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1200 - accuracy: 0.9981\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1202 - accuracy: 0.9981 - val_loss: 0.1223 - val_accuracy: 0.9974\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1071 - accuracy: 1.0000\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.1070 - accuracy: 1.0000 - val_loss: 0.1211 - val_accuracy: 0.9898\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0984 - accuracy: 0.9994\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0983 - accuracy: 0.9994 - val_loss: 0.1063 - val_accuracy: 0.9949\n",
            "Epoch 15/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0973 - accuracy: 0.9981\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0973 - accuracy: 0.9981 - val_loss: 0.1699 - val_accuracy: 0.9795\n",
            "Epoch 16/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0910 - accuracy: 0.9993\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0907 - accuracy: 0.9994 - val_loss: 0.0924 - val_accuracy: 0.9974\n",
            "Epoch 17/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0859 - accuracy: 0.9987\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0859 - accuracy: 0.9987 - val_loss: 0.1027 - val_accuracy: 0.9949\n",
            "Epoch 18/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0801 - accuracy: 0.9994\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0801 - accuracy: 0.9994 - val_loss: 0.0939 - val_accuracy: 0.9949\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0833 - accuracy: 0.9987\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0832 - accuracy: 0.9987 - val_loss: 0.0868 - val_accuracy: 0.9949\n",
            "Epoch 20/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0760 - accuracy: 0.9980\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0759 - accuracy: 0.9981 - val_loss: 0.0820 - val_accuracy: 0.9949\n",
            "Epoch 21/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0701 - accuracy: 1.0000\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0701 - accuracy: 1.0000 - val_loss: 0.0768 - val_accuracy: 0.9974\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0692 - accuracy: 0.9994\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0692 - accuracy: 0.9994 - val_loss: 0.0783 - val_accuracy: 0.9923\n",
            "Epoch 23/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0651 - accuracy: 0.9994\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0651 - accuracy: 0.9994 - val_loss: 0.0724 - val_accuracy: 0.9949\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0619 - accuracy: 1.0000\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0619 - accuracy: 1.0000 - val_loss: 0.0713 - val_accuracy: 0.9974\n",
            "Epoch 25/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0613 - accuracy: 1.0000\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0613 - accuracy: 1.0000 - val_loss: 0.0753 - val_accuracy: 0.9974\n",
            "Epoch 26/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0599 - accuracy: 1.0000\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0599 - accuracy: 1.0000 - val_loss: 0.0667 - val_accuracy: 0.9974\n",
            "Epoch 27/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0584 - accuracy: 0.9993\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0583 - accuracy: 0.9994 - val_loss: 0.0656 - val_accuracy: 0.9949\n",
            "Epoch 28/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0569 - accuracy: 0.9993\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0568 - accuracy: 0.9994 - val_loss: 0.0710 - val_accuracy: 0.9949\n",
            "Epoch 29/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0542 - accuracy: 1.0000\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0542 - accuracy: 1.0000 - val_loss: 0.0637 - val_accuracy: 0.9949\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0538 - accuracy: 1.0000\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0538 - accuracy: 1.0000 - val_loss: 0.0620 - val_accuracy: 0.9974\n",
            "Epoch 31/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0521 - accuracy: 1.0000\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0521 - accuracy: 1.0000 - val_loss: 0.0602 - val_accuracy: 0.9974\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0497 - accuracy: 1.0000\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0497 - accuracy: 1.0000 - val_loss: 0.0588 - val_accuracy: 0.9949\n",
            "Epoch 33/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0486 - accuracy: 1.0000\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0486 - accuracy: 1.0000 - val_loss: 0.0579 - val_accuracy: 0.9949\n",
            "Epoch 34/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0468 - accuracy: 1.0000\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0468 - accuracy: 1.0000 - val_loss: 0.0545 - val_accuracy: 0.9949\n",
            "Epoch 35/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0453 - accuracy: 1.0000\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0453 - accuracy: 1.0000 - val_loss: 0.0551 - val_accuracy: 0.9949\n",
            "Epoch 36/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0442 - accuracy: 1.0000\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0442 - accuracy: 1.0000 - val_loss: 0.0562 - val_accuracy: 0.9974\n",
            "Epoch 37/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0439 - accuracy: 1.0000\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0439 - accuracy: 1.0000 - val_loss: 0.0633 - val_accuracy: 0.9923\n",
            "Epoch 38/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0434 - accuracy: 1.0000\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0434 - accuracy: 1.0000 - val_loss: 0.0524 - val_accuracy: 0.9923\n",
            "Epoch 39/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0421 - accuracy: 1.0000\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0421 - accuracy: 1.0000 - val_loss: 0.0542 - val_accuracy: 0.9949\n",
            "Epoch 40/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0424 - accuracy: 1.0000\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0424 - accuracy: 1.0000 - val_loss: 0.0516 - val_accuracy: 0.9949\n",
            "Epoch 41/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0407 - accuracy: 1.0000\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.0408 - accuracy: 1.0000 - val_loss: 0.0581 - val_accuracy: 0.9898\n",
            "Epoch 42/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0391 - accuracy: 1.0000\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0391 - accuracy: 1.0000 - val_loss: 0.0525 - val_accuracy: 0.9949\n",
            "Epoch 43/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0381 - accuracy: 1.0000\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0382 - accuracy: 1.0000 - val_loss: 0.0575 - val_accuracy: 0.9923\n",
            "Epoch 44/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0461 - accuracy: 0.9974\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0461 - accuracy: 0.9974 - val_loss: 0.2629 - val_accuracy: 0.9284\n",
            "Epoch 45/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0477 - accuracy: 0.9987\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0476 - accuracy: 0.9987 - val_loss: 0.0700 - val_accuracy: 0.9872\n",
            "Epoch 45: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/142/assets\n",
            "\n",
            "\n",
            " 72%|███████▏  | 143/200 [5:53:06<2:30:49, 158.76s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 2.9513 - accuracy: 0.3473\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 25ms/step - loss: 2.9503 - accuracy: 0.3474 - val_loss: 1.8776 - val_accuracy: 0.2634\n",
            "Epoch 2/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 2.3314 - accuracy: 0.5250\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 2.3314 - accuracy: 0.5250 - val_loss: 1.8951 - val_accuracy: 0.3555\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.9808 - accuracy: 0.6444\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 1.9797 - accuracy: 0.6455 - val_loss: 1.6890 - val_accuracy: 0.5652\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.7109 - accuracy: 0.7183\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 1.7095 - accuracy: 0.7186 - val_loss: 1.4235 - val_accuracy: 0.7724\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.4839 - accuracy: 0.8005\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 1.4826 - accuracy: 0.8006 - val_loss: 1.2714 - val_accuracy: 0.8900\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.3236 - accuracy: 0.8452\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 1.3241 - accuracy: 0.8442 - val_loss: 1.1357 - val_accuracy: 0.9105\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.1736 - accuracy: 0.9016\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 1.1729 - accuracy: 0.9019 - val_loss: 1.0293 - val_accuracy: 0.9361\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.0840 - accuracy: 0.9203\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 1.0828 - accuracy: 0.9205 - val_loss: 0.9455 - val_accuracy: 0.9668\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.9984 - accuracy: 0.9449\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.9971 - accuracy: 0.9449 - val_loss: 0.8704 - val_accuracy: 0.9719\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.9402 - accuracy: 0.9534\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.9405 - accuracy: 0.9532 - val_loss: 0.8243 - val_accuracy: 0.9847\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8832 - accuracy: 0.9663\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.8839 - accuracy: 0.9654 - val_loss: 0.7830 - val_accuracy: 0.9821\n",
            "Epoch 12/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.8345 - accuracy: 0.9776\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.8345 - accuracy: 0.9776 - val_loss: 0.7426 - val_accuracy: 0.9898\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7873 - accuracy: 0.9838\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.7873 - accuracy: 0.9840 - val_loss: 0.7110 - val_accuracy: 0.9898\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7589 - accuracy: 0.9825\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.7595 - accuracy: 0.9827 - val_loss: 0.6845 - val_accuracy: 0.9949\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7276 - accuracy: 0.9864\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.7268 - accuracy: 0.9865 - val_loss: 0.6520 - val_accuracy: 0.9923\n",
            "Epoch 16/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6973 - accuracy: 0.9859\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.6973 - accuracy: 0.9859 - val_loss: 0.6297 - val_accuracy: 0.9949\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6678 - accuracy: 0.9929\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.6683 - accuracy: 0.9929 - val_loss: 0.6094 - val_accuracy: 0.9898\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6445 - accuracy: 0.9948\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.6459 - accuracy: 0.9942 - val_loss: 0.5841 - val_accuracy: 0.9898\n",
            "Epoch 19/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6246 - accuracy: 0.9936\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.6246 - accuracy: 0.9936 - val_loss: 0.5688 - val_accuracy: 0.9923\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6031 - accuracy: 0.9961\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.6027 - accuracy: 0.9962 - val_loss: 0.5493 - val_accuracy: 0.9949\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5820 - accuracy: 0.9955\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.5828 - accuracy: 0.9955 - val_loss: 0.5374 - val_accuracy: 0.9923\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5656 - accuracy: 0.9916\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.5655 - accuracy: 0.9917 - val_loss: 0.5214 - val_accuracy: 0.9949\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5448 - accuracy: 0.9955\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.5455 - accuracy: 0.9955 - val_loss: 0.5010 - val_accuracy: 0.9923\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5293 - accuracy: 0.9961\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.5284 - accuracy: 0.9962 - val_loss: 0.4872 - val_accuracy: 0.9974\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5132 - accuracy: 0.9968\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.5127 - accuracy: 0.9968 - val_loss: 0.4723 - val_accuracy: 0.9974\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4988 - accuracy: 0.9968\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.4985 - accuracy: 0.9968 - val_loss: 0.4612 - val_accuracy: 0.9923\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4805 - accuracy: 0.9981\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.4806 - accuracy: 0.9981 - val_loss: 0.4446 - val_accuracy: 0.9923\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4669 - accuracy: 0.9961\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.4667 - accuracy: 0.9962 - val_loss: 0.4360 - val_accuracy: 0.9923\n",
            "Epoch 29/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4559 - accuracy: 0.9974\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.4559 - accuracy: 0.9974 - val_loss: 0.4279 - val_accuracy: 0.9923\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4421 - accuracy: 0.9974\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.4428 - accuracy: 0.9968 - val_loss: 0.4120 - val_accuracy: 0.9923\n",
            "Epoch 31/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4305 - accuracy: 0.9974\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.4303 - accuracy: 0.9974 - val_loss: 0.4003 - val_accuracy: 0.9923\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4169 - accuracy: 0.9974\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.4170 - accuracy: 0.9974 - val_loss: 0.3911 - val_accuracy: 0.9974\n",
            "Epoch 33/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4083 - accuracy: 0.9987\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.4082 - accuracy: 0.9987 - val_loss: 0.3803 - val_accuracy: 0.9923\n",
            "Epoch 34/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3965 - accuracy: 0.9994\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.3965 - accuracy: 0.9994 - val_loss: 0.3680 - val_accuracy: 0.9949\n",
            "Epoch 35/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3886 - accuracy: 0.9974\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.3881 - accuracy: 0.9974 - val_loss: 0.3605 - val_accuracy: 0.9923\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3768 - accuracy: 0.9974\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.3769 - accuracy: 0.9974 - val_loss: 0.3483 - val_accuracy: 0.9949\n",
            "Epoch 37/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3681 - accuracy: 0.9987\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.3680 - accuracy: 0.9987 - val_loss: 0.3455 - val_accuracy: 0.9949\n",
            "Epoch 38/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3582 - accuracy: 0.9987\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.3580 - accuracy: 0.9987 - val_loss: 0.3380 - val_accuracy: 0.9949\n",
            "Epoch 39/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3489 - accuracy: 0.9994\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.3489 - accuracy: 0.9994 - val_loss: 0.3299 - val_accuracy: 0.9923\n",
            "Epoch 40/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3370 - accuracy: 0.9994\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.3370 - accuracy: 0.9994 - val_loss: 0.3235 - val_accuracy: 0.9923\n",
            "Epoch 41/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3315 - accuracy: 0.9987\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.3312 - accuracy: 0.9987 - val_loss: 0.3152 - val_accuracy: 0.9923\n",
            "Epoch 42/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3285 - accuracy: 0.9981\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.3281 - accuracy: 0.9981 - val_loss: 0.3069 - val_accuracy: 0.9949\n",
            "Epoch 43/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3196 - accuracy: 0.9981\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.3197 - accuracy: 0.9981 - val_loss: 0.3026 - val_accuracy: 0.9949\n",
            "Epoch 44/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3093 - accuracy: 0.9994\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.3096 - accuracy: 0.9994 - val_loss: 0.2996 - val_accuracy: 0.9949\n",
            "Epoch 45/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3012 - accuracy: 1.0000\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.3010 - accuracy: 1.0000 - val_loss: 0.2871 - val_accuracy: 0.9949\n",
            "Epoch 46/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2958 - accuracy: 0.9987\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2958 - accuracy: 0.9987 - val_loss: 0.2823 - val_accuracy: 0.9949\n",
            "Epoch 47/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2877 - accuracy: 0.9987\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.2876 - accuracy: 0.9987 - val_loss: 0.2728 - val_accuracy: 0.9949\n",
            "Epoch 48/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2812 - accuracy: 1.0000\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.2809 - accuracy: 1.0000 - val_loss: 0.2729 - val_accuracy: 0.9949\n",
            "Epoch 49/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2751 - accuracy: 0.9994\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.2752 - accuracy: 0.9994 - val_loss: 0.2613 - val_accuracy: 0.9949\n",
            "Epoch 50/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2662 - accuracy: 1.0000\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.2662 - accuracy: 1.0000 - val_loss: 0.2600 - val_accuracy: 0.9949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/143/assets\n",
            "\n",
            "\n",
            " 72%|███████▏  | 144/200 [5:57:33<2:58:31, 191.28s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 2.0290 - accuracy: 0.2660\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 24ms/step - loss: 2.0290 - accuracy: 0.2660 - val_loss: 1.8217 - val_accuracy: 0.1535\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.7249 - accuracy: 0.4294\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 1.7235 - accuracy: 0.4308 - val_loss: 1.7822 - val_accuracy: 0.3376\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.5889 - accuracy: 0.5214\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.5871 - accuracy: 0.5231 - val_loss: 1.6202 - val_accuracy: 0.5831\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.4678 - accuracy: 0.6043\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 1.4667 - accuracy: 0.6045 - val_loss: 1.4121 - val_accuracy: 0.6829\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.3596 - accuracy: 0.6632\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.3581 - accuracy: 0.6641 - val_loss: 1.2715 - val_accuracy: 0.7136\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.2323 - accuracy: 0.7105\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.2316 - accuracy: 0.7109 - val_loss: 1.1578 - val_accuracy: 0.7519\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.1228 - accuracy: 0.7584\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.1212 - accuracy: 0.7583 - val_loss: 1.0526 - val_accuracy: 0.7954\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.0349 - accuracy: 0.7863\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.0328 - accuracy: 0.7872 - val_loss: 0.9591 - val_accuracy: 0.8338\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.9429 - accuracy: 0.8135\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.9413 - accuracy: 0.8147 - val_loss: 0.8806 - val_accuracy: 0.8824\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8629 - accuracy: 0.8601\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.8633 - accuracy: 0.8603 - val_loss: 0.8062 - val_accuracy: 0.9054\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8084 - accuracy: 0.8750\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.8073 - accuracy: 0.8750 - val_loss: 0.7455 - val_accuracy: 0.9182\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7493 - accuracy: 0.8899\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.7506 - accuracy: 0.8897 - val_loss: 0.6948 - val_accuracy: 0.9258\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6956 - accuracy: 0.9106\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.6947 - accuracy: 0.9109 - val_loss: 0.6510 - val_accuracy: 0.9335\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6626 - accuracy: 0.9216\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.6620 - accuracy: 0.9224 - val_loss: 0.6141 - val_accuracy: 0.9463\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6175 - accuracy: 0.9365\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.6193 - accuracy: 0.9365 - val_loss: 0.5782 - val_accuracy: 0.9463\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5880 - accuracy: 0.9346\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.5869 - accuracy: 0.9353 - val_loss: 0.5492 - val_accuracy: 0.9488\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5546 - accuracy: 0.9521\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.5546 - accuracy: 0.9513 - val_loss: 0.5161 - val_accuracy: 0.9591\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5379 - accuracy: 0.9462\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.5364 - accuracy: 0.9462 - val_loss: 0.4955 - val_accuracy: 0.9719\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5127 - accuracy: 0.9598\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.5127 - accuracy: 0.9596 - val_loss: 0.4763 - val_accuracy: 0.9642\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4889 - accuracy: 0.9618\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.4885 - accuracy: 0.9622 - val_loss: 0.4605 - val_accuracy: 0.9693\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4595 - accuracy: 0.9702\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.4623 - accuracy: 0.9686 - val_loss: 0.4402 - val_accuracy: 0.9770\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4534 - accuracy: 0.9663\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.4537 - accuracy: 0.9660 - val_loss: 0.4229 - val_accuracy: 0.9821\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4437 - accuracy: 0.9683\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.4434 - accuracy: 0.9686 - val_loss: 0.4074 - val_accuracy: 0.9795\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4279 - accuracy: 0.9676\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.4279 - accuracy: 0.9679 - val_loss: 0.4151 - val_accuracy: 0.9668\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4116 - accuracy: 0.9780\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.4104 - accuracy: 0.9782 - val_loss: 0.3876 - val_accuracy: 0.9770\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3992 - accuracy: 0.9760\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.3987 - accuracy: 0.9763 - val_loss: 0.3834 - val_accuracy: 0.9795\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3853 - accuracy: 0.9832\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.3855 - accuracy: 0.9827 - val_loss: 0.3741 - val_accuracy: 0.9795\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3787 - accuracy: 0.9793\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.3797 - accuracy: 0.9795 - val_loss: 0.3641 - val_accuracy: 0.9795\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3642 - accuracy: 0.9825\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.3639 - accuracy: 0.9827 - val_loss: 0.3470 - val_accuracy: 0.9821\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3614 - accuracy: 0.9845\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.3617 - accuracy: 0.9840 - val_loss: 0.3483 - val_accuracy: 0.9847\n",
            "Epoch 31/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3491 - accuracy: 0.9825\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.3495 - accuracy: 0.9827 - val_loss: 0.3442 - val_accuracy: 0.9847\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3364 - accuracy: 0.9864\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.3363 - accuracy: 0.9865 - val_loss: 0.3326 - val_accuracy: 0.9847\n",
            "Epoch 33/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3302 - accuracy: 0.9896\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.3303 - accuracy: 0.9897 - val_loss: 0.3372 - val_accuracy: 0.9795\n",
            "Epoch 34/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3258 - accuracy: 0.9890\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.3254 - accuracy: 0.9891 - val_loss: 0.3241 - val_accuracy: 0.9847\n",
            "Epoch 35/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3189 - accuracy: 0.9890\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.3183 - accuracy: 0.9891 - val_loss: 0.3142 - val_accuracy: 0.9821\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3116 - accuracy: 0.9877\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.3116 - accuracy: 0.9878 - val_loss: 0.3228 - val_accuracy: 0.9795\n",
            "Epoch 37/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3049 - accuracy: 0.9909\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.3051 - accuracy: 0.9910 - val_loss: 0.3006 - val_accuracy: 0.9847\n",
            "Epoch 38/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2974 - accuracy: 0.9929\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.2968 - accuracy: 0.9929 - val_loss: 0.3018 - val_accuracy: 0.9847\n",
            "Epoch 39/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2951 - accuracy: 0.9916\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.2947 - accuracy: 0.9917 - val_loss: 0.2824 - val_accuracy: 0.9872\n",
            "Epoch 40/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2857 - accuracy: 0.9903\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.2857 - accuracy: 0.9904 - val_loss: 0.2868 - val_accuracy: 0.9847\n",
            "Epoch 41/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2793 - accuracy: 0.9935\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2796 - accuracy: 0.9929 - val_loss: 0.2772 - val_accuracy: 0.9847\n",
            "Epoch 42/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2737 - accuracy: 0.9922\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2735 - accuracy: 0.9923 - val_loss: 0.2771 - val_accuracy: 0.9821\n",
            "Epoch 43/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2741 - accuracy: 0.9922\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2736 - accuracy: 0.9923 - val_loss: 0.2682 - val_accuracy: 0.9872\n",
            "Epoch 44/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2645 - accuracy: 0.9922\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2647 - accuracy: 0.9923 - val_loss: 0.2768 - val_accuracy: 0.9821\n",
            "Epoch 45/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2625 - accuracy: 0.9929\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.2624 - accuracy: 0.9929 - val_loss: 0.2565 - val_accuracy: 0.9898\n",
            "Epoch 46/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2564 - accuracy: 0.9929\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2566 - accuracy: 0.9923 - val_loss: 0.2610 - val_accuracy: 0.9847\n",
            "Epoch 47/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2491 - accuracy: 0.9942\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.2491 - accuracy: 0.9942 - val_loss: 0.2528 - val_accuracy: 0.9872\n",
            "Epoch 48/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2424 - accuracy: 0.9968\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.2423 - accuracy: 0.9968 - val_loss: 0.2454 - val_accuracy: 0.9898\n",
            "Epoch 49/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2436 - accuracy: 0.9955\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.2437 - accuracy: 0.9955 - val_loss: 0.2503 - val_accuracy: 0.9847\n",
            "Epoch 50/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2366 - accuracy: 0.9968\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2366 - accuracy: 0.9968 - val_loss: 0.2413 - val_accuracy: 0.9872\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/144/assets\n",
            "\n",
            "\n",
            " 72%|███████▎  | 145/200 [6:02:00<3:16:12, 214.05s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 2.3889 - accuracy: 0.2174\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 21ms/step - loss: 2.3841 - accuracy: 0.2186 - val_loss: 1.8418 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 2.0512 - accuracy: 0.3667\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 2.0512 - accuracy: 0.3667 - val_loss: 1.8384 - val_accuracy: 0.2864\n",
            "Epoch 3/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.8695 - accuracy: 0.4769\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.8695 - accuracy: 0.4769 - val_loss: 1.7459 - val_accuracy: 0.3811\n",
            "Epoch 4/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.7159 - accuracy: 0.5808\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.7159 - accuracy: 0.5808 - val_loss: 1.5819 - val_accuracy: 0.6471\n",
            "Epoch 5/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.5802 - accuracy: 0.6500\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.5802 - accuracy: 0.6500 - val_loss: 1.4631 - val_accuracy: 0.7289\n",
            "Epoch 6/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.4509 - accuracy: 0.7109\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.4509 - accuracy: 0.7109 - val_loss: 1.3473 - val_accuracy: 0.7673\n",
            "Epoch 7/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.3267 - accuracy: 0.7610\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.3280 - accuracy: 0.7603 - val_loss: 1.2393 - val_accuracy: 0.7928\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.2269 - accuracy: 0.7992\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.2260 - accuracy: 0.8000 - val_loss: 1.1427 - val_accuracy: 0.8159\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.1339 - accuracy: 0.8303\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.1318 - accuracy: 0.8308 - val_loss: 1.0665 - val_accuracy: 0.8338\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.0618 - accuracy: 0.8523\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.0605 - accuracy: 0.8538 - val_loss: 1.0013 - val_accuracy: 0.8721\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.0017 - accuracy: 0.8815\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.9987 - accuracy: 0.8827 - val_loss: 0.9449 - val_accuracy: 0.8849\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.9426 - accuracy: 0.8944\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.9424 - accuracy: 0.8942 - val_loss: 0.8961 - val_accuracy: 0.8977\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8927 - accuracy: 0.9100\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.8918 - accuracy: 0.9103 - val_loss: 0.8488 - val_accuracy: 0.9361\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8404 - accuracy: 0.9223\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.8402 - accuracy: 0.9218 - val_loss: 0.8071 - val_accuracy: 0.9361\n",
            "Epoch 15/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.8029 - accuracy: 0.9301\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.8029 - accuracy: 0.9301 - val_loss: 0.7702 - val_accuracy: 0.9463\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7659 - accuracy: 0.9424\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.7679 - accuracy: 0.9417 - val_loss: 0.7474 - val_accuracy: 0.9514\n",
            "Epoch 17/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.7374 - accuracy: 0.9558\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.7374 - accuracy: 0.9558 - val_loss: 0.7076 - val_accuracy: 0.9616\n",
            "Epoch 18/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.7120 - accuracy: 0.9607\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.7116 - accuracy: 0.9609 - val_loss: 0.6823 - val_accuracy: 0.9668\n",
            "Epoch 19/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.6841 - accuracy: 0.9568\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.6835 - accuracy: 0.9571 - val_loss: 0.6571 - val_accuracy: 0.9719\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6541 - accuracy: 0.9689\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.6533 - accuracy: 0.9692 - val_loss: 0.6350 - val_accuracy: 0.9616\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6332 - accuracy: 0.9624\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.6343 - accuracy: 0.9622 - val_loss: 0.6138 - val_accuracy: 0.9668\n",
            "Epoch 22/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6140 - accuracy: 0.9705\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.6140 - accuracy: 0.9705 - val_loss: 0.5941 - val_accuracy: 0.9744\n",
            "Epoch 23/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5908 - accuracy: 0.9821\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.5908 - accuracy: 0.9821 - val_loss: 0.5777 - val_accuracy: 0.9744\n",
            "Epoch 24/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5683 - accuracy: 0.9801\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.5683 - accuracy: 0.9801 - val_loss: 0.5592 - val_accuracy: 0.9770\n",
            "Epoch 25/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5538 - accuracy: 0.9853\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.5538 - accuracy: 0.9853 - val_loss: 0.5516 - val_accuracy: 0.9719\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5418 - accuracy: 0.9786\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.5406 - accuracy: 0.9788 - val_loss: 0.5296 - val_accuracy: 0.9795\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5302 - accuracy: 0.9819\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.5300 - accuracy: 0.9814 - val_loss: 0.5184 - val_accuracy: 0.9795\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5071 - accuracy: 0.9883\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.5072 - accuracy: 0.9885 - val_loss: 0.5092 - val_accuracy: 0.9821\n",
            "Epoch 29/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4951 - accuracy: 0.9832\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.4947 - accuracy: 0.9833 - val_loss: 0.4915 - val_accuracy: 0.9821\n",
            "Epoch 30/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4805 - accuracy: 0.9891\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.4805 - accuracy: 0.9891 - val_loss: 0.4794 - val_accuracy: 0.9821\n",
            "Epoch 31/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4716 - accuracy: 0.9891\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.4716 - accuracy: 0.9891 - val_loss: 0.4687 - val_accuracy: 0.9847\n",
            "Epoch 32/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4635 - accuracy: 0.9890\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.4631 - accuracy: 0.9891 - val_loss: 0.4585 - val_accuracy: 0.9847\n",
            "Epoch 33/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4445 - accuracy: 0.9910\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.4445 - accuracy: 0.9910 - val_loss: 0.4492 - val_accuracy: 0.9872\n",
            "Epoch 34/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4348 - accuracy: 0.9916\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.4340 - accuracy: 0.9917 - val_loss: 0.4364 - val_accuracy: 0.9847\n",
            "Epoch 35/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4283 - accuracy: 0.9942\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.4283 - accuracy: 0.9942 - val_loss: 0.4316 - val_accuracy: 0.9795\n",
            "Epoch 36/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4128 - accuracy: 0.9929\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.4129 - accuracy: 0.9929 - val_loss: 0.4184 - val_accuracy: 0.9847\n",
            "Epoch 37/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4112 - accuracy: 0.9929\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.4112 - accuracy: 0.9929 - val_loss: 0.4099 - val_accuracy: 0.9898\n",
            "Epoch 38/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4017 - accuracy: 0.9936\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.4014 - accuracy: 0.9936 - val_loss: 0.4066 - val_accuracy: 0.9821\n",
            "Epoch 39/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3933 - accuracy: 0.9903\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.3955 - accuracy: 0.9897 - val_loss: 0.3925 - val_accuracy: 0.9898\n",
            "Epoch 40/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3840 - accuracy: 0.9929\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.3839 - accuracy: 0.9929 - val_loss: 0.4026 - val_accuracy: 0.9821\n",
            "Epoch 41/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3805 - accuracy: 0.9916\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.3802 - accuracy: 0.9917 - val_loss: 0.3882 - val_accuracy: 0.9821\n",
            "Epoch 42/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3687 - accuracy: 0.9961\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.3688 - accuracy: 0.9962 - val_loss: 0.3735 - val_accuracy: 0.9898\n",
            "Epoch 43/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3649 - accuracy: 0.9929\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.3651 - accuracy: 0.9929 - val_loss: 0.3667 - val_accuracy: 0.9898\n",
            "Epoch 44/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3554 - accuracy: 0.9936\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.3555 - accuracy: 0.9936 - val_loss: 0.3635 - val_accuracy: 0.9872\n",
            "Epoch 45/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3502 - accuracy: 0.9955\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.3502 - accuracy: 0.9955 - val_loss: 0.3576 - val_accuracy: 0.9872\n",
            "Epoch 46/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3434 - accuracy: 0.9949\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.3434 - accuracy: 0.9949 - val_loss: 0.3516 - val_accuracy: 0.9872\n",
            "Epoch 47/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3359 - accuracy: 0.9955\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.3359 - accuracy: 0.9955 - val_loss: 0.3440 - val_accuracy: 0.9872\n",
            "Epoch 48/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3295 - accuracy: 0.9974\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.3295 - accuracy: 0.9974 - val_loss: 0.3422 - val_accuracy: 0.9872\n",
            "Epoch 49/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3229 - accuracy: 0.9955\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.3228 - accuracy: 0.9955 - val_loss: 0.3323 - val_accuracy: 0.9898\n",
            "Epoch 50/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3191 - accuracy: 0.9968\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.3191 - accuracy: 0.9968 - val_loss: 0.3274 - val_accuracy: 0.9923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/145/assets\n",
            "\n",
            "\n",
            " 73%|███████▎  | 146/200 [6:05:27<3:10:46, 211.97s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 2.8450 - accuracy: 0.3351\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 20ms/step - loss: 2.8405 - accuracy: 0.3353 - val_loss: 1.8889 - val_accuracy: 0.2634\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.8217 - accuracy: 0.3873\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 1.8204 - accuracy: 0.3878 - val_loss: 1.8164 - val_accuracy: 0.2788\n",
            "Epoch 3/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.5964 - accuracy: 0.4635\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 1.6023 - accuracy: 0.4609 - val_loss: 1.4490 - val_accuracy: 0.4910\n",
            "Epoch 4/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.4250 - accuracy: 0.5232\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 1.4257 - accuracy: 0.5224 - val_loss: 2.0820 - val_accuracy: 0.3990\n",
            "Epoch 5/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.4290 - accuracy: 0.5429\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 1.4290 - accuracy: 0.5429 - val_loss: 1.2302 - val_accuracy: 0.5627\n",
            "Epoch 6/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.3189 - accuracy: 0.5807\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 1.3196 - accuracy: 0.5808 - val_loss: 1.3515 - val_accuracy: 0.5243\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.2345 - accuracy: 0.6431\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 1.2361 - accuracy: 0.6449 - val_loss: 2.2142 - val_accuracy: 0.5780\n",
            "Epoch 8/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.5109 - accuracy: 0.5615\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 1.5109 - accuracy: 0.5615 - val_loss: 3.4347 - val_accuracy: 0.4246\n",
            "Epoch 9/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.2430 - accuracy: 0.6517\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 1.2503 - accuracy: 0.6487 - val_loss: 1.6695 - val_accuracy: 0.5806\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.1173 - accuracy: 0.6891\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 1.1140 - accuracy: 0.6917 - val_loss: 1.7292 - val_accuracy: 0.6343\n",
            "Epoch 10: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/146/assets\n",
            "\n",
            "\n",
            " 74%|███████▎  | 147/200 [6:06:08<2:21:51, 160.59s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.8451 - accuracy: 0.7690\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 13ms/step - loss: 0.8346 - accuracy: 0.7718 - val_loss: 2.4380 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2208 - accuracy: 0.9734\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.2201 - accuracy: 0.9737 - val_loss: 2.7328 - val_accuracy: 0.2941\n",
            "Epoch 3/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 0.1424 - accuracy: 0.9894\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1416 - accuracy: 0.9897 - val_loss: 0.9027 - val_accuracy: 0.6829\n",
            "Epoch 4/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0881 - accuracy: 0.9968\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0881 - accuracy: 0.9968 - val_loss: 0.1749 - val_accuracy: 0.9719\n",
            "Epoch 5/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0847 - accuracy: 0.9961\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0845 - accuracy: 0.9962 - val_loss: 0.2823 - val_accuracy: 0.9079\n",
            "Epoch 6/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.1179 - accuracy: 0.9868\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1170 - accuracy: 0.9872 - val_loss: 0.4777 - val_accuracy: 0.8696\n",
            "Epoch 7/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1021 - accuracy: 0.9885\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1021 - accuracy: 0.9885 - val_loss: 0.7551 - val_accuracy: 0.8670\n",
            "Epoch 8/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0895 - accuracy: 0.9922\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0890 - accuracy: 0.9923 - val_loss: 0.0736 - val_accuracy: 0.9949\n",
            "Epoch 9/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0527 - accuracy: 0.9974\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0528 - accuracy: 0.9974 - val_loss: 0.1305 - val_accuracy: 0.9847\n",
            "Epoch 10/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.0731 - accuracy: 0.9928\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0779 - accuracy: 0.9917 - val_loss: 0.5912 - val_accuracy: 0.8593\n",
            "Epoch 11/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1105 - accuracy: 0.9813\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1102 - accuracy: 0.9814 - val_loss: 0.0933 - val_accuracy: 0.9872\n",
            "Epoch 12/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0480 - accuracy: 0.9987\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0480 - accuracy: 0.9987 - val_loss: 0.0709 - val_accuracy: 0.9923\n",
            "Epoch 13/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 0.0389 - accuracy: 1.0000\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0390 - accuracy: 1.0000 - val_loss: 0.0734 - val_accuracy: 0.9949\n",
            "Epoch 14/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.0375 - accuracy: 1.0000\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0374 - accuracy: 1.0000 - val_loss: 0.0732 - val_accuracy: 0.9898\n",
            "Epoch 15/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0340 - accuracy: 1.0000\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0340 - accuracy: 1.0000 - val_loss: 0.0526 - val_accuracy: 0.9923\n",
            "Epoch 16/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0299 - accuracy: 1.0000\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 0.0514 - val_accuracy: 0.9949\n",
            "Epoch 17/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0294 - accuracy: 1.0000\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0294 - accuracy: 1.0000 - val_loss: 0.0806 - val_accuracy: 0.9898\n",
            "Epoch 18/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.0281 - accuracy: 1.0000\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 0.0502 - val_accuracy: 0.9949\n",
            "Epoch 19/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0289 - accuracy: 1.0000\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 0.0500 - val_accuracy: 0.9923\n",
            "Epoch 20/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0258 - accuracy: 1.0000\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0258 - accuracy: 1.0000 - val_loss: 0.0456 - val_accuracy: 0.9923\n",
            "Epoch 21/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.0252 - accuracy: 1.0000\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0254 - accuracy: 1.0000 - val_loss: 0.0593 - val_accuracy: 0.9872\n",
            "Epoch 22/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2376 - accuracy: 0.9530\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.2372 - accuracy: 0.9532 - val_loss: 1.6258 - val_accuracy: 0.8568\n",
            "Epoch 23/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0906 - accuracy: 0.9903\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0903 - accuracy: 0.9904 - val_loss: 0.1812 - val_accuracy: 0.9437\n",
            "Epoch 24/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0609 - accuracy: 0.9954\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0605 - accuracy: 0.9955 - val_loss: 0.1339 - val_accuracy: 0.9642\n",
            "Epoch 25/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.0485 - accuracy: 0.9987\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0483 - accuracy: 0.9987 - val_loss: 0.0961 - val_accuracy: 0.9898\n",
            "Epoch 25: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/147/assets\n",
            "\n",
            "\n",
            " 74%|███████▍  | 148/200 [6:07:35<2:00:04, 138.56s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.1914 - accuracy: 0.7045\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 29ms/step - loss: 1.1914 - accuracy: 0.7045 - val_loss: 1.6606 - val_accuracy: 0.4859\n",
            "Epoch 2/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3344 - accuracy: 0.9465\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.3335 - accuracy: 0.9468 - val_loss: 2.2426 - val_accuracy: 0.3018\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2198 - accuracy: 0.9786\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.2204 - accuracy: 0.9782 - val_loss: 0.6433 - val_accuracy: 0.9284\n",
            "Epoch 4/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1783 - accuracy: 0.9897\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.1780 - accuracy: 0.9897 - val_loss: 0.2649 - val_accuracy: 0.9591\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1486 - accuracy: 0.9961\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.1559 - accuracy: 0.9949 - val_loss: 4.1024 - val_accuracy: 0.6650\n",
            "Epoch 6/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2567 - accuracy: 0.9684\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.2576 - accuracy: 0.9679 - val_loss: 0.7658 - val_accuracy: 0.8312\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1951 - accuracy: 0.9793\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.1943 - accuracy: 0.9795 - val_loss: 0.2524 - val_accuracy: 0.9719\n",
            "Epoch 8/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1229 - accuracy: 0.9968\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.1227 - accuracy: 0.9968 - val_loss: 0.1398 - val_accuracy: 0.9974\n",
            "Epoch 9/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1151 - accuracy: 0.9974\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.1149 - accuracy: 0.9974 - val_loss: 0.1348 - val_accuracy: 0.9923\n",
            "Epoch 10/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1342 - accuracy: 0.9910\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.1342 - accuracy: 0.9910 - val_loss: 0.1853 - val_accuracy: 0.9872\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1146 - accuracy: 0.9942\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.1145 - accuracy: 0.9942 - val_loss: 0.1528 - val_accuracy: 0.9770\n",
            "Epoch 12/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0973 - accuracy: 0.9974\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.0973 - accuracy: 0.9974 - val_loss: 0.2329 - val_accuracy: 0.9540\n",
            "Epoch 13/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4614 - accuracy: 0.8994\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.4614 - accuracy: 0.8994 - val_loss: 0.7485 - val_accuracy: 0.8747\n",
            "Epoch 14/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2364 - accuracy: 0.9633\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.2358 - accuracy: 0.9635 - val_loss: 0.6762 - val_accuracy: 0.8235\n",
            "Epoch 14: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/148/assets\n",
            "\n",
            "\n",
            " 74%|███████▍  | 149/200 [6:09:02<1:44:40, 123.14s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.2431 - accuracy: 0.6943\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 20ms/step - loss: 1.2373 - accuracy: 0.6955 - val_loss: 1.7840 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.4969 - accuracy: 0.9186\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.4939 - accuracy: 0.9199 - val_loss: 1.6989 - val_accuracy: 0.5217\n",
            "Epoch 3/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2803 - accuracy: 0.9740\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.2802 - accuracy: 0.9744 - val_loss: 0.7487 - val_accuracy: 0.7315\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2202 - accuracy: 0.9845\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.2199 - accuracy: 0.9846 - val_loss: 0.2144 - val_accuracy: 0.9821\n",
            "Epoch 5/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1667 - accuracy: 0.9962\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.1667 - accuracy: 0.9962 - val_loss: 0.2145 - val_accuracy: 0.9744\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1372 - accuracy: 0.9987\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.1372 - accuracy: 0.9987 - val_loss: 0.2636 - val_accuracy: 0.9616\n",
            "Epoch 7/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2798 - accuracy: 0.9646\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.2795 - accuracy: 0.9647 - val_loss: 0.7436 - val_accuracy: 0.8312\n",
            "Epoch 8/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2121 - accuracy: 0.9846\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.2121 - accuracy: 0.9846 - val_loss: 0.2202 - val_accuracy: 0.9770\n",
            "Epoch 9/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1463 - accuracy: 0.9987\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1462 - accuracy: 0.9987 - val_loss: 0.2449 - val_accuracy: 0.9642\n",
            "Epoch 9: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/149/assets\n",
            "\n",
            "\n",
            " 75%|███████▌  | 150/200 [6:09:40<1:21:12, 97.45s/it] \u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 2.3135 - accuracy: 0.2726\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 22ms/step - loss: 2.3100 - accuracy: 0.2731 - val_loss: 1.6958 - val_accuracy: 0.2634\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6887 - accuracy: 0.2798\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.6876 - accuracy: 0.2808 - val_loss: 1.6765 - val_accuracy: 0.2864\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6750 - accuracy: 0.2791\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.6745 - accuracy: 0.2788 - val_loss: 1.6673 - val_accuracy: 0.2864\n",
            "Epoch 4/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6677 - accuracy: 0.2764\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.6668 - accuracy: 0.2776 - val_loss: 1.6630 - val_accuracy: 0.2864\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6611 - accuracy: 0.2804\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.6619 - accuracy: 0.2808 - val_loss: 1.6573 - val_accuracy: 0.2864\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6577 - accuracy: 0.2856\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.6570 - accuracy: 0.2859 - val_loss: 1.6524 - val_accuracy: 0.2864\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6523 - accuracy: 0.2850\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.6537 - accuracy: 0.2859 - val_loss: 1.6490 - val_accuracy: 0.2864\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6494 - accuracy: 0.2850\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.6496 - accuracy: 0.2833 - val_loss: 1.6484 - val_accuracy: 0.2864\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6494 - accuracy: 0.2778\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.6489 - accuracy: 0.2776 - val_loss: 1.6452 - val_accuracy: 0.2864\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6429 - accuracy: 0.2876\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.6462 - accuracy: 0.2872 - val_loss: 1.6409 - val_accuracy: 0.2864\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6418 - accuracy: 0.2882\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.6420 - accuracy: 0.2885 - val_loss: 1.6395 - val_accuracy: 0.2634\n",
            "Epoch 12/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6394 - accuracy: 0.2706\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.6404 - accuracy: 0.2699 - val_loss: 1.6366 - val_accuracy: 0.2864\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6372 - accuracy: 0.2869\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.6384 - accuracy: 0.2859 - val_loss: 1.6349 - val_accuracy: 0.2864\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6385 - accuracy: 0.2804\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.6395 - accuracy: 0.2808 - val_loss: 1.6335 - val_accuracy: 0.2864\n",
            "Epoch 15/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6341 - accuracy: 0.2874\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.6354 - accuracy: 0.2859 - val_loss: 1.6333 - val_accuracy: 0.2864\n",
            "Epoch 16/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6390 - accuracy: 0.2848\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.6386 - accuracy: 0.2859 - val_loss: 1.6305 - val_accuracy: 0.2864\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6333 - accuracy: 0.2785\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.6338 - accuracy: 0.2776 - val_loss: 1.6296 - val_accuracy: 0.2864\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6306 - accuracy: 0.2863\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.6316 - accuracy: 0.2859 - val_loss: 1.6288 - val_accuracy: 0.2864\n",
            "Epoch 19/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6311 - accuracy: 0.2764\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.6310 - accuracy: 0.2756 - val_loss: 1.6286 - val_accuracy: 0.2864\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6317 - accuracy: 0.2824\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.6298 - accuracy: 0.2833 - val_loss: 1.6277 - val_accuracy: 0.2864\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6293 - accuracy: 0.2772\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.6296 - accuracy: 0.2782 - val_loss: 1.6269 - val_accuracy: 0.2864\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6295 - accuracy: 0.2850\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.6298 - accuracy: 0.2859 - val_loss: 1.6262 - val_accuracy: 0.2864\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6303 - accuracy: 0.2791\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.6291 - accuracy: 0.2776 - val_loss: 1.6258 - val_accuracy: 0.2864\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6284 - accuracy: 0.2740\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.6286 - accuracy: 0.2744 - val_loss: 1.6260 - val_accuracy: 0.2864\n",
            "Epoch 25/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6285 - accuracy: 0.2777\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.6280 - accuracy: 0.2769 - val_loss: 1.6254 - val_accuracy: 0.2864\n",
            "Epoch 26/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6281 - accuracy: 0.2861\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.6278 - accuracy: 0.2859 - val_loss: 1.6254 - val_accuracy: 0.2864\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6270 - accuracy: 0.2856\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.6279 - accuracy: 0.2859 - val_loss: 1.6249 - val_accuracy: 0.2864\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6321 - accuracy: 0.2675\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.6317 - accuracy: 0.2692 - val_loss: 1.6261 - val_accuracy: 0.2864\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6274 - accuracy: 0.2856\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.6273 - accuracy: 0.2859 - val_loss: 1.6243 - val_accuracy: 0.2864\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6277 - accuracy: 0.2882\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.6267 - accuracy: 0.2872 - val_loss: 1.6250 - val_accuracy: 0.2634\n",
            "Epoch 31/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6273 - accuracy: 0.2803\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.6274 - accuracy: 0.2788 - val_loss: 1.6243 - val_accuracy: 0.2864\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6274 - accuracy: 0.2591\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.6272 - accuracy: 0.2603 - val_loss: 1.6243 - val_accuracy: 0.2864\n",
            "Epoch 33/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6253 - accuracy: 0.2772\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.6270 - accuracy: 0.2769 - val_loss: 1.6241 - val_accuracy: 0.2864\n",
            "Epoch 34/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6267 - accuracy: 0.2874\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.6272 - accuracy: 0.2859 - val_loss: 1.6244 - val_accuracy: 0.2864\n",
            "Epoch 35/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6265 - accuracy: 0.2788\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.6265 - accuracy: 0.2788 - val_loss: 1.6243 - val_accuracy: 0.2864\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6286 - accuracy: 0.2804\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 1.6271 - accuracy: 0.2814 - val_loss: 1.6249 - val_accuracy: 0.2864\n",
            "Epoch 37/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6235 - accuracy: 0.2772\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.6260 - accuracy: 0.2776 - val_loss: 1.6237 - val_accuracy: 0.2864\n",
            "Epoch 38/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6283 - accuracy: 0.2841\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 1.6291 - accuracy: 0.2846 - val_loss: 1.6240 - val_accuracy: 0.2864\n",
            "Epoch 39/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6258 - accuracy: 0.2804\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.6260 - accuracy: 0.2814 - val_loss: 1.6242 - val_accuracy: 0.2864\n",
            "Epoch 40/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6274 - accuracy: 0.2732\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.6264 - accuracy: 0.2744 - val_loss: 1.6239 - val_accuracy: 0.2864\n",
            "Epoch 41/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6273 - accuracy: 0.2777\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.6270 - accuracy: 0.2763 - val_loss: 1.6240 - val_accuracy: 0.2864\n",
            "Epoch 42/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6260 - accuracy: 0.2867\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.6266 - accuracy: 0.2859 - val_loss: 1.6242 - val_accuracy: 0.2864\n",
            "Epoch 42: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/150/assets\n",
            "\n",
            "\n",
            " 76%|███████▌  | 151/200 [6:12:23<1:35:37, 117.10s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.7714 - accuracy: 0.3743\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 11ms/step - loss: 1.7679 - accuracy: 0.3763 - val_loss: 1.7101 - val_accuracy: 0.2890\n",
            "Epoch 2/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.2942 - accuracy: 0.5573\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.2920 - accuracy: 0.5590 - val_loss: 1.2100 - val_accuracy: 0.6675\n",
            "Epoch 3/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.1050 - accuracy: 0.6695\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.0968 - accuracy: 0.6712 - val_loss: 0.9540 - val_accuracy: 0.6394\n",
            "Epoch 4/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.6919 - accuracy: 0.8178\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.6954 - accuracy: 0.8160 - val_loss: 1.1429 - val_accuracy: 0.5857\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5235 - accuracy: 0.8782\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.5224 - accuracy: 0.8788 - val_loss: 1.3331 - val_accuracy: 0.5754\n",
            "Epoch 6/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.6443 - accuracy: 0.8396\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.6417 - accuracy: 0.8404 - val_loss: 0.7326 - val_accuracy: 0.7826\n",
            "Epoch 7/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4207 - accuracy: 0.9199\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.4207 - accuracy: 0.9199 - val_loss: 0.4342 - val_accuracy: 0.9284\n",
            "Epoch 8/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.4208 - accuracy: 0.8991\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.4172 - accuracy: 0.9006 - val_loss: 3.5977 - val_accuracy: 0.3862\n",
            "Epoch 9/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 0.5368 - accuracy: 0.8896\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.5368 - accuracy: 0.8904 - val_loss: 1.3893 - val_accuracy: 0.6419\n",
            "Epoch 10/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3604 - accuracy: 0.9308\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.3604 - accuracy: 0.9308 - val_loss: 0.4078 - val_accuracy: 0.9079\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3395 - accuracy: 0.9326\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.3375 - accuracy: 0.9333 - val_loss: 0.4903 - val_accuracy: 0.8568\n",
            "Epoch 12/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2426 - accuracy: 0.9622\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.2410 - accuracy: 0.9628 - val_loss: 0.3188 - val_accuracy: 0.9233\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1988 - accuracy: 0.9644\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.1979 - accuracy: 0.9647 - val_loss: 0.3162 - val_accuracy: 0.9488\n",
            "Epoch 14/50\n",
            "188/195 [===========================>..] - ETA: 0s - loss: 0.3322 - accuracy: 0.9315\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.3425 - accuracy: 0.9276 - val_loss: 0.8863 - val_accuracy: 0.7391\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4462 - accuracy: 0.8990\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.4432 - accuracy: 0.9000 - val_loss: 1.7081 - val_accuracy: 0.6215\n",
            "Epoch 16/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3781 - accuracy: 0.9336\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.3750 - accuracy: 0.9346 - val_loss: 0.7448 - val_accuracy: 0.8082\n",
            "Epoch 17/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 0.2112 - accuracy: 0.9755\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.2113 - accuracy: 0.9756 - val_loss: 0.4307 - val_accuracy: 0.9207\n",
            "Epoch 18/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2168 - accuracy: 0.9648\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.2151 - accuracy: 0.9654 - val_loss: 0.1976 - val_accuracy: 0.9616\n",
            "Epoch 19/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.9043 - accuracy: 0.7303\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.9253 - accuracy: 0.7186 - val_loss: 1.6084 - val_accuracy: 0.3325\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.0458 - accuracy: 0.6775\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.0458 - accuracy: 0.6769 - val_loss: 1.9082 - val_accuracy: 0.5524\n",
            "Epoch 21/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.5306 - accuracy: 0.8816\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.5322 - accuracy: 0.8808 - val_loss: 0.7215 - val_accuracy: 0.8286\n",
            "Epoch 22/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.3193 - accuracy: 0.9454\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.3253 - accuracy: 0.9449 - val_loss: 0.3361 - val_accuracy: 0.9335\n",
            "Epoch 23/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2441 - accuracy: 0.9551\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.2428 - accuracy: 0.9551 - val_loss: 0.3913 - val_accuracy: 0.9156\n",
            "Epoch 23: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/151/assets\n",
            "\n",
            "\n",
            " 76%|███████▌  | 152/200 [6:13:08<1:16:31, 95.67s/it] \u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 3.6135 - accuracy: 0.3497\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 24ms/step - loss: 3.5904 - accuracy: 0.3526 - val_loss: 2.0096 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.5046 - accuracy: 0.6593\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 1.4985 - accuracy: 0.6609 - val_loss: 1.2643 - val_accuracy: 0.7315\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.0387 - accuracy: 0.7947\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 1.0360 - accuracy: 0.7962 - val_loss: 0.9748 - val_accuracy: 0.7494\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7017 - accuracy: 0.8802\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.7026 - accuracy: 0.8801 - val_loss: 0.5900 - val_accuracy: 0.9079\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 2.1071 - accuracy: 0.8051\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 2.1241 - accuracy: 0.7994 - val_loss: 98.7311 - val_accuracy: 0.2890\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 2.4565 - accuracy: 0.2766\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 2.4567 - accuracy: 0.2769 - val_loss: 2.3055 - val_accuracy: 0.2864\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 2.2693 - accuracy: 0.2817\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 2.2688 - accuracy: 0.2821 - val_loss: 2.2289 - val_accuracy: 0.2864\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 2.2075 - accuracy: 0.2798\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 2.2070 - accuracy: 0.2801 - val_loss: 2.2270 - val_accuracy: 0.2609\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 2.1664 - accuracy: 0.2837\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 2.1649 - accuracy: 0.2840 - val_loss: 2.1232 - val_accuracy: 0.2864\n",
            "Epoch 9: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/152/assets\n",
            "\n",
            "\n",
            " 76%|███████▋  | 153/200 [6:13:55<1:03:17, 80.79s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.7867 - accuracy: 0.4864\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 17ms/step - loss: 1.7813 - accuracy: 0.4872 - val_loss: 1.7512 - val_accuracy: 0.3939\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.0374 - accuracy: 0.8096\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.0351 - accuracy: 0.8115 - val_loss: 1.7290 - val_accuracy: 0.4041\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6747 - accuracy: 0.9326\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.6730 - accuracy: 0.9333 - val_loss: 1.1957 - val_accuracy: 0.5652\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5173 - accuracy: 0.9722\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.5165 - accuracy: 0.9724 - val_loss: 0.4926 - val_accuracy: 0.9719\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4230 - accuracy: 0.9864\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.4228 - accuracy: 0.9859 - val_loss: 0.4004 - val_accuracy: 0.9872\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3662 - accuracy: 0.9922\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.3653 - accuracy: 0.9923 - val_loss: 0.3623 - val_accuracy: 0.9872\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3292 - accuracy: 0.9942\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.3289 - accuracy: 0.9942 - val_loss: 0.3324 - val_accuracy: 0.9847\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3030 - accuracy: 0.9929\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.3027 - accuracy: 0.9929 - val_loss: 0.2990 - val_accuracy: 0.9898\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2684 - accuracy: 0.9968\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.2683 - accuracy: 0.9968 - val_loss: 0.2797 - val_accuracy: 0.9898\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2492 - accuracy: 0.9968\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.2490 - accuracy: 0.9968 - val_loss: 0.2534 - val_accuracy: 0.9898\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2302 - accuracy: 0.9987\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.2302 - accuracy: 0.9987 - val_loss: 0.2440 - val_accuracy: 0.9898\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2147 - accuracy: 0.9987\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.2149 - accuracy: 0.9987 - val_loss: 0.2368 - val_accuracy: 0.9923\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2029 - accuracy: 0.9994\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.2027 - accuracy: 0.9994 - val_loss: 0.2364 - val_accuracy: 0.9847\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1923 - accuracy: 0.9981\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1919 - accuracy: 0.9981 - val_loss: 0.2004 - val_accuracy: 0.9898\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1808 - accuracy: 0.9981\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1805 - accuracy: 0.9981 - val_loss: 0.1972 - val_accuracy: 0.9898\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1698 - accuracy: 0.9987\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1695 - accuracy: 0.9987 - val_loss: 0.1972 - val_accuracy: 0.9898\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1580 - accuracy: 1.0000\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1577 - accuracy: 1.0000 - val_loss: 0.1807 - val_accuracy: 0.9898\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1524 - accuracy: 0.9981\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1523 - accuracy: 0.9981 - val_loss: 0.1800 - val_accuracy: 0.9923\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1419 - accuracy: 1.0000\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1428 - accuracy: 0.9994 - val_loss: 0.1615 - val_accuracy: 0.9898\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1407 - accuracy: 0.9994\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1407 - accuracy: 0.9994 - val_loss: 0.1585 - val_accuracy: 0.9923\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1337 - accuracy: 1.0000\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1335 - accuracy: 1.0000 - val_loss: 0.1585 - val_accuracy: 0.9872\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1291 - accuracy: 0.9994\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1291 - accuracy: 0.9994 - val_loss: 0.1611 - val_accuracy: 0.9872\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1237 - accuracy: 1.0000\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1237 - accuracy: 1.0000 - val_loss: 0.1419 - val_accuracy: 0.9923\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1210 - accuracy: 0.9987\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1209 - accuracy: 0.9987 - val_loss: 0.1376 - val_accuracy: 0.9949\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1134 - accuracy: 1.0000\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1134 - accuracy: 1.0000 - val_loss: 0.1434 - val_accuracy: 0.9872\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1136 - accuracy: 0.9994\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1138 - accuracy: 0.9994 - val_loss: 0.1603 - val_accuracy: 0.9898\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1290 - accuracy: 0.9968\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1289 - accuracy: 0.9968 - val_loss: 0.1314 - val_accuracy: 0.9949\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1101 - accuracy: 0.9994\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1100 - accuracy: 0.9994 - val_loss: 0.1462 - val_accuracy: 0.9872\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1047 - accuracy: 1.0000\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1046 - accuracy: 1.0000 - val_loss: 0.1234 - val_accuracy: 0.9898\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1002 - accuracy: 1.0000\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1002 - accuracy: 1.0000 - val_loss: 0.1266 - val_accuracy: 0.9923\n",
            "Epoch 31/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1005 - accuracy: 0.9994\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1005 - accuracy: 0.9994 - val_loss: 0.1198 - val_accuracy: 0.9949\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0968 - accuracy: 1.0000\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0967 - accuracy: 1.0000 - val_loss: 0.1159 - val_accuracy: 0.9949\n",
            "Epoch 33/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0933 - accuracy: 1.0000\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0933 - accuracy: 1.0000 - val_loss: 0.1176 - val_accuracy: 0.9949\n",
            "Epoch 34/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0922 - accuracy: 1.0000\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0922 - accuracy: 1.0000 - val_loss: 0.1208 - val_accuracy: 0.9923\n",
            "Epoch 35/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0896 - accuracy: 1.0000\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0897 - accuracy: 1.0000 - val_loss: 0.1152 - val_accuracy: 0.9923\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0878 - accuracy: 1.0000\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0879 - accuracy: 1.0000 - val_loss: 0.1089 - val_accuracy: 0.9949\n",
            "Epoch 37/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0877 - accuracy: 1.0000\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0877 - accuracy: 1.0000 - val_loss: 0.1170 - val_accuracy: 0.9923\n",
            "Epoch 38/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0865 - accuracy: 1.0000\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0865 - accuracy: 1.0000 - val_loss: 0.1063 - val_accuracy: 0.9949\n",
            "Epoch 39/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0828 - accuracy: 1.0000\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0828 - accuracy: 1.0000 - val_loss: 0.1193 - val_accuracy: 0.9923\n",
            "Epoch 40/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0836 - accuracy: 1.0000\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0836 - accuracy: 1.0000 - val_loss: 0.1060 - val_accuracy: 0.9898\n",
            "Epoch 41/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0807 - accuracy: 1.0000\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0806 - accuracy: 1.0000 - val_loss: 0.1054 - val_accuracy: 0.9923\n",
            "Epoch 42/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0786 - accuracy: 1.0000\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0785 - accuracy: 1.0000 - val_loss: 0.1046 - val_accuracy: 0.9923\n",
            "Epoch 43/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0757 - accuracy: 1.0000\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0757 - accuracy: 1.0000 - val_loss: 0.1024 - val_accuracy: 0.9923\n",
            "Epoch 44/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0752 - accuracy: 1.0000\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0753 - accuracy: 1.0000 - val_loss: 0.1060 - val_accuracy: 0.9923\n",
            "Epoch 45/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0739 - accuracy: 1.0000\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0739 - accuracy: 1.0000 - val_loss: 0.1003 - val_accuracy: 0.9923\n",
            "Epoch 46/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0738 - accuracy: 1.0000\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0738 - accuracy: 1.0000 - val_loss: 0.1042 - val_accuracy: 0.9949\n",
            "Epoch 47/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0704 - accuracy: 1.0000\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0704 - accuracy: 1.0000 - val_loss: 0.0967 - val_accuracy: 0.9949\n",
            "Epoch 48/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0699 - accuracy: 1.0000\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0698 - accuracy: 1.0000 - val_loss: 0.0948 - val_accuracy: 0.9974\n",
            "Epoch 49/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0675 - accuracy: 1.0000\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0674 - accuracy: 1.0000 - val_loss: 0.0970 - val_accuracy: 0.9923\n",
            "Epoch 50/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0674 - accuracy: 1.0000\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0674 - accuracy: 1.0000 - val_loss: 0.0904 - val_accuracy: 0.9974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/153/assets\n",
            "\n",
            "\n",
            " 77%|███████▋  | 154/200 [6:16:26<1:18:11, 101.98s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6052 - accuracy: 0.6224\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 21ms/step - loss: 1.6052 - accuracy: 0.6224 - val_loss: 1.8179 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8180 - accuracy: 0.9106\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.8156 - accuracy: 0.9115 - val_loss: 2.4308 - val_accuracy: 0.2864\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6030 - accuracy: 0.9624\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.6023 - accuracy: 0.9628 - val_loss: 1.3293 - val_accuracy: 0.5703\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4721 - accuracy: 0.9864\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.4723 - accuracy: 0.9865 - val_loss: 0.4577 - val_accuracy: 0.9872\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4035 - accuracy: 0.9909\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.4032 - accuracy: 0.9910 - val_loss: 0.3870 - val_accuracy: 0.9872\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3536 - accuracy: 0.9948\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.3534 - accuracy: 0.9949 - val_loss: 0.3657 - val_accuracy: 0.9821\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3144 - accuracy: 0.9961\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.3143 - accuracy: 0.9962 - val_loss: 0.3101 - val_accuracy: 0.9923\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2823 - accuracy: 0.9981\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.2821 - accuracy: 0.9981 - val_loss: 0.2832 - val_accuracy: 0.9898\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2520 - accuracy: 0.9981\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.2518 - accuracy: 0.9981 - val_loss: 0.2739 - val_accuracy: 0.9898\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2266 - accuracy: 0.9994\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.2265 - accuracy: 0.9994 - val_loss: 0.2352 - val_accuracy: 0.9923\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2112 - accuracy: 1.0000\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.2112 - accuracy: 1.0000 - val_loss: 0.2201 - val_accuracy: 0.9923\n",
            "Epoch 12/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1958 - accuracy: 0.9994\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1958 - accuracy: 0.9994 - val_loss: 0.2082 - val_accuracy: 0.9923\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1870 - accuracy: 0.9987\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1869 - accuracy: 0.9987 - val_loss: 0.1963 - val_accuracy: 0.9949\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1671 - accuracy: 1.0000\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1673 - accuracy: 1.0000 - val_loss: 0.1872 - val_accuracy: 0.9923\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1600 - accuracy: 1.0000\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1598 - accuracy: 1.0000 - val_loss: 0.1773 - val_accuracy: 0.9923\n",
            "Epoch 16/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1512 - accuracy: 1.0000\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1511 - accuracy: 1.0000 - val_loss: 0.1661 - val_accuracy: 0.9949\n",
            "Epoch 17/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1463 - accuracy: 0.9994\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1462 - accuracy: 0.9994 - val_loss: 0.1623 - val_accuracy: 0.9949\n",
            "Epoch 18/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1392 - accuracy: 0.9994\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1392 - accuracy: 0.9994 - val_loss: 0.1541 - val_accuracy: 0.9949\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1324 - accuracy: 1.0000\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1323 - accuracy: 1.0000 - val_loss: 0.1515 - val_accuracy: 0.9949\n",
            "Epoch 20/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1349 - accuracy: 0.9994\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1348 - accuracy: 0.9994 - val_loss: 0.1506 - val_accuracy: 0.9949\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1271 - accuracy: 0.9994\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1271 - accuracy: 0.9994 - val_loss: 0.1444 - val_accuracy: 0.9949\n",
            "Epoch 22/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1176 - accuracy: 1.0000\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1176 - accuracy: 1.0000 - val_loss: 0.1352 - val_accuracy: 0.9949\n",
            "Epoch 23/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1150 - accuracy: 1.0000\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1149 - accuracy: 1.0000 - val_loss: 0.1329 - val_accuracy: 0.9949\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1122 - accuracy: 1.0000\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1121 - accuracy: 1.0000 - val_loss: 0.1299 - val_accuracy: 0.9949\n",
            "Epoch 25/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1090 - accuracy: 1.0000\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1090 - accuracy: 1.0000 - val_loss: 0.1286 - val_accuracy: 0.9949\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1108 - accuracy: 1.0000\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1108 - accuracy: 1.0000 - val_loss: 0.1496 - val_accuracy: 0.9949\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1063 - accuracy: 1.0000\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1063 - accuracy: 1.0000 - val_loss: 0.1229 - val_accuracy: 0.9949\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1008 - accuracy: 1.0000\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1008 - accuracy: 1.0000 - val_loss: 0.1242 - val_accuracy: 0.9949\n",
            "Epoch 29/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0991 - accuracy: 1.0000\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0992 - accuracy: 1.0000 - val_loss: 0.1190 - val_accuracy: 0.9949\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0979 - accuracy: 1.0000\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0979 - accuracy: 1.0000 - val_loss: 0.1179 - val_accuracy: 0.9949\n",
            "Epoch 31/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0952 - accuracy: 1.0000\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0952 - accuracy: 1.0000 - val_loss: 0.1183 - val_accuracy: 0.9949\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0936 - accuracy: 1.0000\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0936 - accuracy: 1.0000 - val_loss: 0.1159 - val_accuracy: 0.9949\n",
            "Epoch 33/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0916 - accuracy: 1.0000\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0916 - accuracy: 1.0000 - val_loss: 0.1258 - val_accuracy: 0.9949\n",
            "Epoch 34/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0914 - accuracy: 1.0000\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0914 - accuracy: 1.0000 - val_loss: 0.1161 - val_accuracy: 0.9949\n",
            "Epoch 35/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0917 - accuracy: 1.0000\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0917 - accuracy: 1.0000 - val_loss: 0.1156 - val_accuracy: 0.9949\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0868 - accuracy: 1.0000\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0868 - accuracy: 1.0000 - val_loss: 0.1176 - val_accuracy: 0.9949\n",
            "Epoch 37/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0866 - accuracy: 1.0000\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0865 - accuracy: 1.0000 - val_loss: 0.1080 - val_accuracy: 0.9949\n",
            "Epoch 38/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0832 - accuracy: 1.0000\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0832 - accuracy: 1.0000 - val_loss: 0.1086 - val_accuracy: 0.9949\n",
            "Epoch 39/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0807 - accuracy: 1.0000\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0807 - accuracy: 1.0000 - val_loss: 0.1092 - val_accuracy: 0.9949\n",
            "Epoch 40/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0788 - accuracy: 1.0000\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0788 - accuracy: 1.0000 - val_loss: 0.1080 - val_accuracy: 0.9949\n",
            "Epoch 41/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0758 - accuracy: 1.0000\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0758 - accuracy: 1.0000 - val_loss: 0.1072 - val_accuracy: 0.9949\n",
            "Epoch 42/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0747 - accuracy: 1.0000\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0747 - accuracy: 1.0000 - val_loss: 0.1040 - val_accuracy: 0.9949\n",
            "Epoch 43/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0724 - accuracy: 1.0000\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0724 - accuracy: 1.0000 - val_loss: 0.1019 - val_accuracy: 0.9949\n",
            "Epoch 44/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0705 - accuracy: 1.0000\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0704 - accuracy: 1.0000 - val_loss: 0.0976 - val_accuracy: 0.9949\n",
            "Epoch 45/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0689 - accuracy: 1.0000\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0689 - accuracy: 1.0000 - val_loss: 0.0989 - val_accuracy: 0.9949\n",
            "Epoch 46/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0668 - accuracy: 1.0000\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0668 - accuracy: 1.0000 - val_loss: 0.0953 - val_accuracy: 0.9949\n",
            "Epoch 47/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0698 - accuracy: 0.9994\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0698 - accuracy: 0.9994 - val_loss: 0.1658 - val_accuracy: 0.9795\n",
            "Epoch 48/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1359 - accuracy: 0.9884\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1356 - accuracy: 0.9885 - val_loss: 0.1355 - val_accuracy: 0.9898\n",
            "Epoch 49/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0838 - accuracy: 0.9974\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0838 - accuracy: 0.9974 - val_loss: 0.1042 - val_accuracy: 0.9949\n",
            "Epoch 50/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0722 - accuracy: 1.0000\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0722 - accuracy: 1.0000 - val_loss: 0.0977 - val_accuracy: 0.9949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/154/assets\n",
            "\n",
            "\n",
            " 78%|███████▊  | 155/200 [6:19:37<1:36:31, 128.70s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.4264 - accuracy: 0.6579\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 27ms/step - loss: 1.4219 - accuracy: 0.6596 - val_loss: 1.7744 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.5979 - accuracy: 0.9459\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.5979 - accuracy: 0.9455 - val_loss: 2.1879 - val_accuracy: 0.2890\n",
            "Epoch 3/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4105 - accuracy: 0.9807\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.4098 - accuracy: 0.9808 - val_loss: 1.2875 - val_accuracy: 0.5217\n",
            "Epoch 4/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3342 - accuracy: 0.9885\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.3342 - accuracy: 0.9885 - val_loss: 0.3749 - val_accuracy: 0.9693\n",
            "Epoch 5/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2789 - accuracy: 0.9962\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 25ms/step - loss: 0.2789 - accuracy: 0.9962 - val_loss: 0.2850 - val_accuracy: 0.9872\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2516 - accuracy: 0.9981\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 25ms/step - loss: 0.2512 - accuracy: 0.9981 - val_loss: 0.2586 - val_accuracy: 0.9923\n",
            "Epoch 7/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2155 - accuracy: 0.9994\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.2155 - accuracy: 0.9994 - val_loss: 0.2565 - val_accuracy: 0.9847\n",
            "Epoch 8/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2111 - accuracy: 0.9968\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.2111 - accuracy: 0.9968 - val_loss: 0.2157 - val_accuracy: 0.9898\n",
            "Epoch 9/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1806 - accuracy: 0.9994\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1806 - accuracy: 0.9994 - val_loss: 0.1948 - val_accuracy: 0.9898\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1766 - accuracy: 0.9968\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1764 - accuracy: 0.9968 - val_loss: 0.2143 - val_accuracy: 0.9898\n",
            "Epoch 11/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1579 - accuracy: 1.0000\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1579 - accuracy: 1.0000 - val_loss: 0.1742 - val_accuracy: 0.9923\n",
            "Epoch 12/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1494 - accuracy: 0.9981\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1494 - accuracy: 0.9981 - val_loss: 0.1649 - val_accuracy: 0.9923\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1397 - accuracy: 1.0000\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1398 - accuracy: 1.0000 - val_loss: 0.1526 - val_accuracy: 0.9923\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1328 - accuracy: 0.9994\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1328 - accuracy: 0.9994 - val_loss: 0.1449 - val_accuracy: 0.9923\n",
            "Epoch 15/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1244 - accuracy: 0.9994\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1243 - accuracy: 0.9994 - val_loss: 0.1437 - val_accuracy: 0.9923\n",
            "Epoch 16/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1247 - accuracy: 1.0000\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1247 - accuracy: 1.0000 - val_loss: 0.1353 - val_accuracy: 0.9949\n",
            "Epoch 17/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1194 - accuracy: 0.9994\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1194 - accuracy: 0.9994 - val_loss: 0.1531 - val_accuracy: 0.9949\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1168 - accuracy: 1.0000\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1167 - accuracy: 1.0000 - val_loss: 0.1374 - val_accuracy: 0.9923\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1339 - accuracy: 0.9948\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1338 - accuracy: 0.9949 - val_loss: 0.1500 - val_accuracy: 0.9898\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1155 - accuracy: 1.0000\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1153 - accuracy: 1.0000 - val_loss: 0.1435 - val_accuracy: 0.9898\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1048 - accuracy: 1.0000\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1048 - accuracy: 1.0000 - val_loss: 0.1283 - val_accuracy: 0.9898\n",
            "Epoch 22/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1011 - accuracy: 1.0000\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1011 - accuracy: 1.0000 - val_loss: 0.1303 - val_accuracy: 0.9923\n",
            "Epoch 23/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0984 - accuracy: 1.0000\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0984 - accuracy: 1.0000 - val_loss: 0.1230 - val_accuracy: 0.9923\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0959 - accuracy: 1.0000\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0959 - accuracy: 1.0000 - val_loss: 0.2281 - val_accuracy: 0.9642\n",
            "Epoch 25/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0947 - accuracy: 1.0000\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0947 - accuracy: 1.0000 - val_loss: 0.1201 - val_accuracy: 0.9898\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0910 - accuracy: 1.0000\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0910 - accuracy: 1.0000 - val_loss: 0.1148 - val_accuracy: 0.9949\n",
            "Epoch 27/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0931 - accuracy: 1.0000\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0931 - accuracy: 1.0000 - val_loss: 0.1353 - val_accuracy: 0.9872\n",
            "Epoch 28/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0931 - accuracy: 1.0000\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.0931 - accuracy: 1.0000 - val_loss: 0.1145 - val_accuracy: 0.9923\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0868 - accuracy: 1.0000\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0871 - accuracy: 1.0000 - val_loss: 0.1123 - val_accuracy: 0.9923\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0843 - accuracy: 1.0000\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0843 - accuracy: 1.0000 - val_loss: 0.1100 - val_accuracy: 0.9923\n",
            "Epoch 31/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0819 - accuracy: 1.0000\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0820 - accuracy: 1.0000 - val_loss: 0.1043 - val_accuracy: 0.9923\n",
            "Epoch 32/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0808 - accuracy: 1.0000\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0808 - accuracy: 1.0000 - val_loss: 0.1052 - val_accuracy: 0.9923\n",
            "Epoch 33/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0791 - accuracy: 1.0000\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.0791 - accuracy: 1.0000 - val_loss: 0.1057 - val_accuracy: 0.9923\n",
            "Epoch 34/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0775 - accuracy: 1.0000\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0775 - accuracy: 1.0000 - val_loss: 0.1067 - val_accuracy: 0.9949\n",
            "Epoch 35/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1207 - accuracy: 0.9878\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1207 - accuracy: 0.9878 - val_loss: 0.3924 - val_accuracy: 0.9258\n",
            "Epoch 36/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1050 - accuracy: 0.9968\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.1050 - accuracy: 0.9968 - val_loss: 0.1155 - val_accuracy: 0.9949\n",
            "Epoch 36: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/155/assets\n",
            "\n",
            "\n",
            " 78%|███████▊  | 156/200 [6:22:34<1:44:57, 143.12s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 2.4546 - accuracy: 0.3177\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 28ms/step - loss: 2.4518 - accuracy: 0.3186 - val_loss: 1.8794 - val_accuracy: 0.2609\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.9693 - accuracy: 0.5615\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 1.9675 - accuracy: 0.5628 - val_loss: 1.8357 - val_accuracy: 0.4041\n",
            "Epoch 3/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6829 - accuracy: 0.6865\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 1.6829 - accuracy: 0.6865 - val_loss: 1.6058 - val_accuracy: 0.6598\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.4524 - accuracy: 0.7766\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 1.4506 - accuracy: 0.7776 - val_loss: 1.3259 - val_accuracy: 0.7877\n",
            "Epoch 5/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.2724 - accuracy: 0.8260\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 1.2724 - accuracy: 0.8250 - val_loss: 1.1788 - val_accuracy: 0.8491\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.1193 - accuracy: 0.8834\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 1.1185 - accuracy: 0.8840 - val_loss: 1.0466 - val_accuracy: 0.9028\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.0014 - accuracy: 0.9229\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.9993 - accuracy: 0.9237 - val_loss: 0.9532 - val_accuracy: 0.9182\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.9032 - accuracy: 0.9417\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.9020 - accuracy: 0.9423 - val_loss: 0.8616 - val_accuracy: 0.9616\n",
            "Epoch 9/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.8268 - accuracy: 0.9635\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.8268 - accuracy: 0.9635 - val_loss: 0.8033 - val_accuracy: 0.9668\n",
            "Epoch 10/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.7758 - accuracy: 0.9654\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.7758 - accuracy: 0.9654 - val_loss: 0.7510 - val_accuracy: 0.9693\n",
            "Epoch 11/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.7276 - accuracy: 0.9742\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.7275 - accuracy: 0.9744 - val_loss: 0.7070 - val_accuracy: 0.9795\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6854 - accuracy: 0.9747\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.6857 - accuracy: 0.9750 - val_loss: 0.6676 - val_accuracy: 0.9821\n",
            "Epoch 13/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.6487 - accuracy: 0.9800\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.6491 - accuracy: 0.9795 - val_loss: 0.6450 - val_accuracy: 0.9872\n",
            "Epoch 14/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6101 - accuracy: 0.9917\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.6101 - accuracy: 0.9917 - val_loss: 0.6060 - val_accuracy: 0.9898\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5874 - accuracy: 0.9929\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.5868 - accuracy: 0.9929 - val_loss: 0.5846 - val_accuracy: 0.9847\n",
            "Epoch 16/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5613 - accuracy: 0.9923\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.5613 - accuracy: 0.9923 - val_loss: 0.5671 - val_accuracy: 0.9898\n",
            "Epoch 17/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.5389 - accuracy: 0.9955\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.5389 - accuracy: 0.9955 - val_loss: 0.5361 - val_accuracy: 0.9923\n",
            "Epoch 18/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5241 - accuracy: 0.9929\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.5241 - accuracy: 0.9929 - val_loss: 0.5495 - val_accuracy: 0.9795\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5029 - accuracy: 0.9922\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.5023 - accuracy: 0.9923 - val_loss: 0.5050 - val_accuracy: 0.9872\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4850 - accuracy: 0.9948\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.4855 - accuracy: 0.9949 - val_loss: 0.4839 - val_accuracy: 0.9949\n",
            "Epoch 21/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4719 - accuracy: 0.9949\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.4719 - accuracy: 0.9949 - val_loss: 0.4697 - val_accuracy: 0.9974\n",
            "Epoch 22/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4533 - accuracy: 0.9961\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.4530 - accuracy: 0.9962 - val_loss: 0.4550 - val_accuracy: 0.9974\n",
            "Epoch 23/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4391 - accuracy: 0.9968\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.4391 - accuracy: 0.9968 - val_loss: 0.4533 - val_accuracy: 0.9872\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4308 - accuracy: 0.9942\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.4307 - accuracy: 0.9942 - val_loss: 0.4312 - val_accuracy: 0.9974\n",
            "Epoch 25/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4122 - accuracy: 0.9981\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.4126 - accuracy: 0.9981 - val_loss: 0.4253 - val_accuracy: 0.9949\n",
            "Epoch 26/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4042 - accuracy: 0.9968\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.4042 - accuracy: 0.9968 - val_loss: 0.4099 - val_accuracy: 0.9949\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3909 - accuracy: 0.9961\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.3910 - accuracy: 0.9962 - val_loss: 0.4005 - val_accuracy: 0.9949\n",
            "Epoch 28/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3827 - accuracy: 0.9974\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.3827 - accuracy: 0.9974 - val_loss: 0.3888 - val_accuracy: 0.9974\n",
            "Epoch 29/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3718 - accuracy: 0.9974\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.3718 - accuracy: 0.9974 - val_loss: 0.3808 - val_accuracy: 0.9949\n",
            "Epoch 30/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3633 - accuracy: 0.9981\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.3639 - accuracy: 0.9974 - val_loss: 0.3716 - val_accuracy: 0.9974\n",
            "Epoch 31/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3551 - accuracy: 0.9974\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.3553 - accuracy: 0.9974 - val_loss: 0.3652 - val_accuracy: 0.9949\n",
            "Epoch 32/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3442 - accuracy: 0.9981\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.3441 - accuracy: 0.9981 - val_loss: 0.3557 - val_accuracy: 0.9974\n",
            "Epoch 33/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3382 - accuracy: 0.9974\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.3380 - accuracy: 0.9974 - val_loss: 0.3466 - val_accuracy: 0.9949\n",
            "Epoch 34/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3321 - accuracy: 0.9987\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.3322 - accuracy: 0.9987 - val_loss: 0.3419 - val_accuracy: 0.9949\n",
            "Epoch 35/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3237 - accuracy: 0.9987\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.3234 - accuracy: 0.9987 - val_loss: 0.3331 - val_accuracy: 0.9974\n",
            "Epoch 36/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3186 - accuracy: 0.9981\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.3186 - accuracy: 0.9981 - val_loss: 0.3384 - val_accuracy: 0.9923\n",
            "Epoch 37/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3124 - accuracy: 0.9987\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.3124 - accuracy: 0.9987 - val_loss: 0.3216 - val_accuracy: 0.9949\n",
            "Epoch 38/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3023 - accuracy: 0.9981\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.3022 - accuracy: 0.9981 - val_loss: 0.3159 - val_accuracy: 0.9949\n",
            "Epoch 39/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2983 - accuracy: 0.9987\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.2980 - accuracy: 0.9987 - val_loss: 0.3135 - val_accuracy: 0.9949\n",
            "Epoch 40/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2944 - accuracy: 0.9987\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.2944 - accuracy: 0.9987 - val_loss: 0.3013 - val_accuracy: 0.9949\n",
            "Epoch 41/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2880 - accuracy: 0.9974\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.2880 - accuracy: 0.9974 - val_loss: 0.2967 - val_accuracy: 0.9949\n",
            "Epoch 42/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2804 - accuracy: 0.9994\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.2804 - accuracy: 0.9994 - val_loss: 0.2907 - val_accuracy: 0.9949\n",
            "Epoch 43/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2789 - accuracy: 0.9981\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.2791 - accuracy: 0.9981 - val_loss: 0.3165 - val_accuracy: 0.9847\n",
            "Epoch 44/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2714 - accuracy: 1.0000\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.2713 - accuracy: 1.0000 - val_loss: 0.2822 - val_accuracy: 0.9974\n",
            "Epoch 45/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2679 - accuracy: 0.9987\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.2679 - accuracy: 0.9987 - val_loss: 0.2796 - val_accuracy: 0.9949\n",
            "Epoch 46/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2643 - accuracy: 0.9987\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.2641 - accuracy: 0.9987 - val_loss: 0.2731 - val_accuracy: 0.9949\n",
            "Epoch 47/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2588 - accuracy: 1.0000\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.2587 - accuracy: 1.0000 - val_loss: 0.2739 - val_accuracy: 0.9923\n",
            "Epoch 48/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2560 - accuracy: 0.9994\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.2557 - accuracy: 0.9994 - val_loss: 0.2653 - val_accuracy: 0.9923\n",
            "Epoch 49/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2500 - accuracy: 0.9994\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.2500 - accuracy: 0.9994 - val_loss: 0.2609 - val_accuracy: 0.9923\n",
            "Epoch 50/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2464 - accuracy: 1.0000\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.2464 - accuracy: 1.0000 - val_loss: 0.2569 - val_accuracy: 0.9949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/156/assets\n",
            "\n",
            "\n",
            " 78%|███████▊  | 157/200 [6:26:53<2:07:30, 177.92s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.0524 - accuracy: 0.7455\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 26ms/step - loss: 1.0491 - accuracy: 0.7462 - val_loss: 1.8331 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3772 - accuracy: 0.9333\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.3760 - accuracy: 0.9340 - val_loss: 2.0849 - val_accuracy: 0.1023\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2028 - accuracy: 0.9838\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.2020 - accuracy: 0.9840 - val_loss: 1.0949 - val_accuracy: 0.6240\n",
            "Epoch 4/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1952 - accuracy: 0.9795\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1952 - accuracy: 0.9795 - val_loss: 0.2826 - val_accuracy: 0.9719\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1364 - accuracy: 0.9955\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.1360 - accuracy: 0.9955 - val_loss: 0.7115 - val_accuracy: 0.7621\n",
            "Epoch 6/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1216 - accuracy: 0.9942\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.1216 - accuracy: 0.9942 - val_loss: 0.1828 - val_accuracy: 0.9821\n",
            "Epoch 7/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1172 - accuracy: 0.9974\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.1172 - accuracy: 0.9974 - val_loss: 0.2482 - val_accuracy: 0.9463\n",
            "Epoch 8/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0917 - accuracy: 0.9981\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0917 - accuracy: 0.9981 - val_loss: 0.2094 - val_accuracy: 0.9719\n",
            "Epoch 9/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0888 - accuracy: 0.9974\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0888 - accuracy: 0.9974 - val_loss: 0.1607 - val_accuracy: 0.9821\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1302 - accuracy: 0.9909\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1304 - accuracy: 0.9910 - val_loss: 0.6250 - val_accuracy: 0.9591\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2122 - accuracy: 0.9637\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.2121 - accuracy: 0.9641 - val_loss: 0.4952 - val_accuracy: 0.9463\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1788 - accuracy: 0.9780\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1784 - accuracy: 0.9782 - val_loss: 1.1891 - val_accuracy: 0.5908\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1625 - accuracy: 0.9838\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1617 - accuracy: 0.9840 - val_loss: 0.1570 - val_accuracy: 0.9693\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1052 - accuracy: 0.9955\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1050 - accuracy: 0.9955 - val_loss: 0.1221 - val_accuracy: 0.9821\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0791 - accuracy: 1.0000\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0790 - accuracy: 1.0000 - val_loss: 0.1246 - val_accuracy: 0.9847\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0682 - accuracy: 1.0000\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0682 - accuracy: 1.0000 - val_loss: 0.0945 - val_accuracy: 0.9949\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0647 - accuracy: 1.0000\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0647 - accuracy: 1.0000 - val_loss: 0.0921 - val_accuracy: 0.9923\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0595 - accuracy: 1.0000\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0595 - accuracy: 1.0000 - val_loss: 0.1168 - val_accuracy: 0.9898\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1460 - accuracy: 0.9793\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1461 - accuracy: 0.9795 - val_loss: 9.1144 - val_accuracy: 0.5678\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2290 - accuracy: 0.9683\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.2279 - accuracy: 0.9686 - val_loss: 0.6496 - val_accuracy: 0.8184\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1372 - accuracy: 0.9896\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1372 - accuracy: 0.9897 - val_loss: 0.2497 - val_accuracy: 0.9335\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0921 - accuracy: 0.9974\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.0919 - accuracy: 0.9974 - val_loss: 0.1774 - val_accuracy: 0.9693\n",
            "Epoch 22: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/157/assets\n",
            "\n",
            "\n",
            " 79%|███████▉  | 158/200 [6:28:38<1:49:14, 156.05s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 2.4462 - accuracy: 0.3846\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 30ms/step - loss: 2.4462 - accuracy: 0.3846 - val_loss: 1.8578 - val_accuracy: 0.2634\n",
            "Epoch 2/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.9570 - accuracy: 0.5936\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 1.9570 - accuracy: 0.5936 - val_loss: 1.8218 - val_accuracy: 0.2992\n",
            "Epoch 3/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6622 - accuracy: 0.7122\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 1.6622 - accuracy: 0.7122 - val_loss: 1.5760 - val_accuracy: 0.5601\n",
            "Epoch 4/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.3956 - accuracy: 0.8179\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 1.3956 - accuracy: 0.8179 - val_loss: 1.1939 - val_accuracy: 0.8619\n",
            "Epoch 5/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.1822 - accuracy: 0.8866\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 1.1807 - accuracy: 0.8872 - val_loss: 1.0435 - val_accuracy: 0.9079\n",
            "Epoch 6/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.0285 - accuracy: 0.9288\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 1.0285 - accuracy: 0.9288 - val_loss: 0.9233 - val_accuracy: 0.9514\n",
            "Epoch 7/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.9169 - accuracy: 0.9538\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.9169 - accuracy: 0.9538 - val_loss: 0.8353 - val_accuracy: 0.9668\n",
            "Epoch 8/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.8419 - accuracy: 0.9659\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.8410 - accuracy: 0.9660 - val_loss: 0.7720 - val_accuracy: 0.9719\n",
            "Epoch 9/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.7689 - accuracy: 0.9788\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.7689 - accuracy: 0.9788 - val_loss: 0.7089 - val_accuracy: 0.9821\n",
            "Epoch 10/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.7233 - accuracy: 0.9820\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.7238 - accuracy: 0.9821 - val_loss: 0.6698 - val_accuracy: 0.9898\n",
            "Epoch 11/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6844 - accuracy: 0.9859\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.6844 - accuracy: 0.9859 - val_loss: 0.6348 - val_accuracy: 0.9847\n",
            "Epoch 12/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6427 - accuracy: 0.9891\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.6427 - accuracy: 0.9891 - val_loss: 0.6036 - val_accuracy: 0.9923\n",
            "Epoch 13/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6131 - accuracy: 0.9897\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.6131 - accuracy: 0.9897 - val_loss: 0.5731 - val_accuracy: 0.9923\n",
            "Epoch 14/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5848 - accuracy: 0.9936\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.5848 - accuracy: 0.9936 - val_loss: 0.5550 - val_accuracy: 0.9923\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5593 - accuracy: 0.9942\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.5595 - accuracy: 0.9942 - val_loss: 0.5259 - val_accuracy: 0.9949\n",
            "Epoch 16/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.5375 - accuracy: 0.9968\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.5371 - accuracy: 0.9968 - val_loss: 0.5062 - val_accuracy: 0.9949\n",
            "Epoch 17/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5201 - accuracy: 0.9955\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.5201 - accuracy: 0.9955 - val_loss: 0.4891 - val_accuracy: 0.9949\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4966 - accuracy: 0.9968\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.4969 - accuracy: 0.9968 - val_loss: 0.4705 - val_accuracy: 0.9949\n",
            "Epoch 19/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4813 - accuracy: 0.9974\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.4813 - accuracy: 0.9974 - val_loss: 0.4520 - val_accuracy: 0.9923\n",
            "Epoch 20/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4671 - accuracy: 0.9955\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.4671 - accuracy: 0.9955 - val_loss: 0.4397 - val_accuracy: 0.9974\n",
            "Epoch 21/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4476 - accuracy: 0.9987\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.4476 - accuracy: 0.9987 - val_loss: 0.4294 - val_accuracy: 0.9949\n",
            "Epoch 22/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4375 - accuracy: 0.9955\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.4375 - accuracy: 0.9955 - val_loss: 0.4154 - val_accuracy: 0.9974\n",
            "Epoch 23/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4201 - accuracy: 0.9981\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.4201 - accuracy: 0.9981 - val_loss: 0.4019 - val_accuracy: 0.9974\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4084 - accuracy: 0.9994\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.4081 - accuracy: 0.9994 - val_loss: 0.3909 - val_accuracy: 0.9923\n",
            "Epoch 25/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3981 - accuracy: 0.9987\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.3981 - accuracy: 0.9987 - val_loss: 0.3827 - val_accuracy: 0.9923\n",
            "Epoch 26/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3863 - accuracy: 0.9974\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.3868 - accuracy: 0.9974 - val_loss: 0.3739 - val_accuracy: 0.9949\n",
            "Epoch 27/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3737 - accuracy: 0.9981\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.3740 - accuracy: 0.9981 - val_loss: 0.3581 - val_accuracy: 0.9949\n",
            "Epoch 28/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3645 - accuracy: 0.9974\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.3644 - accuracy: 0.9974 - val_loss: 0.3477 - val_accuracy: 0.9974\n",
            "Epoch 29/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3530 - accuracy: 0.9987\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.3531 - accuracy: 0.9987 - val_loss: 0.3411 - val_accuracy: 0.9949\n",
            "Epoch 30/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3452 - accuracy: 0.9994\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.3452 - accuracy: 0.9994 - val_loss: 0.3341 - val_accuracy: 0.9923\n",
            "Epoch 31/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3354 - accuracy: 0.9994\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.3351 - accuracy: 0.9994 - val_loss: 0.3277 - val_accuracy: 0.9974\n",
            "Epoch 32/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3261 - accuracy: 0.9987\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.3261 - accuracy: 0.9987 - val_loss: 0.3165 - val_accuracy: 0.9923\n",
            "Epoch 33/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3184 - accuracy: 0.9994\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.3184 - accuracy: 0.9994 - val_loss: 0.3091 - val_accuracy: 0.9949\n",
            "Epoch 34/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3110 - accuracy: 0.9987\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.3110 - accuracy: 0.9987 - val_loss: 0.3007 - val_accuracy: 0.9923\n",
            "Epoch 35/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3035 - accuracy: 0.9987\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.3037 - accuracy: 0.9987 - val_loss: 0.2926 - val_accuracy: 0.9949\n",
            "Epoch 36/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2959 - accuracy: 0.9987\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.2960 - accuracy: 0.9987 - val_loss: 0.2863 - val_accuracy: 0.9949\n",
            "Epoch 37/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2909 - accuracy: 0.9974\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.2910 - accuracy: 0.9974 - val_loss: 0.2789 - val_accuracy: 0.9949\n",
            "Epoch 38/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2796 - accuracy: 1.0000\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.2796 - accuracy: 1.0000 - val_loss: 0.2741 - val_accuracy: 0.9923\n",
            "Epoch 39/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2731 - accuracy: 1.0000\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.2728 - accuracy: 1.0000 - val_loss: 0.2694 - val_accuracy: 0.9923\n",
            "Epoch 40/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2681 - accuracy: 0.9987\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.2681 - accuracy: 0.9987 - val_loss: 0.2661 - val_accuracy: 0.9949\n",
            "Epoch 41/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2605 - accuracy: 0.9994\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.2604 - accuracy: 0.9994 - val_loss: 0.2653 - val_accuracy: 0.9949\n",
            "Epoch 42/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2549 - accuracy: 0.9994\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.2549 - accuracy: 0.9994 - val_loss: 0.2522 - val_accuracy: 0.9923\n",
            "Epoch 43/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2507 - accuracy: 0.9987\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.2505 - accuracy: 0.9987 - val_loss: 0.2479 - val_accuracy: 0.9923\n",
            "Epoch 44/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2445 - accuracy: 1.0000\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.2443 - accuracy: 1.0000 - val_loss: 0.2429 - val_accuracy: 0.9949\n",
            "Epoch 45/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2380 - accuracy: 1.0000\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.2379 - accuracy: 1.0000 - val_loss: 0.2366 - val_accuracy: 0.9923\n",
            "Epoch 46/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2326 - accuracy: 1.0000\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.2326 - accuracy: 1.0000 - val_loss: 0.2345 - val_accuracy: 0.9923\n",
            "Epoch 47/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2270 - accuracy: 0.9994\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.2269 - accuracy: 0.9994 - val_loss: 0.2265 - val_accuracy: 0.9923\n",
            "Epoch 48/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2209 - accuracy: 0.9994\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.2208 - accuracy: 0.9994 - val_loss: 0.2209 - val_accuracy: 0.9923\n",
            "Epoch 49/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2176 - accuracy: 0.9994\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.2176 - accuracy: 0.9994 - val_loss: 0.2299 - val_accuracy: 0.9923\n",
            "Epoch 50/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2149 - accuracy: 0.9994\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.2148 - accuracy: 0.9994 - val_loss: 0.2170 - val_accuracy: 0.9923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/158/assets\n",
            "\n",
            "\n",
            " 80%|███████▉  | 159/200 [6:33:10<2:10:21, 190.78s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.8550 - accuracy: 0.4449\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 11ms/step - loss: 1.8550 - accuracy: 0.4449 - val_loss: 1.7726 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.1793 - accuracy: 0.7519\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 1.1787 - accuracy: 0.7526 - val_loss: 2.2913 - val_accuracy: 0.2864\n",
            "Epoch 3/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.8250 - accuracy: 0.8829\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.8231 - accuracy: 0.8840 - val_loss: 1.6041 - val_accuracy: 0.4859\n",
            "Epoch 4/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.6298 - accuracy: 0.9414\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.6304 - accuracy: 0.9410 - val_loss: 0.6259 - val_accuracy: 0.9284\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5138 - accuracy: 0.9728\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.5154 - accuracy: 0.9731 - val_loss: 0.4969 - val_accuracy: 0.9872\n",
            "Epoch 6/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4495 - accuracy: 0.9865\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.4495 - accuracy: 0.9865 - val_loss: 0.4495 - val_accuracy: 0.9693\n",
            "Epoch 7/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4065 - accuracy: 0.9839\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.4074 - accuracy: 0.9840 - val_loss: 0.4047 - val_accuracy: 0.9872\n",
            "Epoch 8/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 0.3612 - accuracy: 0.9940\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.3599 - accuracy: 0.9936 - val_loss: 0.3641 - val_accuracy: 0.9949\n",
            "Epoch 9/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.3275 - accuracy: 0.9935\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.3265 - accuracy: 0.9936 - val_loss: 0.3348 - val_accuracy: 0.9949\n",
            "Epoch 10/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 0.2960 - accuracy: 0.9974\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.2956 - accuracy: 0.9974 - val_loss: 0.3128 - val_accuracy: 0.9949\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2725 - accuracy: 0.9955\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.2727 - accuracy: 0.9955 - val_loss: 0.2895 - val_accuracy: 0.9949\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2541 - accuracy: 0.9974\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.2540 - accuracy: 0.9974 - val_loss: 0.2747 - val_accuracy: 0.9949\n",
            "Epoch 13/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2368 - accuracy: 0.9967\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.2363 - accuracy: 0.9968 - val_loss: 0.2603 - val_accuracy: 0.9949\n",
            "Epoch 14/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 0.2204 - accuracy: 0.9980\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.2203 - accuracy: 0.9981 - val_loss: 0.2419 - val_accuracy: 0.9949\n",
            "Epoch 15/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2026 - accuracy: 0.9987\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.2026 - accuracy: 0.9987 - val_loss: 0.2315 - val_accuracy: 0.9949\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1923 - accuracy: 0.9987\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1924 - accuracy: 0.9987 - val_loss: 0.2114 - val_accuracy: 0.9949\n",
            "Epoch 17/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1819 - accuracy: 0.9987\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.1818 - accuracy: 0.9987 - val_loss: 0.1983 - val_accuracy: 0.9949\n",
            "Epoch 18/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 0.1663 - accuracy: 1.0000\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.1666 - accuracy: 1.0000 - val_loss: 0.1872 - val_accuracy: 0.9949\n",
            "Epoch 19/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1601 - accuracy: 1.0000\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.1601 - accuracy: 1.0000 - val_loss: 0.1790 - val_accuracy: 0.9949\n",
            "Epoch 20/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1489 - accuracy: 1.0000\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.1489 - accuracy: 1.0000 - val_loss: 0.1687 - val_accuracy: 0.9949\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1457 - accuracy: 0.9974\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1455 - accuracy: 0.9974 - val_loss: 0.1622 - val_accuracy: 0.9949\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1364 - accuracy: 1.0000\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.1363 - accuracy: 1.0000 - val_loss: 0.1528 - val_accuracy: 0.9974\n",
            "Epoch 23/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1272 - accuracy: 0.9993\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.1270 - accuracy: 0.9994 - val_loss: 0.1472 - val_accuracy: 0.9949\n",
            "Epoch 24/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.1223 - accuracy: 1.0000\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.1226 - accuracy: 1.0000 - val_loss: 0.1448 - val_accuracy: 0.9923\n",
            "Epoch 25/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1161 - accuracy: 1.0000\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.1161 - accuracy: 1.0000 - val_loss: 0.1374 - val_accuracy: 0.9949\n",
            "Epoch 26/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1132 - accuracy: 1.0000\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.1132 - accuracy: 1.0000 - val_loss: 0.1307 - val_accuracy: 0.9974\n",
            "Epoch 27/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1084 - accuracy: 0.9994\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.1083 - accuracy: 0.9994 - val_loss: 0.1253 - val_accuracy: 0.9974\n",
            "Epoch 28/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1050 - accuracy: 1.0000\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.1050 - accuracy: 1.0000 - val_loss: 0.1292 - val_accuracy: 0.9949\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1022 - accuracy: 1.0000\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.1020 - accuracy: 1.0000 - val_loss: 0.1253 - val_accuracy: 0.9923\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0968 - accuracy: 1.0000\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0967 - accuracy: 1.0000 - val_loss: 0.1169 - val_accuracy: 0.9974\n",
            "Epoch 31/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0942 - accuracy: 1.0000\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0942 - accuracy: 1.0000 - val_loss: 0.1153 - val_accuracy: 0.9949\n",
            "Epoch 32/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.0907 - accuracy: 1.0000\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.0905 - accuracy: 1.0000 - val_loss: 0.1101 - val_accuracy: 0.9974\n",
            "Epoch 33/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0872 - accuracy: 1.0000\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0872 - accuracy: 1.0000 - val_loss: 0.1045 - val_accuracy: 0.9974\n",
            "Epoch 34/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0880 - accuracy: 1.0000\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0879 - accuracy: 1.0000 - val_loss: 0.1067 - val_accuracy: 0.9974\n",
            "Epoch 35/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0831 - accuracy: 1.0000\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0830 - accuracy: 1.0000 - val_loss: 0.1038 - val_accuracy: 0.9949\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0806 - accuracy: 1.0000\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.0806 - accuracy: 1.0000 - val_loss: 0.1011 - val_accuracy: 0.9923\n",
            "Epoch 37/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.0789 - accuracy: 1.0000\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.0790 - accuracy: 1.0000 - val_loss: 0.0973 - val_accuracy: 0.9974\n",
            "Epoch 38/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 0.0760 - accuracy: 1.0000\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0760 - accuracy: 1.0000 - val_loss: 0.0963 - val_accuracy: 0.9949\n",
            "Epoch 39/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0743 - accuracy: 1.0000\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0743 - accuracy: 1.0000 - val_loss: 0.0945 - val_accuracy: 0.9974\n",
            "Epoch 40/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.0721 - accuracy: 1.0000\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0721 - accuracy: 1.0000 - val_loss: 0.0894 - val_accuracy: 0.9974\n",
            "Epoch 41/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.0711 - accuracy: 1.0000\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.0711 - accuracy: 1.0000 - val_loss: 0.0903 - val_accuracy: 0.9974\n",
            "Epoch 42/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0700 - accuracy: 1.0000\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0700 - accuracy: 1.0000 - val_loss: 0.0976 - val_accuracy: 0.9898\n",
            "Epoch 43/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.0683 - accuracy: 1.0000\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0684 - accuracy: 1.0000 - val_loss: 0.0864 - val_accuracy: 0.9923\n",
            "Epoch 44/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0661 - accuracy: 1.0000\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0661 - accuracy: 1.0000 - val_loss: 0.0838 - val_accuracy: 0.9974\n",
            "Epoch 45/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0633 - accuracy: 1.0000\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0634 - accuracy: 1.0000 - val_loss: 0.0824 - val_accuracy: 0.9949\n",
            "Epoch 46/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0633 - accuracy: 1.0000\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.0633 - accuracy: 1.0000 - val_loss: 0.0930 - val_accuracy: 0.9923\n",
            "Epoch 47/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 0.0621 - accuracy: 1.0000\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.0620 - accuracy: 1.0000 - val_loss: 0.0830 - val_accuracy: 0.9949\n",
            "Epoch 48/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0619 - accuracy: 1.0000\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0618 - accuracy: 1.0000 - val_loss: 0.0796 - val_accuracy: 0.9949\n",
            "Epoch 49/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0590 - accuracy: 1.0000\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.0590 - accuracy: 1.0000 - val_loss: 0.0839 - val_accuracy: 0.9923\n",
            "Epoch 50/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.0587 - accuracy: 1.0000\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.0586 - accuracy: 1.0000 - val_loss: 0.0793 - val_accuracy: 0.9974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/159/assets\n",
            "\n",
            "\n",
            " 80%|████████  | 160/200 [6:35:37<1:58:27, 177.70s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.6285 - accuracy: 0.4974\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 16ms/step - loss: 1.6232 - accuracy: 0.5013 - val_loss: 3.4912 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.0047 - accuracy: 0.7403\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 1.0041 - accuracy: 0.7404 - val_loss: 3.9478 - val_accuracy: 0.1151\n",
            "Epoch 3/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.5055 - accuracy: 0.8757\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.5072 - accuracy: 0.8737 - val_loss: 0.9942 - val_accuracy: 0.6624\n",
            "Epoch 4/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.6000 - accuracy: 0.8436\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.6231 - accuracy: 0.8314 - val_loss: 1.4229 - val_accuracy: 0.5141\n",
            "Epoch 5/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.8473 - accuracy: 0.7910\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.8383 - accuracy: 0.7936 - val_loss: 0.5022 - val_accuracy: 0.8900\n",
            "Epoch 6/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4315 - accuracy: 0.9143\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.4300 - accuracy: 0.9147 - val_loss: 1.4259 - val_accuracy: 0.5652\n",
            "Epoch 7/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.4031 - accuracy: 0.9116\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.4068 - accuracy: 0.9109 - val_loss: 0.5490 - val_accuracy: 0.8517\n",
            "Epoch 8/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.2976 - accuracy: 0.9346\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.2965 - accuracy: 0.9346 - val_loss: 0.6767 - val_accuracy: 0.8210\n",
            "Epoch 9/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2236 - accuracy: 0.9615\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.2236 - accuracy: 0.9615 - val_loss: 0.3682 - val_accuracy: 0.9003\n",
            "Epoch 10/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1893 - accuracy: 0.9660\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.1893 - accuracy: 0.9660 - val_loss: 0.7951 - val_accuracy: 0.8363\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2528 - accuracy: 0.9437\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.2518 - accuracy: 0.9442 - val_loss: 1.0151 - val_accuracy: 0.7980\n",
            "Epoch 12/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.5923 - accuracy: 0.8770\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.5913 - accuracy: 0.8769 - val_loss: 0.3777 - val_accuracy: 0.9105\n",
            "Epoch 13/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.8074 - accuracy: 0.7917\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.8074 - accuracy: 0.7917 - val_loss: 0.5926 - val_accuracy: 0.8517\n",
            "Epoch 14/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2639 - accuracy: 0.9492\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.2657 - accuracy: 0.9481 - val_loss: 0.3441 - val_accuracy: 0.9182\n",
            "Epoch 15/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.2572 - accuracy: 0.9391\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.2591 - accuracy: 0.9372 - val_loss: 0.2932 - val_accuracy: 0.9488\n",
            "Epoch 16/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2346 - accuracy: 0.9558\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.2346 - accuracy: 0.9558 - val_loss: 0.4751 - val_accuracy: 0.8977\n",
            "Epoch 17/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1703 - accuracy: 0.9628\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1703 - accuracy: 0.9628 - val_loss: 1.5652 - val_accuracy: 0.7263\n",
            "Epoch 18/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1750 - accuracy: 0.9609\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.1750 - accuracy: 0.9609 - val_loss: 0.5304 - val_accuracy: 0.8696\n",
            "Epoch 19/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.8053 - accuracy: 0.8229\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.7963 - accuracy: 0.8250 - val_loss: 0.6368 - val_accuracy: 0.9028\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2562 - accuracy: 0.9598\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.2554 - accuracy: 0.9596 - val_loss: 0.2673 - val_accuracy: 0.9463\n",
            "Epoch 21/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.2021 - accuracy: 0.9660\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.2027 - accuracy: 0.9654 - val_loss: 0.4555 - val_accuracy: 0.8568\n",
            "Epoch 22/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1593 - accuracy: 0.9772\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1590 - accuracy: 0.9769 - val_loss: 0.4320 - val_accuracy: 0.9079\n",
            "Epoch 23/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1257 - accuracy: 0.9824\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1251 - accuracy: 0.9827 - val_loss: 0.2357 - val_accuracy: 0.9386\n",
            "Epoch 24/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1394 - accuracy: 0.9753\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1383 - accuracy: 0.9756 - val_loss: 0.2943 - val_accuracy: 0.9233\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1038 - accuracy: 0.9838\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1036 - accuracy: 0.9840 - val_loss: 0.3000 - val_accuracy: 0.9284\n",
            "Epoch 26/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1596 - accuracy: 0.9710\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1689 - accuracy: 0.9692 - val_loss: 0.8784 - val_accuracy: 0.8133\n",
            "Epoch 27/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.9002 - accuracy: 0.3691\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 1.9029 - accuracy: 0.3654 - val_loss: 1.7696 - val_accuracy: 0.2634\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.7553 - accuracy: 0.2720\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 1.7544 - accuracy: 0.2712 - val_loss: 1.7403 - val_accuracy: 0.2864\n",
            "Epoch 28: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/160/assets\n",
            "\n",
            "\n",
            " 80%|████████  | 161/200 [6:36:56<1:36:22, 148.27s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 2.6008 - accuracy: 0.2258\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 14ms/step - loss: 2.5951 - accuracy: 0.2244 - val_loss: 1.8329 - val_accuracy: 0.2634\n",
            "Epoch 2/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 2.0556 - accuracy: 0.3305\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 2.0544 - accuracy: 0.3314 - val_loss: 1.8168 - val_accuracy: 0.2660\n",
            "Epoch 3/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.9058 - accuracy: 0.4466\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 1.9071 - accuracy: 0.4455 - val_loss: 1.7246 - val_accuracy: 0.3606\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.7885 - accuracy: 0.4994\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 1.7870 - accuracy: 0.5000 - val_loss: 1.6709 - val_accuracy: 0.5345\n",
            "Epoch 5/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6825 - accuracy: 0.5741\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.6808 - accuracy: 0.5744 - val_loss: 1.6103 - val_accuracy: 0.5703\n",
            "Epoch 6/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.5960 - accuracy: 0.6120\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.5929 - accuracy: 0.6128 - val_loss: 1.5212 - val_accuracy: 0.6189\n",
            "Epoch 7/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.4885 - accuracy: 0.6616\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.4852 - accuracy: 0.6647 - val_loss: 1.4315 - val_accuracy: 0.6598\n",
            "Epoch 8/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.4032 - accuracy: 0.7036\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 1.4025 - accuracy: 0.7038 - val_loss: 1.3477 - val_accuracy: 0.6752\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.3309 - accuracy: 0.7228\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.3292 - accuracy: 0.7237 - val_loss: 1.2709 - val_accuracy: 0.7494\n",
            "Epoch 10/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.2580 - accuracy: 0.7454\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.2555 - accuracy: 0.7436 - val_loss: 1.1962 - val_accuracy: 0.7775\n",
            "Epoch 11/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.1766 - accuracy: 0.7827\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 1.1766 - accuracy: 0.7827 - val_loss: 1.1282 - val_accuracy: 0.7954\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.1068 - accuracy: 0.8089\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.1049 - accuracy: 0.8103 - val_loss: 1.0631 - val_accuracy: 0.8235\n",
            "Epoch 13/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.0515 - accuracy: 0.8268\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.0502 - accuracy: 0.8276 - val_loss: 1.0028 - val_accuracy: 0.8414\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.9970 - accuracy: 0.8446\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.9980 - accuracy: 0.8429 - val_loss: 0.9509 - val_accuracy: 0.8491\n",
            "Epoch 15/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.9411 - accuracy: 0.8615\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.9407 - accuracy: 0.8622 - val_loss: 0.9048 - val_accuracy: 0.8772\n",
            "Epoch 16/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.8998 - accuracy: 0.8776\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.8981 - accuracy: 0.8788 - val_loss: 0.8591 - val_accuracy: 0.8875\n",
            "Epoch 17/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.8542 - accuracy: 0.8942\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.8542 - accuracy: 0.8942 - val_loss: 0.8175 - val_accuracy: 0.8977\n",
            "Epoch 18/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.8119 - accuracy: 0.9071\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.8119 - accuracy: 0.9071 - val_loss: 0.7821 - val_accuracy: 0.9079\n",
            "Epoch 19/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.7841 - accuracy: 0.9212\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.7827 - accuracy: 0.9218 - val_loss: 0.7584 - val_accuracy: 0.9130\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7388 - accuracy: 0.9326\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.7377 - accuracy: 0.9333 - val_loss: 0.7175 - val_accuracy: 0.9386\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7113 - accuracy: 0.9430\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.7114 - accuracy: 0.9436 - val_loss: 0.6935 - val_accuracy: 0.9437\n",
            "Epoch 22/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.6839 - accuracy: 0.9476\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.6870 - accuracy: 0.9468 - val_loss: 0.6723 - val_accuracy: 0.9514\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6630 - accuracy: 0.9501\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.6630 - accuracy: 0.9506 - val_loss: 0.6422 - val_accuracy: 0.9540\n",
            "Epoch 24/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.6379 - accuracy: 0.9510\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.6387 - accuracy: 0.9506 - val_loss: 0.6201 - val_accuracy: 0.9591\n",
            "Epoch 25/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6253 - accuracy: 0.9545\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.6253 - accuracy: 0.9545 - val_loss: 0.6005 - val_accuracy: 0.9616\n",
            "Epoch 26/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.5896 - accuracy: 0.9701\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.5883 - accuracy: 0.9705 - val_loss: 0.5832 - val_accuracy: 0.9642\n",
            "Epoch 27/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5783 - accuracy: 0.9686\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.5783 - accuracy: 0.9686 - val_loss: 0.5619 - val_accuracy: 0.9744\n",
            "Epoch 28/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.5584 - accuracy: 0.9740\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.5583 - accuracy: 0.9737 - val_loss: 0.5428 - val_accuracy: 0.9719\n",
            "Epoch 29/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5469 - accuracy: 0.9750\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.5469 - accuracy: 0.9750 - val_loss: 0.5258 - val_accuracy: 0.9744\n",
            "Epoch 30/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.5310 - accuracy: 0.9740\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.5317 - accuracy: 0.9724 - val_loss: 0.5248 - val_accuracy: 0.9719\n",
            "Epoch 31/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5199 - accuracy: 0.9754\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.5193 - accuracy: 0.9756 - val_loss: 0.4999 - val_accuracy: 0.9795\n",
            "Epoch 32/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.4930 - accuracy: 0.9850\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.4944 - accuracy: 0.9840 - val_loss: 0.4865 - val_accuracy: 0.9795\n",
            "Epoch 33/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.4897 - accuracy: 0.9823\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.4885 - accuracy: 0.9827 - val_loss: 0.4779 - val_accuracy: 0.9821\n",
            "Epoch 34/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4814 - accuracy: 0.9814\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.4814 - accuracy: 0.9814 - val_loss: 0.4664 - val_accuracy: 0.9847\n",
            "Epoch 35/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4627 - accuracy: 0.9896\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.4629 - accuracy: 0.9897 - val_loss: 0.4483 - val_accuracy: 0.9898\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4552 - accuracy: 0.9851\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.4544 - accuracy: 0.9853 - val_loss: 0.4373 - val_accuracy: 0.9872\n",
            "Epoch 37/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4416 - accuracy: 0.9838\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.4417 - accuracy: 0.9840 - val_loss: 0.4326 - val_accuracy: 0.9872\n",
            "Epoch 38/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.4342 - accuracy: 0.9829\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.4346 - accuracy: 0.9827 - val_loss: 0.4215 - val_accuracy: 0.9898\n",
            "Epoch 39/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4209 - accuracy: 0.9883\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.4220 - accuracy: 0.9872 - val_loss: 0.4138 - val_accuracy: 0.9898\n",
            "Epoch 40/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.4096 - accuracy: 0.9902\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.4098 - accuracy: 0.9904 - val_loss: 0.4008 - val_accuracy: 0.9898\n",
            "Epoch 41/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4015 - accuracy: 0.9904\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.4015 - accuracy: 0.9904 - val_loss: 0.3925 - val_accuracy: 0.9898\n",
            "Epoch 42/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3990 - accuracy: 0.9929\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.3985 - accuracy: 0.9929 - val_loss: 0.3864 - val_accuracy: 0.9923\n",
            "Epoch 43/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3883 - accuracy: 0.9902\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.3883 - accuracy: 0.9904 - val_loss: 0.3774 - val_accuracy: 0.9923\n",
            "Epoch 44/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3795 - accuracy: 0.9902\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.3790 - accuracy: 0.9904 - val_loss: 0.3715 - val_accuracy: 0.9923\n",
            "Epoch 45/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3768 - accuracy: 0.9961\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.3761 - accuracy: 0.9962 - val_loss: 0.3640 - val_accuracy: 0.9898\n",
            "Epoch 46/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3701 - accuracy: 0.9935\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.3704 - accuracy: 0.9936 - val_loss: 0.3553 - val_accuracy: 0.9949\n",
            "Epoch 47/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.3563 - accuracy: 0.9967\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.3559 - accuracy: 0.9962 - val_loss: 0.3504 - val_accuracy: 0.9898\n",
            "Epoch 48/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.3509 - accuracy: 0.9947\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.3504 - accuracy: 0.9949 - val_loss: 0.3404 - val_accuracy: 0.9949\n",
            "Epoch 49/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3473 - accuracy: 0.9948\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.3473 - accuracy: 0.9949 - val_loss: 0.3359 - val_accuracy: 0.9949\n",
            "Epoch 50/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.3372 - accuracy: 0.9948\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.3372 - accuracy: 0.9949 - val_loss: 0.3327 - val_accuracy: 0.9923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/161/assets\n",
            "\n",
            "\n",
            " 81%|████████  | 162/200 [6:39:24<1:33:42, 147.95s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.1329 - accuracy: 0.7719\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 26ms/step - loss: 1.1298 - accuracy: 0.7731 - val_loss: 1.8917 - val_accuracy: 0.2660\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3475 - accuracy: 0.9747\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.3464 - accuracy: 0.9750 - val_loss: 1.7068 - val_accuracy: 0.4757\n",
            "Epoch 3/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4184 - accuracy: 0.9526\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.4184 - accuracy: 0.9526 - val_loss: 1.7562 - val_accuracy: 0.5396\n",
            "Epoch 4/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2525 - accuracy: 0.9865\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.2525 - accuracy: 0.9865 - val_loss: 0.3785 - val_accuracy: 0.9488\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2014 - accuracy: 0.9942\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.2013 - accuracy: 0.9942 - val_loss: 0.2699 - val_accuracy: 0.9719\n",
            "Epoch 6/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2267 - accuracy: 0.9852\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.2265 - accuracy: 0.9853 - val_loss: 0.3172 - val_accuracy: 0.9770\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2242 - accuracy: 0.9877\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.2235 - accuracy: 0.9878 - val_loss: 0.2511 - val_accuracy: 0.9744\n",
            "Epoch 8/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2146 - accuracy: 0.9852\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 25ms/step - loss: 0.2145 - accuracy: 0.9853 - val_loss: 0.2275 - val_accuracy: 0.9795\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1621 - accuracy: 0.9981\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1620 - accuracy: 0.9981 - val_loss: 0.1833 - val_accuracy: 0.9847\n",
            "Epoch 10/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1720 - accuracy: 0.9948\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1719 - accuracy: 0.9949 - val_loss: 0.2791 - val_accuracy: 0.9770\n",
            "Epoch 11/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1605 - accuracy: 0.9962\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1605 - accuracy: 0.9962 - val_loss: 0.3390 - val_accuracy: 0.9284\n",
            "Epoch 12/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1436 - accuracy: 0.9974\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1436 - accuracy: 0.9974 - val_loss: 0.3589 - val_accuracy: 0.9284\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1285 - accuracy: 0.9987\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1283 - accuracy: 0.9987 - val_loss: 0.1582 - val_accuracy: 0.9898\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1208 - accuracy: 0.9974\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1209 - accuracy: 0.9974 - val_loss: 0.1920 - val_accuracy: 0.9821\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2424 - accuracy: 0.9670\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.2421 - accuracy: 0.9673 - val_loss: 0.6115 - val_accuracy: 0.9437\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2019 - accuracy: 0.9851\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.2020 - accuracy: 0.9846 - val_loss: 0.2564 - val_accuracy: 0.9540\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1487 - accuracy: 0.9948\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1485 - accuracy: 0.9949 - val_loss: 0.2340 - val_accuracy: 0.9872\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1242 - accuracy: 0.9994\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1240 - accuracy: 0.9994 - val_loss: 0.1263 - val_accuracy: 0.9949\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1318 - accuracy: 0.9935\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1319 - accuracy: 0.9936 - val_loss: 0.2175 - val_accuracy: 0.9616\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2510 - accuracy: 0.9689\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.2505 - accuracy: 0.9686 - val_loss: 3.0377 - val_accuracy: 0.4757\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1522 - accuracy: 0.9968\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1518 - accuracy: 0.9968 - val_loss: 0.1409 - val_accuracy: 0.9923\n",
            "Epoch 22/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1088 - accuracy: 0.9987\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1087 - accuracy: 0.9987 - val_loss: 0.1225 - val_accuracy: 0.9949\n",
            "Epoch 23/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0974 - accuracy: 1.0000\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0974 - accuracy: 1.0000 - val_loss: 0.1167 - val_accuracy: 0.9949\n",
            "Epoch 24/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1442 - accuracy: 0.9865\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1442 - accuracy: 0.9865 - val_loss: 2.1930 - val_accuracy: 0.7775\n",
            "Epoch 25/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1406 - accuracy: 0.9948\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1404 - accuracy: 0.9949 - val_loss: 0.1291 - val_accuracy: 0.9923\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1056 - accuracy: 0.9955\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1055 - accuracy: 0.9955 - val_loss: 0.2256 - val_accuracy: 0.9821\n",
            "Epoch 27/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0949 - accuracy: 0.9981\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0948 - accuracy: 0.9981 - val_loss: 0.1045 - val_accuracy: 0.9949\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0802 - accuracy: 0.9994\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0801 - accuracy: 0.9994 - val_loss: 0.1004 - val_accuracy: 0.9898\n",
            "Epoch 29/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0758 - accuracy: 0.9994\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0758 - accuracy: 0.9994 - val_loss: 0.1061 - val_accuracy: 0.9923\n",
            "Epoch 30/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0658 - accuracy: 1.0000\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0658 - accuracy: 1.0000 - val_loss: 0.0874 - val_accuracy: 0.9923\n",
            "Epoch 31/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0627 - accuracy: 1.0000\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0627 - accuracy: 1.0000 - val_loss: 0.1302 - val_accuracy: 0.9770\n",
            "Epoch 32/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0770 - accuracy: 0.9968\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0769 - accuracy: 0.9968 - val_loss: 0.0938 - val_accuracy: 0.9923\n",
            "Epoch 33/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0588 - accuracy: 1.0000\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0588 - accuracy: 1.0000 - val_loss: 0.0737 - val_accuracy: 0.9949\n",
            "Epoch 34/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0721 - accuracy: 0.9948\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0724 - accuracy: 0.9949 - val_loss: 0.2597 - val_accuracy: 0.9719\n",
            "Epoch 35/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1707 - accuracy: 0.9780\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1745 - accuracy: 0.9769 - val_loss: 0.3074 - val_accuracy: 0.9744\n",
            "Epoch 36/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1430 - accuracy: 0.9859\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1430 - accuracy: 0.9859 - val_loss: 0.1250 - val_accuracy: 0.9923\n",
            "Epoch 37/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0829 - accuracy: 1.0000\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0829 - accuracy: 1.0000 - val_loss: 0.1172 - val_accuracy: 0.9923\n",
            "Epoch 38/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0778 - accuracy: 0.9987\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0778 - accuracy: 0.9987 - val_loss: 0.1034 - val_accuracy: 0.9898\n",
            "Epoch 38: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/162/assets\n",
            "\n",
            "\n",
            " 82%|████████▏ | 163/200 [6:42:51<1:42:12, 165.73s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.3610 - accuracy: 0.6955\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 17ms/step - loss: 1.3610 - accuracy: 0.6955 - val_loss: 1.8369 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4242 - accuracy: 0.9508\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.4247 - accuracy: 0.9506 - val_loss: 1.6930 - val_accuracy: 0.2864\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2805 - accuracy: 0.9799\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.2801 - accuracy: 0.9801 - val_loss: 0.8597 - val_accuracy: 0.7136\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2216 - accuracy: 0.9896\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.2219 - accuracy: 0.9897 - val_loss: 0.4242 - val_accuracy: 0.9130\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2332 - accuracy: 0.9845\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.2329 - accuracy: 0.9840 - val_loss: 0.3549 - val_accuracy: 0.9335\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1629 - accuracy: 0.9987\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1626 - accuracy: 0.9987 - val_loss: 0.1728 - val_accuracy: 0.9949\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1519 - accuracy: 0.9968\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1524 - accuracy: 0.9968 - val_loss: 0.9170 - val_accuracy: 0.7596\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1948 - accuracy: 0.9903\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1945 - accuracy: 0.9904 - val_loss: 0.2368 - val_accuracy: 0.9770\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1642 - accuracy: 0.9948\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1639 - accuracy: 0.9949 - val_loss: 0.1518 - val_accuracy: 0.9949\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1278 - accuracy: 1.0000\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1277 - accuracy: 1.0000 - val_loss: 0.1384 - val_accuracy: 0.9949\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1163 - accuracy: 1.0000\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1163 - accuracy: 1.0000 - val_loss: 0.1380 - val_accuracy: 0.9974\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1056 - accuracy: 1.0000\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1056 - accuracy: 1.0000 - val_loss: 0.1174 - val_accuracy: 0.9974\n",
            "Epoch 13/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1024 - accuracy: 0.9993\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1030 - accuracy: 0.9994 - val_loss: 0.1574 - val_accuracy: 0.9923\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1561 - accuracy: 0.9935\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1593 - accuracy: 0.9923 - val_loss: 2.0793 - val_accuracy: 0.6982\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4835 - accuracy: 0.9152\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.4806 - accuracy: 0.9160 - val_loss: 0.3534 - val_accuracy: 0.9488\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1898 - accuracy: 0.9890\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1897 - accuracy: 0.9891 - val_loss: 0.2258 - val_accuracy: 0.9847\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1466 - accuracy: 1.0000\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1466 - accuracy: 1.0000 - val_loss: 0.1637 - val_accuracy: 0.9898\n",
            "Epoch 17: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/163/assets\n",
            "\n",
            "\n",
            " 82%|████████▏ | 164/200 [6:44:18<1:25:17, 142.15s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.3760 - accuracy: 0.7191\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 27ms/step - loss: 1.3717 - accuracy: 0.7205 - val_loss: 1.7530 - val_accuracy: 0.4118\n",
            "Epoch 2/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.5229 - accuracy: 0.9781\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 25ms/step - loss: 0.5223 - accuracy: 0.9782 - val_loss: 1.7687 - val_accuracy: 0.3683\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3742 - accuracy: 0.9961\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 25ms/step - loss: 0.3738 - accuracy: 0.9962 - val_loss: 0.8081 - val_accuracy: 0.8619\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3086 - accuracy: 0.9981\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.3083 - accuracy: 0.9981 - val_loss: 0.3103 - val_accuracy: 0.9923\n",
            "Epoch 5/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2658 - accuracy: 0.9981\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.2657 - accuracy: 0.9981 - val_loss: 0.2458 - val_accuracy: 0.9974\n",
            "Epoch 6/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2352 - accuracy: 0.9981\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.2352 - accuracy: 0.9981 - val_loss: 0.2245 - val_accuracy: 0.9949\n",
            "Epoch 7/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2107 - accuracy: 0.9974\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.2106 - accuracy: 0.9974 - val_loss: 0.2113 - val_accuracy: 0.9923\n",
            "Epoch 8/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1972 - accuracy: 0.9981\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.1969 - accuracy: 0.9981 - val_loss: 0.1943 - val_accuracy: 0.9949\n",
            "Epoch 9/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1743 - accuracy: 0.9987\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.1743 - accuracy: 0.9987 - val_loss: 0.1730 - val_accuracy: 0.9949\n",
            "Epoch 10/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1595 - accuracy: 1.0000\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.1597 - accuracy: 1.0000 - val_loss: 0.1770 - val_accuracy: 0.9923\n",
            "Epoch 11/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1497 - accuracy: 0.9994\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.1497 - accuracy: 0.9994 - val_loss: 0.1866 - val_accuracy: 0.9898\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1417 - accuracy: 1.0000\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 25ms/step - loss: 0.1415 - accuracy: 1.0000 - val_loss: 0.1488 - val_accuracy: 0.9949\n",
            "Epoch 13/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1322 - accuracy: 0.9994\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 25ms/step - loss: 0.1322 - accuracy: 0.9994 - val_loss: 0.1527 - val_accuracy: 0.9923\n",
            "Epoch 14/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1335 - accuracy: 0.9981\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 25ms/step - loss: 0.1335 - accuracy: 0.9981 - val_loss: 0.1539 - val_accuracy: 0.9949\n",
            "Epoch 15/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1232 - accuracy: 1.0000\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 25ms/step - loss: 0.1232 - accuracy: 1.0000 - val_loss: 0.1381 - val_accuracy: 0.9949\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1195 - accuracy: 0.9994\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 25ms/step - loss: 0.1195 - accuracy: 0.9994 - val_loss: 0.1370 - val_accuracy: 0.9949\n",
            "Epoch 17/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1138 - accuracy: 1.0000\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 25ms/step - loss: 0.1138 - accuracy: 1.0000 - val_loss: 0.1258 - val_accuracy: 0.9949\n",
            "Epoch 18/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1088 - accuracy: 1.0000\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 25ms/step - loss: 0.1088 - accuracy: 1.0000 - val_loss: 0.1230 - val_accuracy: 0.9949\n",
            "Epoch 19/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1067 - accuracy: 1.0000\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 25ms/step - loss: 0.1067 - accuracy: 1.0000 - val_loss: 0.1234 - val_accuracy: 0.9949\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1064 - accuracy: 1.0000\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 25ms/step - loss: 0.1064 - accuracy: 1.0000 - val_loss: 0.1316 - val_accuracy: 0.9923\n",
            "Epoch 21/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1008 - accuracy: 1.0000\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 25ms/step - loss: 0.1008 - accuracy: 1.0000 - val_loss: 0.1215 - val_accuracy: 0.9949\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0973 - accuracy: 1.0000\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 25ms/step - loss: 0.0972 - accuracy: 1.0000 - val_loss: 0.1159 - val_accuracy: 0.9949\n",
            "Epoch 23/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0958 - accuracy: 1.0000\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 25ms/step - loss: 0.0958 - accuracy: 1.0000 - val_loss: 0.1102 - val_accuracy: 0.9949\n",
            "Epoch 24/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0956 - accuracy: 1.0000\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 25ms/step - loss: 0.0956 - accuracy: 1.0000 - val_loss: 0.1027 - val_accuracy: 0.9974\n",
            "Epoch 25/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0912 - accuracy: 1.0000\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.0912 - accuracy: 1.0000 - val_loss: 0.1100 - val_accuracy: 0.9949\n",
            "Epoch 26/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0905 - accuracy: 1.0000\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 25ms/step - loss: 0.0905 - accuracy: 1.0000 - val_loss: 0.1096 - val_accuracy: 0.9923\n",
            "Epoch 27/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0874 - accuracy: 1.0000\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 25ms/step - loss: 0.0874 - accuracy: 1.0000 - val_loss: 0.1053 - val_accuracy: 0.9949\n",
            "Epoch 28/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0844 - accuracy: 1.0000\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 25ms/step - loss: 0.0844 - accuracy: 1.0000 - val_loss: 0.0981 - val_accuracy: 0.9949\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0819 - accuracy: 1.0000\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 25ms/step - loss: 0.0819 - accuracy: 1.0000 - val_loss: 0.0962 - val_accuracy: 0.9949\n",
            "Epoch 30/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0799 - accuracy: 1.0000\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.0798 - accuracy: 1.0000 - val_loss: 0.0982 - val_accuracy: 0.9949\n",
            "Epoch 31/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0779 - accuracy: 1.0000\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 25ms/step - loss: 0.0779 - accuracy: 1.0000 - val_loss: 0.1008 - val_accuracy: 0.9949\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0763 - accuracy: 1.0000\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 25ms/step - loss: 0.0770 - accuracy: 0.9994 - val_loss: 0.1195 - val_accuracy: 0.9898\n",
            "Epoch 33/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0848 - accuracy: 0.9981\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.0848 - accuracy: 0.9981 - val_loss: 0.1652 - val_accuracy: 0.9821\n",
            "Epoch 34/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1209 - accuracy: 0.9916\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 25ms/step - loss: 0.1207 - accuracy: 0.9917 - val_loss: 0.1590 - val_accuracy: 0.9872\n",
            "Epoch 34: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/164/assets\n",
            "\n",
            "\n",
            " 82%|████████▎ | 165/200 [6:47:13<1:28:40, 152.02s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.8913 - accuracy: 0.3920\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 16ms/step - loss: 1.8875 - accuracy: 0.3897 - val_loss: 1.8505 - val_accuracy: 0.1714\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.3042 - accuracy: 0.6101\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.3012 - accuracy: 0.6109 - val_loss: 1.8005 - val_accuracy: 0.2506\n",
            "Epoch 3/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.8277 - accuracy: 0.7796\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.8262 - accuracy: 0.7801 - val_loss: 2.0129 - val_accuracy: 0.4604\n",
            "Epoch 4/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.5607 - accuracy: 0.8704\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.5656 - accuracy: 0.8692 - val_loss: 1.4825 - val_accuracy: 0.7417\n",
            "Epoch 5/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.5411 - accuracy: 0.8945\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.5396 - accuracy: 0.8955 - val_loss: 1.4660 - val_accuracy: 0.7187\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4631 - accuracy: 0.9145\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.4642 - accuracy: 0.9135 - val_loss: 0.5336 - val_accuracy: 0.8670\n",
            "Epoch 7/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3489 - accuracy: 0.9353\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.3489 - accuracy: 0.9353 - val_loss: 0.7635 - val_accuracy: 0.7545\n",
            "Epoch 8/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.7792 - accuracy: 0.8538\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.7792 - accuracy: 0.8538 - val_loss: 1.2839 - val_accuracy: 0.6087\n",
            "Epoch 9/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3579 - accuracy: 0.9486\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.3574 - accuracy: 0.9487 - val_loss: 0.4055 - val_accuracy: 0.9463\n",
            "Epoch 10/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2934 - accuracy: 0.9506\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.2934 - accuracy: 0.9506 - val_loss: 0.6101 - val_accuracy: 0.8542\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2766 - accuracy: 0.9521\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.2765 - accuracy: 0.9519 - val_loss: 0.7390 - val_accuracy: 0.7826\n",
            "Epoch 12/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4255 - accuracy: 0.9336\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.4243 - accuracy: 0.9340 - val_loss: 1.0201 - val_accuracy: 0.6215\n",
            "Epoch 13/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2400 - accuracy: 0.9609\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.2397 - accuracy: 0.9609 - val_loss: 0.8054 - val_accuracy: 0.7519\n",
            "Epoch 14/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.2878 - accuracy: 0.9522\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.2868 - accuracy: 0.9513 - val_loss: 0.2951 - val_accuracy: 0.9488\n",
            "Epoch 15/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2615 - accuracy: 0.9583\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.2615 - accuracy: 0.9583 - val_loss: 0.8907 - val_accuracy: 0.7263\n",
            "Epoch 16/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2927 - accuracy: 0.9517\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.2938 - accuracy: 0.9506 - val_loss: 0.3296 - val_accuracy: 0.9233\n",
            "Epoch 17/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.1130 - accuracy: 0.6808\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.1130 - accuracy: 0.6808 - val_loss: 2.1522 - val_accuracy: 0.2634\n",
            "Epoch 18/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.7707 - accuracy: 0.2762\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 1.7683 - accuracy: 0.2744 - val_loss: 1.7479 - val_accuracy: 0.2864\n",
            "Epoch 19/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.7402 - accuracy: 0.2750\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 1.7402 - accuracy: 0.2750 - val_loss: 1.7258 - val_accuracy: 0.2864\n",
            "Epoch 19: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/165/assets\n",
            "\n",
            "\n",
            " 83%|████████▎ | 166/200 [6:48:40<1:15:08, 132.59s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.3325 - accuracy: 0.6686\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 16ms/step - loss: 1.3232 - accuracy: 0.6705 - val_loss: 1.8257 - val_accuracy: 0.2711\n",
            "Epoch 2/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3907 - accuracy: 0.9478\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.3896 - accuracy: 0.9481 - val_loss: 1.5886 - val_accuracy: 0.5243\n",
            "Epoch 3/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2542 - accuracy: 0.9792\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.2545 - accuracy: 0.9788 - val_loss: 0.7509 - val_accuracy: 0.7980\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2618 - accuracy: 0.9709\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.2645 - accuracy: 0.9699 - val_loss: 0.3105 - val_accuracy: 0.9386\n",
            "Epoch 5/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2140 - accuracy: 0.9827\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.2140 - accuracy: 0.9827 - val_loss: 0.3196 - val_accuracy: 0.9744\n",
            "Epoch 6/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1716 - accuracy: 0.9929\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.1714 - accuracy: 0.9929 - val_loss: 0.1881 - val_accuracy: 0.9847\n",
            "Epoch 7/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1669 - accuracy: 0.9922\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.1667 - accuracy: 0.9923 - val_loss: 0.1961 - val_accuracy: 0.9821\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1824 - accuracy: 0.9858\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.1822 - accuracy: 0.9859 - val_loss: 0.4690 - val_accuracy: 0.9207\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1776 - accuracy: 0.9864\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.1774 - accuracy: 0.9865 - val_loss: 0.2121 - val_accuracy: 0.9847\n",
            "Epoch 10/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1462 - accuracy: 0.9929\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.1460 - accuracy: 0.9929 - val_loss: 0.1935 - val_accuracy: 0.9693\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1225 - accuracy: 0.9981\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.1231 - accuracy: 0.9974 - val_loss: 0.1376 - val_accuracy: 0.9923\n",
            "Epoch 12/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1088 - accuracy: 1.0000\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.1088 - accuracy: 1.0000 - val_loss: 0.1543 - val_accuracy: 0.9847\n",
            "Epoch 13/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1073 - accuracy: 0.9967\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.1088 - accuracy: 0.9962 - val_loss: 0.1990 - val_accuracy: 0.9719\n",
            "Epoch 14/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1133 - accuracy: 0.9967\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.1130 - accuracy: 0.9968 - val_loss: 0.1441 - val_accuracy: 0.9847\n",
            "Epoch 15/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0931 - accuracy: 1.0000\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0931 - accuracy: 1.0000 - val_loss: 0.1102 - val_accuracy: 0.9974\n",
            "Epoch 16/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0901 - accuracy: 0.9987\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0901 - accuracy: 0.9987 - val_loss: 0.1572 - val_accuracy: 0.9821\n",
            "Epoch 17/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2147 - accuracy: 0.9694\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.2144 - accuracy: 0.9699 - val_loss: 2.7788 - val_accuracy: 0.7647\n",
            "Epoch 18/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1807 - accuracy: 0.9839\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.1803 - accuracy: 0.9840 - val_loss: 0.1588 - val_accuracy: 0.9872\n",
            "Epoch 19/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1183 - accuracy: 0.9936\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.1183 - accuracy: 0.9936 - val_loss: 0.1989 - val_accuracy: 0.9616\n",
            "Epoch 20/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1229 - accuracy: 0.9915\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.1223 - accuracy: 0.9917 - val_loss: 0.1285 - val_accuracy: 0.9898\n",
            "Epoch 20: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/166/assets\n",
            "\n",
            "\n",
            " 84%|████████▎ | 167/200 [6:49:41<1:01:07, 111.12s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.9611 - accuracy: 0.2906\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 23ms/step - loss: 1.9595 - accuracy: 0.2917 - val_loss: 1.7914 - val_accuracy: 0.3018\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.7775 - accuracy: 0.4003\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 1.7786 - accuracy: 0.4000 - val_loss: 1.7563 - val_accuracy: 0.3811\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6357 - accuracy: 0.5298\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 1.6346 - accuracy: 0.5301 - val_loss: 1.6097 - val_accuracy: 0.4808\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.4731 - accuracy: 0.6444\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 1.4720 - accuracy: 0.6436 - val_loss: 1.3612 - val_accuracy: 0.6803\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.3002 - accuracy: 0.7209\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 1.2978 - accuracy: 0.7231 - val_loss: 1.1757 - val_accuracy: 0.7519\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.1283 - accuracy: 0.7740\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 1.1290 - accuracy: 0.7737 - val_loss: 1.0159 - val_accuracy: 0.8235\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.9731 - accuracy: 0.8387\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.9736 - accuracy: 0.8378 - val_loss: 0.8930 - val_accuracy: 0.8542\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8643 - accuracy: 0.8672\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.8622 - accuracy: 0.8679 - val_loss: 0.7846 - val_accuracy: 0.9054\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7673 - accuracy: 0.9035\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.7676 - accuracy: 0.9032 - val_loss: 0.7150 - val_accuracy: 0.9105\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7034 - accuracy: 0.9145\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.7024 - accuracy: 0.9154 - val_loss: 0.6473 - val_accuracy: 0.9335\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6515 - accuracy: 0.9339\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.6507 - accuracy: 0.9346 - val_loss: 0.6085 - val_accuracy: 0.9437\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6032 - accuracy: 0.9424\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.6038 - accuracy: 0.9417 - val_loss: 0.5685 - val_accuracy: 0.9514\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5676 - accuracy: 0.9540\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.5674 - accuracy: 0.9538 - val_loss: 0.5311 - val_accuracy: 0.9668\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5439 - accuracy: 0.9508\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.5429 - accuracy: 0.9513 - val_loss: 0.5027 - val_accuracy: 0.9693\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5092 - accuracy: 0.9657\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.5088 - accuracy: 0.9660 - val_loss: 0.4767 - val_accuracy: 0.9795\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4809 - accuracy: 0.9734\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.4811 - accuracy: 0.9731 - val_loss: 0.4490 - val_accuracy: 0.9847\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4599 - accuracy: 0.9741\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.4608 - accuracy: 0.9724 - val_loss: 0.4255 - val_accuracy: 0.9795\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4392 - accuracy: 0.9734\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.4382 - accuracy: 0.9737 - val_loss: 0.4070 - val_accuracy: 0.9847\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4223 - accuracy: 0.9760\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.4225 - accuracy: 0.9763 - val_loss: 0.3938 - val_accuracy: 0.9847\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4049 - accuracy: 0.9819\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.4046 - accuracy: 0.9814 - val_loss: 0.3778 - val_accuracy: 0.9821\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3892 - accuracy: 0.9838\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.3891 - accuracy: 0.9840 - val_loss: 0.3617 - val_accuracy: 0.9847\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3741 - accuracy: 0.9864\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.3738 - accuracy: 0.9865 - val_loss: 0.3493 - val_accuracy: 0.9898\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3671 - accuracy: 0.9838\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.3663 - accuracy: 0.9840 - val_loss: 0.3369 - val_accuracy: 0.9872\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3504 - accuracy: 0.9890\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.3506 - accuracy: 0.9891 - val_loss: 0.3320 - val_accuracy: 0.9872\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3385 - accuracy: 0.9851\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.3378 - accuracy: 0.9853 - val_loss: 0.3199 - val_accuracy: 0.9923\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3287 - accuracy: 0.9896\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.3292 - accuracy: 0.9897 - val_loss: 0.3067 - val_accuracy: 0.9923\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3165 - accuracy: 0.9896\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.3176 - accuracy: 0.9891 - val_loss: 0.3012 - val_accuracy: 0.9923\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3091 - accuracy: 0.9916\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.3092 - accuracy: 0.9910 - val_loss: 0.2886 - val_accuracy: 0.9949\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3009 - accuracy: 0.9916\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.3004 - accuracy: 0.9917 - val_loss: 0.2842 - val_accuracy: 0.9898\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2938 - accuracy: 0.9942\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2936 - accuracy: 0.9942 - val_loss: 0.2755 - val_accuracy: 0.9923\n",
            "Epoch 31/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2831 - accuracy: 0.9942\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2836 - accuracy: 0.9936 - val_loss: 0.2675 - val_accuracy: 0.9923\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2786 - accuracy: 0.9935\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2787 - accuracy: 0.9936 - val_loss: 0.2609 - val_accuracy: 0.9949\n",
            "Epoch 33/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2730 - accuracy: 0.9942\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2726 - accuracy: 0.9942 - val_loss: 0.2552 - val_accuracy: 0.9949\n",
            "Epoch 34/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2675 - accuracy: 0.9942\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2675 - accuracy: 0.9942 - val_loss: 0.2543 - val_accuracy: 0.9949\n",
            "Epoch 35/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2611 - accuracy: 0.9961\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2608 - accuracy: 0.9962 - val_loss: 0.2452 - val_accuracy: 0.9923\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2521 - accuracy: 0.9955\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2520 - accuracy: 0.9955 - val_loss: 0.2387 - val_accuracy: 0.9949\n",
            "Epoch 37/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2517 - accuracy: 0.9961\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2518 - accuracy: 0.9962 - val_loss: 0.2351 - val_accuracy: 0.9949\n",
            "Epoch 38/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2413 - accuracy: 0.9935\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2415 - accuracy: 0.9936 - val_loss: 0.2255 - val_accuracy: 0.9949\n",
            "Epoch 39/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2401 - accuracy: 0.9961\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2398 - accuracy: 0.9962 - val_loss: 0.2241 - val_accuracy: 0.9949\n",
            "Epoch 40/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2328 - accuracy: 0.9955\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2327 - accuracy: 0.9955 - val_loss: 0.2204 - val_accuracy: 0.9949\n",
            "Epoch 41/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2288 - accuracy: 0.9974\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2285 - accuracy: 0.9974 - val_loss: 0.2140 - val_accuracy: 0.9949\n",
            "Epoch 42/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2243 - accuracy: 0.9974\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2244 - accuracy: 0.9974 - val_loss: 0.2119 - val_accuracy: 0.9949\n",
            "Epoch 43/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2177 - accuracy: 0.9961\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2177 - accuracy: 0.9962 - val_loss: 0.2082 - val_accuracy: 0.9949\n",
            "Epoch 44/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2207 - accuracy: 0.9948\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2205 - accuracy: 0.9949 - val_loss: 0.2082 - val_accuracy: 0.9949\n",
            "Epoch 45/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2091 - accuracy: 0.9981\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2092 - accuracy: 0.9981 - val_loss: 0.2046 - val_accuracy: 0.9949\n",
            "Epoch 46/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2041 - accuracy: 0.9974\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2038 - accuracy: 0.9974 - val_loss: 0.1977 - val_accuracy: 0.9949\n",
            "Epoch 47/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2045 - accuracy: 0.9968\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2042 - accuracy: 0.9968 - val_loss: 0.1993 - val_accuracy: 0.9949\n",
            "Epoch 48/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2040 - accuracy: 0.9961\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2045 - accuracy: 0.9955 - val_loss: 0.1943 - val_accuracy: 0.9949\n",
            "Epoch 49/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1967 - accuracy: 0.9994\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1966 - accuracy: 0.9994 - val_loss: 0.1936 - val_accuracy: 0.9923\n",
            "Epoch 50/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1933 - accuracy: 0.9968\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1934 - accuracy: 0.9968 - val_loss: 0.1868 - val_accuracy: 0.9949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/167/assets\n",
            "\n",
            "\n",
            " 84%|████████▍ | 168/200 [6:53:00<1:13:20, 137.52s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.0485 - accuracy: 0.7597\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 21ms/step - loss: 1.0447 - accuracy: 0.7609 - val_loss: 1.6943 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3183 - accuracy: 0.9532\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.3183 - accuracy: 0.9532 - val_loss: 1.6819 - val_accuracy: 0.2941\n",
            "Epoch 3/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2337 - accuracy: 0.9705\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.2337 - accuracy: 0.9705 - val_loss: 1.0865 - val_accuracy: 0.7136\n",
            "Epoch 4/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1963 - accuracy: 0.9776\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.1963 - accuracy: 0.9776 - val_loss: 0.2889 - val_accuracy: 0.9437\n",
            "Epoch 5/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1705 - accuracy: 0.9857\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.1695 - accuracy: 0.9859 - val_loss: 0.1577 - val_accuracy: 0.9872\n",
            "Epoch 6/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1138 - accuracy: 0.9981\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1138 - accuracy: 0.9981 - val_loss: 0.1977 - val_accuracy: 0.9821\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1164 - accuracy: 0.9948\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.1174 - accuracy: 0.9942 - val_loss: 0.2704 - val_accuracy: 0.9540\n",
            "Epoch 8/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2906 - accuracy: 0.9601\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.2904 - accuracy: 0.9603 - val_loss: 0.2138 - val_accuracy: 0.9795\n",
            "Epoch 9/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1601 - accuracy: 0.9850\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.1601 - accuracy: 0.9853 - val_loss: 0.1792 - val_accuracy: 0.9744\n",
            "Epoch 10/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1108 - accuracy: 0.9955\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.1107 - accuracy: 0.9955 - val_loss: 0.1182 - val_accuracy: 0.9898\n",
            "Epoch 11/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0863 - accuracy: 0.9994\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.0863 - accuracy: 0.9994 - val_loss: 0.1155 - val_accuracy: 0.9923\n",
            "Epoch 12/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0880 - accuracy: 0.9968\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.0880 - accuracy: 0.9968 - val_loss: 0.1949 - val_accuracy: 0.9872\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0796 - accuracy: 1.0000\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.0796 - accuracy: 1.0000 - val_loss: 0.1108 - val_accuracy: 0.9898\n",
            "Epoch 14/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0691 - accuracy: 1.0000\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.0691 - accuracy: 1.0000 - val_loss: 0.1430 - val_accuracy: 0.9923\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0644 - accuracy: 1.0000\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.0643 - accuracy: 1.0000 - val_loss: 0.1467 - val_accuracy: 0.9847\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2738 - accuracy: 0.9488\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 0.2758 - accuracy: 0.9481 - val_loss: 0.5916 - val_accuracy: 0.8184\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2033 - accuracy: 0.9676\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.2024 - accuracy: 0.9679 - val_loss: 0.2013 - val_accuracy: 0.9719\n",
            "Epoch 18/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1109 - accuracy: 0.9936\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.1109 - accuracy: 0.9936 - val_loss: 0.1678 - val_accuracy: 0.9668\n",
            "Epoch 18: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/168/assets\n",
            "\n",
            "\n",
            " 84%|████████▍ | 169/200 [6:54:11<1:00:37, 117.35s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 2.2306 - accuracy: 0.2676\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 17ms/step - loss: 2.2186 - accuracy: 0.2724 - val_loss: 1.7348 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.5929 - accuracy: 0.3737\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.5936 - accuracy: 0.3731 - val_loss: 1.6725 - val_accuracy: 0.3708\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.4519 - accuracy: 0.4741\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.4528 - accuracy: 0.4724 - val_loss: 1.5471 - val_accuracy: 0.4348\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.1791 - accuracy: 0.5939\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.1822 - accuracy: 0.5923 - val_loss: 1.1989 - val_accuracy: 0.6189\n",
            "Epoch 5/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.0486 - accuracy: 0.6732\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.0493 - accuracy: 0.6731 - val_loss: 1.2292 - val_accuracy: 0.6061\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.3369 - accuracy: 0.6431\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.3346 - accuracy: 0.6423 - val_loss: 1.2036 - val_accuracy: 0.6368\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.9999 - accuracy: 0.7299\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.9994 - accuracy: 0.7295 - val_loss: 1.1185 - val_accuracy: 0.6368\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8315 - accuracy: 0.7830\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.8345 - accuracy: 0.7827 - val_loss: 1.2085 - val_accuracy: 0.6598\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8201 - accuracy: 0.7707\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.8153 - accuracy: 0.7724 - val_loss: 0.7374 - val_accuracy: 0.8389\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6483 - accuracy: 0.8452\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.6475 - accuracy: 0.8455 - val_loss: 0.8258 - val_accuracy: 0.8235\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7085 - accuracy: 0.8310\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.7092 - accuracy: 0.8288 - val_loss: 1.1560 - val_accuracy: 0.6957\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5668 - accuracy: 0.8782\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.5682 - accuracy: 0.8776 - val_loss: 0.7904 - val_accuracy: 0.7980\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.2984 - accuracy: 0.6846\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 1.3000 - accuracy: 0.6833 - val_loss: 1.4570 - val_accuracy: 0.4706\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.0615 - accuracy: 0.6852\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 1.0579 - accuracy: 0.6865 - val_loss: 1.1060 - val_accuracy: 0.6471\n",
            "Epoch 14: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/169/assets\n",
            "\n",
            "\n",
            " 85%|████████▌ | 170/200 [6:54:58<48:13, 96.45s/it]   \u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.9881 - accuracy: 0.2718\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 22ms/step - loss: 1.9881 - accuracy: 0.2718 - val_loss: 1.8040 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.8303 - accuracy: 0.3789\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 1.8329 - accuracy: 0.3776 - val_loss: 1.7727 - val_accuracy: 0.3760\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6877 - accuracy: 0.5188\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 1.6896 - accuracy: 0.5192 - val_loss: 1.6592 - val_accuracy: 0.4910\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.5173 - accuracy: 0.6535\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 1.5170 - accuracy: 0.6532 - val_loss: 1.4122 - val_accuracy: 0.7084\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.3172 - accuracy: 0.7144\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 1.3202 - accuracy: 0.7128 - val_loss: 1.2003 - val_accuracy: 0.7468\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.1381 - accuracy: 0.7630\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 1.1402 - accuracy: 0.7603 - val_loss: 1.0343 - val_accuracy: 0.8107\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.9935 - accuracy: 0.8038\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.9941 - accuracy: 0.8045 - val_loss: 0.9019 - val_accuracy: 0.8414\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8793 - accuracy: 0.8614\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.8789 - accuracy: 0.8622 - val_loss: 0.8049 - val_accuracy: 0.8747\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7966 - accuracy: 0.8880\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.7960 - accuracy: 0.8885 - val_loss: 0.7290 - val_accuracy: 0.9156\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7322 - accuracy: 0.9035\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.7314 - accuracy: 0.9038 - val_loss: 0.6708 - val_accuracy: 0.9207\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6762 - accuracy: 0.9236\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.6749 - accuracy: 0.9244 - val_loss: 0.6264 - val_accuracy: 0.9335\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6319 - accuracy: 0.9398\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.6318 - accuracy: 0.9397 - val_loss: 0.5859 - val_accuracy: 0.9488\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5874 - accuracy: 0.9514\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.5869 - accuracy: 0.9513 - val_loss: 0.5467 - val_accuracy: 0.9642\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5661 - accuracy: 0.9521\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.5672 - accuracy: 0.9526 - val_loss: 0.5258 - val_accuracy: 0.9642\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5237 - accuracy: 0.9573\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.5231 - accuracy: 0.9577 - val_loss: 0.4963 - val_accuracy: 0.9642\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5058 - accuracy: 0.9611\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.5048 - accuracy: 0.9615 - val_loss: 0.4737 - val_accuracy: 0.9668\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4826 - accuracy: 0.9722\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.4810 - accuracy: 0.9724 - val_loss: 0.4523 - val_accuracy: 0.9719\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4535 - accuracy: 0.9741\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.4537 - accuracy: 0.9744 - val_loss: 0.4341 - val_accuracy: 0.9795\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4377 - accuracy: 0.9767\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.4376 - accuracy: 0.9763 - val_loss: 0.4170 - val_accuracy: 0.9719\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4181 - accuracy: 0.9754\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.4190 - accuracy: 0.9750 - val_loss: 0.3968 - val_accuracy: 0.9795\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3979 - accuracy: 0.9870\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.3984 - accuracy: 0.9865 - val_loss: 0.3853 - val_accuracy: 0.9795\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3784 - accuracy: 0.9877\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.3797 - accuracy: 0.9872 - val_loss: 0.3669 - val_accuracy: 0.9847\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3691 - accuracy: 0.9877\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.3689 - accuracy: 0.9878 - val_loss: 0.3567 - val_accuracy: 0.9795\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3585 - accuracy: 0.9870\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.3586 - accuracy: 0.9872 - val_loss: 0.3447 - val_accuracy: 0.9821\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3473 - accuracy: 0.9883\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.3480 - accuracy: 0.9878 - val_loss: 0.3340 - val_accuracy: 0.9847\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3365 - accuracy: 0.9877\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.3371 - accuracy: 0.9872 - val_loss: 0.3260 - val_accuracy: 0.9821\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3225 - accuracy: 0.9883\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.3221 - accuracy: 0.9885 - val_loss: 0.3167 - val_accuracy: 0.9821\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3202 - accuracy: 0.9864\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.3213 - accuracy: 0.9859 - val_loss: 0.3055 - val_accuracy: 0.9821\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3101 - accuracy: 0.9864\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.3098 - accuracy: 0.9865 - val_loss: 0.2963 - val_accuracy: 0.9847\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2899 - accuracy: 0.9948\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2904 - accuracy: 0.9942 - val_loss: 0.2889 - val_accuracy: 0.9821\n",
            "Epoch 31/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2867 - accuracy: 0.9903\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2878 - accuracy: 0.9897 - val_loss: 0.2804 - val_accuracy: 0.9872\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2823 - accuracy: 0.9896\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2820 - accuracy: 0.9897 - val_loss: 0.2705 - val_accuracy: 0.9847\n",
            "Epoch 33/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2715 - accuracy: 0.9955\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2725 - accuracy: 0.9949 - val_loss: 0.2669 - val_accuracy: 0.9847\n",
            "Epoch 34/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2737 - accuracy: 0.9896\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2736 - accuracy: 0.9897 - val_loss: 0.2649 - val_accuracy: 0.9821\n",
            "Epoch 35/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2584 - accuracy: 0.9935\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2581 - accuracy: 0.9936 - val_loss: 0.2551 - val_accuracy: 0.9898\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2577 - accuracy: 0.9916\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2576 - accuracy: 0.9917 - val_loss: 0.2501 - val_accuracy: 0.9872\n",
            "Epoch 37/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2465 - accuracy: 0.9968\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2468 - accuracy: 0.9968 - val_loss: 0.2427 - val_accuracy: 0.9872\n",
            "Epoch 38/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2412 - accuracy: 0.9948\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2416 - accuracy: 0.9949 - val_loss: 0.2387 - val_accuracy: 0.9872\n",
            "Epoch 39/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2369 - accuracy: 0.9968\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2367 - accuracy: 0.9968 - val_loss: 0.2324 - val_accuracy: 0.9872\n",
            "Epoch 40/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2310 - accuracy: 0.9948\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2307 - accuracy: 0.9949 - val_loss: 0.2268 - val_accuracy: 0.9898\n",
            "Epoch 41/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2280 - accuracy: 0.9942\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2276 - accuracy: 0.9942 - val_loss: 0.2210 - val_accuracy: 0.9923\n",
            "Epoch 42/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2216 - accuracy: 0.9942\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2214 - accuracy: 0.9942 - val_loss: 0.2202 - val_accuracy: 0.9898\n",
            "Epoch 43/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2122 - accuracy: 0.9981\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2124 - accuracy: 0.9981 - val_loss: 0.2154 - val_accuracy: 0.9949\n",
            "Epoch 44/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2093 - accuracy: 0.9968\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2094 - accuracy: 0.9968 - val_loss: 0.2098 - val_accuracy: 0.9949\n",
            "Epoch 45/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2104 - accuracy: 0.9942\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2103 - accuracy: 0.9942 - val_loss: 0.2068 - val_accuracy: 0.9974\n",
            "Epoch 46/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2062 - accuracy: 0.9929\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2070 - accuracy: 0.9923 - val_loss: 0.2016 - val_accuracy: 0.9949\n",
            "Epoch 47/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1990 - accuracy: 0.9961\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1994 - accuracy: 0.9962 - val_loss: 0.1978 - val_accuracy: 0.9949\n",
            "Epoch 48/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1945 - accuracy: 0.9955\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1944 - accuracy: 0.9955 - val_loss: 0.1978 - val_accuracy: 0.9898\n",
            "Epoch 49/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1943 - accuracy: 0.9955\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1943 - accuracy: 0.9955 - val_loss: 0.1922 - val_accuracy: 0.9923\n",
            "Epoch 50/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1878 - accuracy: 0.9968\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1875 - accuracy: 0.9968 - val_loss: 0.1873 - val_accuracy: 0.9949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/170/assets\n",
            "\n",
            "\n",
            " 86%|████████▌ | 171/200 [6:58:26<1:02:40, 129.67s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.0434 - accuracy: 0.7350\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 17ms/step - loss: 1.0336 - accuracy: 0.7391 - val_loss: 1.7383 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3898 - accuracy: 0.9452\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.3890 - accuracy: 0.9455 - val_loss: 1.6011 - val_accuracy: 0.3939\n",
            "Epoch 3/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2711 - accuracy: 0.9684\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.2713 - accuracy: 0.9679 - val_loss: 0.6311 - val_accuracy: 0.9207\n",
            "Epoch 4/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1969 - accuracy: 0.9865\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1969 - accuracy: 0.9865 - val_loss: 0.6972 - val_accuracy: 0.7391\n",
            "Epoch 5/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1555 - accuracy: 0.9955\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1552 - accuracy: 0.9955 - val_loss: 0.2498 - val_accuracy: 0.9668\n",
            "Epoch 6/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1268 - accuracy: 0.9987\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.1266 - accuracy: 0.9987 - val_loss: 0.1542 - val_accuracy: 0.9795\n",
            "Epoch 7/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1727 - accuracy: 0.9850\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1722 - accuracy: 0.9846 - val_loss: 0.1936 - val_accuracy: 0.9719\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1134 - accuracy: 0.9981\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1135 - accuracy: 0.9981 - val_loss: 0.4156 - val_accuracy: 0.9054\n",
            "Epoch 9/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1283 - accuracy: 0.9929\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.1281 - accuracy: 0.9929 - val_loss: 0.1449 - val_accuracy: 0.9949\n",
            "Epoch 10/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1109 - accuracy: 0.9942\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1109 - accuracy: 0.9942 - val_loss: 0.2304 - val_accuracy: 0.9540\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1100 - accuracy: 0.9961\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.1096 - accuracy: 0.9962 - val_loss: 0.1050 - val_accuracy: 0.9974\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1025 - accuracy: 0.9974\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.1025 - accuracy: 0.9974 - val_loss: 0.1073 - val_accuracy: 0.9949\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1000 - accuracy: 0.9955\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.1005 - accuracy: 0.9955 - val_loss: 0.1360 - val_accuracy: 0.9872\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0999 - accuracy: 0.9981\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0997 - accuracy: 0.9981 - val_loss: 0.1456 - val_accuracy: 0.9923\n",
            "Epoch 15/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0813 - accuracy: 0.9994\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.0813 - accuracy: 0.9994 - val_loss: 0.1603 - val_accuracy: 0.9770\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0764 - accuracy: 1.0000\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.0764 - accuracy: 1.0000 - val_loss: 0.1103 - val_accuracy: 0.9923\n",
            "Epoch 16: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/171/assets\n",
            "\n",
            "\n",
            " 86%|████████▌ | 172/200 [6:59:53<54:33, 116.92s/it]  \u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.8239 - accuracy: 0.2773\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 20ms/step - loss: 1.8255 - accuracy: 0.2756 - val_loss: 1.7255 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.6951 - accuracy: 0.3034\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 1.6945 - accuracy: 0.3038 - val_loss: 1.7291 - val_accuracy: 0.2864\n",
            "Epoch 3/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.7002 - accuracy: 0.2839\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 1.6986 - accuracy: 0.2840 - val_loss: 1.6783 - val_accuracy: 0.2634\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6766 - accuracy: 0.2785\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 1.6771 - accuracy: 0.2795 - val_loss: 1.6765 - val_accuracy: 0.2864\n",
            "Epoch 5/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.6731 - accuracy: 0.2786\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 1.6742 - accuracy: 0.2782 - val_loss: 1.7510 - val_accuracy: 0.2864\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6615 - accuracy: 0.2966\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 1.6633 - accuracy: 0.2955 - val_loss: 1.6541 - val_accuracy: 0.2634\n",
            "Epoch 7/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6521 - accuracy: 0.2833\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 1.6521 - accuracy: 0.2833 - val_loss: 1.6468 - val_accuracy: 0.2864\n",
            "Epoch 8/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6470 - accuracy: 0.2859\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 1.6470 - accuracy: 0.2859 - val_loss: 1.6426 - val_accuracy: 0.2864\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6493 - accuracy: 0.2843\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.6482 - accuracy: 0.2859 - val_loss: 1.6428 - val_accuracy: 0.2864\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6419 - accuracy: 0.2869\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 1.6431 - accuracy: 0.2859 - val_loss: 1.6385 - val_accuracy: 0.2864\n",
            "Epoch 11/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6393 - accuracy: 0.2854\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.6398 - accuracy: 0.2853 - val_loss: 1.6360 - val_accuracy: 0.2634\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6364 - accuracy: 0.2636\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 1.6378 - accuracy: 0.2641 - val_loss: 1.6333 - val_accuracy: 0.2864\n",
            "Epoch 13/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6366 - accuracy: 0.2840\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.6366 - accuracy: 0.2840 - val_loss: 1.6309 - val_accuracy: 0.2864\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6315 - accuracy: 0.2869\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 1.6326 - accuracy: 0.2859 - val_loss: 1.6299 - val_accuracy: 0.2864\n",
            "Epoch 15/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6317 - accuracy: 0.2788\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.6317 - accuracy: 0.2788 - val_loss: 1.6289 - val_accuracy: 0.2864\n",
            "Epoch 16/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6315 - accuracy: 0.2769\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.6315 - accuracy: 0.2769 - val_loss: 1.6275 - val_accuracy: 0.2864\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6298 - accuracy: 0.2882\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 1.6297 - accuracy: 0.2859 - val_loss: 1.6271 - val_accuracy: 0.2864\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6293 - accuracy: 0.2759\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.6290 - accuracy: 0.2756 - val_loss: 1.6262 - val_accuracy: 0.2864\n",
            "Epoch 19/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.6298 - accuracy: 0.2812\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 1.6293 - accuracy: 0.2814 - val_loss: 1.6257 - val_accuracy: 0.2864\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6277 - accuracy: 0.2811\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.6286 - accuracy: 0.2808 - val_loss: 1.6254 - val_accuracy: 0.2864\n",
            "Epoch 21/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6281 - accuracy: 0.2854\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 1.6278 - accuracy: 0.2859 - val_loss: 1.6247 - val_accuracy: 0.2864\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6285 - accuracy: 0.2733\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 1.6290 - accuracy: 0.2731 - val_loss: 1.6253 - val_accuracy: 0.2864\n",
            "Epoch 23/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.6299 - accuracy: 0.2819\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 1.6266 - accuracy: 0.2840 - val_loss: 1.6254 - val_accuracy: 0.2634\n",
            "Epoch 24/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6273 - accuracy: 0.2833\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 1.6273 - accuracy: 0.2833 - val_loss: 1.6241 - val_accuracy: 0.2864\n",
            "Epoch 25/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.6291 - accuracy: 0.2858\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 1.6277 - accuracy: 0.2859 - val_loss: 1.6243 - val_accuracy: 0.2864\n",
            "Epoch 26/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6279 - accuracy: 0.2771\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 1.6276 - accuracy: 0.2769 - val_loss: 1.6240 - val_accuracy: 0.2864\n",
            "Epoch 27/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6274 - accuracy: 0.2801\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 1.6274 - accuracy: 0.2801 - val_loss: 1.6242 - val_accuracy: 0.2864\n",
            "Epoch 28/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6298 - accuracy: 0.2835\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 1.6291 - accuracy: 0.2833 - val_loss: 1.6257 - val_accuracy: 0.2864\n",
            "Epoch 29/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6271 - accuracy: 0.2859\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 1.6271 - accuracy: 0.2859 - val_loss: 1.6242 - val_accuracy: 0.2864\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6274 - accuracy: 0.2908\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 1.6272 - accuracy: 0.2904 - val_loss: 1.6254 - val_accuracy: 0.2634\n",
            "Epoch 31/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6275 - accuracy: 0.2750\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 1.6275 - accuracy: 0.2750 - val_loss: 1.6252 - val_accuracy: 0.2864\n",
            "Epoch 31: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/172/assets\n",
            "\n",
            "\n",
            " 86%|████████▋ | 173/200 [7:01:50<52:40, 117.05s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.9851 - accuracy: 0.7904\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 8s 31ms/step - loss: 0.9851 - accuracy: 0.7904 - val_loss: 1.8621 - val_accuracy: 0.3248\n",
            "Epoch 2/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3633 - accuracy: 0.9583\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.3633 - accuracy: 0.9583 - val_loss: 1.6914 - val_accuracy: 0.3964\n",
            "Epoch 3/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3328 - accuracy: 0.9641\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.3328 - accuracy: 0.9641 - val_loss: 0.6402 - val_accuracy: 0.8210\n",
            "Epoch 4/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2755 - accuracy: 0.9788\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.2755 - accuracy: 0.9788 - val_loss: 1.0503 - val_accuracy: 0.6266\n",
            "Epoch 5/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1879 - accuracy: 0.9962\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.1879 - accuracy: 0.9962 - val_loss: 0.4938 - val_accuracy: 0.9054\n",
            "Epoch 6/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1633 - accuracy: 0.9987\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 0.1633 - accuracy: 0.9987 - val_loss: 0.1766 - val_accuracy: 0.9949\n",
            "Epoch 7/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2157 - accuracy: 0.9840\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.2157 - accuracy: 0.9840 - val_loss: 0.9255 - val_accuracy: 0.8645\n",
            "Epoch 8/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2082 - accuracy: 0.9858\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.2081 - accuracy: 0.9859 - val_loss: 0.2082 - val_accuracy: 0.9923\n",
            "Epoch 9/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1598 - accuracy: 0.9936\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 0.1598 - accuracy: 0.9936 - val_loss: 0.2204 - val_accuracy: 0.9847\n",
            "Epoch 10/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1611 - accuracy: 0.9923\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 0.1611 - accuracy: 0.9923 - val_loss: 0.5016 - val_accuracy: 0.9079\n",
            "Epoch 11/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1883 - accuracy: 0.9885\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.1883 - accuracy: 0.9885 - val_loss: 0.1915 - val_accuracy: 0.9923\n",
            "Epoch 11: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/173/assets\n",
            "\n",
            "\n",
            " 87%|████████▋ | 174/200 [7:02:57<44:15, 102.12s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.8677 - accuracy: 0.7690\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 16ms/step - loss: 0.8613 - accuracy: 0.7724 - val_loss: 1.8734 - val_accuracy: 0.1944\n",
            "Epoch 2/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2425 - accuracy: 0.9801\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.2425 - accuracy: 0.9801 - val_loss: 1.8713 - val_accuracy: 0.2864\n",
            "Epoch 3/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2023 - accuracy: 0.9794\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.2023 - accuracy: 0.9795 - val_loss: 0.8431 - val_accuracy: 0.6598\n",
            "Epoch 4/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1709 - accuracy: 0.9831\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1706 - accuracy: 0.9833 - val_loss: 0.2067 - val_accuracy: 0.9770\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1195 - accuracy: 0.9922\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.1192 - accuracy: 0.9923 - val_loss: 0.2583 - val_accuracy: 0.9591\n",
            "Epoch 6/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0891 - accuracy: 0.9987\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.0889 - accuracy: 0.9987 - val_loss: 0.1105 - val_accuracy: 0.9898\n",
            "Epoch 7/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0768 - accuracy: 0.9987\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0767 - accuracy: 0.9987 - val_loss: 0.1123 - val_accuracy: 0.9872\n",
            "Epoch 8/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1578 - accuracy: 0.9795\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.1578 - accuracy: 0.9795 - val_loss: 0.5449 - val_accuracy: 0.8619\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1818 - accuracy: 0.9715\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.1809 - accuracy: 0.9718 - val_loss: 0.1839 - val_accuracy: 0.9770\n",
            "Epoch 10/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0842 - accuracy: 0.9981\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0845 - accuracy: 0.9981 - val_loss: 0.1084 - val_accuracy: 0.9872\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0734 - accuracy: 0.9974\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.0736 - accuracy: 0.9974 - val_loss: 0.1547 - val_accuracy: 0.9668\n",
            "Epoch 12/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1128 - accuracy: 0.9878\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.1127 - accuracy: 0.9878 - val_loss: 0.4588 - val_accuracy: 0.8977\n",
            "Epoch 13/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1417 - accuracy: 0.9845\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1417 - accuracy: 0.9846 - val_loss: 0.1272 - val_accuracy: 0.9872\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0738 - accuracy: 0.9994\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0737 - accuracy: 0.9994 - val_loss: 0.1071 - val_accuracy: 0.9872\n",
            "Epoch 15/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0626 - accuracy: 1.0000\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.0626 - accuracy: 1.0000 - val_loss: 0.0985 - val_accuracy: 0.9847\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0568 - accuracy: 1.0000\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0568 - accuracy: 1.0000 - val_loss: 0.1493 - val_accuracy: 0.9847\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0550 - accuracy: 1.0000\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0549 - accuracy: 1.0000 - val_loss: 0.0837 - val_accuracy: 0.9923\n",
            "Epoch 18/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0513 - accuracy: 1.0000\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.0513 - accuracy: 1.0000 - val_loss: 0.1603 - val_accuracy: 0.9821\n",
            "Epoch 19/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0535 - accuracy: 1.0000\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0535 - accuracy: 1.0000 - val_loss: 0.1070 - val_accuracy: 0.9898\n",
            "Epoch 20/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0490 - accuracy: 1.0000\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0490 - accuracy: 1.0000 - val_loss: 0.0713 - val_accuracy: 0.9949\n",
            "Epoch 21/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0480 - accuracy: 1.0000\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.0484 - accuracy: 1.0000 - val_loss: 0.3829 - val_accuracy: 0.9437\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0839 - accuracy: 0.9896\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.0869 - accuracy: 0.9878 - val_loss: 2.0629 - val_accuracy: 0.7391\n",
            "Epoch 23/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2459 - accuracy: 0.9544\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.2433 - accuracy: 0.9551 - val_loss: 0.2837 - val_accuracy: 0.9386\n",
            "Epoch 24/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1183 - accuracy: 0.9878\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.1181 - accuracy: 0.9878 - val_loss: 0.1242 - val_accuracy: 0.9949\n",
            "Epoch 25/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0746 - accuracy: 0.9987\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.0747 - accuracy: 0.9987 - val_loss: 0.3731 - val_accuracy: 0.9105\n",
            "Epoch 25: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/174/assets\n",
            "\n",
            "\n",
            " 88%|████████▊ | 175/200 [7:04:25<40:40, 97.62s/it] \u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.1844 - accuracy: 0.6476\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 13ms/step - loss: 1.1822 - accuracy: 0.6487 - val_loss: 1.7099 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3580 - accuracy: 0.9521\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.3565 - accuracy: 0.9526 - val_loss: 1.8647 - val_accuracy: 0.3146\n",
            "Epoch 3/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2150 - accuracy: 0.9844\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.2145 - accuracy: 0.9846 - val_loss: 0.5300 - val_accuracy: 0.9079\n",
            "Epoch 4/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1695 - accuracy: 0.9909\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1688 - accuracy: 0.9910 - val_loss: 0.8412 - val_accuracy: 0.7161\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1308 - accuracy: 0.9955\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1308 - accuracy: 0.9955 - val_loss: 0.2196 - val_accuracy: 0.9847\n",
            "Epoch 6/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1235 - accuracy: 0.9962\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.1235 - accuracy: 0.9962 - val_loss: 0.1321 - val_accuracy: 0.9898\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1108 - accuracy: 0.9909\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1117 - accuracy: 0.9910 - val_loss: 0.2403 - val_accuracy: 0.9744\n",
            "Epoch 8/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1137 - accuracy: 0.9949\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1137 - accuracy: 0.9949 - val_loss: 0.1571 - val_accuracy: 0.9744\n",
            "Epoch 9/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0809 - accuracy: 0.9993\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0808 - accuracy: 0.9994 - val_loss: 0.1005 - val_accuracy: 0.9923\n",
            "Epoch 10/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0786 - accuracy: 0.9994\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0786 - accuracy: 0.9994 - val_loss: 0.1196 - val_accuracy: 0.9923\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0822 - accuracy: 0.9987\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0820 - accuracy: 0.9987 - val_loss: 0.1604 - val_accuracy: 0.9642\n",
            "Epoch 12/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2729 - accuracy: 0.9517\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.2724 - accuracy: 0.9519 - val_loss: 0.1811 - val_accuracy: 0.9898\n",
            "Epoch 13/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1359 - accuracy: 0.9872\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1359 - accuracy: 0.9872 - val_loss: 0.1108 - val_accuracy: 0.9898\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0835 - accuracy: 0.9994\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0835 - accuracy: 0.9994 - val_loss: 0.0939 - val_accuracy: 0.9949\n",
            "Epoch 15/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0715 - accuracy: 1.0000\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0715 - accuracy: 1.0000 - val_loss: 0.1129 - val_accuracy: 0.9949\n",
            "Epoch 16/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0638 - accuracy: 1.0000\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0638 - accuracy: 1.0000 - val_loss: 0.0936 - val_accuracy: 0.9949\n",
            "Epoch 17/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0600 - accuracy: 1.0000\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0599 - accuracy: 1.0000 - val_loss: 0.0844 - val_accuracy: 0.9949\n",
            "Epoch 18/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0574 - accuracy: 1.0000\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0574 - accuracy: 1.0000 - val_loss: 0.0927 - val_accuracy: 0.9949\n",
            "Epoch 19/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.0563 - accuracy: 1.0000\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0562 - accuracy: 1.0000 - val_loss: 0.0809 - val_accuracy: 0.9949\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0515 - accuracy: 1.0000\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0515 - accuracy: 1.0000 - val_loss: 0.0780 - val_accuracy: 0.9923\n",
            "Epoch 21/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0500 - accuracy: 1.0000\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0500 - accuracy: 1.0000 - val_loss: 0.0763 - val_accuracy: 0.9923\n",
            "Epoch 22/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0487 - accuracy: 1.0000\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0487 - accuracy: 1.0000 - val_loss: 0.0827 - val_accuracy: 0.9923\n",
            "Epoch 23/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.2735 - accuracy: 0.9535\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.2705 - accuracy: 0.9545 - val_loss: 0.2426 - val_accuracy: 0.9463\n",
            "Epoch 24/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1154 - accuracy: 0.9890\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1154 - accuracy: 0.9891 - val_loss: 0.1263 - val_accuracy: 0.9821\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0830 - accuracy: 0.9987\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0832 - accuracy: 0.9987 - val_loss: 0.1283 - val_accuracy: 0.9872\n",
            "Epoch 26/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0728 - accuracy: 0.9993\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0729 - accuracy: 0.9994 - val_loss: 0.1049 - val_accuracy: 0.9872\n",
            "Epoch 26: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/175/assets\n",
            "\n",
            "\n",
            " 88%|████████▊ | 176/200 [7:05:52<37:47, 94.49s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 2.7982 - accuracy: 0.2230\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 12ms/step - loss: 2.7880 - accuracy: 0.2224 - val_loss: 1.8206 - val_accuracy: 0.1944\n",
            "Epoch 2/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 2.1422 - accuracy: 0.3043\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 2.1403 - accuracy: 0.3045 - val_loss: 1.8159 - val_accuracy: 0.2890\n",
            "Epoch 3/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.9452 - accuracy: 0.3509\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 1.9460 - accuracy: 0.3494 - val_loss: 1.7595 - val_accuracy: 0.3529\n",
            "Epoch 4/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.8383 - accuracy: 0.4137\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 1.8375 - accuracy: 0.4141 - val_loss: 1.7462 - val_accuracy: 0.4373\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.7639 - accuracy: 0.4469\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.7608 - accuracy: 0.4474 - val_loss: 1.7187 - val_accuracy: 0.4655\n",
            "Epoch 6/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 1.6921 - accuracy: 0.4809\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.6906 - accuracy: 0.4821 - val_loss: 1.6644 - val_accuracy: 0.5064\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6253 - accuracy: 0.5343\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 1.6239 - accuracy: 0.5346 - val_loss: 1.6090 - val_accuracy: 0.5473\n",
            "Epoch 8/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.5701 - accuracy: 0.5645\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 1.5709 - accuracy: 0.5647 - val_loss: 1.5545 - val_accuracy: 0.5627\n",
            "Epoch 9/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.5152 - accuracy: 0.5941\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.5148 - accuracy: 0.5936 - val_loss: 1.5034 - val_accuracy: 0.5908\n",
            "Epoch 10/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.4586 - accuracy: 0.6289\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.4611 - accuracy: 0.6269 - val_loss: 1.4551 - val_accuracy: 0.6138\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.4037 - accuracy: 0.6587\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 1.4029 - accuracy: 0.6603 - val_loss: 1.4046 - val_accuracy: 0.6471\n",
            "Epoch 12/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 1.3539 - accuracy: 0.6803\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 1.3498 - accuracy: 0.6814 - val_loss: 1.3546 - val_accuracy: 0.6752\n",
            "Epoch 13/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.3021 - accuracy: 0.6996\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.3001 - accuracy: 0.7013 - val_loss: 1.3067 - val_accuracy: 0.6931\n",
            "Epoch 14/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 1.2605 - accuracy: 0.7191\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.2593 - accuracy: 0.7199 - val_loss: 1.2601 - val_accuracy: 0.7161\n",
            "Epoch 15/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.2057 - accuracy: 0.7344\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.2048 - accuracy: 0.7353 - val_loss: 1.2146 - val_accuracy: 0.7366\n",
            "Epoch 16/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.1509 - accuracy: 0.7571\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 1.1525 - accuracy: 0.7564 - val_loss: 1.1700 - val_accuracy: 0.7621\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.1050 - accuracy: 0.7727\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 1.1042 - accuracy: 0.7737 - val_loss: 1.1254 - val_accuracy: 0.7775\n",
            "Epoch 18/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.0616 - accuracy: 0.7988\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.0617 - accuracy: 0.7987 - val_loss: 1.0825 - val_accuracy: 0.8005\n",
            "Epoch 19/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.0239 - accuracy: 0.8028\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 1.0229 - accuracy: 0.8038 - val_loss: 1.0430 - val_accuracy: 0.8082\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.9816 - accuracy: 0.8180\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.9821 - accuracy: 0.8173 - val_loss: 1.0047 - val_accuracy: 0.8235\n",
            "Epoch 21/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.9334 - accuracy: 0.8385\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.9334 - accuracy: 0.8385 - val_loss: 0.9659 - val_accuracy: 0.8286\n",
            "Epoch 22/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.9099 - accuracy: 0.8370\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.9060 - accuracy: 0.8391 - val_loss: 0.9296 - val_accuracy: 0.8312\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8663 - accuracy: 0.8575\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.8682 - accuracy: 0.8571 - val_loss: 0.8952 - val_accuracy: 0.8491\n",
            "Epoch 24/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.8354 - accuracy: 0.8640\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.8361 - accuracy: 0.8641 - val_loss: 0.8644 - val_accuracy: 0.8491\n",
            "Epoch 25/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.8135 - accuracy: 0.8711\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.8087 - accuracy: 0.8737 - val_loss: 0.8338 - val_accuracy: 0.8696\n",
            "Epoch 26/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.7886 - accuracy: 0.8731\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.7886 - accuracy: 0.8731 - val_loss: 0.8054 - val_accuracy: 0.8772\n",
            "Epoch 27/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 0.7526 - accuracy: 0.8935\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.7577 - accuracy: 0.8897 - val_loss: 0.7790 - val_accuracy: 0.8798\n",
            "Epoch 28/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.7220 - accuracy: 0.9089\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.7234 - accuracy: 0.9090 - val_loss: 0.7522 - val_accuracy: 0.8926\n",
            "Epoch 29/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.7104 - accuracy: 0.9062\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.7096 - accuracy: 0.9077 - val_loss: 0.7301 - val_accuracy: 0.9003\n",
            "Epoch 30/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.6847 - accuracy: 0.9130\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.6865 - accuracy: 0.9122 - val_loss: 0.7083 - val_accuracy: 0.9054\n",
            "Epoch 31/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.6605 - accuracy: 0.9211\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.6620 - accuracy: 0.9205 - val_loss: 0.6888 - val_accuracy: 0.9156\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6505 - accuracy: 0.9275\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.6513 - accuracy: 0.9276 - val_loss: 0.6686 - val_accuracy: 0.9233\n",
            "Epoch 33/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6271 - accuracy: 0.9340\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.6271 - accuracy: 0.9340 - val_loss: 0.6504 - val_accuracy: 0.9309\n",
            "Epoch 34/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.6123 - accuracy: 0.9375\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.6126 - accuracy: 0.9365 - val_loss: 0.6349 - val_accuracy: 0.9335\n",
            "Epoch 35/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5865 - accuracy: 0.9404\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.5858 - accuracy: 0.9410 - val_loss: 0.6152 - val_accuracy: 0.9386\n",
            "Epoch 36/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 0.5767 - accuracy: 0.9438\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.5766 - accuracy: 0.9455 - val_loss: 0.5998 - val_accuracy: 0.9437\n",
            "Epoch 37/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5615 - accuracy: 0.9514\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.5618 - accuracy: 0.9513 - val_loss: 0.5832 - val_accuracy: 0.9437\n",
            "Epoch 38/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5490 - accuracy: 0.9514\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.5487 - accuracy: 0.9513 - val_loss: 0.5694 - val_accuracy: 0.9540\n",
            "Epoch 39/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.5332 - accuracy: 0.9614\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.5341 - accuracy: 0.9609 - val_loss: 0.5569 - val_accuracy: 0.9540\n",
            "Epoch 40/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.5207 - accuracy: 0.9566\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.5202 - accuracy: 0.9571 - val_loss: 0.5429 - val_accuracy: 0.9591\n",
            "Epoch 41/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 0.5068 - accuracy: 0.9643\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.5075 - accuracy: 0.9641 - val_loss: 0.5300 - val_accuracy: 0.9642\n",
            "Epoch 42/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4988 - accuracy: 0.9603\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.4988 - accuracy: 0.9603 - val_loss: 0.5185 - val_accuracy: 0.9668\n",
            "Epoch 43/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.4862 - accuracy: 0.9640\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.4870 - accuracy: 0.9628 - val_loss: 0.5096 - val_accuracy: 0.9616\n",
            "Epoch 44/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4729 - accuracy: 0.9710\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.4728 - accuracy: 0.9712 - val_loss: 0.5001 - val_accuracy: 0.9693\n",
            "Epoch 45/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.4613 - accuracy: 0.9692\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.4615 - accuracy: 0.9692 - val_loss: 0.4904 - val_accuracy: 0.9591\n",
            "Epoch 46/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4538 - accuracy: 0.9747\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.4538 - accuracy: 0.9750 - val_loss: 0.4777 - val_accuracy: 0.9616\n",
            "Epoch 47/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.4414 - accuracy: 0.9738\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.4401 - accuracy: 0.9744 - val_loss: 0.4694 - val_accuracy: 0.9693\n",
            "Epoch 48/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4315 - accuracy: 0.9768\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.4321 - accuracy: 0.9769 - val_loss: 0.4624 - val_accuracy: 0.9591\n",
            "Epoch 49/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4304 - accuracy: 0.9760\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.4302 - accuracy: 0.9763 - val_loss: 0.4534 - val_accuracy: 0.9668\n",
            "Epoch 50/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.4177 - accuracy: 0.9811\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.4184 - accuracy: 0.9808 - val_loss: 0.4419 - val_accuracy: 0.9744\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/176/assets\n",
            "\n",
            "\n",
            " 88%|████████▊ | 177/200 [7:07:30<36:40, 95.69s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 2.4805 - accuracy: 0.2906\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 28ms/step - loss: 2.4796 - accuracy: 0.2897 - val_loss: 1.8727 - val_accuracy: 0.2634\n",
            "Epoch 2/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 2.0483 - accuracy: 0.4691\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 2.0472 - accuracy: 0.4692 - val_loss: 1.8601 - val_accuracy: 0.2737\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.8193 - accuracy: 0.5946\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 1.8180 - accuracy: 0.5962 - val_loss: 1.7210 - val_accuracy: 0.3964\n",
            "Epoch 4/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6261 - accuracy: 0.6798\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 1.6247 - accuracy: 0.6808 - val_loss: 1.4804 - val_accuracy: 0.7442\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.4557 - accuracy: 0.7370\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 1.4556 - accuracy: 0.7365 - val_loss: 1.3180 - val_accuracy: 0.7980\n",
            "Epoch 6/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.3085 - accuracy: 0.7899\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 1.3084 - accuracy: 0.7897 - val_loss: 1.1706 - val_accuracy: 0.8440\n",
            "Epoch 7/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.1726 - accuracy: 0.8346\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 1.1726 - accuracy: 0.8346 - val_loss: 1.0511 - val_accuracy: 0.8645\n",
            "Epoch 8/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.0761 - accuracy: 0.8705\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 1.0761 - accuracy: 0.8705 - val_loss: 0.9545 - val_accuracy: 0.8849\n",
            "Epoch 9/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.9855 - accuracy: 0.8949\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.9855 - accuracy: 0.8949 - val_loss: 0.8761 - val_accuracy: 0.9284\n",
            "Epoch 10/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.9127 - accuracy: 0.9179\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.9127 - accuracy: 0.9179 - val_loss: 0.8149 - val_accuracy: 0.9514\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8436 - accuracy: 0.9326\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.8420 - accuracy: 0.9333 - val_loss: 0.7550 - val_accuracy: 0.9719\n",
            "Epoch 12/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.8004 - accuracy: 0.9420\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.8003 - accuracy: 0.9417 - val_loss: 0.7350 - val_accuracy: 0.9693\n",
            "Epoch 13/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.7499 - accuracy: 0.9543\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.7497 - accuracy: 0.9545 - val_loss: 0.6758 - val_accuracy: 0.9795\n",
            "Epoch 14/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.7166 - accuracy: 0.9558\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.7166 - accuracy: 0.9558 - val_loss: 0.6462 - val_accuracy: 0.9795\n",
            "Epoch 15/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6826 - accuracy: 0.9622\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.6826 - accuracy: 0.9622 - val_loss: 0.6156 - val_accuracy: 0.9872\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6486 - accuracy: 0.9722\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.6478 - accuracy: 0.9724 - val_loss: 0.5926 - val_accuracy: 0.9872\n",
            "Epoch 17/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.6309 - accuracy: 0.9684\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.6308 - accuracy: 0.9686 - val_loss: 0.5695 - val_accuracy: 0.9847\n",
            "Epoch 18/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.5978 - accuracy: 0.9800\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.5983 - accuracy: 0.9795 - val_loss: 0.5482 - val_accuracy: 0.9847\n",
            "Epoch 19/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5806 - accuracy: 0.9763\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.5806 - accuracy: 0.9763 - val_loss: 0.5298 - val_accuracy: 0.9847\n",
            "Epoch 20/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.5646 - accuracy: 0.9794\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.5642 - accuracy: 0.9795 - val_loss: 0.5148 - val_accuracy: 0.9847\n",
            "Epoch 21/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5398 - accuracy: 0.9846\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.5398 - accuracy: 0.9846 - val_loss: 0.5007 - val_accuracy: 0.9847\n",
            "Epoch 22/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.5208 - accuracy: 0.9884\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.5216 - accuracy: 0.9878 - val_loss: 0.4823 - val_accuracy: 0.9872\n",
            "Epoch 23/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.5025 - accuracy: 0.9910\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.5024 - accuracy: 0.9910 - val_loss: 0.4708 - val_accuracy: 0.9923\n",
            "Epoch 24/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4919 - accuracy: 0.9903\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.4919 - accuracy: 0.9904 - val_loss: 0.4595 - val_accuracy: 0.9898\n",
            "Epoch 25/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4764 - accuracy: 0.9891\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.4764 - accuracy: 0.9891 - val_loss: 0.4471 - val_accuracy: 0.9872\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4658 - accuracy: 0.9916\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.4666 - accuracy: 0.9910 - val_loss: 0.4335 - val_accuracy: 0.9898\n",
            "Epoch 27/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4493 - accuracy: 0.9942\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.4493 - accuracy: 0.9942 - val_loss: 0.4244 - val_accuracy: 0.9898\n",
            "Epoch 28/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4440 - accuracy: 0.9936\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.4440 - accuracy: 0.9936 - val_loss: 0.4151 - val_accuracy: 0.9898\n",
            "Epoch 29/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4298 - accuracy: 0.9942\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.4299 - accuracy: 0.9942 - val_loss: 0.4057 - val_accuracy: 0.9923\n",
            "Epoch 30/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4174 - accuracy: 0.9962\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.4174 - accuracy: 0.9962 - val_loss: 0.3955 - val_accuracy: 0.9923\n",
            "Epoch 31/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4088 - accuracy: 0.9942\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.4090 - accuracy: 0.9942 - val_loss: 0.3862 - val_accuracy: 0.9923\n",
            "Epoch 32/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4002 - accuracy: 0.9955\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.4005 - accuracy: 0.9955 - val_loss: 0.3777 - val_accuracy: 0.9923\n",
            "Epoch 33/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3877 - accuracy: 0.9968\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.3875 - accuracy: 0.9968 - val_loss: 0.3698 - val_accuracy: 0.9923\n",
            "Epoch 34/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3817 - accuracy: 0.9968\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.3816 - accuracy: 0.9968 - val_loss: 0.3617 - val_accuracy: 0.9974\n",
            "Epoch 35/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3764 - accuracy: 0.9974\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.3764 - accuracy: 0.9974 - val_loss: 0.3561 - val_accuracy: 0.9949\n",
            "Epoch 36/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3677 - accuracy: 0.9994\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.3676 - accuracy: 0.9994 - val_loss: 0.3457 - val_accuracy: 0.9949\n",
            "Epoch 37/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3575 - accuracy: 0.9968\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.3575 - accuracy: 0.9968 - val_loss: 0.3394 - val_accuracy: 0.9923\n",
            "Epoch 38/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3546 - accuracy: 0.9948\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.3545 - accuracy: 0.9949 - val_loss: 0.3366 - val_accuracy: 0.9923\n",
            "Epoch 39/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3460 - accuracy: 0.9968\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.3460 - accuracy: 0.9968 - val_loss: 0.3280 - val_accuracy: 0.9949\n",
            "Epoch 40/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3383 - accuracy: 0.9987\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.3380 - accuracy: 0.9987 - val_loss: 0.3265 - val_accuracy: 0.9923\n",
            "Epoch 41/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3333 - accuracy: 0.9981\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.3333 - accuracy: 0.9981 - val_loss: 0.3171 - val_accuracy: 0.9949\n",
            "Epoch 42/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3239 - accuracy: 0.9974\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.3236 - accuracy: 0.9974 - val_loss: 0.3120 - val_accuracy: 0.9949\n",
            "Epoch 43/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3189 - accuracy: 0.9974\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.3189 - accuracy: 0.9974 - val_loss: 0.3055 - val_accuracy: 0.9949\n",
            "Epoch 44/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3130 - accuracy: 0.9987\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.3130 - accuracy: 0.9987 - val_loss: 0.3078 - val_accuracy: 0.9974\n",
            "Epoch 45/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3099 - accuracy: 0.9981\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.3099 - accuracy: 0.9981 - val_loss: 0.3052 - val_accuracy: 0.9949\n",
            "Epoch 46/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3045 - accuracy: 0.9968\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.3046 - accuracy: 0.9968 - val_loss: 0.2980 - val_accuracy: 0.9974\n",
            "Epoch 47/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3007 - accuracy: 0.9981\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.3004 - accuracy: 0.9981 - val_loss: 0.2911 - val_accuracy: 0.9949\n",
            "Epoch 48/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2955 - accuracy: 0.9974\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.2955 - accuracy: 0.9974 - val_loss: 0.2864 - val_accuracy: 0.9923\n",
            "Epoch 49/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2890 - accuracy: 0.9994\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.2891 - accuracy: 0.9994 - val_loss: 0.2811 - val_accuracy: 0.9974\n",
            "Epoch 50/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2850 - accuracy: 0.9968\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.2850 - accuracy: 0.9968 - val_loss: 0.2833 - val_accuracy: 0.9974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/177/assets\n",
            "\n",
            "\n",
            " 89%|████████▉ | 178/200 [7:11:57<53:56, 147.10s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 2.2328 - accuracy: 0.2661\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 14ms/step - loss: 2.2326 - accuracy: 0.2667 - val_loss: 1.8455 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 2.0318 - accuracy: 0.3822\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 2.0324 - accuracy: 0.3821 - val_loss: 1.8610 - val_accuracy: 0.2864\n",
            "Epoch 3/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.9047 - accuracy: 0.4395\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.9020 - accuracy: 0.4410 - val_loss: 1.7900 - val_accuracy: 0.3504\n",
            "Epoch 4/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.8104 - accuracy: 0.4987\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 1.8104 - accuracy: 0.4987 - val_loss: 1.6826 - val_accuracy: 0.4885\n",
            "Epoch 5/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.7246 - accuracy: 0.5651\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 1.7234 - accuracy: 0.5654 - val_loss: 1.6104 - val_accuracy: 0.5703\n",
            "Epoch 6/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.6388 - accuracy: 0.6087\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.6371 - accuracy: 0.6109 - val_loss: 1.5247 - val_accuracy: 0.6240\n",
            "Epoch 7/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.5660 - accuracy: 0.6387\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.5618 - accuracy: 0.6397 - val_loss: 1.4578 - val_accuracy: 0.6471\n",
            "Epoch 8/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.4903 - accuracy: 0.6758\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 1.4888 - accuracy: 0.6769 - val_loss: 1.3786 - val_accuracy: 0.6880\n",
            "Epoch 9/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.4211 - accuracy: 0.7214\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 1.4195 - accuracy: 0.7205 - val_loss: 1.2983 - val_accuracy: 0.7468\n",
            "Epoch 10/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.3629 - accuracy: 0.7331\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 1.3621 - accuracy: 0.7340 - val_loss: 1.2453 - val_accuracy: 0.7366\n",
            "Epoch 11/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.2859 - accuracy: 0.7635\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 1.2859 - accuracy: 0.7635 - val_loss: 1.1910 - val_accuracy: 0.7545\n",
            "Epoch 12/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.2315 - accuracy: 0.7683\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 1.2353 - accuracy: 0.7654 - val_loss: 1.1265 - val_accuracy: 0.8056\n",
            "Epoch 13/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.1771 - accuracy: 0.7840\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 1.1771 - accuracy: 0.7840 - val_loss: 1.0716 - val_accuracy: 0.8107\n",
            "Epoch 14/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.1383 - accuracy: 0.7880\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.1371 - accuracy: 0.7885 - val_loss: 1.0322 - val_accuracy: 0.8517\n",
            "Epoch 15/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.0888 - accuracy: 0.8050\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 1.0886 - accuracy: 0.8051 - val_loss: 1.0074 - val_accuracy: 0.8465\n",
            "Epoch 16/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 1.0420 - accuracy: 0.8200\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 1.0436 - accuracy: 0.8192 - val_loss: 0.9479 - val_accuracy: 0.8542\n",
            "Epoch 17/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.0038 - accuracy: 0.8441\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 1.0046 - accuracy: 0.8442 - val_loss: 0.9201 - val_accuracy: 0.8619\n",
            "Epoch 18/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.9730 - accuracy: 0.8421\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.9726 - accuracy: 0.8423 - val_loss: 0.8778 - val_accuracy: 0.8824\n",
            "Epoch 19/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.9321 - accuracy: 0.8600\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.9327 - accuracy: 0.8596 - val_loss: 0.8448 - val_accuracy: 0.8875\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8953 - accuracy: 0.8828\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.8973 - accuracy: 0.8814 - val_loss: 0.8236 - val_accuracy: 0.9028\n",
            "Epoch 21/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.8812 - accuracy: 0.8789\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.8822 - accuracy: 0.8788 - val_loss: 0.7928 - val_accuracy: 0.9028\n",
            "Epoch 22/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.8467 - accuracy: 0.8914\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.8459 - accuracy: 0.8923 - val_loss: 0.7690 - val_accuracy: 0.9105\n",
            "Epoch 23/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.8172 - accuracy: 0.8966\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.8192 - accuracy: 0.8962 - val_loss: 0.7518 - val_accuracy: 0.9233\n",
            "Epoch 24/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.7959 - accuracy: 0.9030\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.7937 - accuracy: 0.9045 - val_loss: 0.7246 - val_accuracy: 0.9361\n",
            "Epoch 25/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.7724 - accuracy: 0.9098\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.7719 - accuracy: 0.9103 - val_loss: 0.7048 - val_accuracy: 0.9361\n",
            "Epoch 26/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.7658 - accuracy: 0.9135\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.7658 - accuracy: 0.9135 - val_loss: 0.6887 - val_accuracy: 0.9412\n",
            "Epoch 27/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.7266 - accuracy: 0.9287\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.7247 - accuracy: 0.9295 - val_loss: 0.6665 - val_accuracy: 0.9488\n",
            "Epoch 28/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.7096 - accuracy: 0.9264\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.7086 - accuracy: 0.9269 - val_loss: 0.6528 - val_accuracy: 0.9565\n",
            "Epoch 29/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.7070 - accuracy: 0.9323\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.7052 - accuracy: 0.9333 - val_loss: 0.6384 - val_accuracy: 0.9540\n",
            "Epoch 30/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.6872 - accuracy: 0.9381\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.6866 - accuracy: 0.9385 - val_loss: 0.6213 - val_accuracy: 0.9616\n",
            "Epoch 31/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6670 - accuracy: 0.9424\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.6669 - accuracy: 0.9417 - val_loss: 0.6111 - val_accuracy: 0.9719\n",
            "Epoch 32/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.6550 - accuracy: 0.9470\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.6554 - accuracy: 0.9474 - val_loss: 0.5910 - val_accuracy: 0.9719\n",
            "Epoch 33/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6412 - accuracy: 0.9500\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.6412 - accuracy: 0.9500 - val_loss: 0.5799 - val_accuracy: 0.9719\n",
            "Epoch 34/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.6327 - accuracy: 0.9476\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.6308 - accuracy: 0.9481 - val_loss: 0.5736 - val_accuracy: 0.9770\n",
            "Epoch 35/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.6081 - accuracy: 0.9603\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.6072 - accuracy: 0.9603 - val_loss: 0.5542 - val_accuracy: 0.9744\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5998 - accuracy: 0.9534\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.5999 - accuracy: 0.9538 - val_loss: 0.5442 - val_accuracy: 0.9770\n",
            "Epoch 37/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5874 - accuracy: 0.9571\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.5874 - accuracy: 0.9571 - val_loss: 0.5389 - val_accuracy: 0.9795\n",
            "Epoch 38/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.5658 - accuracy: 0.9727\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.5637 - accuracy: 0.9731 - val_loss: 0.5239 - val_accuracy: 0.9795\n",
            "Epoch 39/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5638 - accuracy: 0.9667\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.5638 - accuracy: 0.9667 - val_loss: 0.5177 - val_accuracy: 0.9719\n",
            "Epoch 40/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.5412 - accuracy: 0.9712\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.5414 - accuracy: 0.9718 - val_loss: 0.5051 - val_accuracy: 0.9821\n",
            "Epoch 41/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5421 - accuracy: 0.9631\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.5437 - accuracy: 0.9622 - val_loss: 0.4920 - val_accuracy: 0.9821\n",
            "Epoch 42/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.5299 - accuracy: 0.9704\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.5295 - accuracy: 0.9705 - val_loss: 0.4871 - val_accuracy: 0.9770\n",
            "Epoch 43/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.5242 - accuracy: 0.9668\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.5246 - accuracy: 0.9654 - val_loss: 0.4785 - val_accuracy: 0.9847\n",
            "Epoch 44/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5148 - accuracy: 0.9737\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.5148 - accuracy: 0.9737 - val_loss: 0.4692 - val_accuracy: 0.9821\n",
            "Epoch 45/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.4982 - accuracy: 0.9766\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.4976 - accuracy: 0.9769 - val_loss: 0.4669 - val_accuracy: 0.9770\n",
            "Epoch 46/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.4964 - accuracy: 0.9772\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.4957 - accuracy: 0.9776 - val_loss: 0.4541 - val_accuracy: 0.9770\n",
            "Epoch 47/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4877 - accuracy: 0.9767\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.4872 - accuracy: 0.9769 - val_loss: 0.4464 - val_accuracy: 0.9847\n",
            "Epoch 48/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.4760 - accuracy: 0.9764\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.4765 - accuracy: 0.9756 - val_loss: 0.4383 - val_accuracy: 0.9847\n",
            "Epoch 49/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.4669 - accuracy: 0.9822\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.4674 - accuracy: 0.9814 - val_loss: 0.4312 - val_accuracy: 0.9872\n",
            "Epoch 50/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4618 - accuracy: 0.9795\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.4618 - accuracy: 0.9795 - val_loss: 0.4269 - val_accuracy: 0.9847\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/178/assets\n",
            "\n",
            "\n",
            " 90%|████████▉ | 179/200 [7:13:57<48:35, 138.82s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 2.0026 - accuracy: 0.5551\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 25ms/step - loss: 2.0026 - accuracy: 0.5551 - val_loss: 1.8289 - val_accuracy: 0.3529\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.9862 - accuracy: 0.9009\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.9843 - accuracy: 0.9019 - val_loss: 1.4491 - val_accuracy: 0.8133\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6770 - accuracy: 0.9728\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.6781 - accuracy: 0.9718 - val_loss: 0.7680 - val_accuracy: 0.8951\n",
            "Epoch 4/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5312 - accuracy: 0.9808\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.5312 - accuracy: 0.9808 - val_loss: 0.5013 - val_accuracy: 0.9616\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4323 - accuracy: 0.9929\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.4319 - accuracy: 0.9929 - val_loss: 0.3869 - val_accuracy: 0.9898\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3680 - accuracy: 0.9929\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.3671 - accuracy: 0.9929 - val_loss: 0.3238 - val_accuracy: 0.9949\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3199 - accuracy: 0.9955\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.3196 - accuracy: 0.9955 - val_loss: 0.2843 - val_accuracy: 0.9949\n",
            "Epoch 8/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2716 - accuracy: 0.9968\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.2716 - accuracy: 0.9968 - val_loss: 0.2577 - val_accuracy: 0.9949\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2468 - accuracy: 0.9961\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.2466 - accuracy: 0.9962 - val_loss: 0.2328 - val_accuracy: 0.9949\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2201 - accuracy: 0.9987\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.2200 - accuracy: 0.9987 - val_loss: 0.2176 - val_accuracy: 0.9949\n",
            "Epoch 11/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2098 - accuracy: 0.9981\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.2098 - accuracy: 0.9981 - val_loss: 0.2023 - val_accuracy: 0.9949\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1932 - accuracy: 0.9987\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1940 - accuracy: 0.9981 - val_loss: 0.2020 - val_accuracy: 0.9949\n",
            "Epoch 13/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1838 - accuracy: 0.9994\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1836 - accuracy: 0.9994 - val_loss: 0.1776 - val_accuracy: 0.9949\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1745 - accuracy: 0.9981\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1745 - accuracy: 0.9981 - val_loss: 0.1808 - val_accuracy: 0.9923\n",
            "Epoch 15/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1690 - accuracy: 0.9981\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1690 - accuracy: 0.9981 - val_loss: 0.1698 - val_accuracy: 0.9923\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1583 - accuracy: 0.9994\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1583 - accuracy: 0.9994 - val_loss: 0.1726 - val_accuracy: 0.9949\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1545 - accuracy: 0.9994\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.1547 - accuracy: 0.9994 - val_loss: 0.1561 - val_accuracy: 0.9949\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1455 - accuracy: 1.0000\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1452 - accuracy: 1.0000 - val_loss: 0.1540 - val_accuracy: 0.9974\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1403 - accuracy: 0.9994\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1402 - accuracy: 0.9994 - val_loss: 0.1511 - val_accuracy: 0.9923\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1404 - accuracy: 0.9994\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.1404 - accuracy: 0.9994 - val_loss: 0.1526 - val_accuracy: 0.9898\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1316 - accuracy: 0.9994\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1315 - accuracy: 0.9994 - val_loss: 0.1555 - val_accuracy: 0.9898\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1283 - accuracy: 1.0000\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1282 - accuracy: 1.0000 - val_loss: 0.1391 - val_accuracy: 0.9923\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1273 - accuracy: 0.9994\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1273 - accuracy: 0.9994 - val_loss: 0.1387 - val_accuracy: 0.9949\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1207 - accuracy: 1.0000\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1207 - accuracy: 1.0000 - val_loss: 0.1291 - val_accuracy: 0.9949\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1187 - accuracy: 1.0000\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1186 - accuracy: 1.0000 - val_loss: 0.1331 - val_accuracy: 0.9923\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1164 - accuracy: 0.9994\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.1164 - accuracy: 0.9994 - val_loss: 0.1305 - val_accuracy: 0.9923\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1414 - accuracy: 0.9935\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1414 - accuracy: 0.9936 - val_loss: 0.1587 - val_accuracy: 0.9923\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1165 - accuracy: 0.9994\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1164 - accuracy: 0.9994 - val_loss: 0.1237 - val_accuracy: 0.9949\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1104 - accuracy: 1.0000\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1103 - accuracy: 1.0000 - val_loss: 0.1250 - val_accuracy: 0.9949\n",
            "Epoch 30/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1072 - accuracy: 1.0000\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1072 - accuracy: 1.0000 - val_loss: 0.1206 - val_accuracy: 0.9949\n",
            "Epoch 31/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1035 - accuracy: 1.0000\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1034 - accuracy: 1.0000 - val_loss: 0.1216 - val_accuracy: 0.9923\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1010 - accuracy: 1.0000\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1010 - accuracy: 1.0000 - val_loss: 0.1151 - val_accuracy: 0.9974\n",
            "Epoch 33/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1024 - accuracy: 0.9994\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1024 - accuracy: 0.9994 - val_loss: 0.1571 - val_accuracy: 0.9898\n",
            "Epoch 34/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1091 - accuracy: 0.9987\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1091 - accuracy: 0.9987 - val_loss: 0.1179 - val_accuracy: 0.9949\n",
            "Epoch 35/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0959 - accuracy: 0.9994\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0959 - accuracy: 0.9994 - val_loss: 0.1135 - val_accuracy: 0.9949\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0926 - accuracy: 1.0000\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0926 - accuracy: 1.0000 - val_loss: 0.1121 - val_accuracy: 0.9923\n",
            "Epoch 37/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0906 - accuracy: 1.0000\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0907 - accuracy: 1.0000 - val_loss: 0.1092 - val_accuracy: 0.9923\n",
            "Epoch 38/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0881 - accuracy: 1.0000\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0881 - accuracy: 1.0000 - val_loss: 0.1059 - val_accuracy: 0.9923\n",
            "Epoch 39/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0859 - accuracy: 1.0000\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0859 - accuracy: 1.0000 - val_loss: 0.1001 - val_accuracy: 0.9949\n",
            "Epoch 40/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0834 - accuracy: 1.0000\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0833 - accuracy: 1.0000 - val_loss: 0.1007 - val_accuracy: 0.9923\n",
            "Epoch 41/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0810 - accuracy: 1.0000\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.0810 - accuracy: 1.0000 - val_loss: 0.0977 - val_accuracy: 0.9923\n",
            "Epoch 42/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0789 - accuracy: 1.0000\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0789 - accuracy: 1.0000 - val_loss: 0.1014 - val_accuracy: 0.9923\n",
            "Epoch 43/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0765 - accuracy: 1.0000\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0765 - accuracy: 1.0000 - val_loss: 0.0945 - val_accuracy: 0.9923\n",
            "Epoch 44/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0742 - accuracy: 1.0000\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0742 - accuracy: 1.0000 - val_loss: 0.0900 - val_accuracy: 0.9949\n",
            "Epoch 45/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0715 - accuracy: 1.0000\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0715 - accuracy: 1.0000 - val_loss: 0.0875 - val_accuracy: 0.9949\n",
            "Epoch 46/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0690 - accuracy: 1.0000\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0689 - accuracy: 1.0000 - val_loss: 0.0865 - val_accuracy: 0.9923\n",
            "Epoch 47/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0666 - accuracy: 1.0000\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0666 - accuracy: 1.0000 - val_loss: 0.0877 - val_accuracy: 0.9923\n",
            "Epoch 48/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0652 - accuracy: 1.0000\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0651 - accuracy: 1.0000 - val_loss: 0.0810 - val_accuracy: 0.9923\n",
            "Epoch 49/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0619 - accuracy: 1.0000\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0619 - accuracy: 1.0000 - val_loss: 0.0785 - val_accuracy: 0.9923\n",
            "Epoch 50/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0588 - accuracy: 1.0000\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0588 - accuracy: 1.0000 - val_loss: 0.0769 - val_accuracy: 0.9923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/179/assets\n",
            "\n",
            "\n",
            " 90%|█████████ | 180/200 [7:17:45<55:15, 165.78s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.2087 - accuracy: 0.7474\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 10s 42ms/step - loss: 1.2087 - accuracy: 0.7474 - val_loss: 1.8444 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4695 - accuracy: 0.9827\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 8s 40ms/step - loss: 0.4695 - accuracy: 0.9827 - val_loss: 1.6500 - val_accuracy: 0.3887\n",
            "Epoch 3/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3563 - accuracy: 0.9962\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 8s 40ms/step - loss: 0.3563 - accuracy: 0.9962 - val_loss: 0.6190 - val_accuracy: 0.9540\n",
            "Epoch 4/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2931 - accuracy: 0.9974\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 8s 41ms/step - loss: 0.2931 - accuracy: 0.9974 - val_loss: 0.2922 - val_accuracy: 0.9923\n",
            "Epoch 5/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2568 - accuracy: 0.9987\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 8s 40ms/step - loss: 0.2568 - accuracy: 0.9987 - val_loss: 0.2525 - val_accuracy: 0.9923\n",
            "Epoch 6/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2542 - accuracy: 0.9936\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 8s 40ms/step - loss: 0.2542 - accuracy: 0.9936 - val_loss: 0.2600 - val_accuracy: 0.9898\n",
            "Epoch 7/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2199 - accuracy: 0.9994\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 8s 40ms/step - loss: 0.2199 - accuracy: 0.9994 - val_loss: 0.2163 - val_accuracy: 0.9923\n",
            "Epoch 8/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1994 - accuracy: 1.0000\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 8s 40ms/step - loss: 0.1994 - accuracy: 1.0000 - val_loss: 0.2347 - val_accuracy: 0.9872\n",
            "Epoch 9/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1914 - accuracy: 0.9994\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 8s 40ms/step - loss: 0.1914 - accuracy: 0.9994 - val_loss: 0.2293 - val_accuracy: 0.9821\n",
            "Epoch 10/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1766 - accuracy: 0.9994\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 8s 40ms/step - loss: 0.1766 - accuracy: 0.9994 - val_loss: 0.1897 - val_accuracy: 0.9923\n",
            "Epoch 11/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1678 - accuracy: 1.0000\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 8s 40ms/step - loss: 0.1678 - accuracy: 1.0000 - val_loss: 0.1893 - val_accuracy: 0.9923\n",
            "Epoch 12/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1621 - accuracy: 0.9994\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 8s 40ms/step - loss: 0.1621 - accuracy: 0.9994 - val_loss: 0.2063 - val_accuracy: 0.9923\n",
            "Epoch 13/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1583 - accuracy: 1.0000\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 8s 40ms/step - loss: 0.1583 - accuracy: 1.0000 - val_loss: 0.1771 - val_accuracy: 0.9898\n",
            "Epoch 14/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1509 - accuracy: 1.0000\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 8s 40ms/step - loss: 0.1509 - accuracy: 1.0000 - val_loss: 0.1863 - val_accuracy: 0.9923\n",
            "Epoch 15/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1504 - accuracy: 1.0000\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 8s 40ms/step - loss: 0.1504 - accuracy: 1.0000 - val_loss: 0.1802 - val_accuracy: 0.9923\n",
            "Epoch 16/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1435 - accuracy: 1.0000\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 8s 40ms/step - loss: 0.1435 - accuracy: 1.0000 - val_loss: 0.1563 - val_accuracy: 0.9923\n",
            "Epoch 17/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1388 - accuracy: 1.0000\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 8s 40ms/step - loss: 0.1388 - accuracy: 1.0000 - val_loss: 0.1583 - val_accuracy: 0.9923\n",
            "Epoch 18/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1347 - accuracy: 1.0000\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 8s 40ms/step - loss: 0.1347 - accuracy: 1.0000 - val_loss: 0.1536 - val_accuracy: 0.9923\n",
            "Epoch 19/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1306 - accuracy: 1.0000\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 8s 40ms/step - loss: 0.1306 - accuracy: 1.0000 - val_loss: 0.1520 - val_accuracy: 0.9923\n",
            "Epoch 20/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1270 - accuracy: 1.0000\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 8s 40ms/step - loss: 0.1270 - accuracy: 1.0000 - val_loss: 0.1554 - val_accuracy: 0.9949\n",
            "Epoch 21/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1277 - accuracy: 1.0000\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 8s 40ms/step - loss: 0.1277 - accuracy: 1.0000 - val_loss: 0.1538 - val_accuracy: 0.9923\n",
            "Epoch 22/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1227 - accuracy: 1.0000\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 8s 40ms/step - loss: 0.1227 - accuracy: 1.0000 - val_loss: 0.1499 - val_accuracy: 0.9923\n",
            "Epoch 23/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1206 - accuracy: 1.0000\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 8s 40ms/step - loss: 0.1206 - accuracy: 1.0000 - val_loss: 0.1406 - val_accuracy: 0.9923\n",
            "Epoch 24/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1173 - accuracy: 1.0000\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 8s 40ms/step - loss: 0.1173 - accuracy: 1.0000 - val_loss: 0.1292 - val_accuracy: 0.9949\n",
            "Epoch 25/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1122 - accuracy: 1.0000\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 8s 40ms/step - loss: 0.1122 - accuracy: 1.0000 - val_loss: 0.1321 - val_accuracy: 0.9923\n",
            "Epoch 26/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1087 - accuracy: 1.0000\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 8s 40ms/step - loss: 0.1087 - accuracy: 1.0000 - val_loss: 0.1308 - val_accuracy: 0.9923\n",
            "Epoch 27/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1666 - accuracy: 0.9891\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 8s 40ms/step - loss: 0.1666 - accuracy: 0.9891 - val_loss: 0.7482 - val_accuracy: 0.9361\n",
            "Epoch 28/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1609 - accuracy: 0.9929\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 8s 39ms/step - loss: 0.1609 - accuracy: 0.9929 - val_loss: 0.1374 - val_accuracy: 0.9949\n",
            "Epoch 29/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1175 - accuracy: 0.9994\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 8s 39ms/step - loss: 0.1175 - accuracy: 0.9994 - val_loss: 0.1525 - val_accuracy: 0.9898\n",
            "Epoch 29: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/180/assets\n",
            "\n",
            "\n",
            " 90%|█████████ | 181/200 [7:22:13<1:02:07, 196.21s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 2.4668 - accuracy: 0.3340\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 19ms/step - loss: 2.4668 - accuracy: 0.3340 - val_loss: 1.8295 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 2.0925 - accuracy: 0.4839\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 2.0918 - accuracy: 0.4846 - val_loss: 1.8690 - val_accuracy: 0.2864\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.8447 - accuracy: 0.6075\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 1.8437 - accuracy: 0.6071 - val_loss: 1.6889 - val_accuracy: 0.3402\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6197 - accuracy: 0.6898\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 1.6174 - accuracy: 0.6910 - val_loss: 1.4131 - val_accuracy: 0.7187\n",
            "Epoch 5/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.4458 - accuracy: 0.7396\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 1.4434 - accuracy: 0.7404 - val_loss: 1.2808 - val_accuracy: 0.8031\n",
            "Epoch 6/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.3018 - accuracy: 0.7982\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 1.2997 - accuracy: 0.7994 - val_loss: 1.1800 - val_accuracy: 0.8133\n",
            "Epoch 7/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.1841 - accuracy: 0.8421\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 1.1834 - accuracy: 0.8423 - val_loss: 1.0708 - val_accuracy: 0.8593\n",
            "Epoch 8/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.0888 - accuracy: 0.8641\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 1.0888 - accuracy: 0.8641 - val_loss: 0.9892 - val_accuracy: 0.8977\n",
            "Epoch 9/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.0096 - accuracy: 0.8892\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 1.0093 - accuracy: 0.8891 - val_loss: 0.9232 - val_accuracy: 0.9284\n",
            "Epoch 10/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.9279 - accuracy: 0.9147\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.9279 - accuracy: 0.9147 - val_loss: 0.8660 - val_accuracy: 0.9335\n",
            "Epoch 11/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.8751 - accuracy: 0.9314\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.8751 - accuracy: 0.9314 - val_loss: 0.8118 - val_accuracy: 0.9565\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8160 - accuracy: 0.9482\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.8156 - accuracy: 0.9481 - val_loss: 0.7690 - val_accuracy: 0.9488\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7696 - accuracy: 0.9508\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.7690 - accuracy: 0.9513 - val_loss: 0.7324 - val_accuracy: 0.9565\n",
            "Epoch 14/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.7268 - accuracy: 0.9609\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.7259 - accuracy: 0.9609 - val_loss: 0.6966 - val_accuracy: 0.9693\n",
            "Epoch 15/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6880 - accuracy: 0.9737\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.6880 - accuracy: 0.9737 - val_loss: 0.6652 - val_accuracy: 0.9693\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6583 - accuracy: 0.9734\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.6580 - accuracy: 0.9737 - val_loss: 0.6390 - val_accuracy: 0.9693\n",
            "Epoch 17/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.6293 - accuracy: 0.9807\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.6286 - accuracy: 0.9808 - val_loss: 0.6067 - val_accuracy: 0.9795\n",
            "Epoch 18/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6046 - accuracy: 0.9859\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.6046 - accuracy: 0.9859 - val_loss: 0.5858 - val_accuracy: 0.9821\n",
            "Epoch 19/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.5775 - accuracy: 0.9865\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.5791 - accuracy: 0.9859 - val_loss: 0.5630 - val_accuracy: 0.9847\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5568 - accuracy: 0.9858\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.5560 - accuracy: 0.9859 - val_loss: 0.5400 - val_accuracy: 0.9821\n",
            "Epoch 21/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.5374 - accuracy: 0.9883\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.5374 - accuracy: 0.9885 - val_loss: 0.5220 - val_accuracy: 0.9821\n",
            "Epoch 22/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.5185 - accuracy: 0.9929\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.5181 - accuracy: 0.9929 - val_loss: 0.5072 - val_accuracy: 0.9847\n",
            "Epoch 23/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.4994 - accuracy: 0.9909\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.4987 - accuracy: 0.9910 - val_loss: 0.4911 - val_accuracy: 0.9821\n",
            "Epoch 24/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4834 - accuracy: 0.9942\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.4834 - accuracy: 0.9942 - val_loss: 0.4821 - val_accuracy: 0.9872\n",
            "Epoch 25/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4674 - accuracy: 0.9949\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.4674 - accuracy: 0.9949 - val_loss: 0.4660 - val_accuracy: 0.9898\n",
            "Epoch 26/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.4522 - accuracy: 0.9941\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.4520 - accuracy: 0.9942 - val_loss: 0.4456 - val_accuracy: 0.9898\n",
            "Epoch 27/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.4421 - accuracy: 0.9928\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.4422 - accuracy: 0.9929 - val_loss: 0.4416 - val_accuracy: 0.9898\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4288 - accuracy: 0.9948\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.4291 - accuracy: 0.9949 - val_loss: 0.4258 - val_accuracy: 0.9923\n",
            "Epoch 29/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.4136 - accuracy: 0.9954\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.4138 - accuracy: 0.9955 - val_loss: 0.4116 - val_accuracy: 0.9923\n",
            "Epoch 30/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.4040 - accuracy: 0.9954\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.4041 - accuracy: 0.9949 - val_loss: 0.4045 - val_accuracy: 0.9923\n",
            "Epoch 31/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3957 - accuracy: 0.9974\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.3957 - accuracy: 0.9974 - val_loss: 0.3929 - val_accuracy: 0.9923\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3821 - accuracy: 0.9981\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.3818 - accuracy: 0.9981 - val_loss: 0.3822 - val_accuracy: 0.9923\n",
            "Epoch 33/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3722 - accuracy: 0.9962\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.3722 - accuracy: 0.9962 - val_loss: 0.3767 - val_accuracy: 0.9872\n",
            "Epoch 34/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3594 - accuracy: 0.9968\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.3590 - accuracy: 0.9968 - val_loss: 0.3628 - val_accuracy: 0.9974\n",
            "Epoch 35/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3546 - accuracy: 0.9962\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.3546 - accuracy: 0.9962 - val_loss: 0.3593 - val_accuracy: 0.9898\n",
            "Epoch 36/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3455 - accuracy: 0.9961\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.3453 - accuracy: 0.9962 - val_loss: 0.3458 - val_accuracy: 0.9923\n",
            "Epoch 37/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3362 - accuracy: 0.9981\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.3361 - accuracy: 0.9981 - val_loss: 0.3335 - val_accuracy: 0.9974\n",
            "Epoch 38/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3296 - accuracy: 0.9974\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.3296 - accuracy: 0.9974 - val_loss: 0.3318 - val_accuracy: 0.9923\n",
            "Epoch 39/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3213 - accuracy: 0.9981\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.3213 - accuracy: 0.9981 - val_loss: 0.3277 - val_accuracy: 0.9898\n",
            "Epoch 40/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3154 - accuracy: 0.9968\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.3154 - accuracy: 0.9968 - val_loss: 0.3206 - val_accuracy: 0.9898\n",
            "Epoch 41/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3050 - accuracy: 0.9974\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.3050 - accuracy: 0.9974 - val_loss: 0.3082 - val_accuracy: 0.9949\n",
            "Epoch 42/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3001 - accuracy: 0.9980\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.2999 - accuracy: 0.9981 - val_loss: 0.3022 - val_accuracy: 0.9949\n",
            "Epoch 43/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2924 - accuracy: 0.9987\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.2921 - accuracy: 0.9987 - val_loss: 0.2930 - val_accuracy: 0.9949\n",
            "Epoch 44/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2858 - accuracy: 0.9981\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.2858 - accuracy: 0.9981 - val_loss: 0.2891 - val_accuracy: 0.9923\n",
            "Epoch 45/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2823 - accuracy: 0.9980\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.2817 - accuracy: 0.9981 - val_loss: 0.2853 - val_accuracy: 0.9923\n",
            "Epoch 46/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2746 - accuracy: 0.9987\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.2744 - accuracy: 0.9987 - val_loss: 0.2765 - val_accuracy: 0.9949\n",
            "Epoch 47/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2655 - accuracy: 0.9994\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.2655 - accuracy: 0.9994 - val_loss: 0.2713 - val_accuracy: 0.9949\n",
            "Epoch 48/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2638 - accuracy: 0.9987\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.2635 - accuracy: 0.9987 - val_loss: 0.2633 - val_accuracy: 0.9974\n",
            "Epoch 49/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2568 - accuracy: 0.9987\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.2567 - accuracy: 0.9987 - val_loss: 0.2606 - val_accuracy: 0.9974\n",
            "Epoch 50/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2532 - accuracy: 0.9974\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 0.2531 - accuracy: 0.9974 - val_loss: 0.2564 - val_accuracy: 0.9923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/181/assets\n",
            "\n",
            "\n",
            " 91%|█████████ | 182/200 [7:25:01<56:19, 187.73s/it]  \u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.9075 - accuracy: 0.7539\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 12ms/step - loss: 0.8943 - accuracy: 0.7590 - val_loss: 2.5833 - val_accuracy: 0.3504\n",
            "Epoch 2/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2326 - accuracy: 0.9699\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.2326 - accuracy: 0.9699 - val_loss: 3.3904 - val_accuracy: 0.2967\n",
            "Epoch 3/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2216 - accuracy: 0.9626\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.2212 - accuracy: 0.9628 - val_loss: 0.5723 - val_accuracy: 0.8798\n",
            "Epoch 4/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0896 - accuracy: 0.9987\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0896 - accuracy: 0.9987 - val_loss: 0.3880 - val_accuracy: 0.9105\n",
            "Epoch 5/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1138 - accuracy: 0.9852\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1143 - accuracy: 0.9853 - val_loss: 0.6279 - val_accuracy: 0.8414\n",
            "Epoch 6/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1805 - accuracy: 0.9681\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.1791 - accuracy: 0.9686 - val_loss: 0.1285 - val_accuracy: 0.9821\n",
            "Epoch 7/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.0986 - accuracy: 0.9868\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0997 - accuracy: 0.9859 - val_loss: 0.1841 - val_accuracy: 0.9616\n",
            "Epoch 8/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0684 - accuracy: 0.9974\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0682 - accuracy: 0.9974 - val_loss: 0.0737 - val_accuracy: 0.9974\n",
            "Epoch 9/50\n",
            "189/195 [============================>.] - ETA: 0s - loss: 0.0770 - accuracy: 0.9907\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0780 - accuracy: 0.9904 - val_loss: 1.1217 - val_accuracy: 0.6113\n",
            "Epoch 10/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1030 - accuracy: 0.9876\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.1021 - accuracy: 0.9878 - val_loss: 0.0787 - val_accuracy: 0.9949\n",
            "Epoch 11/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0554 - accuracy: 0.9987\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0554 - accuracy: 0.9987 - val_loss: 0.0722 - val_accuracy: 0.9949\n",
            "Epoch 12/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.0480 - accuracy: 1.0000\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0485 - accuracy: 1.0000 - val_loss: 0.0647 - val_accuracy: 0.9949\n",
            "Epoch 13/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0437 - accuracy: 1.0000\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0438 - accuracy: 1.0000 - val_loss: 0.0598 - val_accuracy: 0.9949\n",
            "Epoch 14/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0455 - accuracy: 0.9987\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0455 - accuracy: 0.9987 - val_loss: 0.0834 - val_accuracy: 0.9898\n",
            "Epoch 15/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1770 - accuracy: 0.9667\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1770 - accuracy: 0.9667 - val_loss: 0.5917 - val_accuracy: 0.8696\n",
            "Epoch 16/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1065 - accuracy: 0.9839\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.1067 - accuracy: 0.9833 - val_loss: 0.2404 - val_accuracy: 0.9258\n",
            "Epoch 17/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.0585 - accuracy: 0.9954\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0582 - accuracy: 0.9955 - val_loss: 0.0770 - val_accuracy: 0.9949\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0494 - accuracy: 0.9981\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0494 - accuracy: 0.9981 - val_loss: 0.0527 - val_accuracy: 1.0000\n",
            "Epoch 19/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0442 - accuracy: 0.9993\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0442 - accuracy: 0.9994 - val_loss: 0.0680 - val_accuracy: 0.9923\n",
            "Epoch 20/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0399 - accuracy: 0.9993\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0398 - accuracy: 0.9994 - val_loss: 0.0678 - val_accuracy: 0.9923\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0394 - accuracy: 0.9981\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0393 - accuracy: 0.9981 - val_loss: 0.0432 - val_accuracy: 0.9974\n",
            "Epoch 22/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0359 - accuracy: 1.0000\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0359 - accuracy: 1.0000 - val_loss: 0.0515 - val_accuracy: 0.9974\n",
            "Epoch 23/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0802 - accuracy: 0.9884\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.0801 - accuracy: 0.9885 - val_loss: 0.2860 - val_accuracy: 0.9284\n",
            "Epoch 24/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.0966 - accuracy: 0.9809\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0955 - accuracy: 0.9814 - val_loss: 0.1536 - val_accuracy: 0.9719\n",
            "Epoch 25/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0539 - accuracy: 0.9961\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0553 - accuracy: 0.9955 - val_loss: 0.1914 - val_accuracy: 0.9488\n",
            "Epoch 26/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.0584 - accuracy: 0.9947\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.0579 - accuracy: 0.9949 - val_loss: 0.0663 - val_accuracy: 0.9949\n",
            "Epoch 26: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/182/assets\n",
            "\n",
            "\n",
            " 92%|█████████▏| 183/200 [7:25:59<42:10, 148.83s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.0193 - accuracy: 0.7197\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 15ms/step - loss: 1.0170 - accuracy: 0.7205 - val_loss: 1.6436 - val_accuracy: 0.2941\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2733 - accuracy: 0.9637\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.2717 - accuracy: 0.9641 - val_loss: 2.0015 - val_accuracy: 0.4552\n",
            "Epoch 3/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1443 - accuracy: 0.9908\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.1444 - accuracy: 0.9910 - val_loss: 1.1783 - val_accuracy: 0.6419\n",
            "Epoch 4/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.2184 - accuracy: 0.9692\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.2164 - accuracy: 0.9699 - val_loss: 0.1589 - val_accuracy: 0.9898\n",
            "Epoch 5/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1146 - accuracy: 0.9942\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.1144 - accuracy: 0.9942 - val_loss: 0.1324 - val_accuracy: 0.9872\n",
            "Epoch 6/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0990 - accuracy: 0.9949\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.0990 - accuracy: 0.9949 - val_loss: 0.1888 - val_accuracy: 0.9591\n",
            "Epoch 7/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0811 - accuracy: 0.9974\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0811 - accuracy: 0.9974 - val_loss: 0.1317 - val_accuracy: 0.9847\n",
            "Epoch 8/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0732 - accuracy: 0.9974\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0732 - accuracy: 0.9974 - val_loss: 0.1176 - val_accuracy: 0.9872\n",
            "Epoch 9/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1137 - accuracy: 0.9878\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.1137 - accuracy: 0.9878 - val_loss: 0.1901 - val_accuracy: 0.9591\n",
            "Epoch 10/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0677 - accuracy: 0.9994\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0676 - accuracy: 0.9994 - val_loss: 0.0882 - val_accuracy: 0.9949\n",
            "Epoch 11/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0752 - accuracy: 0.9974\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0748 - accuracy: 0.9974 - val_loss: 0.1011 - val_accuracy: 0.9949\n",
            "Epoch 12/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0966 - accuracy: 0.9921\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0964 - accuracy: 0.9923 - val_loss: 0.1727 - val_accuracy: 0.9872\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0640 - accuracy: 0.9961\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.0642 - accuracy: 0.9962 - val_loss: 0.0980 - val_accuracy: 0.9949\n",
            "Epoch 14/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1018 - accuracy: 0.9908\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.1049 - accuracy: 0.9904 - val_loss: 0.1835 - val_accuracy: 0.9693\n",
            "Epoch 15/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2080 - accuracy: 0.9686\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.2080 - accuracy: 0.9686 - val_loss: 1.5441 - val_accuracy: 0.7621\n",
            "Epoch 15: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/183/assets\n",
            "\n",
            "\n",
            " 92%|█████████▏| 184/200 [7:26:41<31:08, 116.77s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6381 - accuracy: 0.6186\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 26ms/step - loss: 1.6381 - accuracy: 0.6186 - val_loss: 1.7893 - val_accuracy: 0.4041\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8673 - accuracy: 0.8905\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.8647 - accuracy: 0.8910 - val_loss: 1.8811 - val_accuracy: 0.4859\n",
            "Epoch 3/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5936 - accuracy: 0.9718\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.5936 - accuracy: 0.9718 - val_loss: 0.9199 - val_accuracy: 0.8210\n",
            "Epoch 4/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4949 - accuracy: 0.9769\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.4949 - accuracy: 0.9769 - val_loss: 0.4926 - val_accuracy: 0.9795\n",
            "Epoch 5/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4162 - accuracy: 0.9865\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.4162 - accuracy: 0.9865 - val_loss: 0.3843 - val_accuracy: 0.9923\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3637 - accuracy: 0.9916\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.3640 - accuracy: 0.9917 - val_loss: 0.3491 - val_accuracy: 0.9923\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3220 - accuracy: 0.9961\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.3219 - accuracy: 0.9962 - val_loss: 0.3114 - val_accuracy: 0.9923\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2928 - accuracy: 0.9961\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.2926 - accuracy: 0.9962 - val_loss: 0.3086 - val_accuracy: 0.9847\n",
            "Epoch 9/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2683 - accuracy: 0.9968\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.2683 - accuracy: 0.9968 - val_loss: 0.2821 - val_accuracy: 0.9898\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2502 - accuracy: 0.9981\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.2500 - accuracy: 0.9981 - val_loss: 0.2619 - val_accuracy: 0.9898\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2334 - accuracy: 0.9974\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.2338 - accuracy: 0.9974 - val_loss: 0.2460 - val_accuracy: 0.9898\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2188 - accuracy: 0.9981\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.2186 - accuracy: 0.9981 - val_loss: 0.2199 - val_accuracy: 0.9898\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2018 - accuracy: 0.9987\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.2017 - accuracy: 0.9987 - val_loss: 0.2376 - val_accuracy: 0.9898\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1954 - accuracy: 0.9994\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.1953 - accuracy: 0.9994 - val_loss: 0.2235 - val_accuracy: 0.9872\n",
            "Epoch 15/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1828 - accuracy: 0.9994\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.1828 - accuracy: 0.9994 - val_loss: 0.1949 - val_accuracy: 0.9898\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1748 - accuracy: 0.9987\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.1748 - accuracy: 0.9987 - val_loss: 0.1925 - val_accuracy: 0.9898\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1707 - accuracy: 0.9994\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1705 - accuracy: 0.9994 - val_loss: 0.1894 - val_accuracy: 0.9898\n",
            "Epoch 18/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1602 - accuracy: 0.9994\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.1602 - accuracy: 0.9994 - val_loss: 0.1836 - val_accuracy: 0.9898\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1527 - accuracy: 0.9994\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1527 - accuracy: 0.9994 - val_loss: 0.1690 - val_accuracy: 0.9898\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1572 - accuracy: 0.9994\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.1571 - accuracy: 0.9994 - val_loss: 0.1699 - val_accuracy: 0.9923\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1470 - accuracy: 0.9994\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1469 - accuracy: 0.9994 - val_loss: 0.1721 - val_accuracy: 0.9898\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1414 - accuracy: 0.9994\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.1414 - accuracy: 0.9994 - val_loss: 0.1624 - val_accuracy: 0.9949\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1374 - accuracy: 1.0000\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1373 - accuracy: 1.0000 - val_loss: 0.1656 - val_accuracy: 0.9898\n",
            "Epoch 24/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1360 - accuracy: 0.9994\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.1360 - accuracy: 0.9994 - val_loss: 0.1551 - val_accuracy: 0.9923\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1339 - accuracy: 1.0000\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.1339 - accuracy: 1.0000 - val_loss: 0.1606 - val_accuracy: 0.9898\n",
            "Epoch 26/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1288 - accuracy: 0.9994\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.1288 - accuracy: 0.9994 - val_loss: 0.1513 - val_accuracy: 0.9923\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1254 - accuracy: 1.0000\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.1254 - accuracy: 1.0000 - val_loss: 0.1528 - val_accuracy: 0.9898\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1223 - accuracy: 1.0000\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.1223 - accuracy: 1.0000 - val_loss: 0.1441 - val_accuracy: 0.9923\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1262 - accuracy: 0.9994\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.1271 - accuracy: 0.9987 - val_loss: 0.2052 - val_accuracy: 0.9719\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1434 - accuracy: 0.9942\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1432 - accuracy: 0.9942 - val_loss: 0.1484 - val_accuracy: 0.9923\n",
            "Epoch 31/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1213 - accuracy: 1.0000\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.1212 - accuracy: 1.0000 - val_loss: 0.1491 - val_accuracy: 0.9949\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1163 - accuracy: 1.0000\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1163 - accuracy: 1.0000 - val_loss: 0.1384 - val_accuracy: 0.9949\n",
            "Epoch 33/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1125 - accuracy: 1.0000\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.1125 - accuracy: 1.0000 - val_loss: 0.1362 - val_accuracy: 0.9923\n",
            "Epoch 34/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1109 - accuracy: 1.0000\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1109 - accuracy: 1.0000 - val_loss: 0.1391 - val_accuracy: 0.9923\n",
            "Epoch 35/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1085 - accuracy: 1.0000\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.1085 - accuracy: 1.0000 - val_loss: 0.1451 - val_accuracy: 0.9898\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1074 - accuracy: 1.0000\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1074 - accuracy: 1.0000 - val_loss: 0.1333 - val_accuracy: 0.9923\n",
            "Epoch 37/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1048 - accuracy: 1.0000\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.1048 - accuracy: 1.0000 - val_loss: 0.1280 - val_accuracy: 0.9898\n",
            "Epoch 38/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1027 - accuracy: 1.0000\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.1027 - accuracy: 1.0000 - val_loss: 0.1336 - val_accuracy: 0.9923\n",
            "Epoch 39/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1008 - accuracy: 1.0000\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.1008 - accuracy: 1.0000 - val_loss: 0.1255 - val_accuracy: 0.9949\n",
            "Epoch 40/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0989 - accuracy: 1.0000\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.0988 - accuracy: 1.0000 - val_loss: 0.1256 - val_accuracy: 0.9898\n",
            "Epoch 41/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0957 - accuracy: 1.0000\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0956 - accuracy: 1.0000 - val_loss: 0.1310 - val_accuracy: 0.9923\n",
            "Epoch 42/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0932 - accuracy: 1.0000\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.0932 - accuracy: 1.0000 - val_loss: 0.1197 - val_accuracy: 0.9949\n",
            "Epoch 43/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0909 - accuracy: 1.0000\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0909 - accuracy: 1.0000 - val_loss: 0.1192 - val_accuracy: 0.9949\n",
            "Epoch 44/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0996 - accuracy: 0.9974\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.0997 - accuracy: 0.9974 - val_loss: 0.1839 - val_accuracy: 0.9872\n",
            "Epoch 45/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0988 - accuracy: 1.0000\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0988 - accuracy: 1.0000 - val_loss: 0.1203 - val_accuracy: 0.9923\n",
            "Epoch 46/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0888 - accuracy: 1.0000\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.0888 - accuracy: 1.0000 - val_loss: 0.1218 - val_accuracy: 0.9923\n",
            "Epoch 47/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0866 - accuracy: 1.0000\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.0866 - accuracy: 1.0000 - val_loss: 0.1128 - val_accuracy: 0.9949\n",
            "Epoch 48/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0825 - accuracy: 1.0000\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.0825 - accuracy: 1.0000 - val_loss: 0.1124 - val_accuracy: 0.9949\n",
            "Epoch 49/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0806 - accuracy: 1.0000\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.0806 - accuracy: 1.0000 - val_loss: 0.1072 - val_accuracy: 0.9949\n",
            "Epoch 50/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0782 - accuracy: 1.0000\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 23ms/step - loss: 0.0782 - accuracy: 1.0000 - val_loss: 0.1113 - val_accuracy: 0.9923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/184/assets\n",
            "\n",
            "\n",
            " 92%|█████████▎| 185/200 [7:30:34<37:54, 151.66s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 2.4811 - accuracy: 0.3387\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 20ms/step - loss: 2.4700 - accuracy: 0.3410 - val_loss: 1.8656 - val_accuracy: 0.1535\n",
            "Epoch 2/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6213 - accuracy: 0.4130\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 1.6225 - accuracy: 0.4135 - val_loss: 1.6178 - val_accuracy: 0.3836\n",
            "Epoch 3/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.5964 - accuracy: 0.4238\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 1.5902 - accuracy: 0.4263 - val_loss: 1.6349 - val_accuracy: 0.4425\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6365 - accuracy: 0.4417\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 1.6352 - accuracy: 0.4404 - val_loss: 3.0912 - val_accuracy: 0.3862\n",
            "Epoch 5/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.4979 - accuracy: 0.4954\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 1.4993 - accuracy: 0.4936 - val_loss: 1.6443 - val_accuracy: 0.3887\n",
            "Epoch 6/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.2468 - accuracy: 0.5896\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 17ms/step - loss: 1.2471 - accuracy: 0.5885 - val_loss: 1.0995 - val_accuracy: 0.6240\n",
            "Epoch 7/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6087 - accuracy: 0.5006\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 1.6086 - accuracy: 0.4994 - val_loss: 1.5707 - val_accuracy: 0.4476\n",
            "Epoch 8/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.2495 - accuracy: 0.6083\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 1.2495 - accuracy: 0.6083 - val_loss: 1.1668 - val_accuracy: 0.5908\n",
            "Epoch 9/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.1389 - accuracy: 0.6436\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 1.1389 - accuracy: 0.6436 - val_loss: 1.0566 - val_accuracy: 0.6189\n",
            "Epoch 10/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.0044 - accuracy: 0.6917\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 18ms/step - loss: 1.0044 - accuracy: 0.6917 - val_loss: 1.0593 - val_accuracy: 0.6829\n",
            "Epoch 11/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.9358 - accuracy: 0.7352\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.9354 - accuracy: 0.7359 - val_loss: 1.1746 - val_accuracy: 0.6266\n",
            "Epoch 12/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.9072 - accuracy: 0.7423\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.9064 - accuracy: 0.7423 - val_loss: 1.1920 - val_accuracy: 0.6598\n",
            "Epoch 13/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.8587 - accuracy: 0.7526\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.8664 - accuracy: 0.7494 - val_loss: 1.5849 - val_accuracy: 0.4297\n",
            "Epoch 14/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.1752 - accuracy: 0.6510\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 1.1704 - accuracy: 0.6526 - val_loss: 1.1995 - val_accuracy: 0.6087\n",
            "Epoch 14: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/185/assets\n",
            "\n",
            "\n",
            " 93%|█████████▎| 186/200 [7:31:28<28:34, 122.45s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 2.6829 - accuracy: 0.1833\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 16ms/step - loss: 2.6790 - accuracy: 0.1840 - val_loss: 1.8329 - val_accuracy: 0.2634\n",
            "Epoch 2/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 2.1539 - accuracy: 0.3170\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 2.1552 - accuracy: 0.3160 - val_loss: 1.8408 - val_accuracy: 0.2609\n",
            "Epoch 3/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.9447 - accuracy: 0.4027\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 1.9438 - accuracy: 0.4032 - val_loss: 1.7657 - val_accuracy: 0.3990\n",
            "Epoch 4/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.7916 - accuracy: 0.4948\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 1.7876 - accuracy: 0.4962 - val_loss: 1.6749 - val_accuracy: 0.5141\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6679 - accuracy: 0.5764\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6687 - accuracy: 0.5750 - val_loss: 1.6011 - val_accuracy: 0.5703\n",
            "Epoch 6/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.5448 - accuracy: 0.6314\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 1.5449 - accuracy: 0.6314 - val_loss: 1.4967 - val_accuracy: 0.6189\n",
            "Epoch 7/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.4378 - accuracy: 0.6840\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 1.4378 - accuracy: 0.6840 - val_loss: 1.3965 - val_accuracy: 0.6957\n",
            "Epoch 8/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.3356 - accuracy: 0.7214\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.3353 - accuracy: 0.7212 - val_loss: 1.2985 - val_accuracy: 0.7366\n",
            "Epoch 9/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.2493 - accuracy: 0.7702\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 1.2466 - accuracy: 0.7718 - val_loss: 1.2113 - val_accuracy: 0.7877\n",
            "Epoch 10/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.1544 - accuracy: 0.7988\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 1.1550 - accuracy: 0.7974 - val_loss: 1.1326 - val_accuracy: 0.8056\n",
            "Epoch 11/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.0772 - accuracy: 0.8397\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 1.0772 - accuracy: 0.8397 - val_loss: 1.0611 - val_accuracy: 0.8312\n",
            "Epoch 12/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.0110 - accuracy: 0.8583\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.0110 - accuracy: 0.8583 - val_loss: 1.0062 - val_accuracy: 0.8465\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.9530 - accuracy: 0.8731\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.9528 - accuracy: 0.8731 - val_loss: 0.9538 - val_accuracy: 0.8593\n",
            "Epoch 14/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.8998 - accuracy: 0.8930\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.8997 - accuracy: 0.8936 - val_loss: 0.9049 - val_accuracy: 0.8747\n",
            "Epoch 15/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.8587 - accuracy: 0.8971\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.8590 - accuracy: 0.8968 - val_loss: 0.8660 - val_accuracy: 0.8951\n",
            "Epoch 16/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.8177 - accuracy: 0.9201\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.8170 - accuracy: 0.9205 - val_loss: 0.8312 - val_accuracy: 0.8951\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7824 - accuracy: 0.9313\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.7828 - accuracy: 0.9308 - val_loss: 0.7945 - val_accuracy: 0.9105\n",
            "Epoch 18/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.7472 - accuracy: 0.9349\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.7466 - accuracy: 0.9353 - val_loss: 0.7665 - val_accuracy: 0.9156\n",
            "Epoch 19/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.7174 - accuracy: 0.9460\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.7170 - accuracy: 0.9455 - val_loss: 0.7426 - val_accuracy: 0.9182\n",
            "Epoch 20/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.6949 - accuracy: 0.9510\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.6943 - accuracy: 0.9513 - val_loss: 0.7114 - val_accuracy: 0.9514\n",
            "Epoch 21/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.6637 - accuracy: 0.9575\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.6633 - accuracy: 0.9577 - val_loss: 0.6885 - val_accuracy: 0.9412\n",
            "Epoch 22/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.6424 - accuracy: 0.9590\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.6407 - accuracy: 0.9596 - val_loss: 0.6696 - val_accuracy: 0.9463\n",
            "Epoch 23/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.6191 - accuracy: 0.9620\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.6189 - accuracy: 0.9622 - val_loss: 0.6532 - val_accuracy: 0.9386\n",
            "Epoch 24/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.6011 - accuracy: 0.9661\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.6009 - accuracy: 0.9654 - val_loss: 0.6311 - val_accuracy: 0.9514\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5838 - accuracy: 0.9734\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.5848 - accuracy: 0.9724 - val_loss: 0.6083 - val_accuracy: 0.9668\n",
            "Epoch 26/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.5637 - accuracy: 0.9781\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.5635 - accuracy: 0.9782 - val_loss: 0.5940 - val_accuracy: 0.9591\n",
            "Epoch 27/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.5470 - accuracy: 0.9820\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.5466 - accuracy: 0.9821 - val_loss: 0.5805 - val_accuracy: 0.9693\n",
            "Epoch 28/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.5296 - accuracy: 0.9811\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.5289 - accuracy: 0.9808 - val_loss: 0.5634 - val_accuracy: 0.9693\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5172 - accuracy: 0.9838\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.5161 - accuracy: 0.9840 - val_loss: 0.5495 - val_accuracy: 0.9719\n",
            "Epoch 30/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.5028 - accuracy: 0.9839\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.5023 - accuracy: 0.9840 - val_loss: 0.5341 - val_accuracy: 0.9693\n",
            "Epoch 31/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.4920 - accuracy: 0.9824\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.4919 - accuracy: 0.9827 - val_loss: 0.5295 - val_accuracy: 0.9744\n",
            "Epoch 32/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4785 - accuracy: 0.9845\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.4786 - accuracy: 0.9846 - val_loss: 0.5112 - val_accuracy: 0.9770\n",
            "Epoch 33/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.4601 - accuracy: 0.9882\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.4601 - accuracy: 0.9885 - val_loss: 0.4945 - val_accuracy: 0.9821\n",
            "Epoch 34/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.4513 - accuracy: 0.9922\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.4508 - accuracy: 0.9923 - val_loss: 0.4918 - val_accuracy: 0.9795\n",
            "Epoch 35/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4411 - accuracy: 0.9916\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.4409 - accuracy: 0.9917 - val_loss: 0.4731 - val_accuracy: 0.9795\n",
            "Epoch 36/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.4303 - accuracy: 0.9928\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.4307 - accuracy: 0.9923 - val_loss: 0.4648 - val_accuracy: 0.9821\n",
            "Epoch 37/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.4201 - accuracy: 0.9935\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.4202 - accuracy: 0.9936 - val_loss: 0.4531 - val_accuracy: 0.9795\n",
            "Epoch 38/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4097 - accuracy: 0.9936\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.4097 - accuracy: 0.9936 - val_loss: 0.4453 - val_accuracy: 0.9821\n",
            "Epoch 39/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4042 - accuracy: 0.9929\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.4042 - accuracy: 0.9929 - val_loss: 0.4373 - val_accuracy: 0.9821\n",
            "Epoch 40/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3933 - accuracy: 0.9929\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.3937 - accuracy: 0.9929 - val_loss: 0.4285 - val_accuracy: 0.9847\n",
            "Epoch 41/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.3859 - accuracy: 0.9941\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.3867 - accuracy: 0.9936 - val_loss: 0.4207 - val_accuracy: 0.9821\n",
            "Epoch 42/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.3748 - accuracy: 0.9967\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.3748 - accuracy: 0.9968 - val_loss: 0.4086 - val_accuracy: 0.9847\n",
            "Epoch 43/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3708 - accuracy: 0.9968\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.3705 - accuracy: 0.9968 - val_loss: 0.4032 - val_accuracy: 0.9821\n",
            "Epoch 44/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3650 - accuracy: 0.9949\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.3650 - accuracy: 0.9949 - val_loss: 0.3991 - val_accuracy: 0.9821\n",
            "Epoch 45/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3573 - accuracy: 0.9942\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.3572 - accuracy: 0.9942 - val_loss: 0.3894 - val_accuracy: 0.9847\n",
            "Epoch 46/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3478 - accuracy: 0.9948\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.3476 - accuracy: 0.9949 - val_loss: 0.3900 - val_accuracy: 0.9847\n",
            "Epoch 47/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3415 - accuracy: 0.9968\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.3415 - accuracy: 0.9968 - val_loss: 0.3719 - val_accuracy: 0.9872\n",
            "Epoch 48/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3333 - accuracy: 0.9955\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.3333 - accuracy: 0.9955 - val_loss: 0.3665 - val_accuracy: 0.9898\n",
            "Epoch 49/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3278 - accuracy: 0.9961\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.3292 - accuracy: 0.9955 - val_loss: 0.3626 - val_accuracy: 0.9872\n",
            "Epoch 50/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3221 - accuracy: 0.9968\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.3221 - accuracy: 0.9968 - val_loss: 0.3582 - val_accuracy: 0.9847\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/186/assets\n",
            "\n",
            "\n",
            " 94%|█████████▎| 187/200 [7:33:44<27:26, 126.64s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.9667 - accuracy: 0.5519\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 24ms/step - loss: 1.9667 - accuracy: 0.5519 - val_loss: 1.8754 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.0043 - accuracy: 0.8905\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 1.0018 - accuracy: 0.8910 - val_loss: 2.5607 - val_accuracy: 0.2890\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7009 - accuracy: 0.9598\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.6992 - accuracy: 0.9603 - val_loss: 1.0738 - val_accuracy: 0.6829\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5531 - accuracy: 0.9793\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.5526 - accuracy: 0.9788 - val_loss: 0.5106 - val_accuracy: 0.9821\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4702 - accuracy: 0.9851\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.4702 - accuracy: 0.9853 - val_loss: 0.4419 - val_accuracy: 0.9847\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4018 - accuracy: 0.9922\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.4018 - accuracy: 0.9923 - val_loss: 0.3629 - val_accuracy: 0.9923\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3533 - accuracy: 0.9935\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.3530 - accuracy: 0.9936 - val_loss: 0.3232 - val_accuracy: 0.9974\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3074 - accuracy: 0.9955\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.3071 - accuracy: 0.9955 - val_loss: 0.2864 - val_accuracy: 0.9949\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2765 - accuracy: 0.9968\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.2759 - accuracy: 0.9968 - val_loss: 0.2812 - val_accuracy: 0.9898\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2507 - accuracy: 0.9981\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.2505 - accuracy: 0.9981 - val_loss: 0.2344 - val_accuracy: 0.9974\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2301 - accuracy: 0.9942\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.2302 - accuracy: 0.9942 - val_loss: 0.2227 - val_accuracy: 0.9949\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2058 - accuracy: 0.9987\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.2056 - accuracy: 0.9987 - val_loss: 0.2040 - val_accuracy: 0.9949\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1908 - accuracy: 0.9994\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1905 - accuracy: 0.9994 - val_loss: 0.2004 - val_accuracy: 0.9898\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1810 - accuracy: 0.9987\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1807 - accuracy: 0.9987 - val_loss: 0.1781 - val_accuracy: 0.9974\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1699 - accuracy: 0.9994\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1698 - accuracy: 0.9994 - val_loss: 0.1757 - val_accuracy: 0.9974\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1581 - accuracy: 1.0000\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1580 - accuracy: 1.0000 - val_loss: 0.1632 - val_accuracy: 0.9949\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1515 - accuracy: 0.9987\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1515 - accuracy: 0.9987 - val_loss: 0.1565 - val_accuracy: 0.9974\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1483 - accuracy: 0.9981\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1484 - accuracy: 0.9981 - val_loss: 0.1572 - val_accuracy: 0.9974\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1403 - accuracy: 0.9994\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1402 - accuracy: 0.9994 - val_loss: 0.1497 - val_accuracy: 0.9949\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1346 - accuracy: 0.9987\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1346 - accuracy: 0.9987 - val_loss: 0.1430 - val_accuracy: 0.9949\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1312 - accuracy: 0.9994\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1312 - accuracy: 0.9994 - val_loss: 0.1554 - val_accuracy: 0.9949\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1266 - accuracy: 0.9987\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1267 - accuracy: 0.9987 - val_loss: 0.1414 - val_accuracy: 0.9949\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1188 - accuracy: 1.0000\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1188 - accuracy: 1.0000 - val_loss: 0.1330 - val_accuracy: 0.9949\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1165 - accuracy: 0.9994\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1165 - accuracy: 0.9994 - val_loss: 0.1314 - val_accuracy: 0.9949\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1116 - accuracy: 0.9994\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1117 - accuracy: 0.9994 - val_loss: 0.1309 - val_accuracy: 0.9974\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1104 - accuracy: 1.0000\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1103 - accuracy: 1.0000 - val_loss: 0.1234 - val_accuracy: 0.9949\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1059 - accuracy: 1.0000\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1059 - accuracy: 1.0000 - val_loss: 0.1424 - val_accuracy: 0.9872\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1056 - accuracy: 1.0000\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1055 - accuracy: 1.0000 - val_loss: 0.1281 - val_accuracy: 0.9923\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1024 - accuracy: 1.0000\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1024 - accuracy: 1.0000 - val_loss: 0.1200 - val_accuracy: 0.9974\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0988 - accuracy: 1.0000\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0987 - accuracy: 1.0000 - val_loss: 0.1181 - val_accuracy: 0.9923\n",
            "Epoch 31/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0964 - accuracy: 1.0000\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0965 - accuracy: 1.0000 - val_loss: 0.1112 - val_accuracy: 0.9974\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0932 - accuracy: 1.0000\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0931 - accuracy: 1.0000 - val_loss: 0.1100 - val_accuracy: 0.9974\n",
            "Epoch 33/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0911 - accuracy: 1.0000\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0910 - accuracy: 1.0000 - val_loss: 0.1045 - val_accuracy: 0.9974\n",
            "Epoch 34/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0905 - accuracy: 1.0000\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0905 - accuracy: 1.0000 - val_loss: 0.1069 - val_accuracy: 0.9923\n",
            "Epoch 35/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0882 - accuracy: 1.0000\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0881 - accuracy: 1.0000 - val_loss: 0.1055 - val_accuracy: 0.9949\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0856 - accuracy: 1.0000\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0856 - accuracy: 1.0000 - val_loss: 0.1012 - val_accuracy: 0.9974\n",
            "Epoch 37/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0850 - accuracy: 1.0000\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0850 - accuracy: 1.0000 - val_loss: 0.1004 - val_accuracy: 0.9974\n",
            "Epoch 38/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0804 - accuracy: 1.0000\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0804 - accuracy: 1.0000 - val_loss: 0.1018 - val_accuracy: 0.9949\n",
            "Epoch 39/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0791 - accuracy: 1.0000\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0791 - accuracy: 1.0000 - val_loss: 0.1004 - val_accuracy: 0.9923\n",
            "Epoch 40/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0766 - accuracy: 1.0000\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0766 - accuracy: 1.0000 - val_loss: 0.0940 - val_accuracy: 0.9974\n",
            "Epoch 41/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0740 - accuracy: 1.0000\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0740 - accuracy: 1.0000 - val_loss: 0.0963 - val_accuracy: 0.9923\n",
            "Epoch 42/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0761 - accuracy: 1.0000\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0761 - accuracy: 1.0000 - val_loss: 0.0966 - val_accuracy: 0.9974\n",
            "Epoch 43/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0729 - accuracy: 1.0000\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0728 - accuracy: 1.0000 - val_loss: 0.0938 - val_accuracy: 0.9974\n",
            "Epoch 44/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0682 - accuracy: 1.0000\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0682 - accuracy: 1.0000 - val_loss: 0.0854 - val_accuracy: 0.9974\n",
            "Epoch 45/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0670 - accuracy: 1.0000\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0669 - accuracy: 1.0000 - val_loss: 0.0906 - val_accuracy: 0.9949\n",
            "Epoch 46/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0634 - accuracy: 1.0000\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0634 - accuracy: 1.0000 - val_loss: 0.0822 - val_accuracy: 0.9974\n",
            "Epoch 47/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0618 - accuracy: 1.0000\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0618 - accuracy: 1.0000 - val_loss: 0.0800 - val_accuracy: 0.9974\n",
            "Epoch 48/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0593 - accuracy: 1.0000\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0593 - accuracy: 1.0000 - val_loss: 0.0776 - val_accuracy: 0.9949\n",
            "Epoch 49/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0570 - accuracy: 1.0000\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0570 - accuracy: 1.0000 - val_loss: 0.0778 - val_accuracy: 0.9974\n",
            "Epoch 50/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0549 - accuracy: 1.0000\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0549 - accuracy: 1.0000 - val_loss: 0.0722 - val_accuracy: 0.9949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/187/assets\n",
            "\n",
            "\n",
            " 94%|█████████▍| 188/200 [7:37:15<30:23, 151.95s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.5199 - accuracy: 0.4659\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 13ms/step - loss: 1.5167 - accuracy: 0.4679 - val_loss: 1.7760 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.9220 - accuracy: 0.7336\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.9168 - accuracy: 0.7359 - val_loss: 2.7923 - val_accuracy: 0.2685\n",
            "Epoch 3/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.6698 - accuracy: 0.8397\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.6653 - accuracy: 0.8410 - val_loss: 0.5141 - val_accuracy: 0.8926\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5038 - accuracy: 0.8711\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.5026 - accuracy: 0.8712 - val_loss: 0.4138 - val_accuracy: 0.9386\n",
            "Epoch 5/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4533 - accuracy: 0.8904\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.4533 - accuracy: 0.8904 - val_loss: 0.4724 - val_accuracy: 0.8977\n",
            "Epoch 6/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.4126 - accuracy: 0.9010\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.4120 - accuracy: 0.9013 - val_loss: 0.9983 - val_accuracy: 0.7315\n",
            "Epoch 7/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4093 - accuracy: 0.9045\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.4093 - accuracy: 0.9045 - val_loss: 1.2899 - val_accuracy: 0.7621\n",
            "Epoch 8/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.3709 - accuracy: 0.9197\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.3703 - accuracy: 0.9205 - val_loss: 0.4314 - val_accuracy: 0.8926\n",
            "Epoch 9/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3267 - accuracy: 0.9271\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.3248 - accuracy: 0.9276 - val_loss: 0.4203 - val_accuracy: 0.9054\n",
            "Epoch 9: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/188/assets\n",
            "\n",
            "\n",
            " 94%|█████████▍| 189/200 [7:37:39<20:47, 113.42s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.7124 - accuracy: 0.4271\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 16ms/step - loss: 1.7061 - accuracy: 0.4308 - val_loss: 1.8452 - val_accuracy: 0.2813\n",
            "Epoch 2/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.1525 - accuracy: 0.6862\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.1476 - accuracy: 0.6885 - val_loss: 1.7105 - val_accuracy: 0.3146\n",
            "Epoch 3/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.9185 - accuracy: 0.7461\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.9160 - accuracy: 0.7474 - val_loss: 0.7570 - val_accuracy: 0.8210\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7971 - accuracy: 0.8258\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.7958 - accuracy: 0.8263 - val_loss: 9.7261 - val_accuracy: 0.4655\n",
            "Epoch 5/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.5846 - accuracy: 0.8620\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.5946 - accuracy: 0.8615 - val_loss: 1.0062 - val_accuracy: 0.7775\n",
            "Epoch 6/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6494 - accuracy: 0.8526\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.6494 - accuracy: 0.8526 - val_loss: 0.5770 - val_accuracy: 0.8721\n",
            "Epoch 7/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4430 - accuracy: 0.9156\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.4418 - accuracy: 0.9160 - val_loss: 0.8767 - val_accuracy: 0.7903\n",
            "Epoch 8/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.4331 - accuracy: 0.9082\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.4322 - accuracy: 0.9077 - val_loss: 0.8018 - val_accuracy: 0.7596\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5348 - accuracy: 0.8951\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.5349 - accuracy: 0.8955 - val_loss: 38.4252 - val_accuracy: 0.2609\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6815 - accuracy: 0.8517\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.6791 - accuracy: 0.8526 - val_loss: 1.2819 - val_accuracy: 0.7366\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5935 - accuracy: 0.8685\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.5968 - accuracy: 0.8667 - val_loss: 1.3793 - val_accuracy: 0.4936\n",
            "Epoch 11: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/189/assets\n",
            "\n",
            "\n",
            " 95%|█████████▌| 190/200 [7:38:15<15:00, 90.10s/it] \u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.8134 - accuracy: 0.7833\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 21ms/step - loss: 0.8134 - accuracy: 0.7833 - val_loss: 2.0342 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2604 - accuracy: 0.9605\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.2601 - accuracy: 0.9603 - val_loss: 2.0169 - val_accuracy: 0.5064\n",
            "Epoch 3/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1425 - accuracy: 0.9890\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1424 - accuracy: 0.9891 - val_loss: 0.9728 - val_accuracy: 0.6189\n",
            "Epoch 4/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1242 - accuracy: 0.9878\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1242 - accuracy: 0.9878 - val_loss: 0.2521 - val_accuracy: 0.9361\n",
            "Epoch 5/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0831 - accuracy: 0.9974\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0831 - accuracy: 0.9974 - val_loss: 0.3018 - val_accuracy: 0.9258\n",
            "Epoch 6/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1361 - accuracy: 0.9788\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1361 - accuracy: 0.9788 - val_loss: 1.5743 - val_accuracy: 0.7647\n",
            "Epoch 7/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1406 - accuracy: 0.9826\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1403 - accuracy: 0.9827 - val_loss: 0.1788 - val_accuracy: 0.9795\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0884 - accuracy: 0.9909\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0883 - accuracy: 0.9910 - val_loss: 0.8465 - val_accuracy: 0.7366\n",
            "Epoch 9/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1747 - accuracy: 0.9699\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1747 - accuracy: 0.9699 - val_loss: 0.2236 - val_accuracy: 0.9565\n",
            "Epoch 10/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1001 - accuracy: 0.9942\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0999 - accuracy: 0.9942 - val_loss: 0.1692 - val_accuracy: 0.9693\n",
            "Epoch 11/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0670 - accuracy: 0.9981\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0670 - accuracy: 0.9981 - val_loss: 0.0931 - val_accuracy: 0.9949\n",
            "Epoch 12/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0554 - accuracy: 1.0000\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0554 - accuracy: 1.0000 - val_loss: 0.1000 - val_accuracy: 0.9898\n",
            "Epoch 13/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0638 - accuracy: 0.9968\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0638 - accuracy: 0.9968 - val_loss: 0.1736 - val_accuracy: 0.9770\n",
            "Epoch 14/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1008 - accuracy: 0.9890\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.1007 - accuracy: 0.9891 - val_loss: 0.1927 - val_accuracy: 0.9668\n",
            "Epoch 15/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0614 - accuracy: 0.9981\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0614 - accuracy: 0.9981 - val_loss: 0.1415 - val_accuracy: 0.9719\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0596 - accuracy: 0.9981\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 19ms/step - loss: 0.0596 - accuracy: 0.9981 - val_loss: 0.3967 - val_accuracy: 0.8926\n",
            "Epoch 16: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/190/assets\n",
            "\n",
            "\n",
            " 96%|█████████▌| 191/200 [7:39:20<12:22, 82.54s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 2.0658 - accuracy: 0.3402\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 23ms/step - loss: 2.0640 - accuracy: 0.3397 - val_loss: 1.7863 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.7482 - accuracy: 0.4890\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 1.7471 - accuracy: 0.4897 - val_loss: 1.7357 - val_accuracy: 0.2864\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.5506 - accuracy: 0.6030\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 1.5501 - accuracy: 0.6038 - val_loss: 1.6173 - val_accuracy: 0.3095\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.3891 - accuracy: 0.6652\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 1.3909 - accuracy: 0.6635 - val_loss: 1.3068 - val_accuracy: 0.6368\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.2396 - accuracy: 0.7267\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 1.2383 - accuracy: 0.7256 - val_loss: 1.1437 - val_accuracy: 0.7749\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.1226 - accuracy: 0.7630\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 1.1226 - accuracy: 0.7635 - val_loss: 1.0353 - val_accuracy: 0.8107\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.0083 - accuracy: 0.8051\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 1.0099 - accuracy: 0.8038 - val_loss: 0.9416 - val_accuracy: 0.8389\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.9213 - accuracy: 0.8361\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.9194 - accuracy: 0.8372 - val_loss: 0.8546 - val_accuracy: 0.8619\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8450 - accuracy: 0.8543\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.8456 - accuracy: 0.8545 - val_loss: 0.7921 - val_accuracy: 0.8951\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7679 - accuracy: 0.8983\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.7673 - accuracy: 0.8987 - val_loss: 0.7382 - val_accuracy: 0.9028\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7225 - accuracy: 0.9093\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.7207 - accuracy: 0.9103 - val_loss: 0.6924 - val_accuracy: 0.9156\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6720 - accuracy: 0.9203\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.6723 - accuracy: 0.9199 - val_loss: 0.6448 - val_accuracy: 0.9335\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6272 - accuracy: 0.9424\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.6264 - accuracy: 0.9429 - val_loss: 0.6051 - val_accuracy: 0.9437\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5935 - accuracy: 0.9424\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.5924 - accuracy: 0.9423 - val_loss: 0.5653 - val_accuracy: 0.9642\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5491 - accuracy: 0.9605\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.5504 - accuracy: 0.9603 - val_loss: 0.5345 - val_accuracy: 0.9770\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5200 - accuracy: 0.9696\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.5209 - accuracy: 0.9686 - val_loss: 0.5154 - val_accuracy: 0.9642\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5025 - accuracy: 0.9663\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.5027 - accuracy: 0.9660 - val_loss: 0.4928 - val_accuracy: 0.9744\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4784 - accuracy: 0.9696\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.4784 - accuracy: 0.9692 - val_loss: 0.4745 - val_accuracy: 0.9693\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4540 - accuracy: 0.9741\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.4538 - accuracy: 0.9744 - val_loss: 0.4431 - val_accuracy: 0.9847\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4304 - accuracy: 0.9812\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.4305 - accuracy: 0.9814 - val_loss: 0.4296 - val_accuracy: 0.9847\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4113 - accuracy: 0.9851\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.4113 - accuracy: 0.9846 - val_loss: 0.4098 - val_accuracy: 0.9872\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4005 - accuracy: 0.9858\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.4006 - accuracy: 0.9859 - val_loss: 0.3993 - val_accuracy: 0.9872\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3851 - accuracy: 0.9858\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.3847 - accuracy: 0.9859 - val_loss: 0.3818 - val_accuracy: 0.9898\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3765 - accuracy: 0.9845\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.3762 - accuracy: 0.9846 - val_loss: 0.3665 - val_accuracy: 0.9898\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3560 - accuracy: 0.9903\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.3554 - accuracy: 0.9904 - val_loss: 0.3607 - val_accuracy: 0.9898\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3415 - accuracy: 0.9909\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.3412 - accuracy: 0.9910 - val_loss: 0.3441 - val_accuracy: 0.9898\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3347 - accuracy: 0.9916\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.3339 - accuracy: 0.9917 - val_loss: 0.3345 - val_accuracy: 0.9898\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3200 - accuracy: 0.9935\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.3200 - accuracy: 0.9929 - val_loss: 0.3240 - val_accuracy: 0.9898\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3089 - accuracy: 0.9935\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.3091 - accuracy: 0.9936 - val_loss: 0.3157 - val_accuracy: 0.9898\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3045 - accuracy: 0.9942\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.3045 - accuracy: 0.9942 - val_loss: 0.3106 - val_accuracy: 0.9898\n",
            "Epoch 31/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2902 - accuracy: 0.9948\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.2907 - accuracy: 0.9949 - val_loss: 0.3002 - val_accuracy: 0.9898\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2852 - accuracy: 0.9974\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2848 - accuracy: 0.9974 - val_loss: 0.2911 - val_accuracy: 0.9898\n",
            "Epoch 33/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2779 - accuracy: 0.9935\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.2780 - accuracy: 0.9936 - val_loss: 0.2867 - val_accuracy: 0.9898\n",
            "Epoch 34/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2712 - accuracy: 0.9948\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2710 - accuracy: 0.9949 - val_loss: 0.2986 - val_accuracy: 0.9821\n",
            "Epoch 35/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2641 - accuracy: 0.9968\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2635 - accuracy: 0.9968 - val_loss: 0.2803 - val_accuracy: 0.9847\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2542 - accuracy: 0.9987\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2540 - accuracy: 0.9987 - val_loss: 0.2642 - val_accuracy: 0.9898\n",
            "Epoch 37/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2489 - accuracy: 0.9968\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2486 - accuracy: 0.9968 - val_loss: 0.2621 - val_accuracy: 0.9923\n",
            "Epoch 38/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2416 - accuracy: 0.9981\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2416 - accuracy: 0.9981 - val_loss: 0.2537 - val_accuracy: 0.9898\n",
            "Epoch 39/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2369 - accuracy: 0.9981\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2367 - accuracy: 0.9981 - val_loss: 0.2495 - val_accuracy: 0.9949\n",
            "Epoch 40/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2347 - accuracy: 0.9974\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2348 - accuracy: 0.9974 - val_loss: 0.2433 - val_accuracy: 0.9923\n",
            "Epoch 41/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2268 - accuracy: 0.9974\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2264 - accuracy: 0.9974 - val_loss: 0.2471 - val_accuracy: 0.9923\n",
            "Epoch 42/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2220 - accuracy: 0.9981\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2217 - accuracy: 0.9981 - val_loss: 0.2352 - val_accuracy: 0.9949\n",
            "Epoch 43/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2170 - accuracy: 0.9961\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2168 - accuracy: 0.9962 - val_loss: 0.2282 - val_accuracy: 0.9923\n",
            "Epoch 44/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2139 - accuracy: 0.9974\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2136 - accuracy: 0.9974 - val_loss: 0.2307 - val_accuracy: 0.9923\n",
            "Epoch 45/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2136 - accuracy: 0.9968\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2135 - accuracy: 0.9968 - val_loss: 0.2206 - val_accuracy: 0.9949\n",
            "Epoch 46/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2047 - accuracy: 0.9994\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.2047 - accuracy: 0.9994 - val_loss: 0.2199 - val_accuracy: 0.9923\n",
            "Epoch 47/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1997 - accuracy: 0.9981\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1995 - accuracy: 0.9981 - val_loss: 0.2172 - val_accuracy: 0.9949\n",
            "Epoch 48/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1950 - accuracy: 0.9994\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1951 - accuracy: 0.9994 - val_loss: 0.2157 - val_accuracy: 0.9898\n",
            "Epoch 49/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1940 - accuracy: 0.9981\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1940 - accuracy: 0.9981 - val_loss: 0.2066 - val_accuracy: 0.9923\n",
            "Epoch 50/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1911 - accuracy: 0.9981\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 20ms/step - loss: 0.1909 - accuracy: 0.9981 - val_loss: 0.2053 - val_accuracy: 0.9949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/191/assets\n",
            "\n",
            "\n",
            " 96%|█████████▌| 192/200 [7:42:47<15:59, 119.94s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6868 - accuracy: 0.5103\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 15ms/step - loss: 1.6868 - accuracy: 0.5103 - val_loss: 1.7740 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.9536 - accuracy: 0.8244\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.9536 - accuracy: 0.8244 - val_loss: 2.2663 - val_accuracy: 0.2864\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6420 - accuracy: 0.9210\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.6420 - accuracy: 0.9212 - val_loss: 1.9403 - val_accuracy: 0.3760\n",
            "Epoch 4/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4996 - accuracy: 0.9626\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.4990 - accuracy: 0.9628 - val_loss: 0.6809 - val_accuracy: 0.8670\n",
            "Epoch 5/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4168 - accuracy: 0.9781\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.4164 - accuracy: 0.9782 - val_loss: 0.3838 - val_accuracy: 0.9923\n",
            "Epoch 6/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3587 - accuracy: 0.9865\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.3587 - accuracy: 0.9865 - val_loss: 0.3781 - val_accuracy: 0.9770\n",
            "Epoch 7/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.3230 - accuracy: 0.9908\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.3219 - accuracy: 0.9910 - val_loss: 0.3383 - val_accuracy: 0.9821\n",
            "Epoch 8/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.2928 - accuracy: 0.9941\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.2919 - accuracy: 0.9942 - val_loss: 0.3240 - val_accuracy: 0.9821\n",
            "Epoch 9/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.2597 - accuracy: 0.9967\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.2588 - accuracy: 0.9968 - val_loss: 0.2756 - val_accuracy: 0.9898\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2431 - accuracy: 0.9961\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.2427 - accuracy: 0.9962 - val_loss: 0.2499 - val_accuracy: 0.9923\n",
            "Epoch 11/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.2275 - accuracy: 0.9967\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.2272 - accuracy: 0.9968 - val_loss: 0.2534 - val_accuracy: 0.9923\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2100 - accuracy: 0.9987\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.2101 - accuracy: 0.9987 - val_loss: 0.2299 - val_accuracy: 0.9898\n",
            "Epoch 13/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1986 - accuracy: 0.9961\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.1985 - accuracy: 0.9962 - val_loss: 0.2098 - val_accuracy: 0.9923\n",
            "Epoch 14/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1837 - accuracy: 0.9987\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1836 - accuracy: 0.9987 - val_loss: 0.2046 - val_accuracy: 0.9898\n",
            "Epoch 15/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1745 - accuracy: 0.9994\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1745 - accuracy: 0.9994 - val_loss: 0.1856 - val_accuracy: 0.9949\n",
            "Epoch 16/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1709 - accuracy: 0.9961\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1708 - accuracy: 0.9962 - val_loss: 0.1862 - val_accuracy: 0.9872\n",
            "Epoch 17/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.1545 - accuracy: 0.9993\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1545 - accuracy: 0.9994 - val_loss: 0.1724 - val_accuracy: 0.9898\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1489 - accuracy: 0.9974\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1487 - accuracy: 0.9974 - val_loss: 0.1644 - val_accuracy: 0.9949\n",
            "Epoch 19/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1412 - accuracy: 0.9987\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1411 - accuracy: 0.9987 - val_loss: 0.1581 - val_accuracy: 0.9949\n",
            "Epoch 20/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1386 - accuracy: 0.9974\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1386 - accuracy: 0.9974 - val_loss: 0.1656 - val_accuracy: 0.9949\n",
            "Epoch 21/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1286 - accuracy: 0.9994\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1286 - accuracy: 0.9994 - val_loss: 0.1520 - val_accuracy: 0.9949\n",
            "Epoch 22/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1237 - accuracy: 0.9994\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.1237 - accuracy: 0.9994 - val_loss: 0.1361 - val_accuracy: 0.9949\n",
            "Epoch 23/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1174 - accuracy: 1.0000\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1174 - accuracy: 1.0000 - val_loss: 0.1378 - val_accuracy: 0.9949\n",
            "Epoch 24/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1139 - accuracy: 1.0000\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1138 - accuracy: 1.0000 - val_loss: 0.1333 - val_accuracy: 0.9949\n",
            "Epoch 25/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1131 - accuracy: 0.9994\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1132 - accuracy: 0.9994 - val_loss: 0.1413 - val_accuracy: 0.9923\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1068 - accuracy: 1.0000\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1068 - accuracy: 1.0000 - val_loss: 0.1276 - val_accuracy: 0.9949\n",
            "Epoch 27/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1029 - accuracy: 1.0000\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1027 - accuracy: 1.0000 - val_loss: 0.1239 - val_accuracy: 0.9923\n",
            "Epoch 28/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0991 - accuracy: 1.0000\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.0991 - accuracy: 1.0000 - val_loss: 0.1199 - val_accuracy: 0.9923\n",
            "Epoch 29/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0961 - accuracy: 1.0000\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0961 - accuracy: 1.0000 - val_loss: 0.1118 - val_accuracy: 0.9923\n",
            "Epoch 30/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0936 - accuracy: 1.0000\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0940 - accuracy: 1.0000 - val_loss: 0.1120 - val_accuracy: 0.9949\n",
            "Epoch 31/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0902 - accuracy: 1.0000\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0902 - accuracy: 1.0000 - val_loss: 0.1073 - val_accuracy: 0.9949\n",
            "Epoch 32/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0893 - accuracy: 1.0000\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.0893 - accuracy: 1.0000 - val_loss: 0.1173 - val_accuracy: 0.9923\n",
            "Epoch 33/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0857 - accuracy: 1.0000\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0857 - accuracy: 1.0000 - val_loss: 0.1193 - val_accuracy: 0.9923\n",
            "Epoch 34/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0847 - accuracy: 1.0000\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0847 - accuracy: 1.0000 - val_loss: 0.1013 - val_accuracy: 0.9949\n",
            "Epoch 35/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0814 - accuracy: 1.0000\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0814 - accuracy: 1.0000 - val_loss: 0.1128 - val_accuracy: 0.9898\n",
            "Epoch 36/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0793 - accuracy: 1.0000\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0793 - accuracy: 1.0000 - val_loss: 0.1000 - val_accuracy: 0.9949\n",
            "Epoch 37/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0799 - accuracy: 1.0000\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0799 - accuracy: 1.0000 - val_loss: 0.1046 - val_accuracy: 0.9949\n",
            "Epoch 38/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0772 - accuracy: 1.0000\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0772 - accuracy: 1.0000 - val_loss: 0.1152 - val_accuracy: 0.9898\n",
            "Epoch 39/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0848 - accuracy: 0.9987\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0847 - accuracy: 0.9987 - val_loss: 0.1300 - val_accuracy: 0.9847\n",
            "Epoch 40/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0755 - accuracy: 1.0000\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0755 - accuracy: 1.0000 - val_loss: 0.0940 - val_accuracy: 0.9949\n",
            "Epoch 41/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0725 - accuracy: 1.0000\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0726 - accuracy: 1.0000 - val_loss: 0.0929 - val_accuracy: 0.9949\n",
            "Epoch 42/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0704 - accuracy: 1.0000\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0704 - accuracy: 1.0000 - val_loss: 0.0942 - val_accuracy: 0.9923\n",
            "Epoch 43/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0687 - accuracy: 1.0000\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0688 - accuracy: 1.0000 - val_loss: 0.0898 - val_accuracy: 0.9949\n",
            "Epoch 44/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0677 - accuracy: 1.0000\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0676 - accuracy: 1.0000 - val_loss: 0.0881 - val_accuracy: 0.9949\n",
            "Epoch 45/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0666 - accuracy: 1.0000\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0666 - accuracy: 1.0000 - val_loss: 0.0906 - val_accuracy: 0.9898\n",
            "Epoch 46/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0656 - accuracy: 1.0000\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0656 - accuracy: 1.0000 - val_loss: 0.0894 - val_accuracy: 0.9923\n",
            "Epoch 47/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0681 - accuracy: 0.9987\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0682 - accuracy: 0.9987 - val_loss: 0.2384 - val_accuracy: 0.9437\n",
            "Epoch 48/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1056 - accuracy: 0.9872\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1056 - accuracy: 0.9872 - val_loss: 0.1045 - val_accuracy: 0.9898\n",
            "Epoch 49/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0714 - accuracy: 1.0000\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.0714 - accuracy: 1.0000 - val_loss: 0.0930 - val_accuracy: 0.9898\n",
            "Epoch 49: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/192/assets\n",
            "\n",
            "\n",
            " 96%|█████████▋| 193/200 [7:44:58<14:23, 123.31s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.5545 - accuracy: 0.5619\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 25ms/step - loss: 1.5506 - accuracy: 0.5635 - val_loss: 1.8057 - val_accuracy: 0.3964\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7500 - accuracy: 0.8905\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.7472 - accuracy: 0.8917 - val_loss: 2.2531 - val_accuracy: 0.2890\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4801 - accuracy: 0.9689\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.4793 - accuracy: 0.9692 - val_loss: 1.6327 - val_accuracy: 0.5473\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3767 - accuracy: 0.9870\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.3763 - accuracy: 0.9872 - val_loss: 0.4699 - val_accuracy: 0.9412\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3227 - accuracy: 0.9916\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.3222 - accuracy: 0.9917 - val_loss: 0.3439 - val_accuracy: 0.9821\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2771 - accuracy: 0.9968\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.2771 - accuracy: 0.9968 - val_loss: 0.2830 - val_accuracy: 0.9923\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2480 - accuracy: 0.9974\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.2477 - accuracy: 0.9974 - val_loss: 0.2517 - val_accuracy: 0.9923\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2246 - accuracy: 0.9987\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.2255 - accuracy: 0.9981 - val_loss: 0.2370 - val_accuracy: 0.9974\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2083 - accuracy: 0.9987\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.2083 - accuracy: 0.9987 - val_loss: 0.2353 - val_accuracy: 0.9898\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1915 - accuracy: 0.9987\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1915 - accuracy: 0.9987 - val_loss: 0.2092 - val_accuracy: 0.9974\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1816 - accuracy: 0.9987\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1826 - accuracy: 0.9987 - val_loss: 0.2267 - val_accuracy: 0.9898\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1721 - accuracy: 1.0000\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1721 - accuracy: 1.0000 - val_loss: 0.1984 - val_accuracy: 0.9923\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1614 - accuracy: 1.0000\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1614 - accuracy: 1.0000 - val_loss: 0.1830 - val_accuracy: 0.9949\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1540 - accuracy: 0.9994\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1539 - accuracy: 0.9994 - val_loss: 0.1841 - val_accuracy: 0.9872\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1485 - accuracy: 1.0000\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1484 - accuracy: 1.0000 - val_loss: 0.1764 - val_accuracy: 0.9923\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1401 - accuracy: 1.0000\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1400 - accuracy: 1.0000 - val_loss: 0.1699 - val_accuracy: 0.9898\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1375 - accuracy: 1.0000\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1374 - accuracy: 1.0000 - val_loss: 0.1624 - val_accuracy: 0.9949\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1312 - accuracy: 1.0000\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1311 - accuracy: 1.0000 - val_loss: 0.1609 - val_accuracy: 0.9898\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1438 - accuracy: 0.9968\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1440 - accuracy: 0.9968 - val_loss: 0.2996 - val_accuracy: 0.9616\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1732 - accuracy: 0.9916\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1729 - accuracy: 0.9917 - val_loss: 0.1663 - val_accuracy: 0.9949\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1330 - accuracy: 1.0000\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1329 - accuracy: 1.0000 - val_loss: 0.1570 - val_accuracy: 0.9898\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1253 - accuracy: 1.0000\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1252 - accuracy: 1.0000 - val_loss: 0.1512 - val_accuracy: 0.9923\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1193 - accuracy: 1.0000\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1193 - accuracy: 1.0000 - val_loss: 0.1482 - val_accuracy: 0.9923\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1156 - accuracy: 1.0000\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1157 - accuracy: 1.0000 - val_loss: 0.1481 - val_accuracy: 0.9898\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1139 - accuracy: 1.0000\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1138 - accuracy: 1.0000 - val_loss: 0.1414 - val_accuracy: 0.9923\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1116 - accuracy: 1.0000\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1116 - accuracy: 1.0000 - val_loss: 0.1460 - val_accuracy: 0.9923\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1093 - accuracy: 1.0000\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1092 - accuracy: 1.0000 - val_loss: 0.1385 - val_accuracy: 0.9923\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1066 - accuracy: 1.0000\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1066 - accuracy: 1.0000 - val_loss: 0.1340 - val_accuracy: 0.9923\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1491 - accuracy: 0.9896\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1490 - accuracy: 0.9897 - val_loss: 0.2165 - val_accuracy: 0.9770\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1392 - accuracy: 0.9974\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1390 - accuracy: 0.9974 - val_loss: 0.1418 - val_accuracy: 0.9949\n",
            "Epoch 31/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1135 - accuracy: 0.9994\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1135 - accuracy: 0.9994 - val_loss: 0.1375 - val_accuracy: 0.9923\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1077 - accuracy: 1.0000\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1076 - accuracy: 1.0000 - val_loss: 0.1321 - val_accuracy: 0.9923\n",
            "Epoch 33/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1045 - accuracy: 1.0000\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1045 - accuracy: 1.0000 - val_loss: 0.1305 - val_accuracy: 0.9923\n",
            "Epoch 34/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1023 - accuracy: 1.0000\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1023 - accuracy: 1.0000 - val_loss: 0.1320 - val_accuracy: 0.9898\n",
            "Epoch 35/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1003 - accuracy: 1.0000\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1003 - accuracy: 1.0000 - val_loss: 0.1274 - val_accuracy: 0.9923\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0986 - accuracy: 1.0000\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0986 - accuracy: 1.0000 - val_loss: 0.1288 - val_accuracy: 0.9898\n",
            "Epoch 37/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0970 - accuracy: 1.0000\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0970 - accuracy: 1.0000 - val_loss: 0.1246 - val_accuracy: 0.9923\n",
            "Epoch 38/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0948 - accuracy: 1.0000\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0948 - accuracy: 1.0000 - val_loss: 0.1281 - val_accuracy: 0.9898\n",
            "Epoch 39/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0933 - accuracy: 1.0000\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0933 - accuracy: 1.0000 - val_loss: 0.1236 - val_accuracy: 0.9898\n",
            "Epoch 40/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0918 - accuracy: 1.0000\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0919 - accuracy: 1.0000 - val_loss: 0.1250 - val_accuracy: 0.9949\n",
            "Epoch 41/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0899 - accuracy: 1.0000\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0899 - accuracy: 1.0000 - val_loss: 0.1222 - val_accuracy: 0.9898\n",
            "Epoch 42/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0883 - accuracy: 1.0000\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0882 - accuracy: 1.0000 - val_loss: 0.1193 - val_accuracy: 0.9923\n",
            "Epoch 43/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0867 - accuracy: 1.0000\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0867 - accuracy: 1.0000 - val_loss: 0.1196 - val_accuracy: 0.9898\n",
            "Epoch 44/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0847 - accuracy: 1.0000\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0847 - accuracy: 1.0000 - val_loss: 0.1228 - val_accuracy: 0.9898\n",
            "Epoch 45/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0830 - accuracy: 1.0000\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0830 - accuracy: 1.0000 - val_loss: 0.1143 - val_accuracy: 0.9923\n",
            "Epoch 46/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0813 - accuracy: 1.0000\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0813 - accuracy: 1.0000 - val_loss: 0.1204 - val_accuracy: 0.9847\n",
            "Epoch 47/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0794 - accuracy: 1.0000\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0794 - accuracy: 1.0000 - val_loss: 0.1174 - val_accuracy: 0.9898\n",
            "Epoch 48/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0769 - accuracy: 1.0000\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0769 - accuracy: 1.0000 - val_loss: 0.1154 - val_accuracy: 0.9898\n",
            "Epoch 49/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0907 - accuracy: 0.9955\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0942 - accuracy: 0.9949 - val_loss: 0.9464 - val_accuracy: 0.8491\n",
            "Epoch 50/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1555 - accuracy: 0.9851\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1557 - accuracy: 0.9846 - val_loss: 0.1321 - val_accuracy: 0.9898\n",
            "Epoch 50: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/193/assets\n",
            "\n",
            "\n",
            " 97%|█████████▋| 194/200 [7:48:29<14:57, 149.53s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 1.3614 - accuracy: 0.6000\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 11ms/step - loss: 1.3493 - accuracy: 0.6038 - val_loss: 1.7164 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.8399 - accuracy: 0.7885\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.8399 - accuracy: 0.7885 - val_loss: 1.0151 - val_accuracy: 0.6445\n",
            "Epoch 3/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6517 - accuracy: 0.8583\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.6517 - accuracy: 0.8583 - val_loss: 0.9065 - val_accuracy: 0.7187\n",
            "Epoch 4/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4521 - accuracy: 0.9019\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.4521 - accuracy: 0.9019 - val_loss: 0.6035 - val_accuracy: 0.8414\n",
            "Epoch 5/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3097 - accuracy: 0.9460\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.3086 - accuracy: 0.9468 - val_loss: 0.6384 - val_accuracy: 0.8747\n",
            "Epoch 6/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.3667 - accuracy: 0.9212\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.3662 - accuracy: 0.9218 - val_loss: 0.4796 - val_accuracy: 0.8440\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3059 - accuracy: 0.9365\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.3044 - accuracy: 0.9372 - val_loss: 0.2690 - val_accuracy: 0.9488\n",
            "Epoch 8/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2908 - accuracy: 0.9492\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.2908 - accuracy: 0.9494 - val_loss: 0.5991 - val_accuracy: 0.7980\n",
            "Epoch 9/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.5101 - accuracy: 0.8979\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.5061 - accuracy: 0.9000 - val_loss: 0.8199 - val_accuracy: 0.7519\n",
            "Epoch 10/50\n",
            "190/195 [============================>.] - ETA: 0s - loss: 0.2604 - accuracy: 0.9605\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.2640 - accuracy: 0.9609 - val_loss: 0.6247 - val_accuracy: 0.8645\n",
            "Epoch 11/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2683 - accuracy: 0.9538\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.2671 - accuracy: 0.9538 - val_loss: 2.7038 - val_accuracy: 0.5985\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2998 - accuracy: 0.9475\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 8ms/step - loss: 0.2987 - accuracy: 0.9481 - val_loss: 0.3800 - val_accuracy: 0.9130\n",
            "Epoch 12: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/194/assets\n",
            "\n",
            "\n",
            " 98%|█████████▊| 195/200 [7:48:55<09:23, 112.70s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.2352 - accuracy: 0.6869\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 24ms/step - loss: 1.2316 - accuracy: 0.6878 - val_loss: 1.7831 - val_accuracy: 0.2660\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3922 - accuracy: 0.9313\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.3914 - accuracy: 0.9314 - val_loss: 1.3869 - val_accuracy: 0.6292\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2396 - accuracy: 0.9689\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.2389 - accuracy: 0.9692 - val_loss: 1.2381 - val_accuracy: 0.5627\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1815 - accuracy: 0.9845\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1813 - accuracy: 0.9846 - val_loss: 0.1776 - val_accuracy: 0.9821\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1269 - accuracy: 0.9922\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1265 - accuracy: 0.9923 - val_loss: 0.1385 - val_accuracy: 0.9872\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1062 - accuracy: 0.9961\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1061 - accuracy: 0.9962 - val_loss: 0.1535 - val_accuracy: 0.9770\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1052 - accuracy: 0.9961\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1050 - accuracy: 0.9962 - val_loss: 0.1188 - val_accuracy: 0.9949\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1117 - accuracy: 0.9916\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1119 - accuracy: 0.9917 - val_loss: 0.4715 - val_accuracy: 0.8900\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1631 - accuracy: 0.9767\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1661 - accuracy: 0.9763 - val_loss: 0.2018 - val_accuracy: 0.9616\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1422 - accuracy: 0.9851\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1420 - accuracy: 0.9853 - val_loss: 0.2524 - val_accuracy: 0.9565\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1156 - accuracy: 0.9903\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.1153 - accuracy: 0.9904 - val_loss: 0.1338 - val_accuracy: 0.9923\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0808 - accuracy: 0.9987\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 0.0810 - accuracy: 0.9987 - val_loss: 0.1409 - val_accuracy: 0.9872\n",
            "Epoch 12: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/195/assets\n",
            "\n",
            "\n",
            " 98%|█████████▊| 196/200 [7:49:51<06:22, 95.64s/it] \u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.5424 - accuracy: 0.6827\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 8s 31ms/step - loss: 1.5424 - accuracy: 0.6827 - val_loss: 1.8068 - val_accuracy: 0.2788\n",
            "Epoch 2/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.6183 - accuracy: 0.9704\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 0.6174 - accuracy: 0.9705 - val_loss: 1.6382 - val_accuracy: 0.5959\n",
            "Epoch 3/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4397 - accuracy: 0.9917\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.4397 - accuracy: 0.9917 - val_loss: 0.7898 - val_accuracy: 0.9412\n",
            "Epoch 4/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3534 - accuracy: 0.9974\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 0.3533 - accuracy: 0.9974 - val_loss: 0.3386 - val_accuracy: 0.9949\n",
            "Epoch 5/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3001 - accuracy: 0.9987\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.3001 - accuracy: 0.9987 - val_loss: 0.2850 - val_accuracy: 0.9923\n",
            "Epoch 6/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2705 - accuracy: 0.9955\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.2705 - accuracy: 0.9955 - val_loss: 0.2586 - val_accuracy: 0.9949\n",
            "Epoch 7/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2307 - accuracy: 0.9994\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.2307 - accuracy: 0.9994 - val_loss: 0.2443 - val_accuracy: 0.9923\n",
            "Epoch 8/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2107 - accuracy: 0.9981\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.2107 - accuracy: 0.9981 - val_loss: 0.2219 - val_accuracy: 0.9923\n",
            "Epoch 9/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1913 - accuracy: 0.9994\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 0.1913 - accuracy: 0.9994 - val_loss: 0.1959 - val_accuracy: 0.9949\n",
            "Epoch 10/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1735 - accuracy: 0.9994\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.1735 - accuracy: 0.9994 - val_loss: 0.2040 - val_accuracy: 0.9923\n",
            "Epoch 11/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1724 - accuracy: 0.9955\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.1733 - accuracy: 0.9955 - val_loss: 0.3187 - val_accuracy: 0.9616\n",
            "Epoch 12/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1626 - accuracy: 0.9994\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.1626 - accuracy: 0.9994 - val_loss: 0.1657 - val_accuracy: 0.9949\n",
            "Epoch 13/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1484 - accuracy: 1.0000\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 0.1484 - accuracy: 1.0000 - val_loss: 0.1592 - val_accuracy: 0.9949\n",
            "Epoch 14/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1408 - accuracy: 1.0000\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.1411 - accuracy: 1.0000 - val_loss: 0.1500 - val_accuracy: 0.9949\n",
            "Epoch 15/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1379 - accuracy: 1.0000\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 0.1379 - accuracy: 1.0000 - val_loss: 0.1510 - val_accuracy: 0.9949\n",
            "Epoch 16/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1327 - accuracy: 1.0000\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 0.1327 - accuracy: 1.0000 - val_loss: 0.1385 - val_accuracy: 0.9949\n",
            "Epoch 17/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1287 - accuracy: 1.0000\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.1286 - accuracy: 1.0000 - val_loss: 0.1355 - val_accuracy: 0.9949\n",
            "Epoch 18/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1249 - accuracy: 1.0000\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.1249 - accuracy: 1.0000 - val_loss: 0.1438 - val_accuracy: 0.9923\n",
            "Epoch 19/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1213 - accuracy: 1.0000\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 0.1213 - accuracy: 1.0000 - val_loss: 0.1273 - val_accuracy: 0.9949\n",
            "Epoch 20/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1180 - accuracy: 1.0000\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.1181 - accuracy: 1.0000 - val_loss: 0.1299 - val_accuracy: 0.9949\n",
            "Epoch 21/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1154 - accuracy: 1.0000\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 0.1154 - accuracy: 1.0000 - val_loss: 0.1261 - val_accuracy: 0.9949\n",
            "Epoch 22/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1132 - accuracy: 1.0000\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 0.1133 - accuracy: 1.0000 - val_loss: 0.1248 - val_accuracy: 0.9949\n",
            "Epoch 23/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1121 - accuracy: 1.0000\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.1121 - accuracy: 1.0000 - val_loss: 0.1413 - val_accuracy: 0.9949\n",
            "Epoch 24/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1108 - accuracy: 1.0000\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 0.1108 - accuracy: 1.0000 - val_loss: 0.1238 - val_accuracy: 0.9949\n",
            "Epoch 25/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1062 - accuracy: 1.0000\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.1062 - accuracy: 1.0000 - val_loss: 0.1132 - val_accuracy: 0.9974\n",
            "Epoch 26/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1035 - accuracy: 1.0000\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 0.1035 - accuracy: 1.0000 - val_loss: 0.1132 - val_accuracy: 0.9949\n",
            "Epoch 27/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1114 - accuracy: 0.9974\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 0.1114 - accuracy: 0.9974 - val_loss: 0.1268 - val_accuracy: 0.9949\n",
            "Epoch 28/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1025 - accuracy: 1.0000\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.1025 - accuracy: 1.0000 - val_loss: 0.1135 - val_accuracy: 0.9949\n",
            "Epoch 29/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0986 - accuracy: 1.0000\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 0.0986 - accuracy: 1.0000 - val_loss: 0.1177 - val_accuracy: 0.9949\n",
            "Epoch 30/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0954 - accuracy: 1.0000\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.0954 - accuracy: 1.0000 - val_loss: 0.1051 - val_accuracy: 0.9949\n",
            "Epoch 31/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0927 - accuracy: 1.0000\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.0927 - accuracy: 1.0000 - val_loss: 0.1037 - val_accuracy: 0.9949\n",
            "Epoch 32/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0904 - accuracy: 1.0000\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 0.0904 - accuracy: 1.0000 - val_loss: 0.1029 - val_accuracy: 0.9949\n",
            "Epoch 33/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0883 - accuracy: 1.0000\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 0.0883 - accuracy: 1.0000 - val_loss: 0.1006 - val_accuracy: 0.9949\n",
            "Epoch 34/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0856 - accuracy: 1.0000\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.0856 - accuracy: 1.0000 - val_loss: 0.0952 - val_accuracy: 0.9949\n",
            "Epoch 35/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0829 - accuracy: 1.0000\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 0.0829 - accuracy: 1.0000 - val_loss: 0.0930 - val_accuracy: 0.9949\n",
            "Epoch 36/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0804 - accuracy: 1.0000\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.0804 - accuracy: 1.0000 - val_loss: 0.0929 - val_accuracy: 0.9949\n",
            "Epoch 37/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0814 - accuracy: 0.9994\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.0814 - accuracy: 0.9994 - val_loss: 0.1735 - val_accuracy: 0.9872\n",
            "Epoch 38/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1144 - accuracy: 0.9910\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 28ms/step - loss: 0.1144 - accuracy: 0.9910 - val_loss: 0.1169 - val_accuracy: 0.9923\n",
            "Epoch 39/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0827 - accuracy: 1.0000\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.0827 - accuracy: 1.0000 - val_loss: 0.0941 - val_accuracy: 0.9923\n",
            "Epoch 40/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0771 - accuracy: 1.0000\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.0771 - accuracy: 1.0000 - val_loss: 0.0868 - val_accuracy: 0.9974\n",
            "Epoch 41/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0745 - accuracy: 1.0000\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.0745 - accuracy: 1.0000 - val_loss: 0.0858 - val_accuracy: 0.9949\n",
            "Epoch 42/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0722 - accuracy: 1.0000\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.0722 - accuracy: 1.0000 - val_loss: 0.0812 - val_accuracy: 0.9949\n",
            "Epoch 43/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0700 - accuracy: 1.0000\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.0700 - accuracy: 1.0000 - val_loss: 0.0797 - val_accuracy: 0.9949\n",
            "Epoch 44/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0684 - accuracy: 1.0000\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.0683 - accuracy: 1.0000 - val_loss: 0.0804 - val_accuracy: 0.9949\n",
            "Epoch 45/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0661 - accuracy: 1.0000\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.0661 - accuracy: 1.0000 - val_loss: 0.0760 - val_accuracy: 0.9949\n",
            "Epoch 46/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0640 - accuracy: 1.0000\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.0641 - accuracy: 1.0000 - val_loss: 0.0736 - val_accuracy: 0.9949\n",
            "Epoch 47/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0624 - accuracy: 1.0000\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.0624 - accuracy: 1.0000 - val_loss: 0.0719 - val_accuracy: 0.9974\n",
            "Epoch 48/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0604 - accuracy: 1.0000\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.0604 - accuracy: 1.0000 - val_loss: 0.0703 - val_accuracy: 0.9974\n",
            "Epoch 49/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0587 - accuracy: 1.0000\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.0587 - accuracy: 1.0000 - val_loss: 0.0680 - val_accuracy: 0.9974\n",
            "Epoch 50/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0566 - accuracy: 1.0000\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.0566 - accuracy: 1.0000 - val_loss: 0.0678 - val_accuracy: 0.9949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/196/assets\n",
            "\n",
            "\n",
            " 98%|█████████▊| 197/200 [7:55:19<08:15, 165.13s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 2.1002 - accuracy: 0.2720\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 23ms/step - loss: 2.0984 - accuracy: 0.2712 - val_loss: 1.7567 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.7405 - accuracy: 0.2753\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 1.7414 - accuracy: 0.2769 - val_loss: 1.7204 - val_accuracy: 0.2864\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.7051 - accuracy: 0.2759\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 1.7050 - accuracy: 0.2744 - val_loss: 1.6940 - val_accuracy: 0.2864\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6895 - accuracy: 0.2714\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 1.6888 - accuracy: 0.2699 - val_loss: 1.6814 - val_accuracy: 0.2864\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6701 - accuracy: 0.2966\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6711 - accuracy: 0.2949 - val_loss: 1.6642 - val_accuracy: 0.2634\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6621 - accuracy: 0.2636\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 1.6628 - accuracy: 0.2622 - val_loss: 1.6519 - val_accuracy: 0.2864\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6526 - accuracy: 0.2785\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 1.6531 - accuracy: 0.2788 - val_loss: 1.6477 - val_accuracy: 0.2864\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6443 - accuracy: 0.2785\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 1.6450 - accuracy: 0.2776 - val_loss: 1.6510 - val_accuracy: 0.2864\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6465 - accuracy: 0.2850\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 1.6450 - accuracy: 0.2859 - val_loss: 1.6377 - val_accuracy: 0.2864\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6376 - accuracy: 0.2863\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 1.6376 - accuracy: 0.2859 - val_loss: 1.6337 - val_accuracy: 0.2864\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6346 - accuracy: 0.2740\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 1.6358 - accuracy: 0.2737 - val_loss: 1.6322 - val_accuracy: 0.2864\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6339 - accuracy: 0.2850\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 1.6334 - accuracy: 0.2859 - val_loss: 1.6302 - val_accuracy: 0.2864\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6328 - accuracy: 0.2850\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 1.6315 - accuracy: 0.2859 - val_loss: 1.6291 - val_accuracy: 0.2864\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6303 - accuracy: 0.2791\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 1.6309 - accuracy: 0.2788 - val_loss: 1.6275 - val_accuracy: 0.2864\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6308 - accuracy: 0.2837\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 1.6301 - accuracy: 0.2846 - val_loss: 1.6265 - val_accuracy: 0.2864\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6297 - accuracy: 0.2766\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 1.6290 - accuracy: 0.2769 - val_loss: 1.6259 - val_accuracy: 0.2864\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6268 - accuracy: 0.2850\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 1.6283 - accuracy: 0.2859 - val_loss: 1.6259 - val_accuracy: 0.2864\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6266 - accuracy: 0.2856\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 1.6270 - accuracy: 0.2859 - val_loss: 1.6255 - val_accuracy: 0.2864\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6322 - accuracy: 0.2869\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 1.6327 - accuracy: 0.2853 - val_loss: 1.6278 - val_accuracy: 0.2864\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6291 - accuracy: 0.2882\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 1.6288 - accuracy: 0.2878 - val_loss: 1.6268 - val_accuracy: 0.2634\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6282 - accuracy: 0.2863\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 1.6273 - accuracy: 0.2853 - val_loss: 1.6250 - val_accuracy: 0.2864\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6280 - accuracy: 0.2785\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 1.6272 - accuracy: 0.2788 - val_loss: 1.6243 - val_accuracy: 0.2864\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6256 - accuracy: 0.2778\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 1.6266 - accuracy: 0.2776 - val_loss: 1.6245 - val_accuracy: 0.2864\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6244 - accuracy: 0.2863\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 1.6265 - accuracy: 0.2859 - val_loss: 1.6242 - val_accuracy: 0.2864\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6249 - accuracy: 0.2778\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 1.6272 - accuracy: 0.2776 - val_loss: 1.6243 - val_accuracy: 0.2864\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6277 - accuracy: 0.2766\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 1.6267 - accuracy: 0.2782 - val_loss: 1.6250 - val_accuracy: 0.2864\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6508 - accuracy: 0.2766\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 1.6485 - accuracy: 0.2782 - val_loss: 1.6352 - val_accuracy: 0.2864\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6337 - accuracy: 0.2766\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 1.6339 - accuracy: 0.2763 - val_loss: 1.6293 - val_accuracy: 0.2864\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6285 - accuracy: 0.2863\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 21ms/step - loss: 1.6301 - accuracy: 0.2859 - val_loss: 1.6267 - val_accuracy: 0.2864\n",
            "Epoch 29: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/197/assets\n",
            "\n",
            "\n",
            " 99%|█████████▉| 198/200 [7:57:46<05:19, 159.74s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.1495 - accuracy: 0.6946\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 18ms/step - loss: 1.1451 - accuracy: 0.6962 - val_loss: 1.6532 - val_accuracy: 0.2941\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3147 - accuracy: 0.9501\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.3158 - accuracy: 0.9500 - val_loss: 1.3206 - val_accuracy: 0.6317\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1825 - accuracy: 0.9838\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1844 - accuracy: 0.9833 - val_loss: 0.7841 - val_accuracy: 0.6931\n",
            "Epoch 4/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1584 - accuracy: 0.9845\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1581 - accuracy: 0.9846 - val_loss: 0.3454 - val_accuracy: 0.9361\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1401 - accuracy: 0.9864\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1397 - accuracy: 0.9865 - val_loss: 0.2102 - val_accuracy: 0.9744\n",
            "Epoch 6/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0934 - accuracy: 0.9987\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0932 - accuracy: 0.9987 - val_loss: 0.1562 - val_accuracy: 0.9795\n",
            "Epoch 7/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2560 - accuracy: 0.9506\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.2560 - accuracy: 0.9506 - val_loss: 0.8668 - val_accuracy: 0.8619\n",
            "Epoch 8/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.2181 - accuracy: 0.9668\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.2163 - accuracy: 0.9673 - val_loss: 0.2383 - val_accuracy: 0.9565\n",
            "Epoch 9/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1441 - accuracy: 0.9878\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1441 - accuracy: 0.9878 - val_loss: 0.7200 - val_accuracy: 0.8517\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1097 - accuracy: 0.9961\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1095 - accuracy: 0.9962 - val_loss: 0.2477 - val_accuracy: 0.9463\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0857 - accuracy: 0.9974\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0857 - accuracy: 0.9974 - val_loss: 0.1328 - val_accuracy: 0.9795\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0705 - accuracy: 0.9987\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0704 - accuracy: 0.9987 - val_loss: 0.1076 - val_accuracy: 0.9847\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1220 - accuracy: 0.9851\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1217 - accuracy: 0.9853 - val_loss: 0.5171 - val_accuracy: 0.9258\n",
            "Epoch 14/50\n",
            "192/195 [============================>.] - ETA: 0s - loss: 0.0997 - accuracy: 0.9954\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0992 - accuracy: 0.9955 - val_loss: 0.1550 - val_accuracy: 0.9744\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0723 - accuracy: 0.9981\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0725 - accuracy: 0.9981 - val_loss: 0.0995 - val_accuracy: 0.9949\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0627 - accuracy: 0.9994\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0627 - accuracy: 0.9994 - val_loss: 0.0913 - val_accuracy: 0.9923\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0559 - accuracy: 1.0000\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0559 - accuracy: 1.0000 - val_loss: 0.1054 - val_accuracy: 0.9898\n",
            "Epoch 18/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1299 - accuracy: 0.9840\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1299 - accuracy: 0.9840 - val_loss: 20.3375 - val_accuracy: 0.8107\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1966 - accuracy: 0.9728\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.1957 - accuracy: 0.9731 - val_loss: 0.1539 - val_accuracy: 0.9795\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0944 - accuracy: 0.9955\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0942 - accuracy: 0.9955 - val_loss: 0.1445 - val_accuracy: 0.9847\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0708 - accuracy: 0.9994\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 16ms/step - loss: 0.0707 - accuracy: 0.9994 - val_loss: 0.0935 - val_accuracy: 0.9872\n",
            "Epoch 21: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/198/assets\n",
            "\n",
            "\n",
            "100%|█████████▉| 199/200 [7:58:57<02:13, 133.21s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.9239 - accuracy: 0.7247\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 15ms/step - loss: 0.9202 - accuracy: 0.7269 - val_loss: 1.9745 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.2772 - accuracy: 0.9607\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.2756 - accuracy: 0.9609 - val_loss: 2.4612 - val_accuracy: 0.2890\n",
            "Epoch 3/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.2185 - accuracy: 0.9673\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.2221 - accuracy: 0.9647 - val_loss: 0.5254 - val_accuracy: 0.8670\n",
            "Epoch 4/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.1775 - accuracy: 0.9768\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.1772 - accuracy: 0.9769 - val_loss: 0.1296 - val_accuracy: 0.9949\n",
            "Epoch 5/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1004 - accuracy: 0.9948\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.1014 - accuracy: 0.9942 - val_loss: 0.1802 - val_accuracy: 0.9770\n",
            "Epoch 6/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0922 - accuracy: 0.9962\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0922 - accuracy: 0.9962 - val_loss: 0.1015 - val_accuracy: 0.9974\n",
            "Epoch 7/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1974 - accuracy: 0.9692\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.1963 - accuracy: 0.9692 - val_loss: 0.1911 - val_accuracy: 0.9693\n",
            "Epoch 8/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1111 - accuracy: 0.9891\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.1111 - accuracy: 0.9891 - val_loss: 0.0992 - val_accuracy: 0.9949\n",
            "Epoch 9/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0729 - accuracy: 0.9974\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0726 - accuracy: 0.9974 - val_loss: 0.0952 - val_accuracy: 0.9949\n",
            "Epoch 10/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0735 - accuracy: 0.9948\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0733 - accuracy: 0.9949 - val_loss: 0.1207 - val_accuracy: 0.9898\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0671 - accuracy: 0.9981\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0670 - accuracy: 0.9981 - val_loss: 0.0853 - val_accuracy: 0.9923\n",
            "Epoch 12/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0562 - accuracy: 1.0000\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0562 - accuracy: 1.0000 - val_loss: 0.0765 - val_accuracy: 0.9949\n",
            "Epoch 13/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0499 - accuracy: 1.0000\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0498 - accuracy: 1.0000 - val_loss: 0.0864 - val_accuracy: 0.9847\n",
            "Epoch 14/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0671 - accuracy: 0.9941\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0674 - accuracy: 0.9942 - val_loss: 0.2043 - val_accuracy: 0.9565\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1251 - accuracy: 0.9786\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 13ms/step - loss: 0.1261 - accuracy: 0.9782 - val_loss: 0.2757 - val_accuracy: 0.9284\n",
            "Epoch 16/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.1132 - accuracy: 0.9843\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.1123 - accuracy: 0.9846 - val_loss: 0.1083 - val_accuracy: 0.9872\n",
            "Epoch 17/50\n",
            "191/195 [============================>.] - ETA: 0s - loss: 0.0605 - accuracy: 0.9980\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 2s 12ms/step - loss: 0.0607 - accuracy: 0.9981 - val_loss: 0.0875 - val_accuracy: 0.9949\n",
            "Epoch 17: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: CNN_Hyper/080522224246/199/assets\n",
            "\n",
            "\n",
            "100%|██████████| 200/200 [7:59:43<00:00, 143.92s/it]\n"
          ]
        }
      ],
      "source": [
        "##############################################\n",
        "# Hyperparametrizing\n",
        "##############################################\n",
        "\n",
        "os.chdir('/content/drive/MyDrive')\n",
        "# Talos saves up the last epoch not the best model....\n",
        "\n",
        "# start the experiment\n",
        "scan_object = talos.Scan(x=X_train,\n",
        "                         y=y_train,\n",
        "                         x_val=X_test,\n",
        "                         y_val=y_test,\n",
        "                         model=model_CNN,\n",
        "                         experiment_name='CNN_Hyper',\n",
        "                         params=p,\n",
        "                         round_limit = 200,\n",
        "                         save_models = True,\n",
        "                         save_weights = True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the name of the experiment log\n",
        "!ls -lhtr CNN_Hyper"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Hz24mzWmMx2",
        "outputId": "911700f5-9792-4372-834f-eeffc9347119"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access 'CNN_hyperparam': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from talos.utils.recover_best_model import recover_best_model\n",
        "\n",
        "results, models = recover_best_model(x_train=X_train,\n",
        "                                     y_train=y_train,\n",
        "                                     x_val=X_test,\n",
        "                                     y_val=y_test,\n",
        "                                     experiment_log='/content/drive/MyDrive/CNN_Hyper/080522224246.csv',\n",
        "                                     input_model=model_CNN,\n",
        "                                     n_models=5,\n",
        "                                     task='multi_label',\n",
        "                                     metric = 'val_accuracy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxW9imPtoYVm",
        "outputId": "8b1ea5a1-db63-450c-e0f1-a315d9baac4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.9860 - accuracy: 0.2726\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 24ms/step - loss: 1.9849 - accuracy: 0.2731 - val_loss: 1.7986 - val_accuracy: 0.2634\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.8200 - accuracy: 0.3400\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.8188 - accuracy: 0.3417 - val_loss: 1.7471 - val_accuracy: 0.2660\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6953 - accuracy: 0.4469\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.6932 - accuracy: 0.4500 - val_loss: 1.6304 - val_accuracy: 0.3555\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.5436 - accuracy: 0.5758\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.5445 - accuracy: 0.5744 - val_loss: 1.4390 - val_accuracy: 0.5678\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.3810 - accuracy: 0.6373\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.3804 - accuracy: 0.6372 - val_loss: 1.2380 - val_accuracy: 0.7059\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.2115 - accuracy: 0.7124\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.2099 - accuracy: 0.7141 - val_loss: 1.0750 - val_accuracy: 0.7673\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.0638 - accuracy: 0.7720\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 1.0647 - accuracy: 0.7718 - val_loss: 0.9567 - val_accuracy: 0.8056\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.9629 - accuracy: 0.8083\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.9609 - accuracy: 0.8090 - val_loss: 0.8451 - val_accuracy: 0.8363\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8609 - accuracy: 0.8478\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.8596 - accuracy: 0.8487 - val_loss: 0.7791 - val_accuracy: 0.8772\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7720 - accuracy: 0.8841\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.7711 - accuracy: 0.8846 - val_loss: 0.6760 - val_accuracy: 0.9233\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7191 - accuracy: 0.9087\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.7184 - accuracy: 0.9096 - val_loss: 0.6325 - val_accuracy: 0.9361\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6544 - accuracy: 0.9184\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.6538 - accuracy: 0.9186 - val_loss: 0.5827 - val_accuracy: 0.9463\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6129 - accuracy: 0.9346\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.6130 - accuracy: 0.9340 - val_loss: 0.5388 - val_accuracy: 0.9693\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5762 - accuracy: 0.9391\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.5777 - accuracy: 0.9378 - val_loss: 0.5116 - val_accuracy: 0.9616\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5449 - accuracy: 0.9495\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.5438 - accuracy: 0.9500 - val_loss: 0.4901 - val_accuracy: 0.9693\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5129 - accuracy: 0.9514\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.5131 - accuracy: 0.9506 - val_loss: 0.4614 - val_accuracy: 0.9744\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4856 - accuracy: 0.9605\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.4846 - accuracy: 0.9609 - val_loss: 0.4388 - val_accuracy: 0.9744\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4658 - accuracy: 0.9605\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.4672 - accuracy: 0.9596 - val_loss: 0.4270 - val_accuracy: 0.9872\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4401 - accuracy: 0.9663\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.4393 - accuracy: 0.9667 - val_loss: 0.3981 - val_accuracy: 0.9898\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4242 - accuracy: 0.9741\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.4251 - accuracy: 0.9737 - val_loss: 0.3900 - val_accuracy: 0.9923\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4119 - accuracy: 0.9715\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.4110 - accuracy: 0.9718 - val_loss: 0.3735 - val_accuracy: 0.9923\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3884 - accuracy: 0.9799\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.3886 - accuracy: 0.9795 - val_loss: 0.3635 - val_accuracy: 0.9898\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3846 - accuracy: 0.9760\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.3837 - accuracy: 0.9763 - val_loss: 0.3450 - val_accuracy: 0.9923\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3655 - accuracy: 0.9786\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.3654 - accuracy: 0.9788 - val_loss: 0.3349 - val_accuracy: 0.9923\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3551 - accuracy: 0.9799\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.3559 - accuracy: 0.9795 - val_loss: 0.3237 - val_accuracy: 0.9923\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3377 - accuracy: 0.9870\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.3379 - accuracy: 0.9872 - val_loss: 0.3164 - val_accuracy: 0.9923\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3321 - accuracy: 0.9845\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.3314 - accuracy: 0.9846 - val_loss: 0.3132 - val_accuracy: 0.9923\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3189 - accuracy: 0.9896\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.3199 - accuracy: 0.9891 - val_loss: 0.3000 - val_accuracy: 0.9923\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3065 - accuracy: 0.9909\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.3068 - accuracy: 0.9910 - val_loss: 0.2925 - val_accuracy: 0.9949\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3040 - accuracy: 0.9883\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.3037 - accuracy: 0.9885 - val_loss: 0.2811 - val_accuracy: 0.9949\n",
            "Epoch 31/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2964 - accuracy: 0.9909\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2966 - accuracy: 0.9904 - val_loss: 0.2782 - val_accuracy: 0.9923\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2867 - accuracy: 0.9903\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2861 - accuracy: 0.9904 - val_loss: 0.2706 - val_accuracy: 0.9923\n",
            "Epoch 33/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2834 - accuracy: 0.9903\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2834 - accuracy: 0.9904 - val_loss: 0.2684 - val_accuracy: 0.9923\n",
            "Epoch 34/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2710 - accuracy: 0.9942\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2712 - accuracy: 0.9942 - val_loss: 0.2609 - val_accuracy: 0.9923\n",
            "Epoch 35/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2676 - accuracy: 0.9935\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2673 - accuracy: 0.9936 - val_loss: 0.2551 - val_accuracy: 0.9923\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2586 - accuracy: 0.9955\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2583 - accuracy: 0.9955 - val_loss: 0.2478 - val_accuracy: 0.9923\n",
            "Epoch 37/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2534 - accuracy: 0.9955\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2532 - accuracy: 0.9955 - val_loss: 0.2423 - val_accuracy: 0.9923\n",
            "Epoch 38/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2472 - accuracy: 0.9942\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2472 - accuracy: 0.9942 - val_loss: 0.2399 - val_accuracy: 0.9923\n",
            "Epoch 39/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2367 - accuracy: 0.9968\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2373 - accuracy: 0.9968 - val_loss: 0.2338 - val_accuracy: 0.9949\n",
            "Epoch 40/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2364 - accuracy: 0.9929\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2360 - accuracy: 0.9929 - val_loss: 0.2340 - val_accuracy: 0.9949\n",
            "Epoch 41/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2295 - accuracy: 0.9955\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2291 - accuracy: 0.9955 - val_loss: 0.2255 - val_accuracy: 0.9949\n",
            "Epoch 42/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2249 - accuracy: 0.9955\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 24ms/step - loss: 0.2249 - accuracy: 0.9955 - val_loss: 0.2214 - val_accuracy: 0.9923\n",
            "Epoch 43/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2199 - accuracy: 0.9948\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2195 - accuracy: 0.9949 - val_loss: 0.2165 - val_accuracy: 0.9923\n",
            "Epoch 44/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2166 - accuracy: 0.9961\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2162 - accuracy: 0.9962 - val_loss: 0.2100 - val_accuracy: 0.9923\n",
            "Epoch 45/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2155 - accuracy: 0.9961\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2152 - accuracy: 0.9962 - val_loss: 0.2067 - val_accuracy: 0.9949\n",
            "Epoch 46/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2102 - accuracy: 0.9961\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2101 - accuracy: 0.9962 - val_loss: 0.2048 - val_accuracy: 0.9923\n",
            "Epoch 47/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2022 - accuracy: 0.9968\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2027 - accuracy: 0.9968 - val_loss: 0.1995 - val_accuracy: 0.9923\n",
            "Epoch 48/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1961 - accuracy: 1.0000\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1960 - accuracy: 1.0000 - val_loss: 0.1988 - val_accuracy: 0.9949\n",
            "Epoch 49/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1927 - accuracy: 0.9981\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1929 - accuracy: 0.9981 - val_loss: 0.1951 - val_accuracy: 0.9923\n",
            "Epoch 50/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1921 - accuracy: 0.9987\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1921 - accuracy: 0.9987 - val_loss: 0.1894 - val_accuracy: 0.9923\n",
            "Epoch 1/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 3.3503 - accuracy: 0.3244\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 8s 33ms/step - loss: 3.3503 - accuracy: 0.3244 - val_loss: 1.9557 - val_accuracy: 0.2839\n",
            "Epoch 2/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 2.5377 - accuracy: 0.5494\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 2.5377 - accuracy: 0.5494 - val_loss: 2.1238 - val_accuracy: 0.3095\n",
            "Epoch 3/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 2.1701 - accuracy: 0.6904\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 2.1701 - accuracy: 0.6904 - val_loss: 1.9642 - val_accuracy: 0.5269\n",
            "Epoch 4/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.9264 - accuracy: 0.7654\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 1.9264 - accuracy: 0.7654 - val_loss: 1.6791 - val_accuracy: 0.8107\n",
            "Epoch 5/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.7088 - accuracy: 0.8397\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 1.7088 - accuracy: 0.8397 - val_loss: 1.5493 - val_accuracy: 0.8235\n",
            "Epoch 6/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.5394 - accuracy: 0.8840\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 1.5394 - accuracy: 0.8840 - val_loss: 1.3969 - val_accuracy: 0.9079\n",
            "Epoch 7/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.3974 - accuracy: 0.9212\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 1.3974 - accuracy: 0.9212 - val_loss: 1.2807 - val_accuracy: 0.9488\n",
            "Epoch 8/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.2918 - accuracy: 0.9391\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 1.2918 - accuracy: 0.9391 - val_loss: 1.1987 - val_accuracy: 0.9565\n",
            "Epoch 9/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.2017 - accuracy: 0.9615\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 1.2017 - accuracy: 0.9615 - val_loss: 1.1102 - val_accuracy: 0.9668\n",
            "Epoch 10/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.1211 - accuracy: 0.9699\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 1.1211 - accuracy: 0.9699 - val_loss: 1.0419 - val_accuracy: 0.9770\n",
            "Epoch 11/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.0611 - accuracy: 0.9705\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 1.0611 - accuracy: 0.9705 - val_loss: 0.9888 - val_accuracy: 0.9821\n",
            "Epoch 12/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.0050 - accuracy: 0.9795\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 30ms/step - loss: 1.0050 - accuracy: 0.9795 - val_loss: 0.9457 - val_accuracy: 0.9847\n",
            "Epoch 13/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.9541 - accuracy: 0.9814\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.9541 - accuracy: 0.9814 - val_loss: 0.9045 - val_accuracy: 0.9795\n",
            "Epoch 14/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.9134 - accuracy: 0.9821\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.9134 - accuracy: 0.9821 - val_loss: 0.8594 - val_accuracy: 0.9872\n",
            "Epoch 15/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.8758 - accuracy: 0.9891\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.8758 - accuracy: 0.9891 - val_loss: 0.8315 - val_accuracy: 0.9872\n",
            "Epoch 16/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.8423 - accuracy: 0.9859\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.8423 - accuracy: 0.9859 - val_loss: 0.7971 - val_accuracy: 0.9872\n",
            "Epoch 17/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.8123 - accuracy: 0.9878\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.8123 - accuracy: 0.9878 - val_loss: 0.7631 - val_accuracy: 0.9923\n",
            "Epoch 18/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.7798 - accuracy: 0.9929\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.7798 - accuracy: 0.9929 - val_loss: 0.7397 - val_accuracy: 0.9872\n",
            "Epoch 19/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.7543 - accuracy: 0.9904\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.7543 - accuracy: 0.9904 - val_loss: 0.7204 - val_accuracy: 0.9923\n",
            "Epoch 20/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.7292 - accuracy: 0.9897\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.7292 - accuracy: 0.9897 - val_loss: 0.6952 - val_accuracy: 0.9923\n",
            "Epoch 21/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.7075 - accuracy: 0.9929\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 32ms/step - loss: 0.7075 - accuracy: 0.9929 - val_loss: 0.6732 - val_accuracy: 0.9898\n",
            "Epoch 22/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6815 - accuracy: 0.9955\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.6815 - accuracy: 0.9955 - val_loss: 0.6492 - val_accuracy: 0.9923\n",
            "Epoch 23/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6646 - accuracy: 0.9936\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.6646 - accuracy: 0.9936 - val_loss: 0.6295 - val_accuracy: 0.9898\n",
            "Epoch 24/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6413 - accuracy: 0.9955\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.6413 - accuracy: 0.9955 - val_loss: 0.6154 - val_accuracy: 0.9898\n",
            "Epoch 25/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6238 - accuracy: 0.9962\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.6238 - accuracy: 0.9962 - val_loss: 0.5942 - val_accuracy: 0.9923\n",
            "Epoch 26/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.6064 - accuracy: 0.9955\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.6064 - accuracy: 0.9955 - val_loss: 0.5783 - val_accuracy: 0.9898\n",
            "Epoch 27/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5893 - accuracy: 0.9968\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.5893 - accuracy: 0.9968 - val_loss: 0.5748 - val_accuracy: 0.9898\n",
            "Epoch 28/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5751 - accuracy: 0.9949\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 32ms/step - loss: 0.5751 - accuracy: 0.9949 - val_loss: 0.5444 - val_accuracy: 0.9898\n",
            "Epoch 29/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5608 - accuracy: 0.9962\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.5608 - accuracy: 0.9962 - val_loss: 0.5354 - val_accuracy: 0.9898\n",
            "Epoch 30/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5448 - accuracy: 0.9968\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.5448 - accuracy: 0.9968 - val_loss: 0.5195 - val_accuracy: 0.9923\n",
            "Epoch 31/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5268 - accuracy: 0.9968\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.5268 - accuracy: 0.9968 - val_loss: 0.5127 - val_accuracy: 0.9923\n",
            "Epoch 32/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5155 - accuracy: 0.9968\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.5155 - accuracy: 0.9968 - val_loss: 0.4958 - val_accuracy: 0.9923\n",
            "Epoch 33/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5018 - accuracy: 0.9987\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.5018 - accuracy: 0.9987 - val_loss: 0.4807 - val_accuracy: 0.9923\n",
            "Epoch 34/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4911 - accuracy: 0.9974\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.4911 - accuracy: 0.9974 - val_loss: 0.4727 - val_accuracy: 0.9923\n",
            "Epoch 35/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4765 - accuracy: 0.9981\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.4765 - accuracy: 0.9981 - val_loss: 0.4604 - val_accuracy: 0.9923\n",
            "Epoch 36/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4636 - accuracy: 0.9987\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.4636 - accuracy: 0.9987 - val_loss: 0.4466 - val_accuracy: 0.9949\n",
            "Epoch 37/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4525 - accuracy: 0.9987\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.4525 - accuracy: 0.9987 - val_loss: 0.4373 - val_accuracy: 0.9923\n",
            "Epoch 38/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4412 - accuracy: 0.9974\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.4412 - accuracy: 0.9974 - val_loss: 0.4331 - val_accuracy: 0.9923\n",
            "Epoch 39/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4307 - accuracy: 0.9987\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.4307 - accuracy: 0.9987 - val_loss: 0.4163 - val_accuracy: 0.9923\n",
            "Epoch 40/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4212 - accuracy: 0.9981\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.4212 - accuracy: 0.9981 - val_loss: 0.4045 - val_accuracy: 0.9949\n",
            "Epoch 41/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4120 - accuracy: 0.9987\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.4120 - accuracy: 0.9987 - val_loss: 0.4002 - val_accuracy: 0.9949\n",
            "Epoch 42/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3995 - accuracy: 0.9981\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.3995 - accuracy: 0.9981 - val_loss: 0.3926 - val_accuracy: 0.9923\n",
            "Epoch 43/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3931 - accuracy: 0.9987\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.3931 - accuracy: 0.9987 - val_loss: 0.3805 - val_accuracy: 0.9923\n",
            "Epoch 44/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3818 - accuracy: 0.9981\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.3818 - accuracy: 0.9981 - val_loss: 0.3744 - val_accuracy: 0.9949\n",
            "Epoch 45/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3708 - accuracy: 0.9994\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.3708 - accuracy: 0.9994 - val_loss: 0.3639 - val_accuracy: 0.9949\n",
            "Epoch 46/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3646 - accuracy: 0.9981\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.3646 - accuracy: 0.9981 - val_loss: 0.3595 - val_accuracy: 0.9949\n",
            "Epoch 47/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3540 - accuracy: 0.9987\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.3540 - accuracy: 0.9987 - val_loss: 0.3479 - val_accuracy: 0.9898\n",
            "Epoch 48/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3469 - accuracy: 0.9987\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.3469 - accuracy: 0.9987 - val_loss: 0.3430 - val_accuracy: 0.9949\n",
            "Epoch 49/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3382 - accuracy: 0.9987\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.3382 - accuracy: 0.9987 - val_loss: 0.3327 - val_accuracy: 0.9923\n",
            "Epoch 50/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3309 - accuracy: 0.9994\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.3309 - accuracy: 0.9994 - val_loss: 0.3244 - val_accuracy: 0.9949\n",
            "Epoch 1/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.8210 - accuracy: 0.6334\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 25ms/step - loss: 1.8135 - accuracy: 0.6365 - val_loss: 1.9997 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.8422 - accuracy: 0.9430\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.8404 - accuracy: 0.9436 - val_loss: 2.3748 - val_accuracy: 0.2941\n",
            "Epoch 3/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5897 - accuracy: 0.9864\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.5890 - accuracy: 0.9865 - val_loss: 1.1288 - val_accuracy: 0.7161\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4776 - accuracy: 0.9935\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.4768 - accuracy: 0.9936 - val_loss: 0.4203 - val_accuracy: 0.9949\n",
            "Epoch 5/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3972 - accuracy: 0.9948\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.3967 - accuracy: 0.9949 - val_loss: 0.3727 - val_accuracy: 0.9872\n",
            "Epoch 6/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3391 - accuracy: 0.9974\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 23ms/step - loss: 0.3390 - accuracy: 0.9974 - val_loss: 0.3284 - val_accuracy: 0.9872\n",
            "Epoch 7/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2993 - accuracy: 0.9981\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2988 - accuracy: 0.9981 - val_loss: 0.2834 - val_accuracy: 0.9898\n",
            "Epoch 8/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2588 - accuracy: 0.9987\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2585 - accuracy: 0.9987 - val_loss: 0.2628 - val_accuracy: 0.9847\n",
            "Epoch 9/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2376 - accuracy: 0.9974\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2375 - accuracy: 0.9974 - val_loss: 0.2311 - val_accuracy: 0.9923\n",
            "Epoch 10/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.2135 - accuracy: 0.9981\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.2136 - accuracy: 0.9981 - val_loss: 0.2070 - val_accuracy: 0.9949\n",
            "Epoch 11/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1953 - accuracy: 0.9987\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1951 - accuracy: 0.9987 - val_loss: 0.1956 - val_accuracy: 0.9949\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1830 - accuracy: 0.9994\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1829 - accuracy: 0.9994 - val_loss: 0.1903 - val_accuracy: 0.9923\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1736 - accuracy: 0.9994\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1733 - accuracy: 0.9994 - val_loss: 0.1813 - val_accuracy: 0.9923\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1628 - accuracy: 0.9994\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1629 - accuracy: 0.9994 - val_loss: 0.1851 - val_accuracy: 0.9923\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1548 - accuracy: 0.9994\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1548 - accuracy: 0.9994 - val_loss: 0.1643 - val_accuracy: 0.9949\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1475 - accuracy: 1.0000\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1474 - accuracy: 1.0000 - val_loss: 0.2047 - val_accuracy: 0.9821\n",
            "Epoch 17/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1451 - accuracy: 1.0000\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1450 - accuracy: 1.0000 - val_loss: 0.1593 - val_accuracy: 0.9949\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1404 - accuracy: 0.9994\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1404 - accuracy: 0.9994 - val_loss: 0.1525 - val_accuracy: 0.9949\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1349 - accuracy: 0.9987\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1349 - accuracy: 0.9987 - val_loss: 0.1443 - val_accuracy: 0.9949\n",
            "Epoch 20/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1293 - accuracy: 1.0000\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1293 - accuracy: 1.0000 - val_loss: 0.1424 - val_accuracy: 0.9949\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1238 - accuracy: 1.0000\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1238 - accuracy: 1.0000 - val_loss: 0.1369 - val_accuracy: 0.9949\n",
            "Epoch 22/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1216 - accuracy: 1.0000\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1217 - accuracy: 1.0000 - val_loss: 0.1403 - val_accuracy: 0.9949\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1234 - accuracy: 0.9994\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1233 - accuracy: 0.9994 - val_loss: 0.1364 - val_accuracy: 0.9949\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1142 - accuracy: 1.0000\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1143 - accuracy: 1.0000 - val_loss: 0.1375 - val_accuracy: 0.9949\n",
            "Epoch 25/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1126 - accuracy: 1.0000\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1125 - accuracy: 1.0000 - val_loss: 0.1279 - val_accuracy: 0.9949\n",
            "Epoch 26/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1087 - accuracy: 0.9994\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1086 - accuracy: 0.9994 - val_loss: 0.1270 - val_accuracy: 0.9949\n",
            "Epoch 27/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1070 - accuracy: 1.0000\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1071 - accuracy: 1.0000 - val_loss: 0.1259 - val_accuracy: 0.9949\n",
            "Epoch 28/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1054 - accuracy: 1.0000\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1053 - accuracy: 1.0000 - val_loss: 0.1201 - val_accuracy: 0.9949\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1012 - accuracy: 1.0000\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1012 - accuracy: 1.0000 - val_loss: 0.1236 - val_accuracy: 0.9949\n",
            "Epoch 30/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0993 - accuracy: 1.0000\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0993 - accuracy: 1.0000 - val_loss: 0.1129 - val_accuracy: 0.9949\n",
            "Epoch 31/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0972 - accuracy: 1.0000\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0972 - accuracy: 1.0000 - val_loss: 0.1140 - val_accuracy: 0.9923\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0939 - accuracy: 1.0000\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0940 - accuracy: 1.0000 - val_loss: 0.1168 - val_accuracy: 0.9898\n",
            "Epoch 33/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0927 - accuracy: 1.0000\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0927 - accuracy: 1.0000 - val_loss: 0.1118 - val_accuracy: 0.9949\n",
            "Epoch 34/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0913 - accuracy: 1.0000\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0913 - accuracy: 1.0000 - val_loss: 0.1070 - val_accuracy: 0.9949\n",
            "Epoch 35/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0877 - accuracy: 1.0000\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0878 - accuracy: 1.0000 - val_loss: 0.1033 - val_accuracy: 0.9949\n",
            "Epoch 36/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0855 - accuracy: 1.0000\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0855 - accuracy: 1.0000 - val_loss: 0.1018 - val_accuracy: 0.9949\n",
            "Epoch 37/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0823 - accuracy: 1.0000\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0823 - accuracy: 1.0000 - val_loss: 0.0991 - val_accuracy: 0.9949\n",
            "Epoch 38/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.1308 - accuracy: 0.9896\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.1307 - accuracy: 0.9897 - val_loss: 0.1765 - val_accuracy: 0.9898\n",
            "Epoch 39/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0982 - accuracy: 0.9994\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0981 - accuracy: 0.9994 - val_loss: 0.1157 - val_accuracy: 0.9923\n",
            "Epoch 40/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0835 - accuracy: 1.0000\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0834 - accuracy: 1.0000 - val_loss: 0.1053 - val_accuracy: 0.9949\n",
            "Epoch 41/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0799 - accuracy: 1.0000\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0799 - accuracy: 1.0000 - val_loss: 0.1008 - val_accuracy: 0.9949\n",
            "Epoch 42/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.0778 - accuracy: 1.0000\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 4s 22ms/step - loss: 0.0778 - accuracy: 1.0000 - val_loss: 0.1004 - val_accuracy: 0.9923\n",
            "Epoch 42: early stopping\n",
            "Epoch 1/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 2.2876 - accuracy: 0.3987\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 7s 28ms/step - loss: 2.2876 - accuracy: 0.3987 - val_loss: 1.8737 - val_accuracy: 0.2864\n",
            "Epoch 2/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.9084 - accuracy: 0.5788\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 1.9084 - accuracy: 0.5788 - val_loss: 1.8582 - val_accuracy: 0.2864\n",
            "Epoch 3/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6733 - accuracy: 0.6853\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 1.6733 - accuracy: 0.6853 - val_loss: 1.6544 - val_accuracy: 0.4092\n",
            "Epoch 4/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.4665 - accuracy: 0.7526\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 1.4668 - accuracy: 0.7513 - val_loss: 1.3376 - val_accuracy: 0.7877\n",
            "Epoch 5/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.3103 - accuracy: 0.7925\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 1.3089 - accuracy: 0.7929 - val_loss: 1.1791 - val_accuracy: 0.8491\n",
            "Epoch 6/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.1772 - accuracy: 0.8346\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 1.1772 - accuracy: 0.8346 - val_loss: 1.0693 - val_accuracy: 0.8926\n",
            "Epoch 7/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.0696 - accuracy: 0.8808\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 1.0694 - accuracy: 0.8814 - val_loss: 0.9888 - val_accuracy: 0.9130\n",
            "Epoch 8/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.9834 - accuracy: 0.9205\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.9834 - accuracy: 0.9205 - val_loss: 0.9109 - val_accuracy: 0.9207\n",
            "Epoch 9/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.9137 - accuracy: 0.9295\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.9137 - accuracy: 0.9295 - val_loss: 0.8627 - val_accuracy: 0.9258\n",
            "Epoch 10/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.8597 - accuracy: 0.9404\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.8597 - accuracy: 0.9404 - val_loss: 0.7943 - val_accuracy: 0.9565\n",
            "Epoch 11/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.8001 - accuracy: 0.9551\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.8001 - accuracy: 0.9551 - val_loss: 0.7550 - val_accuracy: 0.9642\n",
            "Epoch 12/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7650 - accuracy: 0.9611\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.7634 - accuracy: 0.9615 - val_loss: 0.7212 - val_accuracy: 0.9591\n",
            "Epoch 13/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7199 - accuracy: 0.9715\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.7197 - accuracy: 0.9718 - val_loss: 0.7151 - val_accuracy: 0.9591\n",
            "Epoch 14/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6972 - accuracy: 0.9715\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.6961 - accuracy: 0.9718 - val_loss: 0.6494 - val_accuracy: 0.9770\n",
            "Epoch 15/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6687 - accuracy: 0.9741\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.6670 - accuracy: 0.9744 - val_loss: 0.6222 - val_accuracy: 0.9847\n",
            "Epoch 16/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6341 - accuracy: 0.9838\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.6345 - accuracy: 0.9840 - val_loss: 0.6071 - val_accuracy: 0.9821\n",
            "Epoch 17/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.6144 - accuracy: 0.9832\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.6145 - accuracy: 0.9833 - val_loss: 0.5879 - val_accuracy: 0.9872\n",
            "Epoch 18/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5927 - accuracy: 0.9838\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.5921 - accuracy: 0.9840 - val_loss: 0.5677 - val_accuracy: 0.9898\n",
            "Epoch 19/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5651 - accuracy: 0.9883\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.5647 - accuracy: 0.9885 - val_loss: 0.5719 - val_accuracy: 0.9821\n",
            "Epoch 20/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.5464 - accuracy: 0.9871\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.5458 - accuracy: 0.9872 - val_loss: 0.5497 - val_accuracy: 0.9821\n",
            "Epoch 21/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5302 - accuracy: 0.9870\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.5307 - accuracy: 0.9872 - val_loss: 0.5079 - val_accuracy: 0.9898\n",
            "Epoch 22/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5203 - accuracy: 0.9897\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.5203 - accuracy: 0.9897 - val_loss: 0.4940 - val_accuracy: 0.9923\n",
            "Epoch 23/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5021 - accuracy: 0.9916\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.5014 - accuracy: 0.9917 - val_loss: 0.4839 - val_accuracy: 0.9898\n",
            "Epoch 24/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4845 - accuracy: 0.9916\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.4843 - accuracy: 0.9917 - val_loss: 0.4738 - val_accuracy: 0.9923\n",
            "Epoch 25/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4735 - accuracy: 0.9897\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.4731 - accuracy: 0.9897 - val_loss: 0.4624 - val_accuracy: 0.9923\n",
            "Epoch 26/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4553 - accuracy: 0.9936\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.4553 - accuracy: 0.9936 - val_loss: 0.4554 - val_accuracy: 0.9898\n",
            "Epoch 27/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4497 - accuracy: 0.9910\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 27ms/step - loss: 0.4497 - accuracy: 0.9910 - val_loss: 0.4364 - val_accuracy: 0.9898\n",
            "Epoch 28/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4330 - accuracy: 0.9948\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.4326 - accuracy: 0.9949 - val_loss: 0.4283 - val_accuracy: 0.9923\n",
            "Epoch 29/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4214 - accuracy: 0.9961\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.4209 - accuracy: 0.9962 - val_loss: 0.4139 - val_accuracy: 0.9949\n",
            "Epoch 30/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.4163 - accuracy: 0.9961\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.4164 - accuracy: 0.9962 - val_loss: 0.4082 - val_accuracy: 0.9923\n",
            "Epoch 31/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4036 - accuracy: 0.9955\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.4036 - accuracy: 0.9955 - val_loss: 0.3936 - val_accuracy: 0.9949\n",
            "Epoch 32/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3955 - accuracy: 0.9961\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.3956 - accuracy: 0.9962 - val_loss: 0.3909 - val_accuracy: 0.9949\n",
            "Epoch 33/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3877 - accuracy: 0.9949\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.3877 - accuracy: 0.9949 - val_loss: 0.3851 - val_accuracy: 0.9949\n",
            "Epoch 34/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3806 - accuracy: 0.9955\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.3811 - accuracy: 0.9955 - val_loss: 0.3732 - val_accuracy: 0.9949\n",
            "Epoch 35/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3701 - accuracy: 0.9968\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.3702 - accuracy: 0.9968 - val_loss: 0.3677 - val_accuracy: 0.9949\n",
            "Epoch 36/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3648 - accuracy: 0.9948\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.3650 - accuracy: 0.9949 - val_loss: 0.3536 - val_accuracy: 0.9949\n",
            "Epoch 37/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3590 - accuracy: 0.9942\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.3589 - accuracy: 0.9942 - val_loss: 0.3510 - val_accuracy: 0.9949\n",
            "Epoch 38/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3489 - accuracy: 0.9955\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 28ms/step - loss: 0.3488 - accuracy: 0.9955 - val_loss: 0.3496 - val_accuracy: 0.9949\n",
            "Epoch 39/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3452 - accuracy: 0.9948\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.3455 - accuracy: 0.9949 - val_loss: 0.3386 - val_accuracy: 0.9949\n",
            "Epoch 40/50\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.3379 - accuracy: 0.9955\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.3375 - accuracy: 0.9955 - val_loss: 0.3471 - val_accuracy: 0.9923\n",
            "Epoch 41/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3318 - accuracy: 0.9968\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.3318 - accuracy: 0.9968 - val_loss: 0.3213 - val_accuracy: 0.9949\n",
            "Epoch 42/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.3266 - accuracy: 0.9968\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.3268 - accuracy: 0.9968 - val_loss: 0.3262 - val_accuracy: 0.9923\n",
            "Epoch 43/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3202 - accuracy: 0.9974\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.3202 - accuracy: 0.9974 - val_loss: 0.3150 - val_accuracy: 0.9949\n",
            "Epoch 44/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3108 - accuracy: 0.9974\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.3108 - accuracy: 0.9974 - val_loss: 0.3057 - val_accuracy: 0.9974\n",
            "Epoch 45/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3040 - accuracy: 0.9974\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.3040 - accuracy: 0.9974 - val_loss: 0.3069 - val_accuracy: 0.9974\n",
            "Epoch 46/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3060 - accuracy: 0.9942\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.3060 - accuracy: 0.9942 - val_loss: 0.3024 - val_accuracy: 0.9949\n",
            "Epoch 47/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2978 - accuracy: 0.9974\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.2978 - accuracy: 0.9974 - val_loss: 0.2950 - val_accuracy: 0.9974\n",
            "Epoch 48/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2912 - accuracy: 0.9981\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.2912 - accuracy: 0.9981 - val_loss: 0.2858 - val_accuracy: 0.9974\n",
            "Epoch 49/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2887 - accuracy: 0.9987\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.2887 - accuracy: 0.9987 - val_loss: 0.2875 - val_accuracy: 0.9923\n",
            "Epoch 50/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2809 - accuracy: 0.9987\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 5s 26ms/step - loss: 0.2808 - accuracy: 0.9987 - val_loss: 0.2831 - val_accuracy: 0.9949\n",
            "Epoch 1/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 2.1558 - accuracy: 0.5878\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 8s 33ms/step - loss: 2.1558 - accuracy: 0.5878 - val_loss: 1.8947 - val_accuracy: 0.4962\n",
            "Epoch 2/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.0741 - accuracy: 0.9365\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 1.0741 - accuracy: 0.9365 - val_loss: 1.6706 - val_accuracy: 0.4808\n",
            "Epoch 3/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.7490 - accuracy: 0.9763\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 30ms/step - loss: 0.7490 - accuracy: 0.9763 - val_loss: 0.9268 - val_accuracy: 0.9821\n",
            "Epoch 4/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.5824 - accuracy: 0.9929\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.5824 - accuracy: 0.9929 - val_loss: 0.5605 - val_accuracy: 0.9719\n",
            "Epoch 5/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4782 - accuracy: 0.9936\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 30ms/step - loss: 0.4782 - accuracy: 0.9936 - val_loss: 0.4288 - val_accuracy: 0.9949\n",
            "Epoch 6/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.4015 - accuracy: 0.9974\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.4015 - accuracy: 0.9974 - val_loss: 0.3761 - val_accuracy: 0.9898\n",
            "Epoch 7/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3503 - accuracy: 0.9968\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.3503 - accuracy: 0.9968 - val_loss: 0.3349 - val_accuracy: 0.9898\n",
            "Epoch 8/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.3060 - accuracy: 0.9974\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.3060 - accuracy: 0.9974 - val_loss: 0.2874 - val_accuracy: 0.9949\n",
            "Epoch 9/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2776 - accuracy: 0.9981\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.2776 - accuracy: 0.9981 - val_loss: 0.2687 - val_accuracy: 0.9923\n",
            "Epoch 10/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2560 - accuracy: 0.9974\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.2560 - accuracy: 0.9974 - val_loss: 0.2658 - val_accuracy: 0.9923\n",
            "Epoch 11/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.2432 - accuracy: 0.9974\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.2431 - accuracy: 0.9974 - val_loss: 0.2493 - val_accuracy: 0.9923\n",
            "Epoch 12/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2274 - accuracy: 0.9994\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.2274 - accuracy: 0.9994 - val_loss: 0.2225 - val_accuracy: 0.9949\n",
            "Epoch 13/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2125 - accuracy: 0.9994\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.2125 - accuracy: 0.9994 - val_loss: 0.2166 - val_accuracy: 0.9923\n",
            "Epoch 14/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.2042 - accuracy: 0.9994\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.2042 - accuracy: 0.9994 - val_loss: 0.2078 - val_accuracy: 0.9949\n",
            "Epoch 15/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1982 - accuracy: 0.9987\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.1982 - accuracy: 0.9987 - val_loss: 0.2037 - val_accuracy: 0.9923\n",
            "Epoch 16/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1914 - accuracy: 0.9994\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.1914 - accuracy: 0.9994 - val_loss: 0.1921 - val_accuracy: 0.9923\n",
            "Epoch 17/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1841 - accuracy: 0.9994\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.1841 - accuracy: 0.9994 - val_loss: 0.1942 - val_accuracy: 0.9923\n",
            "Epoch 18/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1776 - accuracy: 1.0000\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.1776 - accuracy: 1.0000 - val_loss: 0.1833 - val_accuracy: 0.9949\n",
            "Epoch 19/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1765 - accuracy: 0.9987\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.1765 - accuracy: 0.9987 - val_loss: 0.1829 - val_accuracy: 0.9923\n",
            "Epoch 20/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1701 - accuracy: 0.9994\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.1701 - accuracy: 0.9994 - val_loss: 0.1744 - val_accuracy: 0.9949\n",
            "Epoch 21/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1643 - accuracy: 0.9994\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.1643 - accuracy: 0.9994 - val_loss: 0.1712 - val_accuracy: 0.9949\n",
            "Epoch 22/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1644 - accuracy: 0.9994\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.1644 - accuracy: 0.9994 - val_loss: 0.1690 - val_accuracy: 0.9949\n",
            "Epoch 23/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1561 - accuracy: 1.0000\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.1561 - accuracy: 1.0000 - val_loss: 0.1645 - val_accuracy: 0.9974\n",
            "Epoch 24/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1531 - accuracy: 0.9994\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.1531 - accuracy: 0.9994 - val_loss: 0.1606 - val_accuracy: 0.9974\n",
            "Epoch 25/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1473 - accuracy: 1.0000\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.1473 - accuracy: 1.0000 - val_loss: 0.1536 - val_accuracy: 0.9974\n",
            "Epoch 26/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1437 - accuracy: 1.0000\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.1437 - accuracy: 1.0000 - val_loss: 0.1501 - val_accuracy: 0.9974\n",
            "Epoch 27/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1408 - accuracy: 1.0000\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.1408 - accuracy: 1.0000 - val_loss: 0.1536 - val_accuracy: 0.9949\n",
            "Epoch 28/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1395 - accuracy: 0.9987\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.1395 - accuracy: 0.9987 - val_loss: 0.1693 - val_accuracy: 0.9923\n",
            "Epoch 29/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1393 - accuracy: 1.0000\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.1393 - accuracy: 1.0000 - val_loss: 0.1440 - val_accuracy: 0.9949\n",
            "Epoch 30/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1320 - accuracy: 1.0000\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.1320 - accuracy: 1.0000 - val_loss: 0.1401 - val_accuracy: 0.9974\n",
            "Epoch 31/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1265 - accuracy: 1.0000\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.1265 - accuracy: 1.0000 - val_loss: 0.1361 - val_accuracy: 0.9974\n",
            "Epoch 32/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1237 - accuracy: 1.0000\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.1237 - accuracy: 1.0000 - val_loss: 0.1410 - val_accuracy: 0.9974\n",
            "Epoch 33/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1192 - accuracy: 1.0000\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.1192 - accuracy: 1.0000 - val_loss: 0.1260 - val_accuracy: 0.9949\n",
            "Epoch 34/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1150 - accuracy: 1.0000\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.1150 - accuracy: 1.0000 - val_loss: 0.1213 - val_accuracy: 0.9974\n",
            "Epoch 35/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1109 - accuracy: 1.0000\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.1109 - accuracy: 1.0000 - val_loss: 0.1217 - val_accuracy: 0.9974\n",
            "Epoch 36/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1069 - accuracy: 1.0000\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.1069 - accuracy: 1.0000 - val_loss: 0.1139 - val_accuracy: 0.9974\n",
            "Epoch 37/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.1017 - accuracy: 1.0000\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.1017 - accuracy: 1.0000 - val_loss: 0.1116 - val_accuracy: 0.9974\n",
            "Epoch 38/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0990 - accuracy: 1.0000\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.0990 - accuracy: 1.0000 - val_loss: 0.1080 - val_accuracy: 0.9974\n",
            "Epoch 39/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0968 - accuracy: 1.0000\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.0968 - accuracy: 1.0000 - val_loss: 0.1067 - val_accuracy: 0.9949\n",
            "Epoch 40/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0893 - accuracy: 1.0000\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.0893 - accuracy: 1.0000 - val_loss: 0.1005 - val_accuracy: 0.9949\n",
            "Epoch 41/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0845 - accuracy: 1.0000\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.0845 - accuracy: 1.0000 - val_loss: 0.0920 - val_accuracy: 0.9974\n",
            "Epoch 42/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0800 - accuracy: 1.0000\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.0800 - accuracy: 1.0000 - val_loss: 0.0884 - val_accuracy: 0.9974\n",
            "Epoch 43/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0754 - accuracy: 1.0000\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.0754 - accuracy: 1.0000 - val_loss: 0.0821 - val_accuracy: 0.9949\n",
            "Epoch 44/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0714 - accuracy: 1.0000\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.0714 - accuracy: 1.0000 - val_loss: 0.0764 - val_accuracy: 0.9974\n",
            "Epoch 45/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0660 - accuracy: 1.0000\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.0660 - accuracy: 1.0000 - val_loss: 0.0730 - val_accuracy: 0.9974\n",
            "Epoch 46/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0621 - accuracy: 1.0000\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 30ms/step - loss: 0.0621 - accuracy: 1.0000 - val_loss: 0.0726 - val_accuracy: 0.9949\n",
            "Epoch 47/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0581 - accuracy: 1.0000\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.0581 - accuracy: 1.0000 - val_loss: 0.0733 - val_accuracy: 0.9923\n",
            "Epoch 48/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0536 - accuracy: 1.0000\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.0536 - accuracy: 1.0000 - val_loss: 0.0587 - val_accuracy: 0.9974\n",
            "Epoch 49/50\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.0941 - accuracy: 0.9936\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.0941 - accuracy: 0.9936 - val_loss: 0.0677 - val_accuracy: 0.9949\n",
            "Epoch 50/50\n",
            "195/195 [==============================] - ETA: 0s - loss: 0.0596 - accuracy: 0.9987\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "195/195 [==============================] - 6s 29ms/step - loss: 0.0596 - accuracy: 0.9987 - val_loss: 0.0636 - val_accuracy: 0.9974\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "yYgEp9ac5fcO",
        "outputId": "14990858-1e93-4bd5-b689-e25db391da0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     round_epochs      loss  accuracy  val_loss  val_accuracy activation  \\\n",
              "97             50  0.194676  0.998718  0.195738      0.997442       relu   \n",
              "96             50  0.322414  0.999359  0.314009      0.997442       relu   \n",
              "37             50  0.055693  1.000000  0.069631      0.997442       relu   \n",
              "177            50  0.285031  0.996795  0.283337      0.997442       relu   \n",
              "6              50  0.061392  1.000000  0.068742      0.997442       relu   \n",
              "\n",
              "    optimizer  kernel_size_1  kernel_size_2  kernel_size_3  learning_rate  \\\n",
              "97       Adam              7             11             13        0.00001   \n",
              "96       Adam              7             11             11        0.00001   \n",
              "37       Adam              7              7              9        0.00010   \n",
              "177      Adam              9             11             13        0.00001   \n",
              "6        Adam             11             13             13        0.00010   \n",
              "\n",
              "     pool_size padding  strides  filters_1  filters_2  filters_3  dropout  \\\n",
              "97           3    same        1        128         16        128     0.10   \n",
              "96           2    same        1         32        128        128     0.05   \n",
              "37           2    same        1         32        128         64     0.05   \n",
              "177          3    same        1        128         64         64     0.10   \n",
              "6            2    same        1         16        128        128     0.10   \n",
              "\n",
              "     batch_size  crossval_mean_f1score  \n",
              "97            8               0.988220  \n",
              "96            8               0.994539  \n",
              "37            8               0.992791  \n",
              "177           8               0.994291  \n",
              "6             8               0.997432  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-02688ee5-9474-4c72-b7d7-89d74e86e35d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>round_epochs</th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>activation</th>\n",
              "      <th>optimizer</th>\n",
              "      <th>kernel_size_1</th>\n",
              "      <th>kernel_size_2</th>\n",
              "      <th>kernel_size_3</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>pool_size</th>\n",
              "      <th>padding</th>\n",
              "      <th>strides</th>\n",
              "      <th>filters_1</th>\n",
              "      <th>filters_2</th>\n",
              "      <th>filters_3</th>\n",
              "      <th>dropout</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>crossval_mean_f1score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>50</td>\n",
              "      <td>0.194676</td>\n",
              "      <td>0.998718</td>\n",
              "      <td>0.195738</td>\n",
              "      <td>0.997442</td>\n",
              "      <td>relu</td>\n",
              "      <td>Adam</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "      <td>13</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>3</td>\n",
              "      <td>same</td>\n",
              "      <td>1</td>\n",
              "      <td>128</td>\n",
              "      <td>16</td>\n",
              "      <td>128</td>\n",
              "      <td>0.10</td>\n",
              "      <td>8</td>\n",
              "      <td>0.988220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>50</td>\n",
              "      <td>0.322414</td>\n",
              "      <td>0.999359</td>\n",
              "      <td>0.314009</td>\n",
              "      <td>0.997442</td>\n",
              "      <td>relu</td>\n",
              "      <td>Adam</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>2</td>\n",
              "      <td>same</td>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>0.05</td>\n",
              "      <td>8</td>\n",
              "      <td>0.994539</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>50</td>\n",
              "      <td>0.055693</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.069631</td>\n",
              "      <td>0.997442</td>\n",
              "      <td>relu</td>\n",
              "      <td>Adam</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "      <td>0.00010</td>\n",
              "      <td>2</td>\n",
              "      <td>same</td>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>128</td>\n",
              "      <td>64</td>\n",
              "      <td>0.05</td>\n",
              "      <td>8</td>\n",
              "      <td>0.992791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>50</td>\n",
              "      <td>0.285031</td>\n",
              "      <td>0.996795</td>\n",
              "      <td>0.283337</td>\n",
              "      <td>0.997442</td>\n",
              "      <td>relu</td>\n",
              "      <td>Adam</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "      <td>13</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>3</td>\n",
              "      <td>same</td>\n",
              "      <td>1</td>\n",
              "      <td>128</td>\n",
              "      <td>64</td>\n",
              "      <td>64</td>\n",
              "      <td>0.10</td>\n",
              "      <td>8</td>\n",
              "      <td>0.994291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>50</td>\n",
              "      <td>0.061392</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.068742</td>\n",
              "      <td>0.997442</td>\n",
              "      <td>relu</td>\n",
              "      <td>Adam</td>\n",
              "      <td>11</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>0.00010</td>\n",
              "      <td>2</td>\n",
              "      <td>same</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>0.10</td>\n",
              "      <td>8</td>\n",
              "      <td>0.997432</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-02688ee5-9474-4c72-b7d7-89d74e86e35d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-02688ee5-9474-4c72-b7d7-89d74e86e35d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-02688ee5-9474-4c72-b7d7-89d74e86e35d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 244
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWvionVW5kVW",
        "outputId": "81537856-890c-47cc-df83-ff2808c6afbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<keras.engine.sequential.Sequential at 0x7fd788422310>,\n",
              " <keras.engine.sequential.Sequential at 0x7fd8b30d64d0>,\n",
              " <keras.engine.sequential.Sequential at 0x7fd797b2e390>,\n",
              " <keras.engine.sequential.Sequential at 0x7fd7979f6790>,\n",
              " <keras.engine.sequential.Sequential at 0x7fd793fae490>]"
            ]
          },
          "metadata": {},
          "execution_count": 245
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# accessing the saved models\n",
        "scan_object.saved_models\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiniEIzsq7bI",
        "outputId": "cdfb43f2-1228-4251-dd14-882d193ae770"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 246
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# accessing the saved weights for models\n",
        "scan_object.saved_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWr2Mwktq-Bk",
        "outputId": "74e998e3-4237-40ab-e24c-0ddfd057b172"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 247
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# use Scan object as input\n",
        "analyze_object = talos.Analyze(scan_object)"
      ],
      "metadata": {
        "id": "3bFUKKoEpu_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# access the dataframe with the results\n",
        "analyze_object.data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 661
        },
        "id": "MmgHsTJKp1Nz",
        "outputId": "ef891187-1cd1-410b-c707-d73f3dbf2a2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               start              end    duration  round_epochs      loss  \\\n",
              "0    08/05/22-224246  08/05/22-224610  203.794710            50  0.092618   \n",
              "1    08/05/22-224614  08/05/22-224933  199.572882            50  0.050800   \n",
              "2    08/05/22-224937  08/05/22-225201  143.768999            50  0.052677   \n",
              "3    08/05/22-225204  08/05/22-225332   87.696338            50  0.345980   \n",
              "4    08/05/22-225335  08/05/22-225659  203.756402            50  0.341067   \n",
              "..               ...              ...         ...           ...       ...   \n",
              "195  08/06/22-063142  08/06/22-063235   52.315868            12  0.080955   \n",
              "196  08/06/22-063238  08/06/22-063802  323.802888            50  0.056621   \n",
              "197  08/06/22-063805  08/06/22-064007  121.574244            29  1.630052   \n",
              "198  08/06/22-064033  08/06/22-064140   67.831452            21  0.070693   \n",
              "199  08/06/22-064144  08/06/22-064227   42.740158            17  0.060692   \n",
              "\n",
              "     accuracy  val_loss  val_accuracy activation optimizer  ...  \\\n",
              "0    0.999359  0.123091      0.989770       relu      Adam  ...   \n",
              "1    1.000000  0.072886      0.994885       relu      Adam  ...   \n",
              "2    1.000000  0.073473      0.992327       relu      Adam  ...   \n",
              "3    0.982051  0.359158      0.971867       relu      Adam  ...   \n",
              "4    0.995513  0.331353      0.992327       relu      Adam  ...   \n",
              "..        ...       ...           ...        ...       ...  ...   \n",
              "195  0.998718  0.140924      0.987212       relu      Adam  ...   \n",
              "196  1.000000  0.067778      0.994885       relu      Adam  ...   \n",
              "197  0.285897  1.626661      0.286445       relu      Adam  ...   \n",
              "198  0.999359  0.093488      0.987212       relu      Adam  ...   \n",
              "199  0.998077  0.087485      0.994885       relu      Adam  ...   \n",
              "\n",
              "     kernel_size_3  learning_rate  pool_size  padding  strides filters_1  \\\n",
              "0                9        0.00010          4     same        1        16   \n",
              "1                9        0.00010          2     same        1        16   \n",
              "2                9        0.00010          4     same        1        32   \n",
              "3               13        0.00001          3     same        1        32   \n",
              "4               13        0.00001          3     same        1        64   \n",
              "..             ...            ...        ...      ...      ...       ...   \n",
              "195             11        0.00100          2     same        1        16   \n",
              "196              7        0.00010          2     same        1       128   \n",
              "197             11        0.01000          4     same        1       128   \n",
              "198              9        0.00100          2     same        1        64   \n",
              "199              7        0.00100          3     same        1        64   \n",
              "\n",
              "     filters_2  filters_3  dropout  batch_size  \n",
              "0          128         64     0.10           8  \n",
              "1          128         32     0.05           8  \n",
              "2           16        128     0.05           8  \n",
              "3           16         16     0.01           8  \n",
              "4           64         64     0.10           8  \n",
              "..         ...        ...      ...         ...  \n",
              "195        128         32     0.05           8  \n",
              "196         64         64     0.10           8  \n",
              "197         32        128     0.01           8  \n",
              "198         32         64     0.10           8  \n",
              "199         16         32     0.05           8  \n",
              "\n",
              "[200 rows x 22 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-18580bdd-5a08-41be-bd3a-863fd9a5e7b7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>duration</th>\n",
              "      <th>round_epochs</th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>activation</th>\n",
              "      <th>optimizer</th>\n",
              "      <th>...</th>\n",
              "      <th>kernel_size_3</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>pool_size</th>\n",
              "      <th>padding</th>\n",
              "      <th>strides</th>\n",
              "      <th>filters_1</th>\n",
              "      <th>filters_2</th>\n",
              "      <th>filters_3</th>\n",
              "      <th>dropout</th>\n",
              "      <th>batch_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>08/05/22-224246</td>\n",
              "      <td>08/05/22-224610</td>\n",
              "      <td>203.794710</td>\n",
              "      <td>50</td>\n",
              "      <td>0.092618</td>\n",
              "      <td>0.999359</td>\n",
              "      <td>0.123091</td>\n",
              "      <td>0.989770</td>\n",
              "      <td>relu</td>\n",
              "      <td>Adam</td>\n",
              "      <td>...</td>\n",
              "      <td>9</td>\n",
              "      <td>0.00010</td>\n",
              "      <td>4</td>\n",
              "      <td>same</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>128</td>\n",
              "      <td>64</td>\n",
              "      <td>0.10</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>08/05/22-224614</td>\n",
              "      <td>08/05/22-224933</td>\n",
              "      <td>199.572882</td>\n",
              "      <td>50</td>\n",
              "      <td>0.050800</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.072886</td>\n",
              "      <td>0.994885</td>\n",
              "      <td>relu</td>\n",
              "      <td>Adam</td>\n",
              "      <td>...</td>\n",
              "      <td>9</td>\n",
              "      <td>0.00010</td>\n",
              "      <td>2</td>\n",
              "      <td>same</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>128</td>\n",
              "      <td>32</td>\n",
              "      <td>0.05</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>08/05/22-224937</td>\n",
              "      <td>08/05/22-225201</td>\n",
              "      <td>143.768999</td>\n",
              "      <td>50</td>\n",
              "      <td>0.052677</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.073473</td>\n",
              "      <td>0.992327</td>\n",
              "      <td>relu</td>\n",
              "      <td>Adam</td>\n",
              "      <td>...</td>\n",
              "      <td>9</td>\n",
              "      <td>0.00010</td>\n",
              "      <td>4</td>\n",
              "      <td>same</td>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>16</td>\n",
              "      <td>128</td>\n",
              "      <td>0.05</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>08/05/22-225204</td>\n",
              "      <td>08/05/22-225332</td>\n",
              "      <td>87.696338</td>\n",
              "      <td>50</td>\n",
              "      <td>0.345980</td>\n",
              "      <td>0.982051</td>\n",
              "      <td>0.359158</td>\n",
              "      <td>0.971867</td>\n",
              "      <td>relu</td>\n",
              "      <td>Adam</td>\n",
              "      <td>...</td>\n",
              "      <td>13</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>3</td>\n",
              "      <td>same</td>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>0.01</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>08/05/22-225335</td>\n",
              "      <td>08/05/22-225659</td>\n",
              "      <td>203.756402</td>\n",
              "      <td>50</td>\n",
              "      <td>0.341067</td>\n",
              "      <td>0.995513</td>\n",
              "      <td>0.331353</td>\n",
              "      <td>0.992327</td>\n",
              "      <td>relu</td>\n",
              "      <td>Adam</td>\n",
              "      <td>...</td>\n",
              "      <td>13</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>3</td>\n",
              "      <td>same</td>\n",
              "      <td>1</td>\n",
              "      <td>64</td>\n",
              "      <td>64</td>\n",
              "      <td>64</td>\n",
              "      <td>0.10</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>08/06/22-063142</td>\n",
              "      <td>08/06/22-063235</td>\n",
              "      <td>52.315868</td>\n",
              "      <td>12</td>\n",
              "      <td>0.080955</td>\n",
              "      <td>0.998718</td>\n",
              "      <td>0.140924</td>\n",
              "      <td>0.987212</td>\n",
              "      <td>relu</td>\n",
              "      <td>Adam</td>\n",
              "      <td>...</td>\n",
              "      <td>11</td>\n",
              "      <td>0.00100</td>\n",
              "      <td>2</td>\n",
              "      <td>same</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>128</td>\n",
              "      <td>32</td>\n",
              "      <td>0.05</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>08/06/22-063238</td>\n",
              "      <td>08/06/22-063802</td>\n",
              "      <td>323.802888</td>\n",
              "      <td>50</td>\n",
              "      <td>0.056621</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.067778</td>\n",
              "      <td>0.994885</td>\n",
              "      <td>relu</td>\n",
              "      <td>Adam</td>\n",
              "      <td>...</td>\n",
              "      <td>7</td>\n",
              "      <td>0.00010</td>\n",
              "      <td>2</td>\n",
              "      <td>same</td>\n",
              "      <td>1</td>\n",
              "      <td>128</td>\n",
              "      <td>64</td>\n",
              "      <td>64</td>\n",
              "      <td>0.10</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>08/06/22-063805</td>\n",
              "      <td>08/06/22-064007</td>\n",
              "      <td>121.574244</td>\n",
              "      <td>29</td>\n",
              "      <td>1.630052</td>\n",
              "      <td>0.285897</td>\n",
              "      <td>1.626661</td>\n",
              "      <td>0.286445</td>\n",
              "      <td>relu</td>\n",
              "      <td>Adam</td>\n",
              "      <td>...</td>\n",
              "      <td>11</td>\n",
              "      <td>0.01000</td>\n",
              "      <td>4</td>\n",
              "      <td>same</td>\n",
              "      <td>1</td>\n",
              "      <td>128</td>\n",
              "      <td>32</td>\n",
              "      <td>128</td>\n",
              "      <td>0.01</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>08/06/22-064033</td>\n",
              "      <td>08/06/22-064140</td>\n",
              "      <td>67.831452</td>\n",
              "      <td>21</td>\n",
              "      <td>0.070693</td>\n",
              "      <td>0.999359</td>\n",
              "      <td>0.093488</td>\n",
              "      <td>0.987212</td>\n",
              "      <td>relu</td>\n",
              "      <td>Adam</td>\n",
              "      <td>...</td>\n",
              "      <td>9</td>\n",
              "      <td>0.00100</td>\n",
              "      <td>2</td>\n",
              "      <td>same</td>\n",
              "      <td>1</td>\n",
              "      <td>64</td>\n",
              "      <td>32</td>\n",
              "      <td>64</td>\n",
              "      <td>0.10</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>08/06/22-064144</td>\n",
              "      <td>08/06/22-064227</td>\n",
              "      <td>42.740158</td>\n",
              "      <td>17</td>\n",
              "      <td>0.060692</td>\n",
              "      <td>0.998077</td>\n",
              "      <td>0.087485</td>\n",
              "      <td>0.994885</td>\n",
              "      <td>relu</td>\n",
              "      <td>Adam</td>\n",
              "      <td>...</td>\n",
              "      <td>7</td>\n",
              "      <td>0.00100</td>\n",
              "      <td>3</td>\n",
              "      <td>same</td>\n",
              "      <td>1</td>\n",
              "      <td>64</td>\n",
              "      <td>16</td>\n",
              "      <td>32</td>\n",
              "      <td>0.05</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200 rows × 22 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-18580bdd-5a08-41be-bd3a-863fd9a5e7b7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-18580bdd-5a08-41be-bd3a-863fd9a5e7b7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-18580bdd-5a08-41be-bd3a-863fd9a5e7b7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 249
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the highest result for any metric\n",
        "analyze_object.high('val_accuracy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1EqEA9fqGtj",
        "outputId": "1d04ae32-cb3c-424e-eacf-4405eba03375"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9974424839019775"
            ]
          },
          "metadata": {},
          "execution_count": 250
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the round with the best result\n",
        "analyze_object.rounds2high('val_accuracy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuE8flRhqID2",
        "outputId": "a2a2aae9-9971-4552-a7cd-7b5b613b41b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 251
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the best paramaters\n",
        "analyze_object.best_params('val_accuracy', ['acc', 'loss', 'val_loss'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hdIQ0OnqK6B",
        "outputId": "e4a80a34-2396-4f2d-a45c-423a8c8e8641"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[128, 7, '08/06/22-024259', 1, 8, 'relu', 16, 128,\n",
              "        218.77062273025513, 0.9987179636955261, 11, 'same', 3, 13, 1e-05,\n",
              "        50, '08/06/22-023921', 'Adam', 0.1, 0],\n",
              "       [32, 7, '08/06/22-023917', 1, 8, 'relu', 128, 128,\n",
              "        301.9984028339386, 0.9993589520454407, 11, 'same', 2, 11, 1e-05,\n",
              "        50, '08/06/22-023415', 'Adam', 0.05, 1],\n",
              "       [32, 7, '08/06/22-001159', 1, 8, 'relu', 128, 64,\n",
              "        221.35736846923828, 1.0, 7, 'same', 2, 9, 0.0001, 50,\n",
              "        '08/06/22-000817', 'Adam', 0.05, 2],\n",
              "       [128, 9, '08/06/22-055441', 1, 8, 'relu', 64, 64,\n",
              "        263.73669695854187, 0.9967948794364929, 11, 'same', 3, 13, 1e-05,\n",
              "        50, '08/06/22-055017', 'Adam', 0.1, 3],\n",
              "       [16, 11, '08/05/22-230454', 1, 8, 'relu', 128, 128,\n",
              "        323.8078465461731, 1.0, 13, 'same', 2, 13, 0.0001, 50,\n",
              "        '08/05/22-225930', 'Adam', 0.1, 4],\n",
              "       [16, 13, '08/06/22-051820', 1, 8, 'relu', 32, 64,\n",
              "        143.75527453422546, 1.0, 7, 'same', 4, 13, 0.0001, 50,\n",
              "        '08/06/22-051557', 'Adam', 0.01, 5],\n",
              "       [16, 9, '08/06/22-045909', 1, 8, 'relu', 128, 32,\n",
              "        147.89246892929077, 1.0, 13, 'same', 4, 7, 0.0001, 50,\n",
              "        '08/06/22-045641', 'Adam', 0.05, 6],\n",
              "       [32, 13, '08/06/22-014243', 1, 8, 'relu', 128, 32,\n",
              "        237.14451336860657, 1.0, 13, 'same', 2, 11, 0.0001, 50,\n",
              "        '08/06/22-013846', 'Adam', 0.01, 7],\n",
              "       [64, 11, '08/06/22-011822', 1, 8, 'relu', 64, 64,\n",
              "        203.7313973903656, 1.0, 7, 'same', 2, 13, 1e-05, 50,\n",
              "        '08/06/22-011459', 'Adam', 0.05, 8],\n",
              "       [16, 11, '08/05/22-232553', 1, 8, 'relu', 16, 128,\n",
              "        143.80819535255432, 0.9961538314819336, 13, 'same', 2, 9, 1e-05,\n",
              "        50, '08/05/22-232329', 'Adam', 0.01, 9]], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 252
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the number of rounds in the Scan\n",
        "analyze_object.rounds()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whwyEIjKqUJA",
        "outputId": "cd56ff52-5896-4f9d-fa6e-0ebecc1913fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {},
          "execution_count": 253
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get correlation for hyperparameters against a metric\n",
        "analyze_object.correlate('val_loss', ['accuracy', 'loss', 'val_loss'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPbCOnI_p4Dt",
        "outputId": "0d082649-47e6-4495-8184-bc21d46afb3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "duration        -0.356419\n",
              "round_epochs    -0.459903\n",
              "val_accuracy    -0.960089\n",
              "kernel_size_1    0.049029\n",
              "kernel_size_2   -0.098250\n",
              "kernel_size_3   -0.084353\n",
              "learning_rate    0.834395\n",
              "pool_size       -0.044059\n",
              "strides               NaN\n",
              "filters_1        0.112208\n",
              "filters_2       -0.050328\n",
              "filters_3       -0.059034\n",
              "dropout          0.057625\n",
              "batch_size            NaN\n",
              "Name: val_loss, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 254
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# a regression plot for two dimensions\n",
        "analyze_object.plot_regs('val_accuracy', 'val_loss')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "mgvXMMlWqZZQ",
        "outputId": "15e4a31d-d55d-454b-a4e3-fc4790286aa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x475.2 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# line plot\n",
        "analyze_object.plot_line('val_accuracy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "ks7xMm1Vqdum",
        "outputId": "2d30f3ba-5489-43e1-a7fa-6729880e1888"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x475.2 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# up to two dimensional kernel density estimator\n",
        "analyze_object.plot_kde('val_accuracy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "hBFqHiIaqmFn",
        "outputId": "c431969c-4acf-443c-ff2a-02866cc82c40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x475.2 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbuxOOfnBbjw"
      },
      "outputs": [],
      "source": [
        "# #####################################################\n",
        "# # Setting the weights for the best model found and saving the model\n",
        "# scan_object[1].load_weights(checkpoint_filepath)\n",
        "# # Guardar el Modelo (Just only once if u are running the network again)\n",
        "# scan_object[1].save('/content/drive/MyDrive/Model_Hyper_CNN.h5')\n",
        "# /content/drive/MyDrive/CNN_Hyper/080522224246/68/saved_model.pb\n",
        "######################################################################\n",
        "# Loading model (already trained)\n",
        "model2_ = keras.models.load_model('/content/drive/MyDrive/hyper_CNN.hdf5')\n",
        "#####################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIp1_DB-sKAq",
        "outputId": "a78dbc67-a21d-414a-ec7b-18a0bace7ca4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 1s 11ms/step - loss: 0.1062 - accuracy: 1.0000\n",
            "\n",
            "Test accuracy: 100.0%\n",
            "49/49 [==============================] - 1s 11ms/step - loss: 0.1068 - accuracy: 0.9942\n",
            "\\Train accuracy: 99.4%\n"
          ]
        }
      ],
      "source": [
        "_, acc = model2_.evaluate(X_test,\n",
        "                        y_test,\n",
        "                        batch_size=32)\n",
        "print(\"\\nTest accuracy: %.1f%%\" % (100.0 * acc))\n",
        "\n",
        "_, acc = model2_.evaluate(X_train,\n",
        "                        y_train,\n",
        "                        batch_size=32)\n",
        "print(\"\\Train accuracy: %.1f%%\" % (100.0 * acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 876
        },
        "id": "KNKVwfndsKTF",
        "outputId": "4b65693c-3232-4407-df8d-74bac9e9de08"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(0, 0.5, 'Normal'),\n",
              " Text(0, 1.5, 'Hor Mis'),\n",
              " Text(0, 2.5, 'Imbalance'),\n",
              " Text(0, 3.5, 'Ver Mis'),\n",
              " Text(0, 4.5, 'Overhang'),\n",
              " Text(0, 5.5, 'Underhang')]"
            ]
          },
          "metadata": {},
          "execution_count": 78
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x864 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# COnfusion matrix resulting\n",
        "\n",
        "y_pred = model2_.predict(X_test)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "underhang_y_test_cm = np.argmax(y_test, axis = -1)\n",
        "matrix = confusion_matrix(underhang_y_test_cm, y_pred)\n",
        "\n",
        "figure = plt.figure(figsize = (12,12))\n",
        "\n",
        "ax = sns.heatmap(matrix, annot=True, cmap='Blues',fmt = 'g')\n",
        "\n",
        "ax.set_title('Confusion Matrix\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted Values')\n",
        "ax.set_ylabel('Actual Values ');\n",
        "\n",
        "## Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels(['Normal','Hor Mis','Imbalance', 'Ver Mis', 'Overhang', 'Underhang'])\n",
        "ax.yaxis.set_ticklabels(['Normal','Hor Mis','Imbalance', 'Ver Mis', 'Overhang', 'Underhang'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# COnfusion matrix resulting\n",
        "\n",
        "y_pred = model2_.predict(X_train)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "underhang_y_test_cm = np.argmax(y_train, axis = -1)\n",
        "matrix = confusion_matrix(underhang_y_test_cm, y_pred)\n",
        "\n",
        "figure = plt.figure(figsize = (12,12))\n",
        "\n",
        "ax = sns.heatmap(matrix, annot=True, cmap='Blues',fmt = 'g')\n",
        "\n",
        "ax.set_title('Confusion Matrix\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted Values')\n",
        "ax.set_ylabel('Actual Values ');\n",
        "\n",
        "## Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels(['Normal','Hor Mis','Imbalance', 'Ver Mis', 'Overhang', 'Underhang'])\n",
        "ax.yaxis.set_ticklabels(['Normal','Hor Mis','Imbalance', 'Ver Mis', 'Overhang', 'Underhang'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 876
        },
        "id": "uRaGX1XjlJtv",
        "outputId": "6bc43274-b468-4617-cd92-ba2ca07ed501"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(0, 0.5, 'Normal'),\n",
              " Text(0, 1.5, 'Hor Mis'),\n",
              " Text(0, 2.5, 'Imbalance'),\n",
              " Text(0, 3.5, 'Ver Mis'),\n",
              " Text(0, 4.5, 'Overhang'),\n",
              " Text(0, 5.5, 'Underhang')]"
            ]
          },
          "metadata": {},
          "execution_count": 79
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x864 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Y4slpTNsYUX",
        "outputId": "65243709-d63a-417a-f2ee-3a59b040f955"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy for class Normal is: 100.0 % =  39 / 39\n",
            "The accuracy for class Hor Mis is: 96.84 % =  153 / 158\n",
            "The accuracy for class Imbalance is: 98.5 % =  262 / 266\n",
            "The accuracy for class Ver Mis is: 100.0 % =  241 / 241\n",
            "The accuracy for class Overhang is: 100.0 % =  410 / 410\n",
            "The accuracy for class Underhang is: 100.0 % =  446 / 446\n"
          ]
        }
      ],
      "source": [
        "# Accuracy per class\n",
        "names = ['Normal','Hor Mis','Imbalance', 'Ver Mis', 'Overhang', 'Underhang']\n",
        "\n",
        "for i in range(6):\n",
        "  ac =0\n",
        "  tot = 0\n",
        "  for j in range(6):\n",
        "    if i == j:\n",
        "      ac += matrix[i][j]\n",
        "      tot += matrix[i][j]\n",
        "    else:\n",
        "      tot += matrix[i][j]\n",
        "\n",
        "  print(\"The accuracy for class\", names[i], 'is:', round(100*ac/tot, 2), '% = ', ac, '/', tot)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVtpbavWqs8I"
      },
      "source": [
        "### Explainability using Grad - CAM techniques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GaGIn8wgqs8I"
      },
      "outputs": [],
      "source": [
        "# Needed for visualization\n",
        "\n",
        "layer_name = \"conv1d_4\"  # last layer\n",
        "cnt = 0\n",
        "xticks = [int(xf[i]) for i in range(0, input_size, 749)]\n",
        "ticks = [i for i in range(0, input_size, 749)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61b5d8b3-9d40-4431-ed69-bbaf67861bf4",
        "id": "_NsxW8Q6qs8J"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: UserWarning: Attempting to set identical bottom == top == 0.0 results in singular transformations; automatically expanding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "390\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: UserWarning: Attempting to set identical bottom == top == 0.0 results in singular transformations; automatically expanding.\n"
          ]
        }
      ],
      "source": [
        "###########################################################################\n",
        "# Independent heatmaps for each data point\n",
        "###########################################################################\n",
        "\n",
        "cnt_2 = 0\n",
        "\n",
        "for i in X_test:\n",
        "    data = np.expand_dims(i,0)\n",
        "    pred = model2_.predict(data)\n",
        "    # Printing a class in particular\n",
        "    actual_class = np.argmax(y_test[cnt_2])\n",
        "\n",
        "\n",
        "    if np.argmax(pred) != actual_class:\n",
        "\n",
        "      heatmap = grad_cam(layer_name,data)\n",
        "\n",
        "      fig1, (ax1) = plt.subplots(1, sharex = True, figsize = (30,10))\n",
        "\n",
        "      ###########################################################################\n",
        "      # AX1 - CNN selection with stacked data\n",
        "      ###########################################################################\n",
        "\n",
        "      ax1.imshow(heatmap, cmap='Reds', aspect=\"auto\" ,extent=[0,5000,i.min(),i.max()], alpha=0.8)\n",
        "      ax1.plot(i,'k')\n",
        "      ax1.set_ylabel('Normalised Amplitud frequency')\n",
        "      ax1.set_title('HeatMap for Incorrect data point')\n",
        "\n",
        "      # Plotting 7 plots:\n",
        "      # - Stacking on all 6 frequencies\n",
        "      # - Axial/Radial/Tangencial Underhang Accelerometer\n",
        "      # - Axial/Radial/Tangencial Overhang Accelerometer\n",
        "\n",
        "      ###########################################################################\n",
        "      # AX2 - Stacked data with colors\n",
        "      ###########################################################################\n",
        "\n",
        "\n",
        "      # df = pd.DataFrame(i)\n",
        "\n",
        "      # ax2.plot(df.iloc[:,0], label = 'AxialUn')\n",
        "      # ax2.plot(df.iloc[:,1], label = 'RadialUn')\n",
        "      # ax2.plot(df.iloc[:,2], label = 'TangUn')\n",
        "      # ax2.plot(df.iloc[:,3], label = 'AxialOv')\n",
        "      # ax2.plot(df.iloc[:,4], label = 'RadialOv')\n",
        "      # ax2.plot(df.iloc[:,5], label = 'TangOv')\n",
        "      # ax2.set_title('Stacked data with colors')\n",
        "      # ax2.set_xlabel('Frequency (Hz)')\n",
        "      # ax2.set_xticks(ticks = ticks)\n",
        "      # ax2.set_xticklabels(xticks)\n",
        "      # ax2.set_ylabel('Normalised Amplitud frequency')\n",
        "      # ax2.legend()\n",
        "\n",
        "\n",
        "      fig1.savefig(directories[6] + '/' + str(cnt)+'_PlotStacked.png')\n",
        "      plt.close()\n",
        "\n",
        "      # Saving photos\n",
        "      ###########################################<################\n",
        "      # if names[np.argmax(pred)] != names[np.argmax(y_test[cnt])]:\n",
        "      #   fig1.savefig(directories[6] + '/' + str(cnt)+'_PlotStacked.png')\n",
        "      #   plt.close()\n",
        "      # else:\n",
        "      #   image_allocation(np.argmax(pred), fig1)\n",
        "      ##############################################################\n",
        "\n",
        "\n",
        "      ###########################################################################\n",
        "      # AX1 - 6 remaining graphs regarding accelerometer\n",
        "      ###########################################################################\n",
        "\n",
        "      # fig2, (ax1, ax2, ax3, ax4, ax5, ax6) = plt.subplots(6, sharex = True, figsize = (30,30))\n",
        "\n",
        "      # ax1.imshow(heatmap,cmap='Greens', aspect=\"auto\", interpolation='nearest',extent=[0,7509,i.min(),i.max()], alpha=0.8)\n",
        "      # ax1.plot(df.iloc[:,0], 'k', label = 'AxialUn')\n",
        "      # ax1.set_title('Axial - Underhang Accelerometer')\n",
        "      # ax1.set_ylabel('Normalised Amplitud frequency')\n",
        "\n",
        "      # ax2.imshow(heatmap,cmap='Greens', aspect=\"auto\", interpolation='nearest',extent=[0,7509,i.min(),i.max()], alpha=0.8)\n",
        "      # ax2.plot(df.iloc[:,1], 'k', label = 'RadialUn')\n",
        "      # ax2.set_title('Radiale - Underhang Accelerometer')\n",
        "      # ax2.set_ylabel('Normalised Amplitud frequency')\n",
        "\n",
        "      # ax3.imshow(heatmap,cmap='Greens', aspect=\"auto\", interpolation='nearest',extent=[0,7509,i.min(),i.max()], alpha=0.8)\n",
        "      # ax3.plot(df.iloc[:,2], 'k', label = 'TangUn')\n",
        "      # ax3.set_title('Tangencial - Underhang Accelerometer')\n",
        "      # ax3.set_ylabel('Normalised Amplitud frequency')\n",
        "\n",
        "      # ax4.imshow(heatmap,cmap='Greens', aspect=\"auto\", interpolation='nearest',extent=[0,7509,i.min(),i.max()], alpha=0.8)\n",
        "      # ax4.plot(df.iloc[:,3], 'k', label = 'AxialOv')\n",
        "      # ax4.set_title('Axial - Overhang Accelerometer')\n",
        "      # ax4.set_ylabel('Normalised Amplitud frequency')\n",
        "\n",
        "      # ax5.imshow(heatmap,cmap='Greens', aspect=\"auto\", interpolation='nearest',extent=[0,7509,i.min(),i.max()], alpha=0.8)\n",
        "      # ax5.plot(df.iloc[:,4], 'k', label = 'RadialOv')\n",
        "      # ax5.set_title('Radiale - Underhang Accelerometer')\n",
        "      # ax5.set_ylabel('Normalised Amplitud frequency')\n",
        "\n",
        "      # ax6.imshow(heatmap,cmap='Greens', aspect=\"auto\", interpolation='nearest',extent=[0,7509,i.min(),i.max()], alpha=0.8)\n",
        "      # ax6.plot(df.iloc[:,5], 'k', label = 'TangOv')\n",
        "      # ax6.set_title('Tangecial - Underhang Accelerometer')\n",
        "      # ax6.set_xlabel('Frequency (Hz)')\n",
        "      # ax6.set_xlim([0,7509])\n",
        "      # ax6.set_ylabel('Normalised Amplitud frequency')\n",
        "      # ax6.set_xticks(ticks = ticks)\n",
        "      # ax6.set_xticklabels(xticks)\n",
        "\n",
        "      # # Saving photos\n",
        "      # ###########################################<################\n",
        "      # if names[np.argmax(pred)] != names[np.argmax(y_test[cnt])]:\n",
        "      #   fig2.savefig(directories[6]+ '/' +str(cnt)+'_Plot6Accelerometer.png')\n",
        "      #   plt.close()\n",
        "      # else:\n",
        "      #   image_allocation(np.argmax(pred), fig2, stacked = False)\n",
        "      # ##############################################################\n",
        "\n",
        "    cnt_2 += 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ghWGnRSIqs8K"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "################################################################\n",
        "# Training + Test\n",
        "################################################################\n",
        "\n",
        "X = np.moveaxis(new_signal2, 0, -1)\n",
        "y = to_categorical(underhang_y)\n",
        "average_spectrum(X, y, 'Tran_Test_Hyper', model2_ = model2_)\n",
        "average_heatmap(X, y, 'Train_Test_Hyper', model2_ = model2_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BX9tqArEqs8K"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "################################################################\n",
        "# Training\n",
        "################################################################\n",
        "\n",
        "average_heatmap(X_train, y_train, 'Train_Hyper', model2_ = model2_)\n",
        "average_spectrum(X_train, y_train, 'Train_Hyper', model2_ = model2_)\n",
        "\n",
        "################################################################\n",
        "# Test\n",
        "################################################################\n",
        "\n",
        "average_heatmap(X_test, y_test, 'Test_Hyper', model2_ = model2_)\n",
        "average_spectrum(X_test, y_test, 'Test_Hyper', model2_ = model2_)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sparse CNN"
      ],
      "metadata": {
        "id": "I23Ysdv7nSyK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sparsity_masks(model,sparsity):\n",
        "    weights_list = model.get_weights()\n",
        "    masks = []\n",
        "    for weights in weights_list:\n",
        "        #We can ignore biases\n",
        "        if len(weights.shape) > 1:\n",
        "            weights_abs = np.abs(weights)\n",
        "            masks.append((weights_abs>np.percentile(weights_abs,sparsity))*1.)\n",
        "    return masks"
      ],
      "metadata": {
        "id": "9E2hfxgFnVaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "masks = create_sparsity_masks(model2_,1) #Closest 70% to 0"
      ],
      "metadata": {
        "id": "AKh4r5zenyXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_errors = 6\n",
        "input_shape = (input_size ,6)\n",
        "kernel_size = 9\n",
        "pool_size = 2\n",
        "\n",
        "sparse_model =  Sequential([\n",
        "                    Conv1D(filters=16,\n",
        "                                    kernel_size=13,\n",
        "                                    activation='relu',\n",
        "                                    input_shape=input_shape,\n",
        "                                    padding = 'same',\n",
        "                                    kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4),\n",
        "                                    bias_regularizer=regularizers.L2(1e-4),\n",
        "                                    activity_regularizer=regularizers.L2(1e-5)),\n",
        "\n",
        "                    BatchNormalization(),\n",
        "\n",
        "                    Dropout(0.1),\n",
        "\n",
        "\n",
        "                    Conv1D(filters=32,\n",
        "                                    kernel_size=13,\n",
        "                                    activation='relu',\n",
        "                                    padding = 'same',\n",
        "                                    kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4),\n",
        "                                    bias_regularizer=regularizers.L2(1e-4),\n",
        "                                    activity_regularizer=regularizers.L2(1e-5)),\n",
        "\n",
        "                    MaxPooling1D(pool_size),\n",
        "\n",
        "                    BatchNormalization(),\n",
        "\n",
        "                    Conv1D(filters=128,\n",
        "                                    kernel_size=13,\n",
        "                                    activation='relu',\n",
        "                                    padding = 'same',\n",
        "                                    kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4),\n",
        "                                    bias_regularizer=regularizers.L2(1e-4),\n",
        "                                    activity_regularizer=regularizers.L2(1e-5)),\n",
        "\n",
        "                    MaxPooling1D(pool_size),\n",
        "\n",
        "                    # dropout added as regularizer\n",
        "                    Dropout(0.1),\n",
        "\n",
        "                    Conv1D(filters=32,\n",
        "                                    kernel_size=13,\n",
        "                                    activation='relu',\n",
        "                                    padding = 'same',\n",
        "                                    kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4),\n",
        "                                    bias_regularizer=regularizers.L2(1e-4),\n",
        "                                    activity_regularizer=regularizers.L2(1e-5)),\n",
        "\n",
        "                    MaxPooling1D(pool_size),\n",
        "\n",
        "                    Conv1D(filters=16,\n",
        "                                    kernel_size=13,\n",
        "                                    activation='relu',\n",
        "                                    padding = 'same',\n",
        "                                    kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4),\n",
        "                                    bias_regularizer=regularizers.L2(1e-4),\n",
        "                                    activity_regularizer=regularizers.L2(1e-5)),\n",
        "\n",
        "                    MaxPooling1D(pool_size),\n",
        "\n",
        "\n",
        "                    Flatten(),\n",
        "\n",
        "                    Dense(num_errors),\n",
        "                    Activation('softmax')\n",
        "\n",
        "  ])\n",
        "sparse_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-io_skyeohln",
        "outputId": "62d5f2ff-b5b4-4750-b8bc-a1c4378eacaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_63 (Conv1D)          (None, 5000, 16)          1264      \n",
            "                                                                 \n",
            " batch_normalization_35 (Bat  (None, 5000, 16)         64        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_18 (Dropout)        (None, 5000, 16)          0         \n",
            "                                                                 \n",
            " conv1d_64 (Conv1D)          (None, 5000, 32)          6688      \n",
            "                                                                 \n",
            " max_pooling1d_38 (MaxPoolin  (None, 2500, 32)         0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_36 (Bat  (None, 2500, 32)         128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv1d_65 (Conv1D)          (None, 2500, 128)         53376     \n",
            "                                                                 \n",
            " max_pooling1d_39 (MaxPoolin  (None, 1250, 128)        0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " dropout_19 (Dropout)        (None, 1250, 128)         0         \n",
            "                                                                 \n",
            " conv1d_66 (Conv1D)          (None, 1250, 32)          53280     \n",
            "                                                                 \n",
            " max_pooling1d_40 (MaxPoolin  (None, 625, 32)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_67 (Conv1D)          (None, 625, 16)           6672      \n",
            "                                                                 \n",
            " max_pooling1d_41 (MaxPoolin  (None, 312, 16)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " flatten_9 (Flatten)         (None, 4992)              0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 6)                 29958     \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 151,430\n",
            "Trainable params: 151,334\n",
            "Non-trainable params: 96\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "########################################\n",
        "# Training the model now (Underhang)\n",
        "########################################\n",
        "import tensorflow as tf\n",
        "\n",
        "checkpoint_filepath = '/content/drive/MyDrive/sparse_model.hdf5'\n",
        "save_best_model = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath = checkpoint_filepath,\n",
        "    monitor=\"val_accuracy\",\n",
        "    verbose=1,\n",
        "    save_best_only=True,\n",
        "    mode=\"auto\",\n",
        "    save_freq=\"epoch\",\n",
        "    options=None,\n",
        "    initial_value_threshold=None\n",
        ")\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(\n",
        "    learning_rate= 0.01,\n",
        "    beta_1=0.9,\n",
        "    beta_2=0.999,\n",
        "    epsilon=1e-07,\n",
        "    amsgrad=False,\n",
        "    name=\"Adam\"\n",
        ")\n",
        "\n",
        "sparse_model.compile(loss='CategoricalCrossentropy',\n",
        "              optimizer= opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "sparse_model.set_weights(model2_.get_weights())\n",
        "\n",
        "# train the network\n",
        "output = sparse_model.fit(X_train, y_train, epochs = 100, batch_size=8,\n",
        "                    validation_data = (X_test , y_test),\n",
        "                    callbacks = [save_best_model])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pnMfzT-Up5Wo",
        "outputId": "9c4103b6-fe28-4149-b8f9-424d3841fc11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "195/195 [==============================] - ETA: 0s - loss: 3.7808 - accuracy: 0.5128\n",
            "Epoch 1: val_accuracy improved from -inf to 0.29923, saving model to /content/drive/MyDrive/sparse_model.hdf5\n",
            "195/195 [==============================] - 6s 20ms/step - loss: 3.7808 - accuracy: 0.5128 - val_loss: 11.8519 - val_accuracy: 0.2992\n",
            "Epoch 2/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.9011 - accuracy: 0.7591\n",
            "Epoch 2: val_accuracy improved from 0.29923 to 0.59847, saving model to /content/drive/MyDrive/sparse_model.hdf5\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.8974 - accuracy: 0.7596 - val_loss: 1.3569 - val_accuracy: 0.5985\n",
            "Epoch 3/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.7852 - accuracy: 0.7938\n",
            "Epoch 3: val_accuracy improved from 0.59847 to 0.83120, saving model to /content/drive/MyDrive/sparse_model.hdf5\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.7836 - accuracy: 0.7942 - val_loss: 1.0478 - val_accuracy: 0.8312\n",
            "Epoch 4/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.7166 - accuracy: 0.8361\n",
            "Epoch 4: val_accuracy improved from 0.83120 to 0.87468, saving model to /content/drive/MyDrive/sparse_model.hdf5\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.7144 - accuracy: 0.8365 - val_loss: 0.5609 - val_accuracy: 0.8747\n",
            "Epoch 5/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.5210 - accuracy: 0.8828\n",
            "Epoch 5: val_accuracy did not improve from 0.87468\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.5305 - accuracy: 0.8821 - val_loss: 2.0957 - val_accuracy: 0.6189\n",
            "Epoch 6/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.6791 - accuracy: 0.8640\n",
            "Epoch 6: val_accuracy improved from 0.87468 to 0.94118, saving model to /content/drive/MyDrive/sparse_model.hdf5\n",
            "195/195 [==============================] - 3s 15ms/step - loss: 0.6760 - accuracy: 0.8647 - val_loss: 0.3853 - val_accuracy: 0.9412\n",
            "Epoch 7/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 0.4338 - accuracy: 0.9249\n",
            "Epoch 7: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.4378 - accuracy: 0.9237 - val_loss: 1.0190 - val_accuracy: 0.6266\n",
            "Epoch 8/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.6285 - accuracy: 0.8563\n",
            "Epoch 8: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.6268 - accuracy: 0.8571 - val_loss: 1.0477 - val_accuracy: 0.6650\n",
            "Epoch 9/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 0.6067 - accuracy: 0.8802\n",
            "Epoch 9: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 0.6050 - accuracy: 0.8808 - val_loss: 0.7113 - val_accuracy: 0.8747\n",
            "Epoch 10/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.5633 - accuracy: 0.4806\n",
            "Epoch 10: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.5670 - accuracy: 0.4782 - val_loss: 1.8214 - val_accuracy: 0.2864\n",
            "Epoch 11/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.7759 - accuracy: 0.2850\n",
            "Epoch 11: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.7761 - accuracy: 0.2846 - val_loss: 1.7686 - val_accuracy: 0.2864\n",
            "Epoch 12/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.7606 - accuracy: 0.2758\n",
            "Epoch 12: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.7602 - accuracy: 0.2750 - val_loss: 1.7475 - val_accuracy: 0.2864\n",
            "Epoch 13/100\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.7439 - accuracy: 0.2801\n",
            "Epoch 13: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.7439 - accuracy: 0.2801 - val_loss: 1.7344 - val_accuracy: 0.2864\n",
            "Epoch 14/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.7299 - accuracy: 0.2719\n",
            "Epoch 14: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.7329 - accuracy: 0.2712 - val_loss: 1.7240 - val_accuracy: 0.2864\n",
            "Epoch 15/100\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.7226 - accuracy: 0.2756\n",
            "Epoch 15: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.7226 - accuracy: 0.2756 - val_loss: 1.7146 - val_accuracy: 0.2864\n",
            "Epoch 16/100\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.7165 - accuracy: 0.2767\n",
            "Epoch 16: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.7138 - accuracy: 0.2776 - val_loss: 1.7069 - val_accuracy: 0.2864\n",
            "Epoch 17/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.7037 - accuracy: 0.2889\n",
            "Epoch 17: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.7044 - accuracy: 0.2878 - val_loss: 1.6999 - val_accuracy: 0.2634\n",
            "Epoch 18/100\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6981 - accuracy: 0.2782\n",
            "Epoch 18: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6981 - accuracy: 0.2782 - val_loss: 1.6929 - val_accuracy: 0.2634\n",
            "Epoch 19/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6940 - accuracy: 0.2759\n",
            "Epoch 19: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6919 - accuracy: 0.2769 - val_loss: 1.6854 - val_accuracy: 0.2864\n",
            "Epoch 20/100\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.6838 - accuracy: 0.2799\n",
            "Epoch 20: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6843 - accuracy: 0.2788 - val_loss: 1.6787 - val_accuracy: 0.2864\n",
            "Epoch 21/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6764 - accuracy: 0.2841\n",
            "Epoch 21: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6781 - accuracy: 0.2833 - val_loss: 1.6738 - val_accuracy: 0.2864\n",
            "Epoch 22/100\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.6756 - accuracy: 0.2858\n",
            "Epoch 22: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6734 - accuracy: 0.2859 - val_loss: 1.6678 - val_accuracy: 0.2864\n",
            "Epoch 23/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6710 - accuracy: 0.2694\n",
            "Epoch 23: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6687 - accuracy: 0.2724 - val_loss: 1.6635 - val_accuracy: 0.2864\n",
            "Epoch 24/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6644 - accuracy: 0.2854\n",
            "Epoch 24: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6633 - accuracy: 0.2859 - val_loss: 1.6584 - val_accuracy: 0.2864\n",
            "Epoch 25/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6604 - accuracy: 0.2835\n",
            "Epoch 25: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6591 - accuracy: 0.2840 - val_loss: 1.6556 - val_accuracy: 0.2634\n",
            "Epoch 26/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6611 - accuracy: 0.2816\n",
            "Epoch 26: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6603 - accuracy: 0.2821 - val_loss: 1.6556 - val_accuracy: 0.2864\n",
            "Epoch 27/100\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.6587 - accuracy: 0.2858\n",
            "Epoch 27: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6562 - accuracy: 0.2859 - val_loss: 1.6527 - val_accuracy: 0.2864\n",
            "Epoch 28/100\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6526 - accuracy: 0.2833\n",
            "Epoch 28: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6526 - accuracy: 0.2833 - val_loss: 1.6498 - val_accuracy: 0.2864\n",
            "Epoch 29/100\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6492 - accuracy: 0.2763\n",
            "Epoch 29: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6492 - accuracy: 0.2763 - val_loss: 1.6455 - val_accuracy: 0.2864\n",
            "Epoch 30/100\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.6480 - accuracy: 0.2773\n",
            "Epoch 30: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6470 - accuracy: 0.2782 - val_loss: 1.6428 - val_accuracy: 0.2864\n",
            "Epoch 31/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6435 - accuracy: 0.2874\n",
            "Epoch 31: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6455 - accuracy: 0.2859 - val_loss: 1.6408 - val_accuracy: 0.2864\n",
            "Epoch 32/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6416 - accuracy: 0.2784\n",
            "Epoch 32: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6421 - accuracy: 0.2782 - val_loss: 1.6393 - val_accuracy: 0.2864\n",
            "Epoch 33/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6397 - accuracy: 0.2816\n",
            "Epoch 33: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6403 - accuracy: 0.2814 - val_loss: 1.6368 - val_accuracy: 0.2864\n",
            "Epoch 34/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6403 - accuracy: 0.2835\n",
            "Epoch 34: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6389 - accuracy: 0.2859 - val_loss: 1.6353 - val_accuracy: 0.2864\n",
            "Epoch 35/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6371 - accuracy: 0.2822\n",
            "Epoch 35: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6371 - accuracy: 0.2814 - val_loss: 1.6339 - val_accuracy: 0.2864\n",
            "Epoch 36/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6370 - accuracy: 0.2784\n",
            "Epoch 36: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6362 - accuracy: 0.2795 - val_loss: 1.6329 - val_accuracy: 0.2864\n",
            "Epoch 37/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6356 - accuracy: 0.2861\n",
            "Epoch 37: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6352 - accuracy: 0.2859 - val_loss: 1.6316 - val_accuracy: 0.2864\n",
            "Epoch 38/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6326 - accuracy: 0.2874\n",
            "Epoch 38: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6339 - accuracy: 0.2859 - val_loss: 1.6309 - val_accuracy: 0.2864\n",
            "Epoch 39/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6380 - accuracy: 0.2790\n",
            "Epoch 39: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6373 - accuracy: 0.2795 - val_loss: 1.6422 - val_accuracy: 0.2864\n",
            "Epoch 40/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6414 - accuracy: 0.2796\n",
            "Epoch 40: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6404 - accuracy: 0.2814 - val_loss: 1.6357 - val_accuracy: 0.2864\n",
            "Epoch 41/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6362 - accuracy: 0.2867\n",
            "Epoch 41: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6366 - accuracy: 0.2859 - val_loss: 1.6330 - val_accuracy: 0.2864\n",
            "Epoch 42/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6360 - accuracy: 0.2777\n",
            "Epoch 42: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6347 - accuracy: 0.2795 - val_loss: 1.6314 - val_accuracy: 0.2864\n",
            "Epoch 43/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6429 - accuracy: 0.2876\n",
            "Epoch 43: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6438 - accuracy: 0.2865 - val_loss: 1.6309 - val_accuracy: 0.2864\n",
            "Epoch 44/100\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6331 - accuracy: 0.2859\n",
            "Epoch 44: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6331 - accuracy: 0.2859 - val_loss: 1.6295 - val_accuracy: 0.2864\n",
            "Epoch 45/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6326 - accuracy: 0.2777\n",
            "Epoch 45: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6314 - accuracy: 0.2776 - val_loss: 1.6286 - val_accuracy: 0.2864\n",
            "Epoch 46/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6304 - accuracy: 0.2796\n",
            "Epoch 46: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6306 - accuracy: 0.2788 - val_loss: 1.6286 - val_accuracy: 0.2864\n",
            "Epoch 47/100\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6305 - accuracy: 0.2737\n",
            "Epoch 47: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6305 - accuracy: 0.2737 - val_loss: 1.6269 - val_accuracy: 0.2864\n",
            "Epoch 48/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6295 - accuracy: 0.2861\n",
            "Epoch 48: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6295 - accuracy: 0.2859 - val_loss: 1.6267 - val_accuracy: 0.2864\n",
            "Epoch 49/100\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6290 - accuracy: 0.2814\n",
            "Epoch 49: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6290 - accuracy: 0.2814 - val_loss: 1.6259 - val_accuracy: 0.2864\n",
            "Epoch 50/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6250 - accuracy: 0.2876\n",
            "Epoch 50: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6290 - accuracy: 0.2859 - val_loss: 1.6253 - val_accuracy: 0.2864\n",
            "Epoch 51/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6282 - accuracy: 0.2816\n",
            "Epoch 51: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6286 - accuracy: 0.2808 - val_loss: 1.6269 - val_accuracy: 0.2634\n",
            "Epoch 52/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6277 - accuracy: 0.2803\n",
            "Epoch 52: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6277 - accuracy: 0.2808 - val_loss: 1.6253 - val_accuracy: 0.2864\n",
            "Epoch 53/100\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6275 - accuracy: 0.2859\n",
            "Epoch 53: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6275 - accuracy: 0.2859 - val_loss: 1.6256 - val_accuracy: 0.2864\n",
            "Epoch 54/100\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6271 - accuracy: 0.2859\n",
            "Epoch 54: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6271 - accuracy: 0.2859 - val_loss: 1.6247 - val_accuracy: 0.2864\n",
            "Epoch 55/100\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6272 - accuracy: 0.2814\n",
            "Epoch 55: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6272 - accuracy: 0.2814 - val_loss: 1.6254 - val_accuracy: 0.2864\n",
            "Epoch 56/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6269 - accuracy: 0.2854\n",
            "Epoch 56: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6264 - accuracy: 0.2859 - val_loss: 1.6250 - val_accuracy: 0.2864\n",
            "Epoch 57/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6392 - accuracy: 0.2841\n",
            "Epoch 57: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6385 - accuracy: 0.2840 - val_loss: 1.6289 - val_accuracy: 0.2864\n",
            "Epoch 58/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6288 - accuracy: 0.2745\n",
            "Epoch 58: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6297 - accuracy: 0.2737 - val_loss: 1.6258 - val_accuracy: 0.2864\n",
            "Epoch 59/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6302 - accuracy: 0.2778\n",
            "Epoch 59: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6291 - accuracy: 0.2788 - val_loss: 1.6253 - val_accuracy: 0.2864\n",
            "Epoch 60/100\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.6276 - accuracy: 0.2858\n",
            "Epoch 60: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6276 - accuracy: 0.2859 - val_loss: 1.6253 - val_accuracy: 0.2864\n",
            "Epoch 61/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6284 - accuracy: 0.2861\n",
            "Epoch 61: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6282 - accuracy: 0.2859 - val_loss: 1.6247 - val_accuracy: 0.2864\n",
            "Epoch 62/100\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6275 - accuracy: 0.2801\n",
            "Epoch 62: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6275 - accuracy: 0.2801 - val_loss: 1.6254 - val_accuracy: 0.2864\n",
            "Epoch 63/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6298 - accuracy: 0.2759\n",
            "Epoch 63: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6283 - accuracy: 0.2756 - val_loss: 1.6251 - val_accuracy: 0.2864\n",
            "Epoch 64/100\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6281 - accuracy: 0.2859\n",
            "Epoch 64: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6281 - accuracy: 0.2859 - val_loss: 1.6249 - val_accuracy: 0.2864\n",
            "Epoch 65/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6282 - accuracy: 0.2745\n",
            "Epoch 65: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6276 - accuracy: 0.2731 - val_loss: 1.6254 - val_accuracy: 0.2864\n",
            "Epoch 66/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6265 - accuracy: 0.2772\n",
            "Epoch 66: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6272 - accuracy: 0.2776 - val_loss: 1.6248 - val_accuracy: 0.2864\n",
            "Epoch 67/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6258 - accuracy: 0.2777\n",
            "Epoch 67: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6273 - accuracy: 0.2788 - val_loss: 1.6249 - val_accuracy: 0.2864\n",
            "Epoch 68/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6266 - accuracy: 0.2777\n",
            "Epoch 68: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6277 - accuracy: 0.2782 - val_loss: 1.6248 - val_accuracy: 0.2864\n",
            "Epoch 69/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6291 - accuracy: 0.2861\n",
            "Epoch 69: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6281 - accuracy: 0.2859 - val_loss: 1.6243 - val_accuracy: 0.2864\n",
            "Epoch 70/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6274 - accuracy: 0.2887\n",
            "Epoch 70: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6271 - accuracy: 0.2885 - val_loss: 1.6259 - val_accuracy: 0.2634\n",
            "Epoch 71/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6284 - accuracy: 0.2720\n",
            "Epoch 71: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6282 - accuracy: 0.2718 - val_loss: 1.6251 - val_accuracy: 0.2864\n",
            "Epoch 72/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6272 - accuracy: 0.2854\n",
            "Epoch 72: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6271 - accuracy: 0.2859 - val_loss: 1.6263 - val_accuracy: 0.2864\n",
            "Epoch 73/100\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6276 - accuracy: 0.2782\n",
            "Epoch 73: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6276 - accuracy: 0.2782 - val_loss: 1.6244 - val_accuracy: 0.2864\n",
            "Epoch 74/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6279 - accuracy: 0.2790\n",
            "Epoch 74: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6276 - accuracy: 0.2788 - val_loss: 1.6247 - val_accuracy: 0.2864\n",
            "Epoch 75/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6255 - accuracy: 0.2796\n",
            "Epoch 75: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6268 - accuracy: 0.2801 - val_loss: 1.6249 - val_accuracy: 0.2634\n",
            "Epoch 76/100\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6277 - accuracy: 0.2731\n",
            "Epoch 76: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6277 - accuracy: 0.2731 - val_loss: 1.6246 - val_accuracy: 0.2864\n",
            "Epoch 77/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6274 - accuracy: 0.2848\n",
            "Epoch 77: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6263 - accuracy: 0.2840 - val_loss: 1.6253 - val_accuracy: 0.2634\n",
            "Epoch 78/100\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6276 - accuracy: 0.2821\n",
            "Epoch 78: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6276 - accuracy: 0.2821 - val_loss: 1.6249 - val_accuracy: 0.2864\n",
            "Epoch 79/100\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6272 - accuracy: 0.2782\n",
            "Epoch 79: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6272 - accuracy: 0.2782 - val_loss: 1.6250 - val_accuracy: 0.2864\n",
            "Epoch 80/100\n",
            "192/195 [============================>.] - ETA: 0s - loss: 1.6295 - accuracy: 0.2852\n",
            "Epoch 80: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6274 - accuracy: 0.2859 - val_loss: 1.6249 - val_accuracy: 0.2864\n",
            "Epoch 81/100\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6273 - accuracy: 0.2859\n",
            "Epoch 81: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6273 - accuracy: 0.2859 - val_loss: 1.6246 - val_accuracy: 0.2864\n",
            "Epoch 82/100\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6261 - accuracy: 0.2808\n",
            "Epoch 82: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6261 - accuracy: 0.2808 - val_loss: 1.6246 - val_accuracy: 0.2864\n",
            "Epoch 83/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6286 - accuracy: 0.2753\n",
            "Epoch 83: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6274 - accuracy: 0.2776 - val_loss: 1.6244 - val_accuracy: 0.2864\n",
            "Epoch 84/100\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6277 - accuracy: 0.2782\n",
            "Epoch 84: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6277 - accuracy: 0.2782 - val_loss: 1.6250 - val_accuracy: 0.2864\n",
            "Epoch 85/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6262 - accuracy: 0.2867\n",
            "Epoch 85: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6274 - accuracy: 0.2859 - val_loss: 1.6245 - val_accuracy: 0.2864\n",
            "Epoch 86/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6484 - accuracy: 0.2759\n",
            "Epoch 86: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6464 - accuracy: 0.2776 - val_loss: 1.6299 - val_accuracy: 0.2864\n",
            "Epoch 87/100\n",
            "193/195 [============================>.] - ETA: 0s - loss: 1.6294 - accuracy: 0.2778\n",
            "Epoch 87: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6302 - accuracy: 0.2788 - val_loss: 1.6270 - val_accuracy: 0.2864\n",
            "Epoch 88/100\n",
            "195/195 [==============================] - ETA: 0s - loss: 1.6292 - accuracy: 0.2859\n",
            "Epoch 88: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6292 - accuracy: 0.2859 - val_loss: 1.6258 - val_accuracy: 0.2864\n",
            "Epoch 89/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6296 - accuracy: 0.2809\n",
            "Epoch 89: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6289 - accuracy: 0.2814 - val_loss: 1.6258 - val_accuracy: 0.2864\n",
            "Epoch 90/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6274 - accuracy: 0.2790\n",
            "Epoch 90: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6279 - accuracy: 0.2801 - val_loss: 1.6262 - val_accuracy: 0.2864\n",
            "Epoch 91/100\n",
            "194/195 [============================>.] - ETA: 0s - loss: 1.6284 - accuracy: 0.2861\n",
            "Epoch 91: val_accuracy did not improve from 0.94118\n",
            "195/195 [==============================] - 3s 14ms/step - loss: 1.6284 - accuracy: 0.2859 - val_loss: 1.6254 - val_accuracy: 0.2864\n",
            "Epoch 92/100\n",
            "146/195 [=====================>........] - ETA: 0s - loss: 1.6284 - accuracy: 0.2671"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-140-d7fba784a169>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m output = sparse_model.fit(X_train, y_train, epochs = 100, batch_size=8,\n\u001b[1;32m     35\u001b[0m                     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                     callbacks = [save_best_model])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1387\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \"\"\"\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    295\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m       raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    316\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1107\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m       \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m     \u001b[0;31m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1221\u001b[0m     \"\"\"\n\u001b[1;32m   1222\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1223\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1224\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1187\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "######################################################\n",
        "# Setting the weights for the best model found and saving the model\n",
        "sparse_model.load_weights(checkpoint_filepath)\n",
        "# Guardar el Modelo (Just only once if u are running the network again)\n",
        "sparse_model.save('/content/drive/MyDrive/Sparse_CNN.h5')\n",
        "\n",
        "######################################################################\n",
        "# Loading model (already trained)\n",
        "sparse_model = keras.models.load_model('/content/drive/MyDrive/Sparse_CNN.h5')\n",
        "#####################################################################"
      ],
      "metadata": {
        "id": "gAePetLSpwBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Minimum value of cross entropy\n",
        "\n",
        "print(\"The minimum loss training found is:\", round(min(output.history['loss']),6) ,\" and was found in epoch number:\", np.argmin(output.history['loss']))\n",
        "print(\"The minimum loss test found is:\", round(min(output.history['val_loss']),6) ,\" and was found in epoch number:\", np.argmin(output.history['val_loss']))\n",
        "\n",
        "# Maximum accuracy\n",
        "\n",
        "print(\"The maximum accuracy training found is:\", round(100*max(output.history['accuracy']),2) ,\"% and was found in epoch number:\", np.argmax(output.history['accuracy']))\n",
        "print(\"The maximum accuracy test found is:\", round(100*max(output.history['val_accuracy']),2) ,\"% and was found in epoch number:\", np.argmax(output.history['val_accuracy']))"
      ],
      "metadata": {
        "id": "s2B5MdMTvYj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting loss and val_loss vs epochs\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20,10))\n",
        "fig.suptitle('History Epochs - Loss')\n",
        "\n",
        "ax1.plot(range(100),output.history['loss'],output.history['val_loss'])\n",
        "ax1.set(ylabel= \"Loss\", xlabel = \"epochs\")\n",
        "ax1.legend([\"Training\", \"Validation\"],loc = \"best\")\n",
        "ax1.set_ylim([0, 0.5])\n",
        "\n",
        "ax2.plot(range(100),output.history['loss'],output.history['val_loss'])\n",
        "ax2.set(ylabel= \"Loss\", xlabel = \"epochs\")\n",
        "ax2.legend([\"Training\", \"Validation\"],loc = \"best\")\n",
        "ax2.set_xlim([20,100])\n",
        "ax2.set_ylim([0, 0.4])"
      ],
      "metadata": {
        "id": "BYxaMTgZvcPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting accuracy and val_accuracy vs epochs\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20,10))\n",
        "fig.suptitle('History Epochs - Accuracy')\n",
        "\n",
        "ax1.plot(range(100),output.history['accuracy'],output.history['val_accuracy'])\n",
        "ax1.set(ylabel= \"Loss\", xlabel = \"epochs\")\n",
        "ax1.legend([\"Training\", \"Validation\"],loc = \"best\")\n",
        "ax1.set_ylim([0.7, 1.05])\n",
        "\n",
        "ax2.plot(range(100),output.history['accuracy'],output.history['val_accuracy'])\n",
        "ax2.set(ylabel= \"Loss\", xlabel = \"epochs\")\n",
        "ax2.legend([\"Training\", \"Validation\"],loc = \"best\")\n",
        "ax2.set_xlim([20,100])\n",
        "ax2.set_ylim([0.94, 1.02])"
      ],
      "metadata": {
        "id": "3s_2cvaVvgnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_, acc = sparse_model.evaluate(X_test,\n",
        "                        y_test,\n",
        "                        batch_size=32)\n",
        "print(\"\\nTest accuracy: %.1f%%\" % (100.0 * acc))\n",
        "\n",
        "_, acc = sparse_model.evaluate(X_train,\n",
        "                        y_train,\n",
        "                        batch_size=32)\n",
        "print(\"\\Train accuracy: %.1f%%\" % (100.0 * acc))"
      ],
      "metadata": {
        "id": "kruQBAq_vkBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# COnfusion matrix resulting\n",
        "\n",
        "y_pred = sparse_model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "underhang_y_test_cm = np.argmax(y_test, axis = -1)\n",
        "matrix = confusion_matrix(underhang_y_test_cm, y_pred)\n",
        "\n",
        "figure = plt.figure(figsize = (12,12))\n",
        "\n",
        "ax = sns.heatmap(matrix, annot=True, cmap='Blues',fmt = 'g')\n",
        "\n",
        "ax.set_title('Underhang Test - Confusion Matrix\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted Values')\n",
        "ax.set_ylabel('Actual Values ');\n",
        "\n",
        "## Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels(['Normal','Hor Mis','Imbalance', 'Ver Mis', 'Overhang', 'Underhang'])\n",
        "ax.yaxis.set_ticklabels(['Normal','Hor Mis','Imbalance', 'Ver Mis', 'Overhang', 'Underhang'])"
      ],
      "metadata": {
        "id": "uZSO3Krtvnfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy per class\n",
        "names = ['Normal','Hor Mis','Imbalance', 'Ver Mis', 'Overhang', 'Underhang']\n",
        "\n",
        "for i in range(6):\n",
        "  ac =0\n",
        "  tot = 0\n",
        "  for j in range(6):\n",
        "    if i == j:\n",
        "      ac += matrix[i][j]\n",
        "      tot += matrix[i][j]\n",
        "    else:\n",
        "      tot += matrix[i][j]\n",
        "\n",
        "  print(\"The accuracy for class\", names[i], 'is:', round(100*ac/tot, 2), '% = ', ac, '/', tot)"
      ],
      "metadata": {
        "id": "TG37VQj8vqek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liyXIyH0v656"
      },
      "source": [
        "### Explainability using Grad - CAM techniques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-BX7NyWFv656"
      },
      "outputs": [],
      "source": [
        "# Needed for visualization\n",
        "\n",
        "layer_name = \"conv1d_24\"  # last layer\n",
        "cnt = 0\n",
        "xticks = [int(xf[i]) for i in range(0, input_size, 749)]\n",
        "ticks = [i for i in range(0, input_size, 749)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61b5d8b3-9d40-4431-ed69-bbaf67861bf4",
        "id": "L7u-pQp5v657"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: UserWarning: Attempting to set identical bottom == top == 0.0 results in singular transformations; automatically expanding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "390\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: UserWarning: Attempting to set identical bottom == top == 0.0 results in singular transformations; automatically expanding.\n"
          ]
        }
      ],
      "source": [
        "###########################################################################\n",
        "# Independent heatmaps for each data point\n",
        "###########################################################################\n",
        "\n",
        "cnt_2 = 0\n",
        "\n",
        "for i in X_test:\n",
        "    data = np.expand_dims(i,0)\n",
        "    pred = sparse_model.predict(data)\n",
        "    # Printing a class in particular\n",
        "    actual_class = np.argmax(y_test[cnt_2])\n",
        "\n",
        "\n",
        "    if np.argmax(pred) != actual_class:\n",
        "\n",
        "      heatmap = grad_cam(layer_name,data)\n",
        "\n",
        "      fig1, (ax1) = plt.subplots(1, sharex = True, figsize = (30,10))\n",
        "\n",
        "      ###########################################################################\n",
        "      # AX1 - CNN selection with stacked data\n",
        "      ###########################################################################\n",
        "\n",
        "      ax1.imshow(heatmap, cmap='Reds', aspect=\"auto\" ,extent=[0,5000,i.min(),i.max()], alpha=0.8)\n",
        "      ax1.plot(i,'k')\n",
        "      ax1.set_ylabel('Normalised Amplitud frequency')\n",
        "      ax1.set_title('HeatMap for Incorrect data point')\n",
        "\n",
        "      # Plotting 7 plots:\n",
        "      # - Stacking on all 6 frequencies\n",
        "      # - Axial/Radial/Tangencial Underhang Accelerometer\n",
        "      # - Axial/Radial/Tangencial Overhang Accelerometer\n",
        "\n",
        "      ###########################################################################\n",
        "      # AX2 - Stacked data with colors\n",
        "      ###########################################################################\n",
        "\n",
        "\n",
        "      # df = pd.DataFrame(i)\n",
        "\n",
        "      # ax2.plot(df.iloc[:,0], label = 'AxialUn')\n",
        "      # ax2.plot(df.iloc[:,1], label = 'RadialUn')\n",
        "      # ax2.plot(df.iloc[:,2], label = 'TangUn')\n",
        "      # ax2.plot(df.iloc[:,3], label = 'AxialOv')\n",
        "      # ax2.plot(df.iloc[:,4], label = 'RadialOv')\n",
        "      # ax2.plot(df.iloc[:,5], label = 'TangOv')\n",
        "      # ax2.set_title('Stacked data with colors')\n",
        "      # ax2.set_xlabel('Frequency (Hz)')\n",
        "      # ax2.set_xticks(ticks = ticks)\n",
        "      # ax2.set_xticklabels(xticks)\n",
        "      # ax2.set_ylabel('Normalised Amplitud frequency')\n",
        "      # ax2.legend()\n",
        "\n",
        "\n",
        "      fig1.savefig(directories[6] + '/' + str(cnt)+'_PlotStacked.png')\n",
        "      plt.close()\n",
        "\n",
        "      # Saving photos\n",
        "      ###########################################<################\n",
        "      # if names[np.argmax(pred)] != names[np.argmax(y_test[cnt])]:\n",
        "      #   fig1.savefig(directories[6] + '/' + str(cnt)+'_PlotStacked.png')\n",
        "      #   plt.close()\n",
        "      # else:\n",
        "      #   image_allocation(np.argmax(pred), fig1)\n",
        "      ##############################################################\n",
        "\n",
        "\n",
        "      ###########################################################################\n",
        "      # AX1 - 6 remaining graphs regarding accelerometer\n",
        "      ###########################################################################\n",
        "\n",
        "      # fig2, (ax1, ax2, ax3, ax4, ax5, ax6) = plt.subplots(6, sharex = True, figsize = (30,30))\n",
        "\n",
        "      # ax1.imshow(heatmap,cmap='Greens', aspect=\"auto\", interpolation='nearest',extent=[0,7509,i.min(),i.max()], alpha=0.8)\n",
        "      # ax1.plot(df.iloc[:,0], 'k', label = 'AxialUn')\n",
        "      # ax1.set_title('Axial - Underhang Accelerometer')\n",
        "      # ax1.set_ylabel('Normalised Amplitud frequency')\n",
        "\n",
        "      # ax2.imshow(heatmap,cmap='Greens', aspect=\"auto\", interpolation='nearest',extent=[0,7509,i.min(),i.max()], alpha=0.8)\n",
        "      # ax2.plot(df.iloc[:,1], 'k', label = 'RadialUn')\n",
        "      # ax2.set_title('Radiale - Underhang Accelerometer')\n",
        "      # ax2.set_ylabel('Normalised Amplitud frequency')\n",
        "\n",
        "      # ax3.imshow(heatmap,cmap='Greens', aspect=\"auto\", interpolation='nearest',extent=[0,7509,i.min(),i.max()], alpha=0.8)\n",
        "      # ax3.plot(df.iloc[:,2], 'k', label = 'TangUn')\n",
        "      # ax3.set_title('Tangencial - Underhang Accelerometer')\n",
        "      # ax3.set_ylabel('Normalised Amplitud frequency')\n",
        "\n",
        "      # ax4.imshow(heatmap,cmap='Greens', aspect=\"auto\", interpolation='nearest',extent=[0,7509,i.min(),i.max()], alpha=0.8)\n",
        "      # ax4.plot(df.iloc[:,3], 'k', label = 'AxialOv')\n",
        "      # ax4.set_title('Axial - Overhang Accelerometer')\n",
        "      # ax4.set_ylabel('Normalised Amplitud frequency')\n",
        "\n",
        "      # ax5.imshow(heatmap,cmap='Greens', aspect=\"auto\", interpolation='nearest',extent=[0,7509,i.min(),i.max()], alpha=0.8)\n",
        "      # ax5.plot(df.iloc[:,4], 'k', label = 'RadialOv')\n",
        "      # ax5.set_title('Radiale - Underhang Accelerometer')\n",
        "      # ax5.set_ylabel('Normalised Amplitud frequency')\n",
        "\n",
        "      # ax6.imshow(heatmap,cmap='Greens', aspect=\"auto\", interpolation='nearest',extent=[0,7509,i.min(),i.max()], alpha=0.8)\n",
        "      # ax6.plot(df.iloc[:,5], 'k', label = 'TangOv')\n",
        "      # ax6.set_title('Tangecial - Underhang Accelerometer')\n",
        "      # ax6.set_xlabel('Frequency (Hz)')\n",
        "      # ax6.set_xlim([0,7509])\n",
        "      # ax6.set_ylabel('Normalised Amplitud frequency')\n",
        "      # ax6.set_xticks(ticks = ticks)\n",
        "      # ax6.set_xticklabels(xticks)\n",
        "\n",
        "      # # Saving photos\n",
        "      # ###########################################<################\n",
        "      # if names[np.argmax(pred)] != names[np.argmax(y_test[cnt])]:\n",
        "      #   fig2.savefig(directories[6]+ '/' +str(cnt)+'_Plot6Accelerometer.png')\n",
        "      #   plt.close()\n",
        "      # else:\n",
        "      #   image_allocation(np.argmax(pred), fig2, stacked = False)\n",
        "      # ##############################################################\n",
        "\n",
        "    cnt_2 += 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGop6RY7v658"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "################################################################\n",
        "# Training + Test\n",
        "################################################################\n",
        "\n",
        "X = np.moveaxis(new_signal2, 0, -1)\n",
        "y = to_categorical(underhang_y)\n",
        "average_spectrum(X, y, 'Tran_Test_Sparse', model2_ = sparse_model)\n",
        "average_heatmap(X, y, 'Train_Test_Sparse', model2_ = sparse_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9q-hJriOv658"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "################################################################\n",
        "# Training\n",
        "################################################################\n",
        "\n",
        "average_heatmap(X_train, y_train, 'Train_Sparse', model2_ = sparse_model)\n",
        "average_spectrum(X_train, y_train, 'Train_sparse', model2_ = sparse_model)\n",
        "\n",
        "################################################################\n",
        "# Test\n",
        "################################################################\n",
        "\n",
        "average_heatmap(X_test, y_test, 'Test_Sparse', model2_ = sparse_model)\n",
        "average_spectrum(X_test, y_test, 'Test_Sparse', model2_ = sparse_model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K8da0iSwv6a6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_gYKFT_xRVn"
      },
      "source": [
        "## Normal and Underhang"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXrPzvJXxTYU"
      },
      "outputs": [],
      "source": [
        "##############################\n",
        "# Creating labels\n",
        "##############################\n",
        "\n",
        "underhang_y = []\n",
        "\n",
        "# Normal\n",
        "for i in range(49):\n",
        "  underhang_y.append(0)\n",
        "\n",
        "# Underhang\n",
        "\n",
        "# Cage Fault\n",
        "for i in range(188):\n",
        "  underhang_y.append(1)\n",
        "\n",
        "# Outer Race\n",
        "for i in range(184):\n",
        "  underhang_y.append(2)\n",
        "\n",
        "# Ball Fault\n",
        "for i in range(186):\n",
        "  underhang_y.append(3)\n",
        "\n",
        "underhang_y = np.array(underhang_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LT9m917zxtNz",
        "outputId": "154c5070-d29d-4609-a6f8-cb65a7374f23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "########################################\n",
            "# Underhang Accelerometer\n",
            "########################################\n",
            "\n",
            "Underhang - Training size: (485, 5000, 6)\n",
            "Underhang - Test size: (122, 5000, 6)\n",
            "Underhang_y - Training size: (485, 4)\n",
            "Underhang_y - Test size: (122, 4)\n"
          ]
        }
      ],
      "source": [
        "##########################################################\n",
        "# Splitting and shuffling the data\n",
        "##########################################################\n",
        "\n",
        "new_signal2 = new_signal.reshape(6, 1951, input_size)\n",
        "new_sig_bin = np.concatenate((new_signal2[:,0:49,:] , new_signal2[:,1393:1951, :]), axis = 1)\n",
        "\n",
        "# Splitting it 65% - 35% (train-test)\n",
        "all_indices = list(range(607))\n",
        "# , stratify = underhang_y\n",
        "train_ind, test_ind = train_test_split(all_indices,stratify = underhang_y, test_size=0.2, shuffle = True,\n",
        "                                       random_state = 420)\n",
        "\n",
        "X_train = np.moveaxis(new_sig_bin[:,train_ind,:], 0, -1)\n",
        "X_test = np.moveaxis(new_sig_bin[:,test_ind, :], 0, -1)\n",
        "# One-hot encoding\n",
        "y_train = to_categorical(underhang_y[train_ind])\n",
        "y_test = to_categorical(underhang_y[test_ind])\n",
        "\n",
        "print(\"\"\"\n",
        "########################################\n",
        "# Underhang Accelerometer\n",
        "########################################\n",
        "\"\"\")\n",
        "print('Underhang - Training size:', X_train.shape)\n",
        "print('Underhang - Test size:', X_test.shape)\n",
        "print('Underhang_y - Training size:', y_train.shape)\n",
        "print('Underhang_y - Test size:', y_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjMU3WbczfDC",
        "outputId": "5e1afa0e-2bcf-4b2a-ce45-964be40e2eff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_30 (Conv1D)          (None, 5000, 16)          1264      \n",
            "                                                                 \n",
            " batch_normalization_12 (Bat  (None, 5000, 16)         64        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 5000, 16)          0         \n",
            "                                                                 \n",
            " conv1d_31 (Conv1D)          (None, 5000, 32)          6688      \n",
            "                                                                 \n",
            " max_pooling1d_24 (MaxPoolin  (None, 2500, 32)         0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_13 (Bat  (None, 2500, 32)         128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv1d_32 (Conv1D)          (None, 2500, 128)         53376     \n",
            "                                                                 \n",
            " max_pooling1d_25 (MaxPoolin  (None, 1250, 128)        0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 1250, 128)         0         \n",
            "                                                                 \n",
            " conv1d_33 (Conv1D)          (None, 1250, 32)          53280     \n",
            "                                                                 \n",
            " max_pooling1d_26 (MaxPoolin  (None, 625, 32)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_34 (Conv1D)          (None, 625, 16)           6672      \n",
            "                                                                 \n",
            " max_pooling1d_27 (MaxPoolin  (None, 312, 16)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 4992)              0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 4)                 19972     \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 4)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 141,444\n",
            "Trainable params: 141,348\n",
            "Non-trainable params: 96\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Obtaining the same model as described in the paper\n",
        "\n",
        "num_errors = 4\n",
        "input_shape = (input_size ,6)\n",
        "kernel_size = 9\n",
        "pool_size = 2\n",
        "dropout = 0.1\n",
        "\n",
        "model2_ =  Sequential([\n",
        "                    Conv1D(filters=16,\n",
        "                                    kernel_size=13,\n",
        "                                    activation='relu',\n",
        "                                    input_shape=input_shape,\n",
        "                                    padding = 'same',\n",
        "                                    kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4),\n",
        "                                    bias_regularizer=regularizers.L2(1e-4),\n",
        "                                    activity_regularizer=regularizers.L2(1e-5)),\n",
        "\n",
        "                    BatchNormalization(),\n",
        "\n",
        "                    Dropout(dropout),\n",
        "\n",
        "                    Conv1D(filters=32,\n",
        "                                    kernel_size=13,\n",
        "                                    activation='relu',\n",
        "                                    padding = 'same',\n",
        "                                    kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4),\n",
        "                                    bias_regularizer=regularizers.L2(1e-4),\n",
        "                                    activity_regularizer=regularizers.L2(1e-5)),\n",
        "\n",
        "                    MaxPooling1D(pool_size),\n",
        "\n",
        "                    BatchNormalization(),\n",
        "\n",
        "                    Conv1D(filters=128,\n",
        "                                    kernel_size=13,\n",
        "                                    activation='relu',\n",
        "                                    padding = 'same',\n",
        "                                    kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4),\n",
        "                                    bias_regularizer=regularizers.L2(1e-4),\n",
        "                                    activity_regularizer=regularizers.L2(1e-5)),\n",
        "\n",
        "                    MaxPooling1D(pool_size),\n",
        "\n",
        "                    # dropout added as regularizer\n",
        "                    Dropout(dropout),\n",
        "\n",
        "                    Conv1D(filters=32,\n",
        "                                    kernel_size=13,\n",
        "                                    activation='relu',\n",
        "                                    padding = 'same',\n",
        "                                    kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4),\n",
        "                                    bias_regularizer=regularizers.L2(1e-4),\n",
        "                                    activity_regularizer=regularizers.L2(1e-5)),\n",
        "\n",
        "                    MaxPooling1D(pool_size),\n",
        "\n",
        "                    Conv1D(filters=16,\n",
        "                                    kernel_size=13,\n",
        "                                    activation='relu',\n",
        "                                    padding = 'same',\n",
        "                                    kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4),\n",
        "                                    bias_regularizer=regularizers.L2(1e-4),\n",
        "                                    activity_regularizer=regularizers.L2(1e-5)),\n",
        "\n",
        "                    MaxPooling1D(pool_size),\n",
        "\n",
        "\n",
        "                    Flatten(),\n",
        "\n",
        "                    Dense(num_errors),\n",
        "                    Activation('softmax')\n",
        "\n",
        "  ])\n",
        "model2_.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sbcbk69zfDC",
        "outputId": "04a6cd03-0ddd-449b-8b53-a94e0521ce95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.9157 - accuracy: 0.9138\n",
            "Epoch 1: val_accuracy improved from -inf to 0.31148, saving model to /content/drive/MyDrive/best_model.hdf5\n",
            "61/61 [==============================] - 3s 26ms/step - loss: 0.9192 - accuracy: 0.9113 - val_loss: 1.3362 - val_accuracy: 0.3115\n",
            "Epoch 2/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.6888 - accuracy: 0.9505\n",
            "Epoch 2: val_accuracy improved from 0.31148 to 0.51639, saving model to /content/drive/MyDrive/best_model.hdf5\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 0.6888 - accuracy: 0.9505 - val_loss: 1.3056 - val_accuracy: 0.5164\n",
            "Epoch 3/100\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.5323 - accuracy: 0.9873\n",
            "Epoch 3: val_accuracy improved from 0.51639 to 0.53279, saving model to /content/drive/MyDrive/best_model.hdf5\n",
            "61/61 [==============================] - 1s 19ms/step - loss: 0.5310 - accuracy: 0.9876 - val_loss: 1.3256 - val_accuracy: 0.5328\n",
            "Epoch 4/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.4600 - accuracy: 0.9959\n",
            "Epoch 4: val_accuracy improved from 0.53279 to 0.62295, saving model to /content/drive/MyDrive/best_model.hdf5\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 0.4600 - accuracy: 0.9959 - val_loss: 1.3732 - val_accuracy: 0.6230\n",
            "Epoch 5/100\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.4387 - accuracy: 0.9958\n",
            "Epoch 5: val_accuracy improved from 0.62295 to 0.65574, saving model to /content/drive/MyDrive/best_model.hdf5\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 0.4386 - accuracy: 0.9959 - val_loss: 1.1660 - val_accuracy: 0.6557\n",
            "Epoch 6/100\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.4126 - accuracy: 0.9833\n",
            "Epoch 6: val_accuracy improved from 0.65574 to 0.89344, saving model to /content/drive/MyDrive/best_model.hdf5\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 0.4130 - accuracy: 0.9835 - val_loss: 0.8506 - val_accuracy: 0.8934\n",
            "Epoch 7/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.3848 - accuracy: 0.9897\n",
            "Epoch 7: val_accuracy improved from 0.89344 to 0.97541, saving model to /content/drive/MyDrive/best_model.hdf5\n",
            "61/61 [==============================] - 1s 19ms/step - loss: 0.3848 - accuracy: 0.9897 - val_loss: 0.5406 - val_accuracy: 0.9754\n",
            "Epoch 8/100\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.3523 - accuracy: 0.9914\n",
            "Epoch 8: val_accuracy improved from 0.97541 to 0.98361, saving model to /content/drive/MyDrive/best_model.hdf5\n",
            "61/61 [==============================] - 1s 19ms/step - loss: 0.3509 - accuracy: 0.9918 - val_loss: 0.3947 - val_accuracy: 0.9836\n",
            "Epoch 9/100\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.3417 - accuracy: 0.9849\n",
            "Epoch 9: val_accuracy did not improve from 0.98361\n",
            "61/61 [==============================] - 1s 19ms/step - loss: 0.3408 - accuracy: 0.9856 - val_loss: 0.4719 - val_accuracy: 0.9672\n",
            "Epoch 10/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.3042 - accuracy: 0.9979\n",
            "Epoch 10: val_accuracy improved from 0.98361 to 1.00000, saving model to /content/drive/MyDrive/best_model.hdf5\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3042 - accuracy: 0.9979 - val_loss: 0.2588 - val_accuracy: 1.0000\n",
            "Epoch 11/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.3034 - accuracy: 0.9959\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 0.3034 - accuracy: 0.9959 - val_loss: 0.3124 - val_accuracy: 1.0000\n",
            "Epoch 12/100\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.2713 - accuracy: 1.0000\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 0.2699 - accuracy: 1.0000 - val_loss: 0.2305 - val_accuracy: 1.0000\n",
            "Epoch 13/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.2719 - accuracy: 0.9918\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 0.2719 - accuracy: 0.9918 - val_loss: 0.2283 - val_accuracy: 1.0000\n",
            "Epoch 14/100\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.2442 - accuracy: 1.0000\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.2435 - accuracy: 1.0000 - val_loss: 0.2176 - val_accuracy: 1.0000\n",
            "Epoch 15/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.2270 - accuracy: 1.0000\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.2270 - accuracy: 1.0000 - val_loss: 0.2061 - val_accuracy: 1.0000\n",
            "Epoch 16/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.2278 - accuracy: 0.9959\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.2278 - accuracy: 0.9959 - val_loss: 0.2010 - val_accuracy: 1.0000\n",
            "Epoch 17/100\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.2173 - accuracy: 0.9978\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.2165 - accuracy: 0.9979 - val_loss: 0.1962 - val_accuracy: 1.0000\n",
            "Epoch 18/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.2016 - accuracy: 0.9979\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.2016 - accuracy: 0.9979 - val_loss: 0.1882 - val_accuracy: 1.0000\n",
            "Epoch 19/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.2038 - accuracy: 0.9959\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.2038 - accuracy: 0.9959 - val_loss: 0.1799 - val_accuracy: 1.0000\n",
            "Epoch 20/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.1838 - accuracy: 0.9979\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.1838 - accuracy: 0.9979 - val_loss: 0.1683 - val_accuracy: 1.0000\n",
            "Epoch 21/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.1919 - accuracy: 0.9918\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.1919 - accuracy: 0.9918 - val_loss: 0.1701 - val_accuracy: 1.0000\n",
            "Epoch 22/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.1761 - accuracy: 1.0000\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.1761 - accuracy: 1.0000 - val_loss: 0.1610 - val_accuracy: 1.0000\n",
            "Epoch 23/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.1640 - accuracy: 0.9979\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 0.1640 - accuracy: 0.9979 - val_loss: 0.1494 - val_accuracy: 1.0000\n",
            "Epoch 24/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.1505 - accuracy: 1.0000\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 0.1505 - accuracy: 1.0000 - val_loss: 0.1428 - val_accuracy: 1.0000\n",
            "Epoch 25/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.1470 - accuracy: 1.0000\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 0.1470 - accuracy: 1.0000 - val_loss: 0.1365 - val_accuracy: 1.0000\n",
            "Epoch 26/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.1439 - accuracy: 1.0000\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 0.1439 - accuracy: 1.0000 - val_loss: 0.1316 - val_accuracy: 1.0000\n",
            "Epoch 27/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.1434 - accuracy: 0.9959\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 0.1434 - accuracy: 0.9959 - val_loss: 0.1316 - val_accuracy: 1.0000\n",
            "Epoch 28/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.1439 - accuracy: 0.9979\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 0.1439 - accuracy: 0.9979 - val_loss: 0.1302 - val_accuracy: 1.0000\n",
            "Epoch 29/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.1289 - accuracy: 1.0000\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 0.1289 - accuracy: 1.0000 - val_loss: 0.1250 - val_accuracy: 1.0000\n",
            "Epoch 30/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.1288 - accuracy: 1.0000\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.1288 - accuracy: 1.0000 - val_loss: 0.1166 - val_accuracy: 1.0000\n",
            "Epoch 31/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.1228 - accuracy: 1.0000\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.1228 - accuracy: 1.0000 - val_loss: 0.1114 - val_accuracy: 1.0000\n",
            "Epoch 32/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.1149 - accuracy: 1.0000\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 0.1149 - accuracy: 1.0000 - val_loss: 0.1076 - val_accuracy: 1.0000\n",
            "Epoch 33/100\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.1095 - accuracy: 1.0000\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 0.1096 - accuracy: 1.0000 - val_loss: 0.1028 - val_accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.1094 - accuracy: 1.0000\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 0.1092 - accuracy: 1.0000 - val_loss: 0.1002 - val_accuracy: 1.0000\n",
            "Epoch 35/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.1063 - accuracy: 1.0000\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 0.1063 - accuracy: 1.0000 - val_loss: 0.0978 - val_accuracy: 1.0000\n",
            "Epoch 36/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.1051 - accuracy: 1.0000\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 0.1051 - accuracy: 1.0000 - val_loss: 0.0968 - val_accuracy: 1.0000\n",
            "Epoch 37/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.1029 - accuracy: 0.9979\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 0.1029 - accuracy: 0.9979 - val_loss: 0.0971 - val_accuracy: 1.0000\n",
            "Epoch 38/100\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.1016 - accuracy: 1.0000\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.1013 - accuracy: 1.0000 - val_loss: 0.0928 - val_accuracy: 1.0000\n",
            "Epoch 39/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.1032 - accuracy: 0.9959\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.1032 - accuracy: 0.9959 - val_loss: 0.1072 - val_accuracy: 0.9918\n",
            "Epoch 40/100\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.0989 - accuracy: 1.0000\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 0.0988 - accuracy: 1.0000 - val_loss: 0.0890 - val_accuracy: 1.0000\n",
            "Epoch 41/100\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.0933 - accuracy: 1.0000\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 0.0933 - accuracy: 1.0000 - val_loss: 0.0865 - val_accuracy: 1.0000\n",
            "Epoch 42/100\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.0943 - accuracy: 0.9979\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 0.0947 - accuracy: 0.9979 - val_loss: 0.0949 - val_accuracy: 1.0000\n",
            "Epoch 43/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.1096 - accuracy: 0.9959\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 19ms/step - loss: 0.1096 - accuracy: 0.9959 - val_loss: 0.0931 - val_accuracy: 1.0000\n",
            "Epoch 44/100\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.0913 - accuracy: 1.0000\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 0.0910 - accuracy: 1.0000 - val_loss: 0.0863 - val_accuracy: 1.0000\n",
            "Epoch 45/100\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.0888 - accuracy: 1.0000\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 0.0887 - accuracy: 1.0000 - val_loss: 0.0843 - val_accuracy: 1.0000\n",
            "Epoch 46/100\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.0879 - accuracy: 1.0000\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 0.0881 - accuracy: 1.0000 - val_loss: 0.0829 - val_accuracy: 1.0000\n",
            "Epoch 47/100\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0879 - accuracy: 0.9978\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 0.0876 - accuracy: 0.9979 - val_loss: 0.0799 - val_accuracy: 1.0000\n",
            "Epoch 48/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0848 - accuracy: 1.0000\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 0.0848 - accuracy: 1.0000 - val_loss: 0.0803 - val_accuracy: 1.0000\n",
            "Epoch 49/100\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.0819 - accuracy: 1.0000\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 19ms/step - loss: 0.0817 - accuracy: 1.0000 - val_loss: 0.0768 - val_accuracy: 1.0000\n",
            "Epoch 50/100\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.0814 - accuracy: 0.9979\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 19ms/step - loss: 0.0813 - accuracy: 0.9979 - val_loss: 0.0859 - val_accuracy: 1.0000\n",
            "Epoch 51/100\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.0824 - accuracy: 1.0000\n",
            "Epoch 51: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 0.0823 - accuracy: 1.0000 - val_loss: 0.0757 - val_accuracy: 1.0000\n",
            "Epoch 52/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0828 - accuracy: 0.9979\n",
            "Epoch 52: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.0828 - accuracy: 0.9979 - val_loss: 0.0767 - val_accuracy: 1.0000\n",
            "Epoch 53/100\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.0882 - accuracy: 0.9958\n",
            "Epoch 53: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 0.0881 - accuracy: 0.9959 - val_loss: 0.0780 - val_accuracy: 1.0000\n",
            "Epoch 54/100\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.0798 - accuracy: 1.0000\n",
            "Epoch 54: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 0.0802 - accuracy: 1.0000 - val_loss: 0.0737 - val_accuracy: 1.0000\n",
            "Epoch 55/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0756 - accuracy: 1.0000\n",
            "Epoch 55: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 0.0756 - accuracy: 1.0000 - val_loss: 0.0724 - val_accuracy: 1.0000\n",
            "Epoch 56/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0749 - accuracy: 1.0000\n",
            "Epoch 56: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 0.0749 - accuracy: 1.0000 - val_loss: 0.0715 - val_accuracy: 1.0000\n",
            "Epoch 57/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0728 - accuracy: 1.0000\n",
            "Epoch 57: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 19ms/step - loss: 0.0728 - accuracy: 1.0000 - val_loss: 0.0702 - val_accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0713 - accuracy: 1.0000\n",
            "Epoch 58: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 0.0713 - accuracy: 1.0000 - val_loss: 0.0693 - val_accuracy: 1.0000\n",
            "Epoch 59/100\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0722 - accuracy: 1.0000\n",
            "Epoch 59: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 0.0720 - accuracy: 1.0000 - val_loss: 0.0687 - val_accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0707 - accuracy: 1.0000\n",
            "Epoch 60: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 0.0721 - accuracy: 1.0000 - val_loss: 0.0676 - val_accuracy: 1.0000\n",
            "Epoch 61/100\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.0751 - accuracy: 0.9979\n",
            "Epoch 61: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 0.0764 - accuracy: 0.9979 - val_loss: 0.0742 - val_accuracy: 1.0000\n",
            "Epoch 62/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0703 - accuracy: 1.0000\n",
            "Epoch 62: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 0.0703 - accuracy: 1.0000 - val_loss: 0.0672 - val_accuracy: 1.0000\n",
            "Epoch 63/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0739 - accuracy: 1.0000\n",
            "Epoch 63: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 19ms/step - loss: 0.0739 - accuracy: 1.0000 - val_loss: 0.0683 - val_accuracy: 1.0000\n",
            "Epoch 64/100\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.0676 - accuracy: 1.0000\n",
            "Epoch 64: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 0.0675 - accuracy: 1.0000 - val_loss: 0.0659 - val_accuracy: 1.0000\n",
            "Epoch 65/100\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.0669 - accuracy: 1.0000\n",
            "Epoch 65: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 0.0669 - accuracy: 1.0000 - val_loss: 0.0652 - val_accuracy: 1.0000\n",
            "Epoch 66/100\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.0659 - accuracy: 1.0000\n",
            "Epoch 66: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 0.0659 - accuracy: 1.0000 - val_loss: 0.0644 - val_accuracy: 1.0000\n",
            "Epoch 67/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0666 - accuracy: 1.0000\n",
            "Epoch 67: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 0.0666 - accuracy: 1.0000 - val_loss: 0.0641 - val_accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0656 - accuracy: 1.0000\n",
            "Epoch 68: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 0.0656 - accuracy: 1.0000 - val_loss: 0.0637 - val_accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0662 - accuracy: 1.0000\n",
            "Epoch 69: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.0662 - accuracy: 1.0000 - val_loss: 0.0642 - val_accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.0645 - accuracy: 1.0000\n",
            "Epoch 70: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.0646 - accuracy: 1.0000 - val_loss: 0.0630 - val_accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0635 - accuracy: 1.0000\n",
            "Epoch 71: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.0635 - accuracy: 1.0000 - val_loss: 0.0629 - val_accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0619 - accuracy: 1.0000\n",
            "Epoch 72: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.0619 - accuracy: 1.0000 - val_loss: 0.0615 - val_accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0618 - accuracy: 1.0000\n",
            "Epoch 73: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.0618 - accuracy: 1.0000 - val_loss: 0.0610 - val_accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0614 - accuracy: 1.0000\n",
            "Epoch 74: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.0614 - accuracy: 1.0000 - val_loss: 0.0608 - val_accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0606 - accuracy: 1.0000\n",
            "Epoch 75: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.0606 - accuracy: 1.0000 - val_loss: 0.0600 - val_accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0605 - accuracy: 1.0000\n",
            "Epoch 76: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.0605 - accuracy: 1.0000 - val_loss: 0.0598 - val_accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0638 - accuracy: 1.0000\n",
            "Epoch 77: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.0638 - accuracy: 1.0000 - val_loss: 0.0609 - val_accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0595 - accuracy: 1.0000\n",
            "Epoch 78: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 0.0595 - accuracy: 1.0000 - val_loss: 0.0589 - val_accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0603 - accuracy: 1.0000\n",
            "Epoch 79: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 0.0603 - accuracy: 1.0000 - val_loss: 0.0584 - val_accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0586 - accuracy: 1.0000\n",
            "Epoch 80: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 0.0586 - accuracy: 1.0000 - val_loss: 0.0582 - val_accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0577 - accuracy: 1.0000\n",
            "Epoch 81: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 0.0577 - accuracy: 1.0000 - val_loss: 0.0569 - val_accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0574 - accuracy: 1.0000\n",
            "Epoch 82: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 0.0574 - accuracy: 1.0000 - val_loss: 0.0564 - val_accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0563 - accuracy: 1.0000\n",
            "Epoch 83: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 0.0563 - accuracy: 1.0000 - val_loss: 0.0559 - val_accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0563 - accuracy: 1.0000\n",
            "Epoch 84: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.0563 - accuracy: 1.0000 - val_loss: 0.0555 - val_accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0583 - accuracy: 1.0000\n",
            "Epoch 85: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.0583 - accuracy: 1.0000 - val_loss: 0.0585 - val_accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0610 - accuracy: 1.0000\n",
            "Epoch 86: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.0610 - accuracy: 1.0000 - val_loss: 0.0571 - val_accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0557 - accuracy: 1.0000\n",
            "Epoch 87: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.0557 - accuracy: 1.0000 - val_loss: 0.0547 - val_accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.0552 - accuracy: 1.0000\n",
            "Epoch 88: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.0551 - accuracy: 1.0000 - val_loss: 0.0544 - val_accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0545 - accuracy: 1.0000\n",
            "Epoch 89: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.0545 - accuracy: 1.0000 - val_loss: 0.0542 - val_accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0541 - accuracy: 1.0000\n",
            "Epoch 90: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.0541 - accuracy: 1.0000 - val_loss: 0.0533 - val_accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0539 - accuracy: 1.0000\n",
            "Epoch 91: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.0539 - accuracy: 1.0000 - val_loss: 0.0532 - val_accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0529 - accuracy: 1.0000\n",
            "Epoch 92: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.0529 - accuracy: 1.0000 - val_loss: 0.0526 - val_accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0530 - accuracy: 1.0000\n",
            "Epoch 93: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.0530 - accuracy: 1.0000 - val_loss: 0.0543 - val_accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0619 - accuracy: 0.9979\n",
            "Epoch 94: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.0619 - accuracy: 0.9979 - val_loss: 0.0558 - val_accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0587 - accuracy: 0.9979\n",
            "Epoch 95: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.0587 - accuracy: 0.9979 - val_loss: 0.0564 - val_accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0542 - accuracy: 1.0000\n",
            "Epoch 96: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.0542 - accuracy: 1.0000 - val_loss: 0.0530 - val_accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0525 - accuracy: 1.0000\n",
            "Epoch 97: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 0.0525 - accuracy: 1.0000 - val_loss: 0.0521 - val_accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0519 - accuracy: 1.0000\n",
            "Epoch 98: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 0.0519 - accuracy: 1.0000 - val_loss: 0.0516 - val_accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0516 - accuracy: 1.0000\n",
            "Epoch 99: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 0.0516 - accuracy: 1.0000 - val_loss: 0.0512 - val_accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0510 - accuracy: 1.0000\n",
            "Epoch 100: val_accuracy did not improve from 1.00000\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 0.0510 - accuracy: 1.0000 - val_loss: 0.0506 - val_accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "########################################\n",
        "# Training the model now (Underhang)\n",
        "########################################\n",
        "import tensorflow as tf\n",
        "\n",
        "checkpoint_filepath = '/content/drive/MyDrive/best_model.hdf5'\n",
        "save_best_model = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath = checkpoint_filepath,\n",
        "    monitor=\"val_accuracy\",\n",
        "    verbose=1,\n",
        "    save_best_only=True,\n",
        "    mode=\"auto\",\n",
        "    save_freq=\"epoch\",\n",
        "    options=None,\n",
        "    initial_value_threshold=None\n",
        ")\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(\n",
        "    learning_rate= 0.0001,\n",
        "    beta_1=0.9,\n",
        "    beta_2=0.999,\n",
        "    epsilon=1e-07,\n",
        "    amsgrad=False,\n",
        "    name=\"Adam\"\n",
        "  )\n",
        "\n",
        "model2_.compile(loss='CategoricalCrossentropy',\n",
        "              optimizer= opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# train the network\n",
        "output = model2_.fit(X_train, y_train, epochs = 100, batch_size=8,\n",
        "                    validation_data = (X_test , y_test),\n",
        "                    callbacks = [save_best_model])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8jen0OOzfDC"
      },
      "outputs": [],
      "source": [
        "# ######################################################\n",
        "# # Setting the weights for the best model found and saving the model\n",
        "# model2_.load_weights(checkpoint_filepath)\n",
        "# # Guardar el Modelo (Just only once if u are running the network again)\n",
        "# model2_.save('/content/drive/MyDrive/Model_CNN_Binary.h5')\n",
        "\n",
        "######################################################################\n",
        "# Loading model (already trained)\n",
        "model2_ = keras.models.load_model('/content/drive/MyDrive/Model_CNN_Binary.h5')\n",
        "#####################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RI5ECIKWzfDD",
        "outputId": "e14220b6-5086-4fbc-ae8c-f909e0374408"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The minimum loss training found is: 0.051027  and was found in epoch number: 99\n",
            "The minimum loss test found is: 0.050591  and was found in epoch number: 99\n",
            "The maximum accuracy training found is: 100.0 % and was found in epoch number: 11\n",
            "The maximum accuracy test found is: 100.0 % and was found in epoch number: 9\n"
          ]
        }
      ],
      "source": [
        "# Minimum value of cross entropy\n",
        "\n",
        "print(\"The minimum loss training found is:\", round(min(output.history['loss']),6) ,\" and was found in epoch number:\", np.argmin(output.history['loss']))\n",
        "print(\"The minimum loss test found is:\", round(min(output.history['val_loss']),6) ,\" and was found in epoch number:\", np.argmin(output.history['val_loss']))\n",
        "\n",
        "# Maximum accuracy\n",
        "\n",
        "print(\"The maximum accuracy training found is:\", round(100*max(output.history['accuracy']),2) ,\"% and was found in epoch number:\", np.argmax(output.history['accuracy']))\n",
        "print(\"The maximum accuracy test found is:\", round(100*max(output.history['val_accuracy']),2) ,\"% and was found in epoch number:\", np.argmax(output.history['val_accuracy']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        },
        "id": "3eInN7JezfDD",
        "outputId": "adcc724b-63ca-46cf-f481-405dd8e37b57"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.0, 0.4)"
            ]
          },
          "execution_count": 255,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x720 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plotting loss and val_loss vs epochs\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20,10))\n",
        "fig.suptitle('History Epochs - Loss')\n",
        "\n",
        "ax1.plot(range(100),output.history['loss'],output.history['val_loss'])\n",
        "ax1.set(ylabel= \"Loss\", xlabel = \"epochs\")\n",
        "ax1.legend([\"Training\", \"Validation\"],loc = \"best\")\n",
        "ax1.set_ylim([0, 0.5])\n",
        "\n",
        "ax2.plot(range(100),output.history['loss'],output.history['val_loss'])\n",
        "ax2.set(ylabel= \"Loss\", xlabel = \"epochs\")\n",
        "ax2.legend([\"Training\", \"Validation\"],loc = \"best\")\n",
        "ax2.set_xlim([20,100])\n",
        "ax2.set_ylim([0, 0.4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        },
        "id": "FAjCQQpqzfDD",
        "outputId": "4b7d44de-88d2-4a30-8e64-cba07ed1e67f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.94, 1.02)"
            ]
          },
          "execution_count": 256,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x720 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plotting accuracy and val_accuracy vs epochs\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20,10))\n",
        "fig.suptitle('History Epochs - Accuracy')\n",
        "\n",
        "ax1.plot(range(100),output.history['accuracy'],output.history['val_accuracy'])\n",
        "ax1.set(ylabel= \"Loss\", xlabel = \"epochs\")\n",
        "ax1.legend([\"Training\", \"Validation\"],loc = \"best\")\n",
        "ax1.set_ylim([0.7, 1.05])\n",
        "\n",
        "ax2.plot(range(100),output.history['accuracy'],output.history['val_accuracy'])\n",
        "ax2.set(ylabel= \"Loss\", xlabel = \"epochs\")\n",
        "ax2.legend([\"Training\", \"Validation\"],loc = \"best\")\n",
        "ax2.set_xlim([20,100])\n",
        "ax2.set_ylim([0.94, 1.02])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c57AtryrzfDD",
        "outputId": "4b7a2c7d-cf6d-4705-b403-09351a517ed5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 1s 71ms/step - loss: 0.2588 - accuracy: 1.0000\n",
            "\n",
            "Test accuracy: 100.0%\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2624 - accuracy: 1.0000\n",
            "\\Train accuracy: 100.0%\n"
          ]
        }
      ],
      "source": [
        "_, acc = model2_.evaluate(X_test,\n",
        "                        y_test,\n",
        "                        batch_size=32)\n",
        "print(\"\\nTest accuracy: %.1f%%\" % (100.0 * acc))\n",
        "\n",
        "_, acc = model2_.evaluate(X_train,\n",
        "                        y_train,\n",
        "                        batch_size=32)\n",
        "print(\"\\Train accuracy: %.1f%%\" % (100.0 * acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 841
        },
        "id": "At2_aV1ZzfDD",
        "outputId": "7e2cca98-413d-4816-9fff-0b0a36b5d818"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Text(0, 0.5, 'Normal'),\n",
              " Text(0, 1.5, 'Cage Fault'),\n",
              " Text(0, 2.5, 'Outer Race'),\n",
              " Text(0, 3.5, 'Ball Fault')]"
            ]
          },
          "execution_count": 271,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x864 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# COnfusion matrix resulting\n",
        "\n",
        "y_pred = model2_.predict(X_test)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "underhang_y_test_cm = np.argmax(y_test, axis = -1)\n",
        "matrix = confusion_matrix(underhang_y_test_cm, y_pred)\n",
        "\n",
        "figure = plt.figure(figsize = (12,12))\n",
        "\n",
        "ax = sns.heatmap(matrix, annot=True, cmap='Blues',fmt = 'g')\n",
        "\n",
        "ax.set_title('Underhang Test - Confusion Matrix\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted Values')\n",
        "ax.set_ylabel('Actual Values ');\n",
        "\n",
        "## Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels(['Normal','Cage Fault','Outer Race', 'Ball Fault'])\n",
        "ax.yaxis.set_ticklabels(['Normal','Cage Fault','Outer Race', 'Ball Fault'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apriq6DMzfDD",
        "outputId": "9a3e7a9a-4092-4fb3-ac05-97352edb4fed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The accuracy for class Normal is: 100.0 % =  10 / 10\n",
            "The accuracy for class Cage Fault is: 100.0 % =  38 / 38\n",
            "The accuracy for class Outer Race is: 100.0 % =  37 / 37\n",
            "The accuracy for class Ball Fault is: 100.0 % =  37 / 37\n"
          ]
        }
      ],
      "source": [
        "# Accuracy per class\n",
        "names = ['Normal','Cage Fault','Outer Race', 'Ball Fault']\n",
        "\n",
        "for i in range(4):\n",
        "  ac =0\n",
        "  tot = 0\n",
        "  for j in range(4):\n",
        "    if i == j:\n",
        "      ac += matrix[i][j]\n",
        "      tot += matrix[i][j]\n",
        "    else:\n",
        "      tot += matrix[i][j]\n",
        "\n",
        "  print(\"The accuracy for class\", names[i], 'is:', round(100*ac/tot, 2), '% = ', ac, '/', tot)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tv_XQ-rAzfDE"
      },
      "source": [
        "### Explainability using Grad - CAM techniques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6hlmEF4zfDE"
      },
      "outputs": [],
      "source": [
        "# Needed for visualization\n",
        "\n",
        "layer_name = \"conv1d_29\"\n",
        "cnt = 0\n",
        "xticks = [int(xf[i]) for i in range(0, input_size, 749)]\n",
        "ticks = [i for i in range(0, input_size, 749)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dpnxXb7izfDE"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "################################################################\n",
        "# Training + Test\n",
        "################################################################\n",
        "\n",
        "X = np.moveaxis(new_sig_bin, 0, -1)\n",
        "y = to_categorical(underhang_y)\n",
        "average_spectrum(X, y, 'Tran_Test_Binary',model2_ = model2_,  Binary = False)\n",
        "average_heatmap(X, y, 'Train_Test_Binary',model2_ = model2_,  Binary = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBqc-Si0zfDF"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "################################################################\n",
        "# Training\n",
        "################################################################\n",
        "\n",
        "average_heatmap(X_train, y_train, 'Train_Binary',model2_ = model2_,  Binary = False)\n",
        "average_spectrum(X_train, y_train, 'Train_Binary',model2_ = model2_,  Binary = False)\n",
        "\n",
        "################################################################\n",
        "# Test\n",
        "################################################################\n",
        "\n",
        "average_heatmap(X_test, y_test, 'Test_Binary',model2_ = model2_,  Binary = False)\n",
        "average_spectrum(X_test, y_test, 'Test_Binary',model2_ = model2_,  Binary = False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "NxRdusiZC2Cf",
        "oMdf-7JH9cSH",
        "sgDyfwXHSBRm",
        "bpMFMzXifFsd",
        "4vQ87KTo29_9",
        "cSgt0pjdAFBg",
        "isjkxd8wxXgT",
        "jS-xyUq8xXgZ",
        "QF_HoiJWxXga",
        "kiLvLmhY93Qp",
        "nWXVYHl893Qx",
        "K1OhKKF093Qx",
        "hH5Y3W6h93Qy",
        "H5GSTknL-02z",
        "X-tL0gV5-027",
        "uItHHqaN-028",
        "B1zTBXqV-029",
        "gJagjjyw-8TA",
        "uyocHdZI-8TB",
        "WnZaxTCT-8TC",
        "KBmoQuLg-8TE",
        "DhUVA95CwPGd",
        "7DAwRM5IR2vM",
        "XVtpbavWqs8I",
        "I23Ysdv7nSyK",
        "liyXIyH0v656",
        "D_gYKFT_xRVn",
        "Tv_XQ-rAzfDE"
      ],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}